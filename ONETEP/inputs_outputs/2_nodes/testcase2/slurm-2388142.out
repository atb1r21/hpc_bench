Running SLURM prolog script on red373.cluster.local
===============================================================================
Job started on Wed Jan 11 15:08:38 GMT 2023
Job ID          : 2388142
Job name        : test
WorkDir         : /mainfs/home/hpc/benchmarks-2022/ONETEP/data_input/testcase2
Command         : /mainfs/home/hpc/benchmarks-2022/ONETEP/data_input/testcase2/jobsubmit.iridis5.2021
Partition       : batch
Num hosts       : 2
Num cores       : 80
Num of tasks    : 4
Hosts allocated : red[373-374]
Job Output Follows ...
===============================================================================
Loading compiler version 2021.2.0
Loading mkl version 2021.2.0
Loading mpi version 2021.2.0
--- This is the submission script, the time is Wed Jan 11 15:08:39 GMT 2023.
--- ONETEP executable is '/home/hpc/benchmarks-2022/ONETEP/source/bin/onetep.iridis5.intel21.omp.scalapack'.
--- workdir is '/home/hpc/benchmarks-2022/ONETEP/data_input/testcase2'.
--- onetep_launcher is '/home/hpc/benchmarks-2022//ONETEP/source/utils/onetep_launcher'.
--- The input file is sc05_protonated_shifted.dat, the output goes to sc05_protonated_shifted.out and errors go to sc05_protonated_shifted.err.
--- Number of nodes as reported by SLURM: 2.
--- Number of tasks as reported by SLURM: 4.
--- Using this srun executable: /local/software/slurm/default/bin/srun
--- Executing ONETEP via /home/hpc/benchmarks-2022//ONETEP/source/utils/onetep_launcher.
slurmstepd-red373: error: *** JOB 2388142 ON red373 CANCELLED AT 2023-01-11T17:08:47 DUE TO TIME LIMIT ***
==============================================================================
Running epilogue script on red373.

Submit time  : 2023-01-11T15:08:37
Start time   : 2023-01-11T15:08:37
End time     : 2023-01-11T17:08:47
Elapsed time : 02:00:10 (Timelimit=02:00:00)

Job ID: 2388142
Cluster: i5
User/Group: hpc/jf
State: TIMEOUT (exit code 0)
Nodes: 2
Cores per node: 40
CPU Utilized: 00:00:01
CPU Efficiency: 0.00% of 6-16:13:20 core-walltime
Job Wall-clock time: 02:00:10
Memory Utilized: 223.50 GB (estimated maximum)
Memory Efficiency: 70.64% of 316.41 GB (158.20 GB/node)

