
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Starting with ONETEP &#8212; ONETEP Documentation 6.2.0 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '6.2.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Ground State Calculation Setup" href="index_ground_state.html" />
    <link rel="prev" title="Welcome to ONETEP’s documentation!" href="index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="starting-with-onetep">
<h1>Starting with ONETEP<a class="headerlink" href="#starting-with-onetep" title="Permalink to this headline">¶</a></h1>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Author:</th><td class="field-body">Arihant Bhandari, University of Southampton</td>
</tr>
<tr class="field-even field"><th class="field-name">Author:</th><td class="field-body">Rebecca J. Clements, University of Southampton</td>
</tr>
<tr class="field-odd field"><th class="field-name">Author:</th><td class="field-body">Jacek Dziedzic, University of Southampton</td>
</tr>
<tr class="field-even field"><th class="field-name">Date:</th><td class="field-body">April 2022</td>
</tr>
</tbody>
</table>
<div class="section" id="obtaining-a-copy-of-onetep">
<h2>Obtaining a copy of ONETEP<a class="headerlink" href="#obtaining-a-copy-of-onetep" title="Permalink to this headline">¶</a></h2>
<p>If you are a collaborator of one of the members of the onetep Developers
Group (ODG), you should have received a tarball of a personalised onetep
copy once you have signed an academic licence agreement. Create a new
directory, unpack the tarball there, and you’re done.</p>
<p>If you plan to be a onetep contributor, you will be using the official
onetep Bitbucket repository, located at
<a class="reference external" href="https://bitbucket.org/onetep/onetep">https://bitbucket.org/onetep/onetep</a>. Create a Bitbucket account with
your university email address. Contact your supervisor and ask to be
added to the <code class="docutils literal"><span class="pre">Contributors</span></code> group in the onetep project to get access
to the repository. Read the relevant sections of the <code class="docutils literal"><span class="pre">contributing</span></code>
document, found at
<a class="reference external" href="https://bitbucket.org/onetep/onetep/src/master/CONTRIBUTING.markdown">https://bitbucket.org/onetep/onetep/src/master/CONTRIBUTING.markdown</a>.
Follow the instructions there to create your own private fork of the
main onetep repository. There you will also find details of how to
contribute any developments you make to the onetep code in the future.</p>
<div class="line-block">
<div class="line">Once you have a private fork of onetep on Bitbucket, you can make a
copy of your onetep repository on your local machine, using
<code class="docutils literal"><span class="pre">git</span> <span class="pre">clone</span></code>. Make sure you have <code class="docutils literal"><span class="pre">git</span></code> installed on your computer.
From your chosen directory, use one of the following commands, which
can also be copied from the Bitbucket website, by clicking <em>clone</em> at
the top of your repository webpage:</div>
<div class="line"><code class="docutils literal"><span class="pre">git</span> <span class="pre">clone</span> <span class="pre">https://&lt;username&gt;&#64;bitbucket.org/&lt;username&gt;/&lt;repo-name&gt;.git</span></code></div>
<div class="line-block">
<div class="line">or</div>
</div>
<div class="line"><code class="docutils literal"><span class="pre">git</span> <span class="pre">clone</span> <span class="pre">git&#64;bitbucket.org:&lt;username&gt;/&lt;repo-name&gt;.git</span></code></div>
<div class="line">and type in your Bitbucket (app) password (see next section for more
detail on app passwords). Substitute <code class="docutils literal"><span class="pre">&lt;username&gt;</span></code> and
<code class="docutils literal"><span class="pre">&lt;repo-name&gt;</span></code> in the above commands with your username and the name
of your private fork, respectively.</div>
</div>
</div>
<div class="section" id="bitbucket-app-password">
<h2>Bitbucket app password<a class="headerlink" href="#bitbucket-app-password" title="Permalink to this headline">¶</a></h2>
<p>Starting March 2022 Bitbucket will require you to create an <em>app
password</em> for accessing the repository through <code class="docutils literal"><span class="pre">git</span></code>. This is a
distinct password from the one you use to access the Bitbucket web
interface, it will only be used for accessing the repository through
<code class="docutils literal"><span class="pre">git</span></code> – the two passwords are not interchangeable.</p>
<p>If you haven’t generated an app password for <code class="docutils literal"><span class="pre">git</span></code> yet, follow the
instructions at
<a class="reference external" href="https://support.atlassian.com/bitbucket-cloud/docs/app-passwords">https://support.atlassian.com/bitbucket-cloud/docs/app-passwords</a>, and
the <em>Create an app password</em> section specifically. Read the instructions
carefully. Copy the generated password to a safe place.</p>
<p>Once the password has been generated, use it every time <code class="docutils literal"><span class="pre">git</span></code> prompts
you for a password when you are accessing the onetep Bitbucket
repository. If you find typing or pasting the password cumbersome, go to
your local repository clone and, from the command line, issue the
following command:
| <code class="docutils literal"><span class="pre">git</span> <span class="pre">config</span> <span class="pre">credential.helper</span> <span class="pre">store</span></code>
| The next time you are prompted for a password will be the last time –</p>
<blockquote>
<div><code class="docutils literal"><span class="pre">git</span></code> will store it for you.</div></blockquote>
</div>
<div class="section" id="changes-to-your-copy-of-onetep">
<h2>Changes to your copy of ONETEP<a class="headerlink" href="#changes-to-your-copy-of-onetep" title="Permalink to this headline">¶</a></h2>
<p>Any changes to the code should be made in your local clone. Once you are
satisfied with them, you can commit them, and push them to your private
fork. If you want them to become a part of official onetep, you should
then create a pull request from your private fork to the official
respository. Details are described in the <em>contributing</em> document, under
<em>Creating a pull request</em>.</p>
<p>Whether you are a contributor or a user, you might want to update your
repository with any latest changes that might have occurred in the
official repository. Users might be interested in recent bug fixes or
new functionality, contributors will want to update their copy before
committing any changes of their own. The procedure for keeping your
repository up to date with the official repository is described under
<em>Development within a fork</em> in the <em>contributing</em> document.</p>
</div>
<div class="section" id="compiling-testing-and-running-onetep">
<h2>Compiling, testing and running ONETEP<a class="headerlink" href="#compiling-testing-and-running-onetep" title="Permalink to this headline">¶</a></h2>
<p>Instructions for setting the environment prior to compiling onetep,
instructions on how to compile onetep, how to run quality-check (“QC”)
tests that will give you confidence in the robustness of your
installation are provided separately – look in the <code class="docutils literal"><span class="pre">hpc_resources</span></code>
directory of your onetep installation. There you will also find
instructions on how to submit jobs on specific HPC facilities.</p>
</div>
<div class="section" id="creating-input-files">
<h2>Creating input files<a class="headerlink" href="#creating-input-files" title="Permalink to this headline">¶</a></h2>
<p>Go to onetep’s website, <a class="reference external" href="onetep.org">onetep.org</a>. Here you will
find the <em>Tutorials</em> section, which introduces running various kinds of
onetep calculations. Take a look at some of the input files at the
bottom of the page. Input files in onetep have the <code class="docutils literal"><span class="pre">.dat</span></code> file
extension. Should any files get downloaded having a <code class="docutils literal"><span class="pre">.txt</span></code> extension,
you will need to rename them to end with <code class="docutils literal"><span class="pre">.dat</span></code>.</p>
<p>Input files contain keywords, instructing onetep on what calculations to
run, and to set the parameters needed to run them. Check out the
keywords on the webpage
<a class="reference external" href="onetep.org/Main/Keywords">onetep.org/Main/Keywords</a> to see what they
mean. If not specified, most of them have default settings, as listed on
the webpage.</p>
<div class="line-block">
<div class="line">The keywords come in different types: <code class="docutils literal"><span class="pre">logical</span></code>, <code class="docutils literal"><span class="pre">integer</span></code>,
<code class="docutils literal"><span class="pre">real</span></code>, <code class="docutils literal"><span class="pre">text</span></code>, <code class="docutils literal"><span class="pre">physical</span></code> and <code class="docutils literal"><span class="pre">block</span></code>. Keywords of the type
<code class="docutils literal"><span class="pre">logical</span></code> can have a value of <code class="docutils literal"><span class="pre">T</span></code> (true) or <code class="docutils literal"><span class="pre">F</span></code> (false).
Keywords that are <code class="docutils literal"><span class="pre">integer</span></code> and <code class="docutils literal"><span class="pre">real</span></code> are numbers. Keywords of
type <code class="docutils literal"><span class="pre">text</span></code> are a string of characters (for example a filename).
Keywords of the type <code class="docutils literal"><span class="pre">physical</span></code> refer to physical variables, which
come with units such as angstroem, bohr, joule, hartree, etc. A
<code class="docutils literal"><span class="pre">block</span></code> indicates more than one line of input, these are often used
for specifying coordinates.</div>
<div class="line">Some of the important keywords to get started are:</div>
</div>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">task</span></code> – to choose what main calculation you would like onetep to
perform, e.g. a single point energy calculation or geometry
optimisation. You can run a properties calculation this way, using
output files generated from a single point energy calculation or
using <code class="docutils literal"><span class="pre">task</span> <span class="pre">singlepoint</span></code> and a separate keyword <code class="docutils literal"><span class="pre">do_properties</span></code>
set to <code class="docutils literal"><span class="pre">T</span></code>.</li>
<li><code class="docutils literal"><span class="pre">xc_functional</span></code> – to choose how to approximate the
exchange-correlation term in the Kohn Sham DFT energy expression.</li>
<li><code class="docutils literal"><span class="pre">%block</span> <span class="pre">lattice_cart</span></code> – to define the dimensions of the simulation
cell.</li>
<li><code class="docutils literal"><span class="pre">%block</span> <span class="pre">positions_abs</span></code> – to define the atomic positions in
Cartesian coordinates.</li>
</ul>
<p>As can be seen from the example input files, all <code class="docutils literal"><span class="pre">block</span></code> keywords must
end with a corresponding <code class="docutils literal"><span class="pre">endblock</span></code>. Be default all coordinates are in
atomic units (bohr). To switch to angstroems, add <code class="docutils literal"><span class="pre">ang</span></code> in the first
line of the block:</p>
<div class="line-block">
<div class="line"><code class="docutils literal"><span class="pre">%block</span> <span class="pre">positions_abs</span></code></div>
<div class="line"><code class="docutils literal"><span class="pre">ang</span></code></div>
<div class="line"><code class="docutils literal"><span class="pre">C</span> <span class="pre">16.521413</span> <span class="pre">15.320039</span> <span class="pre">23.535776</span></code></div>
<div class="line"><code class="docutils literal"><span class="pre">O</span> <span class="pre">16.498729</span> <span class="pre">15.308934</span> <span class="pre">24.717249</span></code></div>
<div class="line">…</div>
<div class="line"><code class="docutils literal"><span class="pre">%endblock</span> <span class="pre">positions_abs</span></code></div>
</div>
<p>The <code class="docutils literal"><span class="pre">species</span></code> and <code class="docutils literal"><span class="pre">species_pot</span></code> blocks detail the parameters of the
atoms. Non-orthogonal Generalised Wannier Functions (NGWFs) are used to
model the atomic orbitals. In the <code class="docutils literal"><span class="pre">species</span></code> block, the name we give to
each type atom in the system is given first, followed by the element of
the atom, its atomic number, the number of NGWFs to use (use -1 for an
educated guess) and the radius of each NGWF typically around 8.0-10.0
(in bohr) for an accurate calculation. For instance for carbon you might
use:</p>
<p><code class="docutils literal"><span class="pre">C</span> <span class="pre">C</span> <span class="pre">6</span> <span class="pre">4</span> <span class="pre">8.0</span></code></p>
<p>The <code class="docutils literal"><span class="pre">species_pot</span></code> block specifies the location of the pseudopotential
used for each element of the system. The standard onetep norm-conserving
pseudopotentials (<code class="docutils literal"><span class="pre">.recpot</span></code> files) exclude core electrons. Core
electrons are included in <code class="docutils literal"><span class="pre">.paw</span></code> files. Some of these can be found in
your repository’s <code class="docutils literal"><span class="pre">pseudo</span></code> directory. A complete database of all
pseudopotentials for all elements in the <code class="docutils literal"><span class="pre">.paw</span></code> format can be
downloaded from
<a class="reference external" href="https://www.physics.rutgers.edu/gbrv/all_pbe_paw_v1.5.tar.gz">https://www.physics.rutgers.edu/gbrv/all_pbe_paw_v1.5.tar.gz</a></p>
<div class="line-block">
<div class="line">To continue a calculation if it has run out of computation time, use
the keywords below. The original input must have the <code class="docutils literal"><span class="pre">write</span></code>
keywords, but no <code class="docutils literal"><span class="pre">read</span></code> keywords because the files aren’t available
to read at this stage. Any continuing input files must include the
<code class="docutils literal"><span class="pre">read</span></code> keywords. If the input file name isn’t changed upon
continuation, the output file will be overwrite with the results of
the continuation, so make sure to back up files before continuing.</div>
<div class="line"><code class="docutils literal"><span class="pre">write_denskern</span> <span class="pre">T</span></code></div>
<div class="line"><code class="docutils literal"><span class="pre">write_tightbox_ngwfs</span> <span class="pre">T</span></code></div>
<div class="line"><code class="docutils literal"><span class="pre">read_denskern</span> <span class="pre">T</span></code></div>
<div class="line"><code class="docutils literal"><span class="pre">read_tightbox_ngwfs</span> <span class="pre">T</span></code></div>
<div class="line">If you are running an ensemble DFT (EDFT) calculation you will also
need to add</div>
<div class="line"><code class="docutils literal"><span class="pre">write_hamiltonian</span> <span class="pre">T</span></code></div>
<div class="line"><code class="docutils literal"><span class="pre">read_hamiltonian</span> <span class="pre">T</span></code></div>
<div class="line">to the above list.</div>
</div>
</div>
<div class="section" id="running-onetep-in-parallel-environments">
<h2>Running ONETEP in parallel environments<a class="headerlink" href="#running-onetep-in-parallel-environments" title="Permalink to this headline">¶</a></h2>
<p>onetep is typically run on more than one CPU core – whether on a desktop
computer, or at a high-performance computing (HPC) facility. This is
termed <em>parallel operation</em>. There are two main modes of parallel
operation – <em>distributed-memory</em> computing (sometimes termed simply
<em>parallelism</em>), and <em>shared-memory</em> computing (sometimes termed
<em>concurrency</em>). onetep combines both of them, so it will be crucial to
understand how they work.</p>
<div class="section" id="distributed-memory-parallelism-mpi">
<h3>Distributed-memory parallelism (MPI)<a class="headerlink" href="#distributed-memory-parallelism-mpi" title="Permalink to this headline">¶</a></h3>
<p>In this scenario a collection of individual <em>processes</em> (that is,
running instances of a program) work together on the same calculation.
The processes can all reside on the same physical machine (often termed
<em>node</em>) – e.g. when you run them on your many-core desktop machine – or
on separate machines (nodes) – e.g. when you run them at an HPC
facility.</p>
<p>In both cases processes reside in separate memory spaces, which is a
fancy way of saying they <em>do not share</em> memory – each of them gets a
chunk of memory and they don’t know what the other processes have in
their chunks. Yes, even when they are on the same machine.</p>
<p>The problem they work on has to be somehow subdivided between them –
this is known as <em>parallel decomposition</em>. One common way of doing that
– and one that onetep employs – is <em>data decomposition</em>, where it’s the
data in the problem that is subdivided across processes. In onetep the
grids on which quantities like electronic density or external potential
are calculated are divided across processes, with each process “owning”
a slab of the grid. Similarly, the atoms in the system are divided
across processes, with each process “owning” a subset of atoms. Both of
these concepts are illustrated in <a class="reference internal" href="#mpi"><span class="std std-numref">Fig. 1</span></a>.</p>
<div class="figure" id="id3">
<span id="mpi"></span><img alt="Illustration of parallel data decomposition in onetep. Figure borrowed from J. Chem. Phys. \ **122**, 084119 (2005), https://doi.org/10.1063/1.1839852, which you are well-advised to read." src="_images/starting_with_onetep_fig1.png" />
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text">Illustration of parallel data decomposition in onetep. Figure borrowed from J. Chem. Phys. <strong>122</strong>, 084119 (2005), <a class="reference external" href="https://doi.org/10.1063/1.1839852">https://doi.org/10.1063/1.1839852</a>, which you are well-advised to read.</span></p>
</div>
<p>From the point of view of the operating system, the processes running on
a machine are separate entities (see <a class="reference internal" href="#processes"><span class="std std-numref">Fig. 2</span></a>), and
collaboration between them almost always necessitates some form of
communication (because, remember, they do not share memory) – e.g.
process #1 may need to ask process #2 “what are the positions of <em>your</em>
atoms?” This is accomplished by a dedicated software library known as
Message Passing Interface (MPI). This is why we often call the processes
<em>MPI processes</em>, or, more technically, <em>MPI ranks</em>.</p>
<div class="figure" id="id4">
<span id="processes"></span><img alt="Four onetep processes running on one machine, each utilising 100% of a CPU core and 0.4% of available memory." src="_images/starting_with_onetep_fig2.png" />
<p class="caption"><span class="caption-number">Fig. 2 </span><span class="caption-text">Four onetep processes running on one machine, each utilising 100% of a CPU core and 0.4% of available memory.</span></p>
</div>
<p>MPI facilitates starting multiple processes as part of a single
calculation, which can become slightly tricky when there are multiple
machines (nodes) involved. Your MPI installation will provide a
dedicated command for running multiple processes. The command is often
called <code class="docutils literal"><span class="pre">mpirun</span></code>, <code class="docutils literal"><span class="pre">aprun</span></code>, <code class="docutils literal"><span class="pre">gerun</span></code>, <code class="docutils literal"><span class="pre">srun</span></code> or something similar
(it will certainly be stated in the documentation for your system). On a
desktop machine its invocation typically looks like this:</p>
<p><code class="docutils literal"><span class="pre">mpirun</span> <span class="pre">-np</span> <span class="pre">4</span> <span class="pre">./onetep_launcher</span> <span class="pre">input.dat</span> <span class="pre">&gt;input.out</span> <span class="pre">2&gt;input.err</span></code></p>
<p>Here, <code class="docutils literal"><span class="pre">mpirun</span></code> is the name of the command for launching multiple
processes, asks for four processes, <code class="docutils literal"><span class="pre">onetep_launcher</span></code> is the name of
the script for launching onetep – it’s the script that will actually be
run on four CPU cores, and each instance will start one onetep process
for you – here we assume it’s in the current directory (<code class="docutils literal"><span class="pre">./</span></code>),
<code class="docutils literal"><span class="pre">input.dat</span></code> is your onetep input file. Output will be sent
(“redirected”) to <code class="docutils literal"><span class="pre">onetep.out</span></code>, and error messages (if any), will be
redirected to <code class="docutils literal"><span class="pre">input.err</span></code>. All four processes will be started on the
same machine.</p>
<p>In HPC environments the syntax will be slightly different, because the
number of processes will be automatically inferred by the batch
(queueing) system, the batch system will also take care of instructing
<code class="docutils literal"><span class="pre">mpirun</span></code> (or equivalent) what machines to put the processes on.</p>
<p>MPI lets you run your calculation on as many processes as you like –
even tens of thousands. However, there are practical limitations to how
far you can go with onetep. Looking at <a class="reference internal" href="#mpi"><span class="std std-numref">Fig. 1</span></a> it becomes clear
that you cannot have more MPI processes than atoms – or some processes
would be left without work to do. In fact this limitation is even
slightly stricter – to divide work more evenly onetep tries to give each
processes a similar number of NGWFs, not atoms. For instance, for a
water molecule run on two processes, it makes sense to assign the O atom
and its 4 NGWFs to one process, and both H atoms (1 NGWF each) to the
second process. If you try to run a calculation on on <em>three</em> processes,
it’s very likely that onetep will do the same thing – assign O to one
processes, both H’s to another process and the third process will wind
up with no atoms. This will cause the calculation to abort. So, one
limitation is <strong>you will not be able to use more MPI processes that you
have atoms in your system, and even slightly smaller numbers of MPI
processes might not work</strong>. Even if they do, you don’t really want that,
because load balancing will be rather poor – the processor that gets the
O atom has roughly twice as much work to do as the one that gets the two
H atoms. The bottom line is – <em>you should have at least several atoms
per MPI rank</em> – in the interest of efficiency.</p>
</div>
<div class="section" id="shared-memory-parallelism-omp">
<h3>Shared-memory parallelism (OMP)<a class="headerlink" href="#shared-memory-parallelism-omp" title="Permalink to this headline">¶</a></h3>
<p>This approach, sometimes known as <em>concurrency</em>, <em>concurrent processing</em>
or colloquially as <em>threads</em>, uses <em>shared memory</em>. The way it works is
a process <em>spawns</em> (starts) a number of <em>threads of execution</em>, with
each thread delegated to a separate CPU core. Typically each thread
works with a subset of data, and, in contrast to processes, threads
within the same process can access each other’s memory. For example, if
a process was given 50 atoms to work with, it can spawn 4 threads and
tell each thread to work on 12-13 atoms. Because threads share memory,
they do not need special mechanisms to communicate – they can just use
memory for this. What they need instead are special mechanisms for
synchronisation – e.g. so that thread 1 knows thread 2 finished writing
something to memory and it’s safe to try to read it. These mechanisms
are described by a standard known as <code class="docutils literal"><span class="pre">OpenMP</span></code>, or <code class="docutils literal"><span class="pre">OMP</span></code> for short.</p>
<p>In onetep threads are most conveniently handled using the launcher’s
<code class="docutils literal"><span class="pre">-t</span></code> option, which instructs it how many threads each process should
spawn. For instance the command</p>
<p><code class="docutils literal"><span class="pre">./onetep_launcher</span> <span class="pre">-t</span> <span class="pre">8</span> <span class="pre">input.dat</span> <span class="pre">&gt;input.out</span> <span class="pre">2&gt;input.err</span></code></p>
<p>runs one process (note the absence of <code class="docutils literal"><span class="pre">mpirun</span></code>), which spawns eight
threads. This is what it looks like to the operating system:</p>
<div class="figure" id="id5">
<img alt="One onetep process that spawned eight threads, running on one machine, utilising almost 800% of a CPU core and 1.3% of available memory – this is for the entire process encompassing eight threads." src="_images/starting_with_onetep_fig3.png" />
<p class="caption"><span class="caption-number">Fig. 3 </span><span class="caption-text">One onetep process that spawned eight threads, running on one machine, utilising almost 800% of a CPU core and 1.3% of available memory – this is for the entire process encompassing eight threads.</span></p>
</div>
<p>Thread-based processing has a number of limitations. As threads reside
within a process, you cannot feasibly run more threads than you have CPU
cores on a node – in other words, threading is limited to a single node.
Moreover, large numbers of threads quickly become inefficient. If a
processes owns 10 atoms, using more than 10 threads will not give you
any advantage, because the additional threads will not have anything to
work with (fortunately, this does not lead to the calculation aborting,
only to some threads idling). Even with four threads you will lose some
efficiency, because some threads will get 3 atoms and some only 2.
onetep works best with about 4-6 threads, unless you are using
Hartree-Fock exchange (HFx), which is the most efficient on large thread
counts.</p>
<p>Threads are easiest to control via <code class="docutils literal"><span class="pre">onetep_launcher</span></code>, which you are
advised to use, but onetep also provides keywords for controlling them
manually – these are <code class="docutils literal"><span class="pre">threads_max</span></code>, <code class="docutils literal"><span class="pre">threads_per_fftbox</span></code>,
<code class="docutils literal"><span class="pre">threads_num_fftboxes</span></code>, <code class="docutils literal"><span class="pre">threads_per_cellfft</span></code> and
<code class="docutils literal"><span class="pre">threads_num_mkl</span></code>. Each of these sets the number of threads spawned
from a single process for some part of onetep’s functionality. This is
advanced stuff and will not be covered in this beginners’ document.</p>
<p>Another point to note is that each thread requires its own <em>stack</em> (a
region of memory for intermediate data) in addition to the global
(per-process) stack. This per-thread stack needs to be large enough –
almost always 64&nbsp;MB suffices. So, if you spawn 16 threads from a
process, that’s an extra 1024&nbsp;MB of memory that you need, per process.
If you use <code class="docutils literal"><span class="pre">onetep_launcher</span></code>, it takes care of setting this stack for
you. If you don’t – you’ll need to take care of this on your own (by
exporting a suitable <code class="docutils literal"><span class="pre">OMP_STACKSIZE</span></code>) or you risk ugly crashes when
the stack runs out. Not recommended.</p>
</div>
<div class="section" id="hybrid-combined-mpi-omp-parallelism">
<h3>Hybrid (combined MPI+OMP) parallelism<a class="headerlink" href="#hybrid-combined-mpi-omp-parallelism" title="Permalink to this headline">¶</a></h3>
<p>For anything but the smallest of systems, combining MPI processes with
OMP threads is the most efficient approach. This is known as <em>hybrid
parallelism</em>. In onetep this is realised simply by combining <code class="docutils literal"><span class="pre">mpirun</span></code>
(or equivalent) with <code class="docutils literal"><span class="pre">onetep_launcher</span></code>’s <code class="docutils literal"><span class="pre">-t</span></code> option, like this:</p>
<p><code class="docutils literal"><span class="pre">mpirun</span> <span class="pre">-np</span> <span class="pre">4</span> <span class="pre">./onetep_launcher</span> <span class="pre">-t</span> <span class="pre">8</span> <span class="pre">input.dat</span> <span class="pre">&gt;input.out</span> <span class="pre">2&gt;input.err</span></code></p>
<p>Here we are starting 4 processes, each of which spawns 8 threads. This
set-up would fully saturate a large, 32-core desktop machine.</p>
<p>Setting up processes and threads looks slightly different in HPC
systems, where you need to start them on separate nodes. Your submission
script (you will find ones for common architectures in the
<code class="docutils literal"><span class="pre">hpc_resources</span></code> directory of your onetep installation) defines all the
parameters at the top of the script and then accordingly invokes
<code class="docutils literal"><span class="pre">mpirun</span></code> (or equivalent) and <code class="docutils literal"><span class="pre">onetep_launcher</span></code>. Look at the
beginning of the script to see what I mean.</p>
</div>
<div class="section" id="how-many-nodes-processes-and-threads-should-i-use">
<h3>How many nodes, processes and threads should I use?<a class="headerlink" href="#how-many-nodes-processes-and-threads-should-i-use" title="Permalink to this headline">¶</a></h3>
<p>There are a few points worth considering here. First of all, efficiency
almost universally decreases with the number of CPU cores assigned to a
problem. That is to say, throwing 100 cores at a problem is likely to
reduce the time to solution by less than 100-fold. This is because of
communication overheads, load imbalance and small sections of the
algorithm that remain sequential, and is formally known as <a class="reference external" href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s
law</a>. It’s worth
keeping this in mind if you have a large number of calculations to
perform (known as <em>task farming</em>) – if you have 1000 calculations to
perform, and have 500 CPU cores at your disposal, time to solution will
be the shortest if you run 500 1-core jobs first, followed by 500 1-core
jobs next. If you opt for running a job on 500 CPU cores simultaneously,
and do this for 1000 jobs in sequence, your time to solution will be
much, much worse, because of efficiency diminishing with the number of
cores.</p>
<p>Having said that, task farming is not the only scenario in the world.
Sometimes you have few jobs, or only one, that you want to run quickly.
Here, you’re not overly worried about efficiency – if running the job on
1 CPU core takes a month, and using 100 CPU cores reduces it to a day,
you’d still take 100 CPU cores, or even more. You just have to remember
that the returns will be diminishing with each CPU core you add <a class="footnote-reference" href="#id2" id="id1">[1]</a>.</p>
<p>The remaining points can be summarised as follows:</p>
<ol class="arabic simple">
<li>Avoid using 1-2 atoms per MPI process, unless there’s no other way.
Try to have at least several atoms per MPI process – for good
load-balancing.</li>
<li>For OMP threads the sweet spot is typically 4-5 threads. If you have
a giant system, so that you have a hundred atoms or more per MPI
process, you might be better off using 2 threads or even 1 (using
purely distributed-memory parallelism). This is because load
balancing will be very good with high numbers of atoms per MPI
process. If you have a small system, or if already using large
numbers of MPI processes, so that you wind up with very few atoms per
MPI process (say, below 5), you might find that using higher numbers
of threads (say, 8) to reduce the number of MPI processes is
beneficial.</li>
<li>Know how many CPU cores you have on a node. Make sure the number of
MPI processes <em>per node</em> and OMP threads per process saturate all the
node’s cores. For instance, if you have 40 CPU cores on a node, you
should aim for 10 processes per node, 4 threads each; or 20 processes
per node, 2 threads each; or 40 processes per node, 1 thread each; or
4 processes per node, 10 threads each. 2 processes per node with 20
threads each would also work, but would likely be suboptimal. Just
don’t do things like 3 processes with 10 threads, because then you
leave 10 CPU cores idle, and don’t do things like 6 processes with 10
threads, because you then oversubscribe the node (meaning you have
more threads than CPU cores) – this degrades performance.</li>
<li>Nodes are often divided internally into <em>NUMA regions</em> – most often
there are two NUMA regions per node. The only thing you need to know
about NUMA regions is that you don’t want a process to span across
them. This is why in the example above you did not see 5 processes
with 8 OMP threads each or 8 processes with 5 OMP threads each – I
assumed there are two NUMA regions with 20 CPU cores each. In both
examples here you would have a process spanning across two NUMA
regions. It works, but is much slower.</li>
<li>Points 1-3 above do not apply to Hartree-Fock exchange calculations.
Point 4 applies. When doing HFx calculations (this includes
calculations with hybrid exchange-correlation functionals, like
B3LYP) follow the more detailed instructions in the HFx manual.</li>
<li>If you find that your calculation is running out of memory, your
first step should be to increase the number of nodes (because it
splits the problem across a set-up with more total RAM). Another idea
is to shift the MPI/OMP balance towards more threads and fewer MPI
processes (because this reduces the number of buffers for
communication between MPI processes). So if your job runs out of
memory on 2 nodes with 10 processes on each and with 4 threads per
process, give it 4 or more nodes with 10 processes on each with 4
threads per each, or switch to 4 processes with 10 OMP threads.</li>
</ol>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>Hartree-Fock exchange calculations being an important exception</td></tr>
</tbody>
</table>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper"><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">Welcome to ONETEP’s documentation!</a></li>
      <li>Next: <a href="index_ground_state.html" title="next chapter">Ground State Calculation Setup</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2022, Joseph Prentice.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.7</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.8</a>
      
      |
      <a href="_sources/starting_with_onetep.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>