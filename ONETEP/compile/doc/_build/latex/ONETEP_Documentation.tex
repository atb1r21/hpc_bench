%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
 \ifdefined\DeclareUnicodeCharacterAsOptional
  \DeclareUnicodeCharacter{"00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{"2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{"2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{"2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{"251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{"2572}{\textbackslash}
 \else
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{2572}{\textbackslash}
 \fi
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage[dontkeepoldnames]{sphinx}

\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}
\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{1}

\usepackage{graphicx,setspace,latexsym,bm}

\title{ONETEP Documentation}
\date{Sep 26, 2022}
\release{6.2.0}
\author{Joseph Prentice}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex

\begin{document}

\maketitle
\sphinxtableofcontents
\phantomsection\label{\detokenize{index::doc}}



\chapter{Starting with ONETEP}
\label{\detokenize{starting_with_onetep:welcome-to-onetep-s-documentation}}\label{\detokenize{starting_with_onetep::doc}}\label{\detokenize{starting_with_onetep:starting-with-onetep}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Arihant Bhandari, University of Southampton

\item[{Author}] \leavevmode
Rebecca J. Clements, University of Southampton

\item[{Author}] \leavevmode
Jacek Dziedzic, University of Southampton

\item[{Date}] \leavevmode
April 2022

\end{description}\end{quote}


\section{Obtaining a copy of ONETEP}
\label{\detokenize{starting_with_onetep:obtaining-a-copy-of-onetep}}
If you are a collaborator of one of the members of the onetep Developers
Group (ODG), you should have received a tarball of a personalised onetep
copy once you have signed an academic licence agreement. Create a new
directory, unpack the tarball there, and you’re done.

If you plan to be a onetep contributor, you will be using the official
onetep Bitbucket repository, located at
\sphinxurl{https://bitbucket.org/onetep/onetep}. Create a Bitbucket account with
your university email address. Contact your supervisor and ask to be
added to the \sphinxcode{Contributors} group in the onetep project to get access
to the repository. Read the relevant sections of the \sphinxcode{contributing}
document, found at
\sphinxurl{https://bitbucket.org/onetep/onetep/src/master/CONTRIBUTING.markdown}.
Follow the instructions there to create your own private fork of the
main onetep repository. There you will also find details of how to
contribute any developments you make to the onetep code in the future.

\begin{DUlineblock}{0em}
\item[] Once you have a private fork of onetep on Bitbucket, you can make a
copy of your onetep repository on your local machine, using
\sphinxcode{git clone}. Make sure you have \sphinxcode{git} installed on your computer.
From your chosen directory, use one of the following commands, which
can also be copied from the Bitbucket website, by clicking \sphinxstyleemphasis{clone} at
the top of your repository webpage:
\item[] \sphinxcode{git clone https://\textless{}username\textgreater{}@bitbucket.org/\textless{}username\textgreater{}/\textless{}repo-name\textgreater{}.git}
\item[]
\begin{DUlineblock}{\DUlineblockindent}
\item[] or
\end{DUlineblock}
\item[] \sphinxcode{git clone git@bitbucket.org:\textless{}username\textgreater{}/\textless{}repo-name\textgreater{}.git}
\item[] and type in your Bitbucket (app) password (see next section for more
detail on app passwords). Substitute \sphinxcode{\textless{}username\textgreater{}} and
\sphinxcode{\textless{}repo-name\textgreater{}} in the above commands with your username and the name
of your private fork, respectively.
\end{DUlineblock}


\section{Bitbucket app password}
\label{\detokenize{starting_with_onetep:bitbucket-app-password}}
Starting March 2022 Bitbucket will require you to create an \sphinxstyleemphasis{app
password} for accessing the repository through \sphinxcode{git}. This is a
distinct password from the one you use to access the Bitbucket web
interface, it will only be used for accessing the repository through
\sphinxcode{git} \textendash{} the two passwords are not interchangeable.

If you haven’t generated an app password for \sphinxcode{git} yet, follow the
instructions at
\sphinxurl{https://support.atlassian.com/bitbucket-cloud/docs/app-passwords}, and
the \sphinxstyleemphasis{Create an app password} section specifically. Read the instructions
carefully. Copy the generated password to a safe place.

Once the password has been generated, use it every time \sphinxcode{git} prompts
you for a password when you are accessing the onetep Bitbucket
repository. If you find typing or pasting the password cumbersome, go to
your local repository clone and, from the command line, issue the
following command:
\textbar{} \sphinxcode{git config credential.helper store}
\textbar{} The next time you are prompted for a password will be the last time \textendash{}
\begin{quote}

\sphinxcode{git} will store it for you.
\end{quote}


\section{Changes to your copy of ONETEP}
\label{\detokenize{starting_with_onetep:changes-to-your-copy-of-onetep}}
Any changes to the code should be made in your local clone. Once you are
satisfied with them, you can commit them, and push them to your private
fork. If you want them to become a part of official onetep, you should
then create a pull request from your private fork to the official
respository. Details are described in the \sphinxstyleemphasis{contributing} document, under
\sphinxstyleemphasis{Creating a pull request}.

Whether you are a contributor or a user, you might want to update your
repository with any latest changes that might have occurred in the
official repository. Users might be interested in recent bug fixes or
new functionality, contributors will want to update their copy before
committing any changes of their own. The procedure for keeping your
repository up to date with the official repository is described under
\sphinxstyleemphasis{Development within a fork} in the \sphinxstyleemphasis{contributing} document.


\section{Compiling, testing and running ONETEP}
\label{\detokenize{starting_with_onetep:compiling-testing-and-running-onetep}}
Instructions for setting the environment prior to compiling onetep,
instructions on how to compile onetep, how to run quality-check (“QC”)
tests that will give you confidence in the robustness of your
installation are provided separately \textendash{} look in the \sphinxcode{hpc\_resources}
directory of your onetep installation. There you will also find
instructions on how to submit jobs on specific HPC facilities.


\section{Creating input files}
\label{\detokenize{starting_with_onetep:creating-input-files}}
Go to onetep’s website, \sphinxurl{onetep.org}. Here you will
find the \sphinxstyleemphasis{Tutorials} section, which introduces running various kinds of
onetep calculations. Take a look at some of the input files at the
bottom of the page. Input files in onetep have the \sphinxcode{.dat} file
extension. Should any files get downloaded having a \sphinxcode{.txt} extension,
you will need to rename them to end with \sphinxcode{.dat}.

Input files contain keywords, instructing onetep on what calculations to
run, and to set the parameters needed to run them. Check out the
keywords on the webpage
\sphinxurl{onetep.org/Main/Keywords} to see what they
mean. If not specified, most of them have default settings, as listed on
the webpage.

\begin{DUlineblock}{0em}
\item[] The keywords come in different types: \sphinxcode{logical}, \sphinxcode{integer},
\sphinxcode{real}, \sphinxcode{text}, \sphinxcode{physical} and \sphinxcode{block}. Keywords of the type
\sphinxcode{logical} can have a value of \sphinxcode{T} (true) or \sphinxcode{F} (false).
Keywords that are \sphinxcode{integer} and \sphinxcode{real} are numbers. Keywords of
type \sphinxcode{text} are a string of characters (for example a filename).
Keywords of the type \sphinxcode{physical} refer to physical variables, which
come with units such as angstroem, bohr, joule, hartree, etc. A
\sphinxcode{block} indicates more than one line of input, these are often used
for specifying coordinates.
\item[] Some of the important keywords to get started are:
\end{DUlineblock}
\begin{itemize}
\item {} 
\sphinxcode{task} \textendash{} to choose what main calculation you would like onetep to
perform, e.g. a single point energy calculation or geometry
optimisation. You can run a properties calculation this way, using
output files generated from a single point energy calculation or
using \sphinxcode{task singlepoint} and a separate keyword \sphinxcode{do\_properties}
set to \sphinxcode{T}.

\item {} 
\sphinxcode{xc\_functional} \textendash{} to choose how to approximate the
exchange-correlation term in the Kohn Sham DFT energy expression.

\item {} 
\sphinxcode{\%block lattice\_cart} \textendash{} to define the dimensions of the simulation
cell.

\item {} 
\sphinxcode{\%block positions\_abs} \textendash{} to define the atomic positions in
Cartesian coordinates.

\end{itemize}

As can be seen from the example input files, all \sphinxcode{block} keywords must
end with a corresponding \sphinxcode{endblock}. Be default all coordinates are in
atomic units (bohr). To switch to angstroems, add \sphinxcode{ang} in the first
line of the block:

\begin{DUlineblock}{0em}
\item[] \sphinxcode{\%block positions\_abs}
\item[] \sphinxcode{ang}
\item[] \sphinxcode{C 16.521413 15.320039 23.535776}
\item[] \sphinxcode{O 16.498729 15.308934 24.717249}
\item[] …
\item[] \sphinxcode{\%endblock positions\_abs}
\end{DUlineblock}

The \sphinxcode{species} and \sphinxcode{species\_pot} blocks detail the parameters of the
atoms. Non-orthogonal Generalised Wannier Functions (NGWFs) are used to
model the atomic orbitals. In the \sphinxcode{species} block, the name we give to
each type atom in the system is given first, followed by the element of
the atom, its atomic number, the number of NGWFs to use (use -1 for an
educated guess) and the radius of each NGWF typically around 8.0-10.0
(in bohr) for an accurate calculation. For instance for carbon you might
use:

\sphinxcode{C C 6 4 8.0}

The \sphinxcode{species\_pot} block specifies the location of the pseudopotential
used for each element of the system. The standard onetep norm-conserving
pseudopotentials (\sphinxcode{.recpot} files) exclude core electrons. Core
electrons are included in \sphinxcode{.paw} files. Some of these can be found in
your repository’s \sphinxcode{pseudo} directory. A complete database of all
pseudopotentials for all elements in the \sphinxcode{.paw} format can be
downloaded from
\sphinxurl{https://www.physics.rutgers.edu/gbrv/all\_pbe\_paw\_v1.5.tar.gz}

\begin{DUlineblock}{0em}
\item[] To continue a calculation if it has run out of computation time, use
the keywords below. The original input must have the \sphinxcode{write}
keywords, but no \sphinxcode{read} keywords because the files aren’t available
to read at this stage. Any continuing input files must include the
\sphinxcode{read} keywords. If the input file name isn’t changed upon
continuation, the output file will be overwrite with the results of
the continuation, so make sure to back up files before continuing.
\item[] \sphinxcode{write\_denskern T}
\item[] \sphinxcode{write\_tightbox\_ngwfs T}
\item[] \sphinxcode{read\_denskern T}
\item[] \sphinxcode{read\_tightbox\_ngwfs T}
\item[] If you are running an ensemble DFT (EDFT) calculation you will also
need to add
\item[] \sphinxcode{write\_hamiltonian T}
\item[] \sphinxcode{read\_hamiltonian T}
\item[] to the above list.
\end{DUlineblock}


\section{Running ONETEP in parallel environments}
\label{\detokenize{starting_with_onetep:running-onetep-in-parallel-environments}}
onetep is typically run on more than one CPU core \textendash{} whether on a desktop
computer, or at a high-performance computing (HPC) facility. This is
termed \sphinxstyleemphasis{parallel operation}. There are two main modes of parallel
operation \textendash{} \sphinxstyleemphasis{distributed-memory} computing (sometimes termed simply
\sphinxstyleemphasis{parallelism}), and \sphinxstyleemphasis{shared-memory} computing (sometimes termed
\sphinxstyleemphasis{concurrency}). onetep combines both of them, so it will be crucial to
understand how they work.


\subsection{Distributed-memory parallelism (MPI)}
\label{\detokenize{starting_with_onetep:distributed-memory-parallelism-mpi}}
In this scenario a collection of individual \sphinxstyleemphasis{processes} (that is,
running instances of a program) work together on the same calculation.
The processes can all reside on the same physical machine (often termed
\sphinxstyleemphasis{node}) \textendash{} e.g. when you run them on your many-core desktop machine \textendash{} or
on separate machines (nodes) \textendash{} e.g. when you run them at an HPC
facility.

In both cases processes reside in separate memory spaces, which is a
fancy way of saying they \sphinxstyleemphasis{do not share} memory \textendash{} each of them gets a
chunk of memory and they don’t know what the other processes have in
their chunks. Yes, even when they are on the same machine.

The problem they work on has to be somehow subdivided between them \textendash{}
this is known as \sphinxstyleemphasis{parallel decomposition}. One common way of doing that
\textendash{} and one that onetep employs \textendash{} is \sphinxstyleemphasis{data decomposition}, where it’s the
data in the problem that is subdivided across processes. In onetep the
grids on which quantities like electronic density or external potential
are calculated are divided across processes, with each process “owning”
a slab of the grid. Similarly, the atoms in the system are divided
across processes, with each process “owning” a subset of atoms. Both of
these concepts are illustrated in \hyperref[\detokenize{starting_with_onetep:mpi}]{Fig.\@ \ref{\detokenize{starting_with_onetep:mpi}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{starting_with_onetep_fig1}.png}
\caption{Illustration of parallel data decomposition in onetep. Figure borrowed from J. Chem. Phys. \sphinxstylestrong{122}, 084119 (2005), \sphinxurl{https://doi.org/10.1063/1.1839852}, which you are well-advised to read.}\label{\detokenize{starting_with_onetep:mpi}}\label{\detokenize{starting_with_onetep:id3}}\end{figure}

From the point of view of the operating system, the processes running on
a machine are separate entities (see \hyperref[\detokenize{starting_with_onetep:processes}]{Fig.\@ \ref{\detokenize{starting_with_onetep:processes}}}), and
collaboration between them almost always necessitates some form of
communication (because, remember, they do not share memory) \textendash{} e.g.
process \#1 may need to ask process \#2 “what are the positions of \sphinxstyleemphasis{your}
atoms?” This is accomplished by a dedicated software library known as
Message Passing Interface (MPI). This is why we often call the processes
\sphinxstyleemphasis{MPI processes}, or, more technically, \sphinxstyleemphasis{MPI ranks}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{starting_with_onetep_fig2}.png}
\caption{Four onetep processes running on one machine, each utilising 100\% of a CPU core and 0.4\% of available memory.}\label{\detokenize{starting_with_onetep:processes}}\label{\detokenize{starting_with_onetep:id4}}\end{figure}

MPI facilitates starting multiple processes as part of a single
calculation, which can become slightly tricky when there are multiple
machines (nodes) involved. Your MPI installation will provide a
dedicated command for running multiple processes. The command is often
called \sphinxcode{mpirun}, \sphinxcode{aprun}, \sphinxcode{gerun}, \sphinxcode{srun} or something similar
(it will certainly be stated in the documentation for your system). On a
desktop machine its invocation typically looks like this:

\sphinxcode{mpirun -np 4 ./onetep\_launcher input.dat \textgreater{}input.out 2\textgreater{}input.err}

Here, \sphinxcode{mpirun} is the name of the command for launching multiple
processes, asks for four processes, \sphinxcode{onetep\_launcher} is the name of
the script for launching onetep \textendash{} it’s the script that will actually be
run on four CPU cores, and each instance will start one onetep process
for you \textendash{} here we assume it’s in the current directory (\sphinxcode{./}),
\sphinxcode{input.dat} is your onetep input file. Output will be sent
(“redirected”) to \sphinxcode{onetep.out}, and error messages (if any), will be
redirected to \sphinxcode{input.err}. All four processes will be started on the
same machine.

In HPC environments the syntax will be slightly different, because the
number of processes will be automatically inferred by the batch
(queueing) system, the batch system will also take care of instructing
\sphinxcode{mpirun} (or equivalent) what machines to put the processes on.

MPI lets you run your calculation on as many processes as you like \textendash{}
even tens of thousands. However, there are practical limitations to how
far you can go with onetep. Looking at \hyperref[\detokenize{starting_with_onetep:mpi}]{Fig.\@ \ref{\detokenize{starting_with_onetep:mpi}}} it becomes clear
that you cannot have more MPI processes than atoms \textendash{} or some processes
would be left without work to do. In fact this limitation is even
slightly stricter \textendash{} to divide work more evenly onetep tries to give each
processes a similar number of NGWFs, not atoms. For instance, for a
water molecule run on two processes, it makes sense to assign the O atom
and its 4 NGWFs to one process, and both H atoms (1 NGWF each) to the
second process. If you try to run a calculation on on \sphinxstyleemphasis{three} processes,
it’s very likely that onetep will do the same thing \textendash{} assign O to one
processes, both H’s to another process and the third process will wind
up with no atoms. This will cause the calculation to abort. So, one
limitation is \sphinxstylestrong{you will not be able to use more MPI processes that you
have atoms in your system, and even slightly smaller numbers of MPI
processes might not work}. Even if they do, you don’t really want that,
because load balancing will be rather poor \textendash{} the processor that gets the
O atom has roughly twice as much work to do as the one that gets the two
H atoms. The bottom line is \textendash{} \sphinxstyleemphasis{you should have at least several atoms
per MPI rank} \textendash{} in the interest of efficiency.


\subsection{Shared-memory parallelism (OMP)}
\label{\detokenize{starting_with_onetep:shared-memory-parallelism-omp}}
This approach, sometimes known as \sphinxstyleemphasis{concurrency}, \sphinxstyleemphasis{concurrent processing}
or colloquially as \sphinxstyleemphasis{threads}, uses \sphinxstyleemphasis{shared memory}. The way it works is
a process \sphinxstyleemphasis{spawns} (starts) a number of \sphinxstyleemphasis{threads of execution}, with
each thread delegated to a separate CPU core. Typically each thread
works with a subset of data, and, in contrast to processes, threads
within the same process can access each other’s memory. For example, if
a process was given 50 atoms to work with, it can spawn 4 threads and
tell each thread to work on 12-13 atoms. Because threads share memory,
they do not need special mechanisms to communicate \textendash{} they can just use
memory for this. What they need instead are special mechanisms for
synchronisation \textendash{} e.g. so that thread 1 knows thread 2 finished writing
something to memory and it’s safe to try to read it. These mechanisms
are described by a standard known as \sphinxcode{OpenMP}, or \sphinxcode{OMP} for short.

In onetep threads are most conveniently handled using the launcher’s
\sphinxcode{-t} option, which instructs it how many threads each process should
spawn. For instance the command

\sphinxcode{./onetep\_launcher -t 8 input.dat \textgreater{}input.out 2\textgreater{}input.err}

runs one process (note the absence of \sphinxcode{mpirun}), which spawns eight
threads. This is what it looks like to the operating system:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{starting_with_onetep_fig3}.png}
\caption{One onetep process that spawned eight threads, running on one machine, utilising almost 800\% of a CPU core and 1.3\% of available memory \textendash{} this is for the entire process encompassing eight threads.}\label{\detokenize{starting_with_onetep:id5}}\end{figure}

Thread-based processing has a number of limitations. As threads reside
within a process, you cannot feasibly run more threads than you have CPU
cores on a node \textendash{} in other words, threading is limited to a single node.
Moreover, large numbers of threads quickly become inefficient. If a
processes owns 10 atoms, using more than 10 threads will not give you
any advantage, because the additional threads will not have anything to
work with (fortunately, this does not lead to the calculation aborting,
only to some threads idling). Even with four threads you will lose some
efficiency, because some threads will get 3 atoms and some only 2.
onetep works best with about 4-6 threads, unless you are using
Hartree-Fock exchange (HFx), which is the most efficient on large thread
counts.

Threads are easiest to control via \sphinxcode{onetep\_launcher}, which you are
advised to use, but onetep also provides keywords for controlling them
manually \textendash{} these are \sphinxcode{threads\_max}, \sphinxcode{threads\_per\_fftbox},
\sphinxcode{threads\_num\_fftboxes}, \sphinxcode{threads\_per\_cellfft} and
\sphinxcode{threads\_num\_mkl}. Each of these sets the number of threads spawned
from a single process for some part of onetep’s functionality. This is
advanced stuff and will not be covered in this beginners’ document.

Another point to note is that each thread requires its own \sphinxstyleemphasis{stack} (a
region of memory for intermediate data) in addition to the global
(per-process) stack. This per-thread stack needs to be large enough \textendash{}
almost always 64 MB suffices. So, if you spawn 16 threads from a
process, that’s an extra 1024 MB of memory that you need, per process.
If you use \sphinxcode{onetep\_launcher}, it takes care of setting this stack for
you. If you don’t \textendash{} you’ll need to take care of this on your own (by
exporting a suitable \sphinxcode{OMP\_STACKSIZE}) or you risk ugly crashes when
the stack runs out. Not recommended.


\subsection{Hybrid (combined MPI+OMP) parallelism}
\label{\detokenize{starting_with_onetep:hybrid-combined-mpi-omp-parallelism}}
For anything but the smallest of systems, combining MPI processes with
OMP threads is the most efficient approach. This is known as \sphinxstyleemphasis{hybrid
parallelism}. In onetep this is realised simply by combining \sphinxcode{mpirun}
(or equivalent) with \sphinxcode{onetep\_launcher}’s \sphinxcode{-t} option, like this:

\sphinxcode{mpirun -np 4 ./onetep\_launcher -t 8 input.dat \textgreater{}input.out 2\textgreater{}input.err}

Here we are starting 4 processes, each of which spawns 8 threads. This
set-up would fully saturate a large, 32-core desktop machine.

Setting up processes and threads looks slightly different in HPC
systems, where you need to start them on separate nodes. Your submission
script (you will find ones for common architectures in the
\sphinxcode{hpc\_resources} directory of your onetep installation) defines all the
parameters at the top of the script and then accordingly invokes
\sphinxcode{mpirun} (or equivalent) and \sphinxcode{onetep\_launcher}. Look at the
beginning of the script to see what I mean.


\subsection{How many nodes, processes and threads should I use?}
\label{\detokenize{starting_with_onetep:how-many-nodes-processes-and-threads-should-i-use}}
There are a few points worth considering here. First of all, efficiency
almost universally decreases with the number of CPU cores assigned to a
problem. That is to say, throwing 100 cores at a problem is likely to
reduce the time to solution by less than 100-fold. This is because of
communication overheads, load imbalance and small sections of the
algorithm that remain sequential, and is formally known as \sphinxhref{https://en.wikipedia.org/wiki/Amdahl\%27s\_law}{Amdahl’s
law}. It’s worth
keeping this in mind if you have a large number of calculations to
perform (known as \sphinxstyleemphasis{task farming}) \textendash{} if you have 1000 calculations to
perform, and have 500 CPU cores at your disposal, time to solution will
be the shortest if you run 500 1-core jobs first, followed by 500 1-core
jobs next. If you opt for running a job on 500 CPU cores simultaneously,
and do this for 1000 jobs in sequence, your time to solution will be
much, much worse, because of efficiency diminishing with the number of
cores.

Having said that, task farming is not the only scenario in the world.
Sometimes you have few jobs, or only one, that you want to run quickly.
Here, you’re not overly worried about efficiency \textendash{} if running the job on
1 CPU core takes a month, and using 100 CPU cores reduces it to a day,
you’d still take 100 CPU cores, or even more. You just have to remember
that the returns will be diminishing with each CPU core you add %
\begin{footnote}[1]\sphinxAtStartFootnote
Hartree-Fock exchange calculations being an important exception
%
\end{footnote}.

The remaining points can be summarised as follows:
\begin{enumerate}
\item {} 
Avoid using 1-2 atoms per MPI process, unless there’s no other way.
Try to have at least several atoms per MPI process \textendash{} for good
load-balancing.

\item {} 
For OMP threads the sweet spot is typically 4-5 threads. If you have
a giant system, so that you have a hundred atoms or more per MPI
process, you might be better off using 2 threads or even 1 (using
purely distributed-memory parallelism). This is because load
balancing will be very good with high numbers of atoms per MPI
process. If you have a small system, or if already using large
numbers of MPI processes, so that you wind up with very few atoms per
MPI process (say, below 5), you might find that using higher numbers
of threads (say, 8) to reduce the number of MPI processes is
beneficial.

\item {} 
Know how many CPU cores you have on a node. Make sure the number of
MPI processes \sphinxstyleemphasis{per node} and OMP threads per process saturate all the
node’s cores. For instance, if you have 40 CPU cores on a node, you
should aim for 10 processes per node, 4 threads each; or 20 processes
per node, 2 threads each; or 40 processes per node, 1 thread each; or
4 processes per node, 10 threads each. 2 processes per node with 20
threads each would also work, but would likely be suboptimal. Just
don’t do things like 3 processes with 10 threads, because then you
leave 10 CPU cores idle, and don’t do things like 6 processes with 10
threads, because you then oversubscribe the node (meaning you have
more threads than CPU cores) \textendash{} this degrades performance.

\item {} 
Nodes are often divided internally into \sphinxstyleemphasis{NUMA regions} \textendash{} most often
there are two NUMA regions per node. The only thing you need to know
about NUMA regions is that you don’t want a process to span across
them. This is why in the example above you did not see 5 processes
with 8 OMP threads each or 8 processes with 5 OMP threads each \textendash{} I
assumed there are two NUMA regions with 20 CPU cores each. In both
examples here you would have a process spanning across two NUMA
regions. It works, but is much slower.

\item {} 
Points 1-3 above do not apply to Hartree-Fock exchange calculations.
Point 4 applies. When doing HFx calculations (this includes
calculations with hybrid exchange-correlation functionals, like
B3LYP) follow the more detailed instructions in the HFx manual.

\item {} 
If you find that your calculation is running out of memory, your
first step should be to increase the number of nodes (because it
splits the problem across a set-up with more total RAM). Another idea
is to shift the MPI/OMP balance towards more threads and fewer MPI
processes (because this reduces the number of buffers for
communication between MPI processes). So if your job runs out of
memory on 2 nodes with 10 processes on each and with 4 threads per
process, give it 4 or more nodes with 10 processes on each with 4
threads per each, or switch to 4 processes with 10 OMP threads.

\end{enumerate}


\chapter{Ground State Calculation Setup}
\label{\detokenize{index_ground_state:ground-state-calculation-setup}}\label{\detokenize{index_ground_state::doc}}

\section{Using the Pseudoatomic Solver to Generate NGWFs}
\label{\detokenize{pseudoatomic_solver::doc}}\label{\detokenize{pseudoatomic_solver:using-the-pseudoatomic-solver-to-generate-ngwfs}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Nicholas D.M. Hine, University of Warwick

\item[{Date}] \leavevmode
September 2011

\item[{Date}] \leavevmode
Updated February 2016

\end{description}\end{quote}


\subsection{What is being calculated?}
\label{\detokenize{pseudoatomic_solver:what-is-being-calculated}}
When the atomic solver is used {[}Ruiz-Serrano2012{]}, a
Kohn-Sham DFT calculation is performed for a “pseudoatom”. This means
that the pseudopotential of a single isolated ion is used as the
external potential, and the single-electron Kohn-Sham states are solved
self-consistently, for a given XC functional. The resulting states can
be expected to form an ‘ideal’ atomic orbital basis for a given
calculation {[}Soler2002{]}, {[}Artacho1999{]}, {[}Blum2009{]}, {[}Tarralba2008{]}, {[}Chen2010{]}.
In practice they are a good starting point for initial NGWFs, or a
passable fixed basis for calculations without NGWF optimisation, in
which context they should be at least comparable to the basis sets
generated in SIESTA, for example (though note that a high cutoff energy
is required for accurate representation on the grid in such cases).

The pseudoatomic orbitals we are looking for solve the Kohn-Sham
equation:
\begin{equation*}
\begin{split}\hat{H}_{\mathrm{KS}}\psi_{n}(\mathbf{r})=\epsilon_{n}\psi_{n}(\mathbf{r})\end{split}
\end{equation*}
where
\begin{equation*}
\begin{split}\hat{H}_{\mathrm{KS}}=-\frac{1}{2}\nabla^{2}+V_{\mathrm{loc}}(r)+\sum_{i}|p_{i}\rangle D_{ij}\langle p_{j}|\end{split}
\end{equation*}
is the Hamiltonian in terms of kinetic, local potential and nonlocal
potential contributions. For a norm conserving pseudopotential the
matrix \(D_{ij}\) is diagonal and there is one term per angular
momentum channel, so there is generally only one contributing nonlocal
projector for each wavefunction. In PAW and USPs, there may be more, and
nonzero cross-terms \(D_{ij}\) for \(i\neq j\). Because it is a
spherical potential, solutions of this form of the Kohn-Sham equation
are easily separable into an angular part, solved by the spherical
harmonics (\(Y_{lm}(\hat{\mathbf{r}})\), or equivalently the real
spherical harmonics \(S_{lm}(\hat{\mathbf{r}})\)) multiplied by
radial part, which we will be solving explicitly in terms of a basis.

The atomic orbitals are solved in a sphere of radius \(R_{c}\). The
most appropriate basis to use therefore consists of normalised spherical
Bessel functions of given angular momentum \(l\). The radial parts
of the basis functions, \(B_{l,\nu}(r)\) are
\begin{equation*}
\begin{split}B_{l,\nu}(r)=j_{l}(q_{l,\nu}r)\:/\,\Big[\int_{0}^{R_{c}}|j_{l}(q_{l,\nu}r)|^{2}r^{2}dr\Big]^{\frac{1}{2}}\;,\end{split}
\end{equation*}
with \(q_{l,\nu}\) such that \(q_{l,\nu}R_{c}\) are the zeros
of the spherical Bessel functions. Thence \(B_{l,\nu}(R_{c})=0\) and
\(\int_{0}^{R_{c}}|B_{l,\nu}(r)|^{2}r^{2}dr=1\) for all \(\nu\).
The basis would be complete if \(\nu\) were infinite: in practice it
must be truncated, and the number of functions included is determined by
a kinetic energy cutoff \(E_{\mathrm{cut}}\). The criterion
\(\frac{1}{2}q_{l,\nu}^{2}<E_{\mathrm{cut}}\) determines the largest
\(\nu\) for each \(l\).

In the pseudoatom calculation we are therefore calculating Kohn-Sham
states of the form
\begin{equation*}
\begin{split}\psi_{n}(\mathbf{r})=\sum_{\nu}c_{n,\nu}\, B_{l_{n},\nu}(r)\, S_{l_{n}m_{n}}(\hat{\mathbf{r}})\;,\end{split}
\end{equation*}
which have eigenvalues \(\epsilon_{n}\) and occupancies
\(f_{n}\) which include spin-degeneracy. The occupancies are fixed,
and determined before the main calculation, such that they sum to the
number of valence electrons. Spherical symmetry of the density is
assumed, so the occupancies of all members of a given set of
\(m\)-degenerate orbitals are always equal — and in fact in practice
the \(m\) states for a given \(l\), \(n\) pair are
amalgamated into one state with \(f_{n}\) summed over all the
degenerate \(m\)’s. For example, for a nitrogen ion with valence
configuration \(2s^{2}\,2p^{3}\), we would have \(f_{2s}=2\),
\(f_{2p}=3\). For this, we therefore need to find the lowest-energy
self-consistent eigenstate of each of \(l=0\) and \(l=1\).
Henceforth we will only consider the radial dependence
\(\psi_{n}(r)\). All radial quantities will be considered to have
been integrated over solid angle already, so factors of \(4\pi\) are
omitted and \(\int|\psi_{n}(r)|^{2}r^{2}dr=1\) for a normalised
orbital.

We define the local potential through
\begin{equation*}
\begin{split}V_{\mathrm{loc}}(r)=V_{\mathrm{psloc}}(r)+V_{H}[n](r)+V_{XC}[n](r)+V_{\mathrm{conf}}(r)\end{split}
\end{equation*}
where for a spherical charge distribution
\(n(r)=\sum_{n}f_{n}|\psi_{n}(r)|^{2}\), the Hartree potential is
given by
\begin{equation*}
\begin{split}V_{H}(r)=\frac{1}{r}\int_{0}^{r}n(r')r'^{2}dr'+\int_{r}^{\infty}n(r')r'\, dr'\;.\end{split}
\end{equation*}
and the XC potential is
\(V_{XC}[n](r)=\frac{\partial E_{XC}[n]}{\partial n(r)}\).
\(V_{\mathrm{conf}}(r)\) is an optional confining potential whose
specific form will be discussed later {[}Blum2009{]}.

For each \(l\) we can define the Hamiltonian matrix
\begin{equation*}
\begin{split}H_{\nu,\nu'}^{l}=\int_{0}^{R_{c}}B_{l,\nu}(r)\left[\hat{H}B_{l,\nu'}(r)\right]r^{2}dr\end{split}
\end{equation*}
and the overlap matrix
\begin{equation*}
\begin{split}S_{\nu,\nu'}^{l}=\int_{0}^{R_{c}}B_{l,\nu}(r)B_{l,\nu'}(r)r^{2}dr\end{split}
\end{equation*}
We then solve the secular equation
\begin{equation*}
\begin{split}\mathbf{H}^{l}.\mathbf{c}_{n}=\epsilon_{n}\mathbf{S}^{l}.\mathbf{c}_{n}\end{split}
\end{equation*}
to give the coefficients \(c_{n,\nu}\) which describe the orbitals.
The orbitals are generated on the real-space grid and density mixing
with a variable mixing parameter \(\alpha\) is then used until
self-consistency is obtained. The result is deemed to be converged once
a) the Harris-Foulkes estimate of the total energy (the bandstructure
energy) matches the total energy as determined from the density to
within a given tolerance (\(10^{-5}\) Ha) and the energy has stopped
changing each iteration, to within a given tolerance (\(10^{-7}\)
Ha).


\subsection{Performing a Calculation with the Pseudoatomic Solver}
\label{\detokenize{pseudoatomic_solver:performing-a-calculation-with-the-pseudoatomic-solver}}
The atomic solver is the default approach to NGWF initialisation, so if
you do not need to change any settings for any species, simply omit the
\sphinxcode{\%block species\_atomic\_set} block.

If there are any tweaks to be made to the default, this block is
required, and for each element symbol the string “SOLVE” should appear
in the entry. If you want to use automatic initialisation of the number
of NGWFs, then specify that to be \sphinxcode{-1} in the species block. The code
will attempt to determine how many orbitals to use, which orbitals
constitute the valence, and what their default occupancies should be. To
illustrate what will happen, we present some simple examples.

Let us imagine setting up a calculation with only nitrogen, for which
\(Z_{\mathrm{atom}}=7\) and \(Z_{\mathrm{ion}}=5\). The valence
manifold consists of \(4\) NGWFs of radius \(R_{c}=8.0\) per
atom, so we would have the following blocks in our input file:


\bigskip\hrule\bigskip


\sphinxcode{\%block species}

\sphinxcode{N N 7 4 8.0}

\sphinxcode{\%endblock species}

\sphinxcode{\%block species\_atomic\_set}

\sphinxcode{N “SOLVE”}

\sphinxcode{\%endblock species\_atomic\_set}

Note that because we may well want to add extra options to this string
later, it’s best to always use the “” quotes around SOLVE. These
settings will activate the pseudoatomic solver and it will attempt to
guess a default configuration for the atom. Since
\(Z_{\mathrm{ion}}=5\), the code will count back five electrons from
the end of the default neutral atom occupancy, which is
\(1s^{2}\,2s^{2}\,2p^{3}\), and will discover that the valence
states are \(2s^{2}\,2p^{3}\). Since we have asked for \(N=4\)
NGWFs, the solver will then count forward from the start of the valence
states and determine that by including the whole first set of \(s\)
and \(p\) states it has enough to span the valence space and create
four orbitals (and thus four NGWFs). The solver will therefore solve for
one state with \(l=0\), \(f=2\) and one state with \(l=1\),
\(f=3\), all with radius \(R_{c}=8.0\), and from these states
will produce one \(s\)-like NGWF and the three degenerate
\(p_{x}\), \(p_{y}\) and \(p_{z}\) NGWFs.

A slightly more complex example would be if we were generating orbitals
for iron (\(Z_{\mathrm{atom}}=26\), \(Z_{\mathrm{ion}}=8)\):


\bigskip\hrule\bigskip


\sphinxcode{\%block species}

\sphinxcode{Fe Fe 26 9 10.0}

\sphinxcode{\%endblock species}

\sphinxcode{\%block species\_atomic\_set}

\sphinxcode{Fe “SOLVE”}

\sphinxcode{\%endblock species\_atomic\_set}

This time, to find the default configuration, the solver initialisation
routines will count back 8 electrons from the neutral atom configuration
of \(1s^{2}\,2s^{2}\,2p^{6}\,3s^{2}\,3p^{6}\,3d^{6}\,4s^{2}\) and
thus will determine that the valence states are \(3d^{6}\,4s^{2}\).
However, this time we have asked for 9 NGWFs, so it will then count
forward from \(3d\), include the fivefold-degenerate lowermost
\(d\)-like state and the lowest \(s\)-like state. This only
makes six, so it then will also have to include the threefold-degenerate
\(4p\)-like state. The solver will have to solve for one unoccupied
\(p\)-like orbital, which will have \(f=0\) throughout the
calculation.


\subsubsection{Controlling the configuration}
\label{\detokenize{pseudoatomic_solver:controlling-the-configuration}}
The default neutral-atom configurations for all the elements up to
\(Z=92\) are included in the code, and will be used by default to
generate the configuration. However, it is also possible to override
these default configurations. For example, to generate NGWFs for iron in
the 3+ state, we might want to set the occupancies to
\(3d^{5}\,4s^{0}\). To do this we use the “conf=” directive after
the SOLVE string:


\bigskip\hrule\bigskip


\sphinxcode{\%block species\_atomic\_set}

\sphinxcode{Fe “SOLVE conf=3d5 4s0”}

\sphinxcode{\%endblock species\_atomic\_set}

Any terms in the configuration which are not overridden are left at
their default values. Another example might be if we wanted to force the
partial occupation of more higher-lying states than would otherwise be
occupied for the neutral atom:


\bigskip\hrule\bigskip


\sphinxcode{\%block species\_atomic\_set}

\sphinxcode{C “SOLVE conf=2s1.5 2p2.5”}

\sphinxcode{\%endblock species\_atomic\_set}

Note that the solver counts through the configuration terms strictly in
the order \(n,l\), i.e. \(n\) is looped over outermost, then
\(l=0\) to \(l=n-1\) for each \(n\) innermost. This means
that sometimes a little thought is required to get the terms one
actually wants, and not spurious extra ones. For example, if we wanted
to run a calculation of oxygen with 9 NGWFs per atom, what we probably
wanted would be to run with 1 \(s\)-like NGWF, 3 \(p\)-like
NGWFs and 5 \(d\)-like NGWFs. However, this is not by default what
one will get if one asks for


\bigskip\hrule\bigskip


\sphinxcode{\%block species}

\sphinxcode{O O 8 9 9.0}

\sphinxcode{\%endblock species}

\sphinxcode{\%block species\_atomic\_set}

\sphinxcode{O “SOLVE”}

\sphinxcode{\%endblock species\_atomic\_set}

This will identify \(2s^{2}\,2p^{4}\) as the valence orbitals, and
counting forward will identify \(2s\), \(2p\), \(3s\),
\(3p\) and just 1 of the 5 degenerate \(3d\) states as the NGWFs
required. Therefore, we must instruct the atomsolver to ignore the
unwanted excited \(3s\) and \(3p\) terms. We do this with an
“X”, which instructs the solver to knock out this term:


\bigskip\hrule\bigskip


\sphinxcode{\%block species\_atomic\_set}

\sphinxcode{O “SOLVE conf=2s2 2p4 3sX 3pX 3d0”}

\sphinxcode{\%endblock species\_atomic\_set}

Strictly speaking, the \(2s\), \(2p\) and \(3d\) strings are
not needed, as they are the default values anyway, but they are left in
for clarity. I find it advisable, so that I can keep track of the terms
which will generate the NGWFs, to add explicitly the terms with zero
occupancy to the conf string.


\subsubsection{Generating larger, non-minimal bases}
\label{\detokenize{pseudoatomic_solver:generating-larger-non-minimal-bases}}
ONETEP is generally used to create an \sphinxstyleemphasis{in-situ-optimised}, minimal basis
(eg 4 NGWFs/atom for C, N, O etc). However, it is also possible to fix
the NGWFs and run with a much larger, unoptimised basis, in a manner
akin to other DFT codes designed for large-scale simulations (eg
SIESTA). One would then normally want to use multiple NGWFs for each
angular momentum channel corresponding to the valence orbitals. This is
known as using a “multiple-zeta” basis set, where zeta refers to the
radial part of the valence atomic orbitals. For example, a “triple-zeta”
basis for carbon would have \(3\) \(s\)-like functions and
\(3\) of each of \(p_{x}\), \(p_{y}\), and
\(p_{z}\)-like functions. There are two approaches to generating
these extra radial functions. This simplest is just generate the
higher-lying orbitals of a given angular momentum. For carbon, for
example, a double-zeta basis in this scheme would include \(3s\) and
\(3p\)-like states. This approach, however, is not very quick to
converge with basis size.

It is often better to apply the commonly-used “split-valence” approach.
This allows the orbitals that have been generated to be “split” into
multiple functions, so as to generate so-called “split-valence
multiple-zeta” basis sets. In this formalism, one function \(f(r)\)
can be split into two functions \(g_{1}(r)\) and \(g_{2}(r)\)
according to the following:
\begin{enumerate}
\item {} 
A matching radius \(r_{m}\) is chosen: for \(r>r_{m}\), we
set \(g_{2}(r)=f(r)\). For \(r\leq r_{m}\), we set
\(g_{2}(r)=r^{l}(a_{l}-b_{l}r^{2})\), where \(a_{l}\) and
\(b_{l}\) are chosen such that \(g_{2}(r_{m})=f(r_{m})\) and
\(g_{2}'(r_{m})=f'(r_{m})\).

\item {} 
The other function, \(g_{1}(r)\), is set to
\(f(r)-g_{2}(r)\), so \(g_{1}(r)=0\) for \(r\geq r_{m}\).

\item {} 
Both functions are renormalised, so
\(\int_{0}^{R_{c}}|g_{1}(r)|^{2}r^{2}dr=1\) and
\(\int_{0}^{R_{c}}|g_{2}(r)|^{2}r^{2}dr=1\).

\end{enumerate}

Splitting of a term is activated by adding a colon after the term and
specifying the “split norm” value. This is the fraction \(p\) of the
total norm of the orbital which is beyond the matching radius
\(r_{m}\), such that
\(\int_{r_{m}}^{R_{c}}|f(r)|^{2}r^{2}dr=p\). If this colon is
present, the solver will take into account the total number of orbitals
which will result from this term \sphinxstyleemphasis{after splitting,} when counting
forward in the configuration terms to determine which orbitals to solve.
For example, if we wished to generate a Double-Zeta Polarisation (DZP)
basis for oxygen (\(2\times1\times s\),
\(2\times3\times p\),\(1\times5\times d\)), where the last 15\%
of the norm was matched for the \(s\) and \(p\)-orbitals, we
would use the following:


\bigskip\hrule\bigskip


\sphinxcode{\%block species}

\sphinxcode{O O 8 13 9.0}

\sphinxcode{\%endblock species}

\sphinxcode{\%block species\_atomic\_set}

\sphinxcode{O “SOLVE conf=2s2:0.15 2p4:0.15 3sX 3pX 3d0”}

\sphinxcode{\%endblock species\_atomic\_set}

So that you can tell that it is happening, the code will output a
message along the following lines when splitting a given orbital.


\bigskip\hrule\bigskip


\sphinxcode{Splitting orbital 1, splitnorm= 0.150000000}

\sphinxcode{Splitting orbital 1, splitnorm= 0.060000000}

The result of the splitting can be viewed in the
“initial\_rad\_ngwf\_xx” files.


\subsubsection{Obtaining Polarisation Orbitals through Perturbation}
\label{\detokenize{pseudoatomic_solver:obtaining-polarisation-orbitals-through-perturbation}}
As well as including more flexibility for the valence orbitals, in the
form of multiple-zeta basis sets, one frequently also wants to expand
the basis by extending it to higher angular momentum channels. This can
be done by simply increasing the number of NGWFs requested and ensuring
through the ’conf=’ string that the extra functions obtained are of the
right angular momentum. However, the resulting high-\(l\) states
tend to be unbound in the free atom, and therefore do not necessarily
add anything particularly useful to the basis.

There is an alternative means to generate higher-\(l\) states,
using perturbation theory. In this, one effectively applies an electric
field to the valence states of angular momentum \(l\) and polarises
them, resulting in a set of states of angular momentum \(l+1\).
Imagine we have an orbital \(\psi_{0}(\mathbf{r})\) of angular
momentum \(l\), \(m\) which is an eigenstates of the original
Hamiltonian \(\hat{H}_{0}\) with eigenvalue \(\epsilon_{0}\):
\begin{equation*}
\begin{split}\psi_{0}(\mathbf{r})=\sum_{\nu}c_{0,\nu}\, B_{l,\nu}(r)\, S_{lm}(\hat{\mathbf{r}})\;.\end{split}
\end{equation*}
We wish to polarise this orbital by applying an electric field
\(\mathcal{E}\) in the \(z\)-direction:
\begin{equation*}
\begin{split}\hat{H}_{1}=\mathcal{E}r\, S_{10}(\hat{\mathbf{r}})\;,\end{split}
\end{equation*}
(since \(S_{10}(\hat{\mathbf{r}})=z/r\)). Perturbing
\(\psi_{0}\) with \(\hat{H}_{1}\) gives us no shift in energy to
first-order, since the perturbation is an odd multiplicative function of
\(z\), meaning \(\epsilon_{1}=0\). What about the change in the
wavefunction? This obeys
\begin{equation*}
\begin{split}(\hat{H}_{0}-\epsilon_{0})\psi_{1}(\mathbf{r})=-(\hat{H}_{1}-\epsilon_{1})\psi_{0}(\mathbf{r})\label{eq:pert}\end{split}
\end{equation*}
In principle, \(\psi_{1}(\mathbf{r})\) could have any angular
momentum components, but we can see that in practice it only contains
\(L=l\pm1\), since the dipole selection rule excludes all other
channels. We already have \(l-1\) states in our basis, so we
conclude that \(\psi_{1}(\mathbf{r})\) need only include
\(l+1\), and we can expand \(\psi_{1}\) in terms of the
\(l+1\) basis functions:
\begin{equation*}
\begin{split}\psi_{1}(\mathbf{r})=\sum_{\nu}c_{1,\nu}\, B_{l+1,\nu}\, S_{l+1,m}(\hat{\mathbf{r}})\end{split}
\end{equation*}
Therefore we can generate a shifted Hamiltonian

\phantomsection\label{\detokenize{pseudoatomic_solver:equation-pert}}\begin{equation}\label{equation:pseudoatomic_solver:pert}
\begin{split}H_{\nu,\nu'}^{l+1}=\int_{0}^{R_{c}}B_{l+1,\nu}(r)\left[(\hat{H}^{l+1}-\epsilon_{0})B_{l+1,\nu'}(r)\right]r^{2}dr\;,\end{split}
\end{equation}
and the components of the RHS of Eq. \eqref{equation:pseudoatomic_solver:pert}
\begin{equation*}
\begin{split}D_{\nu}=-\int_{0}^{R_{c}}B_{l+1,\nu}(r)r\psi_{0}(r)r^{2}dr\;.\end{split}
\end{equation*}
To solve for \(c_{1,\nu}\) we just need to invert
\(H_{\nu,\nu'}^{l+1}\)and apply it to \(D_{\nu}\), and then
renormalise the result to have a norm of 1.

In practice, polarisation of a given configuration term of angular
momentum \(l\), to form a perturbative polarisation orbital for
\(l+1\), is achieved by adding “\textbar{}P” to the term, for example:


\bigskip\hrule\bigskip


\sphinxcode{\%block species}

\sphinxcode{O O 8 13 9.0}

\sphinxcode{\%endblock species}

\sphinxcode{\%block species\_atomic\_set}

\sphinxcode{O “SOLVE conf=2s2:0.15 2p4:0.15\textbar{}P”}

\sphinxcode{\%endblock species\_atomic\_set}

So that you can tell that it is happening, the code will output a
message along the following lines when polarising a given orbital:


\bigskip\hrule\bigskip


\sphinxcode{Polarising orbital 1 to generate l= 2 function (orbital 3)}

Again, the result can be viewed by plotting the relevant
“initial\_rad\_ngwf\_xx” file.


\subsubsection{Overriding radii}
\label{\detokenize{pseudoatomic_solver:overriding-radii}}
By default, the cutoff radius used for all the orbitals of an atom is
the same \(R_{c}\) as defined in the \sphinxcode{\%block species} entry for
that element. However, we can override this, either for all orbitals, or
for certain angular momentum channels.

To override the radius for all channels, for example to
7.0\(a_{0}\), would we add the flag “R=7.0” to the SOLVE string:


\bigskip\hrule\bigskip


\sphinxcode{\%block species\_atomic\_set}

\sphinxcode{O “SOLVE conf=2s2:0.15 2p4:0.15 3sX 3pX 3d0 R=7.0”}

\sphinxcode{\%endblock species\_atomic\_set}

Or leave the default values for all other channels, but override the
\(d\)-channel only to 5.0\(a_{0}\), we would use


\bigskip\hrule\bigskip


\sphinxcode{\%block species\_atomic\_set}

\sphinxcode{O “SOLVE conf=2s2:0.15 2p4:0.15 3sX 3pX 3d0 Rd=5.0”}

\sphinxcode{\%endblock species\_atomic\_set}


\subsubsection{Adjusting confining potentials}
\label{\detokenize{pseudoatomic_solver:adjusting-confining-potentials}}
By default, a confining potential is applied, of the form:
\begin{equation*}
\begin{split}V_{\mathrm{conf}}(r)=S\,\exp[-w_{l}/(r-R_{c}+w_{l})]/(r-R_{c})^2\end{split}
\end{equation*}
where \(S\) is the maximum height of the confining potential (at
\(r=R_{c}\)), and \(w_{l}\) is the width of the region over
which it is applied. By default, \(S=100\) Ha,
and\(w_{l}=3.0a_{0}\) for all \(l\)-channels used. These can
also be overridden, either all at once or for specific \(l\)-values
in the case of \(w\).

For example, to set no confining potential on the confined
\(d\)-orbitals in Zinc, but to keep the default one on all the other
orbitals, we could set \(w_{d}=0\):


\bigskip\hrule\bigskip


\sphinxcode{\%block species\_atomic\_set}

\sphinxcode{Zn “SOLVE conf=3d10 4s2 Rd=5.0 wd=0.0”}

\sphinxcode{\%endblock species\_atomic\_set}

Or to turn off confinement potentials entirely, and generate
\(R_{c}=15.0a_{0}\) orbitals to match those generated by CASTEP’s
atomsolver (this should allow direct comparison of energies, given
suitable tweaking of the energy cutoffs so that they exactly match:


\bigskip\hrule\bigskip


\sphinxcode{\%block species\_atomic\_set}

\sphinxcode{O “SOLVE R=15.0 S=0.0”}

\sphinxcode{\%endblock species\_atomic\_set}

Note that there can be problems with convergence for certain choices of
confining potential. In particular, if you apply different confining
potentials to different \sphinxstyleemphasis{occupied} orbitals, there will be problems
obtaining agreement between the Harris-Foulkes estimator and the actual
total energy - because the band energy will incorporate the different
confining potentials, but the total energy cannot. The confining
potential on angular momentum channels with no occupied orbitals can
therefore be whatever you like, but those of occupied orbitals must all
match. The exception to this is if the cutoff radius ment of one channel
is less than the onset radius for the others. In this case, there is no
need to apply a confinement to the lower-cutoff channel at all (eg in
the example above for Zinc).


\subsubsection{Initial Guess Density: Setting initial charges and spins}
\label{\detokenize{pseudoatomic_solver:initial-guess-density-setting-initial-charges-and-spins}}
The atomsolver solutions are by default also used to provide an initial
guess for the valence electron density. This is used to generate the
initial Hamiltonian, which determines the occupation of the orbitals via
Palser-Manolopoulos or other kernel optimisation schemes. Therefore it
is important that this initial density is a reasonably good guess to the
real density.

A superposition of atomic densities is usually fine for neutral systems
without large magnetic moments. Sometimes, however, one needs to adjust
the charges and spins of this initial density. It appears to be a rather
bad idea to actually adjust the orbital occupations of the pseudoatoms
self-consistently: it becomes impossible to disentangle the effect of
changing the orbital from that of changing the density.

A better approach, therefore, is to retain the same pseudoatomic
solutions for the neutral atom, but adjust the orbital occupations only
at the point where they are used to generate the density.

This can be done by specifying “INIT CHARGE=X SPIN=Y” in the SOLVE
string. Either CHARGE or SPIN can be omitted if they are not required.
For example, for a manganese ion with charge +3 and spin 4, we might set


\bigskip\hrule\bigskip


\sphinxcode{\%block species\_atomic\_set}

\sphinxcode{Mn “SOLVE conf=3d5 4s2 wd=7.0 INIT SPIN=4 CHARGE=+3”}

\sphinxcode{\%endblock species\_atomic\_set}

The default occupation for the neutral atom is \(3d^5\)
\(4s^2\). However, we ask it to apply a charge of +3, and this will
remove occupation number from the orbitals with the highest energy until
the right charge is obtained. In this case the resulting occupation will
be \(3d^4\) \(4s^0\). Next, the spin is applied, resulting in
\(3d_{\uparrow}^4\) \(3d_{\downarrow}^0\). Note that the charge
is applied first, followed by the spin.

{[}Ruiz-Serrano2012{]} A. Ruiz-Serrano, N.D.M. Hine and C.-K. Skylaris, \sphinxstyleemphasis{in press}, (2012).

{[}Soler2002{]} J.M. Soler, E. Artacho, J.D. Gale, A. Garcia, J. Junquera, P. Ordejon,
and D. Sanchez-Portal,\sphinxstyleemphasis{The SIESTA method for ab initio order-N
materials simulation}, J. Phys. Condens. Matter 14, (2002).

{[}Artacho1999{]} E. Artacho, D. Sanchez-Portal, P. Ordejon, A. Garca, and J. M. Soler, \sphinxstyleemphasis{Linear-scaling ab-initio calculations for large and complex systems}, Phys. Status Solidi B 215, 809 (1999).

{[}Blum2009{]} V. Blum, R. Gehrke, F. Hanke, P. Havu, V. Havu, X. Ren, K. Reuter, and M. Scheffler: \sphinxstyleemphasis{Ab initio molecular simulations with numeric atom-centered orbitals}, Comput. Phys. Commun. 180, 2175 (2009).

{[}Tarralba2008{]} A. S. Torralba, M. Todorovic, V. Brazdova, R. Choudhury, T. Miyazaki, M. J. Gillan, and D. R. Bowler. \sphinxstyleemphasis{Pseudo-atomic orbitals as basis sets for the O(N) DFT code CONQUEST}, J. Phys. Condens. Matt. 20(29), (2008).

{[}Chen2010{]} M. Chen, G.-C. Guo, and L. He, \sphinxstyleemphasis{Systematically improvable optimized atomic basis sets for ab initio calculations}, J. Phys. Condens. Matt. 22, 445501, (2010).


\section{Conduction NGWF optimisation and optical absorption spectra}
\label{\detokenize{conduction::doc}}\label{\detokenize{conduction:conduction-ngwf-optimisation-and-optical-absorption-spectra}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Laura E. Ratcliff, Imperial College London

\item[{Date}] \leavevmode
July 2011

\end{description}\end{quote}


\subsection{Conduction calculations}
\label{\detokenize{conduction:conduction-calculations}}
As a consequence of the NGWF optimisation process in ONETEP the occupied
(valence) Kohn-Sham states are well represented by the NGWFs, but the
unoccupied (conduction) NGWFs are not, so that upon diagonalisation of
the Hamiltonian at the end of a calculation, if one were to compare the
resulting eigenvalues with a conventional cubic-scaling DFT code such as
CASTEP {[}Clark2005{]}, the ONETEP conduction states would be
higher in energy than the CASTEP states, and some conduction states
might be missing {[}Skylaris2005{]}. In order to correct this
problem, a method has been implemented whereby a second set of NGWFs
(referred to as the conduction NGWFs) are optimised to accurately
represent the Kohn-Sham conduction states. This is done with asymptotic
linear-scaling computational effort by constructing an idempotent
density matrix representing the manifold of conduction states (rather
than by solving for them explicitly). Optimisation of the NGWFs
describing the conduction states proceeds as with the valence states,
using a dual-loop system by which the conduction density kernel and the
conduction NGWF coefficients are simultaneously optimised.

It should be noted that the Kohn-Sham eigenvalues will of course not be
expected to exactly correspond to the true quasi-particle energies,
however in practice reasonable agreement with experiment has been seen
to occur in a number of systems, particularly when using the scissor
operator {[}Godby1986{]}, {[}Gygi1989{]}.

The conduction NGWF optimisation takes the form of a non-self-consistent
calculation following a ground-state calculation, where the density and
potential calculated in the ground-state calculation are re-used. A
projected Hamiltonian is then constructed in the conduction NGWF basis,
using the density operator as a projection operator. This projected
Hamiltonian is modified to avoid problems which might occur if the
Hamiltonian and density operators do not commute perfectly.
Additionally, the valence states are shifted up in energy by some amount
\(w\), such that they become higher in energy than the conduction
states. The projected conduction Hamiltonian is thus written:
\begin{equation*}
\begin{split}\begin{aligned}
\left(H_\chi^{\textrm{proj}}\right)_{\alpha\beta}&=&\langle \chi_\alpha|\hat{H}-\hat{\rho}\left(\hat{H}-w\right)\hat{\rho}|\chi_\beta\rangle\\ \nonumber
&=&\left(H_\chi\right)_{\alpha\beta} -\left(T^\dag K H_\phi KT\right)_{\alpha\beta}\\ \nonumber
&&+w\left(T^\dag K S_\phi KT\right)_{\alpha\beta}, \end{aligned}\end{split}
\end{equation*}
where \(\{|\phi_{\alpha}\rangle\}\) is the set of valence NGWFs and
\(\{|\chi_{\alpha}\rangle\}\) the set of conduction NGWFs.
\({\bm{\rho}}\) is the valence density matrix, \(\mathbf{K}\) is
the valence density kernel, \(\mathbf{S_{\phi}}\) is the valence
overlap matrix and \(\mathbf{H_{\phi}}\) is the valence Hamiltonian.
\(\mathbf{S_{\chi}}\) is the conduction overlap matrix,
\(\mathbf{T}\) is the valence-conduction cross overlap matrix
defined as
\(T_{\alpha\beta}=\langle \phi_{\alpha} | \chi_{\beta} \rangle\),
\(\mathbf{H_{\chi}}\) is the (unprojected) conduction Hamiltonian,
\(\mathbf{H_\chi^{\textrm{proj}}}\) is the projected conduction
Hamiltonian, \(\mathbf{Q}\) is the conduction density matrix and
\(\mathbf{M}\) is the conduction density kernel. The conduction
NGWFs and kernel are then minimised with respect to the energy
expression
\(E=\text{tr}\left[\mathbf{Q}\mathbf{H_\chi^{\textrm{proj}}}\right]\),
following the same procedure as in a standard ONETEP calculation. The
shift can either be set to a constant value, or updated during a
calculation, by setting it to be higher than the highest eigenvalue as
calculated in the conduction NGWF basis.

At the end of the conduction NGWF optimisation process, the valence and
conduction NGWF basis sets are combined into a new ‘joint’ basis, which
will be capable of accurately representing both the occupied and
unoccupied Kohn-Sham states. Other properties such as optical absorption
spectra can then be calculated in this joint basis.

For further information see Ratcliff \sphinxstyleemphasis{et
al}. {[}Ratcliff2011{]}.


\subsection{Performing conduction calculations in ONETEP}
\label{\detokenize{conduction:performing-conduction-calculations-in-onetep}}
In order to optimise a set of NGWFs capable of accurately representing
the Kohn-Sham conduction states in ONETEP, it is first necessary to have
performed a standard ONETEP ground-state calculation and have retained
the density kernel and NGWF output files. No special parameter values
are required for this stage, although it may be worth setting
ODD\_PSINC\_GRID to true, as conduction NGWF radii generally need to be
larger than valence NGWF radii in order to achieve large convergence,
and so it is more likely that the FFT box will be required to be equal
to the psinc grid, and as both stages of the calculation must have the
same cut-off energy and therefore grid size, it is desirable to have an
odd grid for both the cell size and FFT box.

Once a ground-state calculation has been performed, a conduction
calculation can be performed by setting TASK=COND. The number of
conduction NGWFs per species and their radii must then be specified in
the SPECIES\_COND block, which follows the same pattern as the species
block. The initial NGWFs, if not specified, will be equal to the initial
NGWFs used for the valence density matrix. This choice can be overridden
by specifying different choices in a SPECIES\_ATOMIC\_SET\_COND block,
which can be set to use the pseudoatomic solver by setting “SOLVE” for
each species. One useful option is to specify that certain valence
states, particularly those known to be fully filled and thus not
expected to contribute to the manifold of conduction states, should be
included in the calculation of the ground state of the pseudoatom but
left out of the conduction NGWF set. For example, when generating
conduction NGWFs for Cadmium, one might want to include the 10 filled 4d
states in the atom calculation, but since they are not expected to
contribute to the unoccupied states, they can be omitted from the
conduction NGWFs by setting a splitnorm of “-1” for them, through the
following solver string: “SOLVE conf=4d10:-1”.

The conduction density kernel must contain a specific number of occupied
states, and only these states will contribute to the NGWF gradient:
COND\_NUM\_STATES is used to specify the number of conduction states to
be optimised. In principle this could be any number, but in practice the
higher energy conduction states converge rather slowly with respect to
conduction NGWF radii, and in particular completely delocalised
conduction states are very hard to represent using localised basis
functions. Therefore results should be treated with caution when
optimising high energy conduction states. A good rule-of-thumb is, if at
all possible, to try to choose a manifold of conduction states above
which there is a reasonable sized gap in the density-of-states (as
calculated with the valence NGWFs).

For truly asymptotically linear-scaling calculations, one must truncate
the conduction density kernel. The cutoff for this truncation is
specified using COND\_KERNEL\_CUTOFF, although it is expected that high
levels of kernel truncation will significantly limit the accuracy of the
calculated conduction states. If unsure, do not use kernel truncation
unless you are confident you have verified that the properties you are
interested in are unaffected by the truncation.

At the end of a conduction calculation, diagonalisations are
automatically performed of the valence Hamiltonian, both the projected
and unprojected conduction Hamiltonians and the joint valence-conduction
Hamiltonian. The eigenvalues are written to the corresponding .bands
files. However, no joint basis density kernel is generated and so the
occupancies are not calculated within this basis. The unprojected
conduction eigenvalues are of limited use to most users, as it is
difficult to determine which are conduction states and which are poorly
represented valence states. For the projected conduction eigenvalues,
the gap referred to in the output is not the usual gap, rather it is the
gap between the highest optimised conduction state and the lowest
unoptimised conduction state. If required, it is also possible to plot
the orbitals in either the valence and conduction NGWF basis sets,
and/or in the joint basis set, using the keywords
COND\_PLOT\_VC\_ORBITALS and COND\_PLOT\_JOINT\_ORBITALS.

A standalone properties calculation can also be performed on the basis
of sets of valence and conduction NGWFs and kernels which have already
been calculated. To enable this, set TASK=PROPERTIES\_COND: the options
COND\_READ\_TIGHTBOX\_NGWFS and COND\_READ\_DENSKERN will automatically
be enabled, the NGWF optimisation will skipped and the calculation will
proceed straight to the stage of diagonalisation of the Hamiltonian and
plotting of the orbitals.


\subsubsection{Automatic setup of COND\_NUM\_STATES}
\label{\detokenize{conduction:automatic-setup-of-cond-num-states}}
Since it is not always straightforward to guess a sensible number of
conduction states to converge, the code will by default attempt to
choose an appropriate number of states for the user. By default, at the
start of a conduction optimisation, the code will count the number of
unoccupied states of the valence Hamiltonian with negative eigenvalues
to arrive at a guess of the number of bound states in a finite system.
The code will also check for any degeneracy of the highest unoccupied
state included in the calculation and automatically include more states
until an energy gap of at least 0.001 Ha between states that get
optimised and states that are unoptimised is achieved.

Since counting the number of eigenstates with negative eigenvalues in
order to obtain the number of bound states is only strictly valid in
finite systems, it is possible for the user to define an energy range,
as measured from the HOMO energy level, and the code will attempt to
optimise all states within that energy range. The two keywords
controlling the automatic conduction state setup are given by
COND\_ENERGY\_RANGE and COND\_ENERGY\_GAP. The first keyword defines the
desired energy range in Hartree while COND\_ENERGY\_GAP defines the
minimum required energy gap between the highest conduction state that is
optimised and the lowest conduction state that stays unoptimised.


\subsubsection{Setting the shift}
\label{\detokenize{conduction:setting-the-shift}}
There are a number of parameters relating to the shift, \(w\), used
in the projected conduction Hamiltonian. It is possible to keep the
shift at some fixed value (defined using COND\_INIT\_SHIFT) during the
calculation, by setting COND\_FIXED\_SHIFT to true. Alternatively, it
can be automatically updated during the calculation, which is usually
the safest way to proceed. This is achieved by calculating the highest
eigenvalue within the conduction NGWF basis at the start of each NGWF
iteration (providing COND\_CALC\_MAX\_EIGEN is set to true), and
comparing the current shift to this eigenvalue. Providing the shift is
higher than the highest eigenvalue, it remains unchanged, but if the
maximum eigenvalue has become greater than the current shift, it is
updated to equal the maximum eigenvalue plus some extra buffer value
(defined by COND\_SHIFT\_BUFFER).


\subsubsection{Local minima}
\label{\detokenize{conduction:local-minima}}
In practice, it is sometimes possible to become trapped in local minima,
where the ordering of states within the initial unoptimised basis
doesn’t correspond to the correct order, and so sometimes states are
missed. The problem can be identified by decreasing
NGWF\_THRESHOLD\_ORIG and seeing if the gradient stagnates while the
energy continues to decrease, or by plotting convergence graphs with
conduction NGWF radii where sharp changes in energy are sometimes
observed with small changes in conduction NGWF radii. In practice it is
therefore very important to systematically converge calculations with
respect to the conduction NGWF radii, which might require larger values
than ground-state ONETEP calculations. This problem can typically be
avoided by optimising some extra states (COND\_NUM\_EXTRA\_STATES) above
the required number of conduction states for a few iterations
(COND\_NUM\_EXTRA\_ITS) (typically 5-10 iterations). Selecting the
required number of extra states to include is mostly a trial and error
process whereby the number of extra states should be increased until no
changes are seen in the calculated conduction energy.


\subsubsection{Additional notes on input parameters}
\label{\detokenize{conduction:additional-notes-on-input-parameters}}
As the ground-state NGWFs and density kernel are required for the
conduction calculation, READ\_TIGHTBOX\_NGWFS and READ\_DENSKERN are
automatically set to true. There are separate variables for the
corresponding conduction quantities (COND\_READ\_TIGHTBOX\_NGWFS and
COND\_READ\_DENSKERN) which can be set to true for restarting conduction
calculations. The parameters WRITE\_TIGHTBOX\_NGWFS and WRITE\_DENSKERN
are not independently specified for the conduction and valence NGWF
basis sets.


\subsubsection{Conduction calculations in implicit solvent}
\label{\detokenize{conduction:conduction-calculations-in-implicit-solvent}}
\begin{DUlineblock}{0em}
\item[] Some care has to be taken when performing a conduction optimisation
for a system embedded in an implicit solvent (see the separate
Implicit Solvation documentation on how to perform a ground state
calculation in implicit solvent). The reason for this is that the
ground state in the implicit solvation model is often computed in a
two step process. In the first step the solvation cavity is computed
as an isosurface of the ground state density in vacuum, while in the
second step the ground state of the system is evaluated for that fixed
cavity. In order for the conduction calculation to be consistent with
the ground state calculation, the same solvation cavity has to be used
in both cases. To ensure that the code uses the correct restart files
when setting up the ground state Hamiltonian at the beginning of a
conduction optimisation, the following sets of keywords should be
used:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxcode{Task : Singlepoint Cond}
\item[] \sphinxcode{is\_implicit\_solvent : T}
\item[] \sphinxcode{is\_auto\_solvation : T}
\item[] \sphinxcode{is\_smeared\_ion\_rep : T}
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] The code will then automatically perform a SinglePoint and a
conduction calculation in the implicit solvent, using the same
solvation cavity for both the ground state and the conduction state
calculation. This is achieved by writing .vacuum\_dkn and
.vacuum\_tightbox\_ngwfs files that are used to set up the solvation
cavity.
\end{DUlineblock}

If further conduction calculations are required using the same ground
state, for example in order to change the number of conduction states
converged, it is possible to change the Task to COND and include the
keyword is\_separate\_restart\_files: T. This triggers the use of the
.vacuum files to set up the correct solvation cavity at the beginning of
the COND calculation.


\subsection{Optical absorption spectra}
\label{\detokenize{conduction:optical-absorption-spectra}}
The calculation of matrix elements for the generation of optical
absorption spectra using Fermi’s golden rule has been implemented in
ONETEP following the method used in CASTEP, as outlined by
Pickard {[}Pickard1997{]}. Using the dipole approximation, the
imaginary component of the dielectric function is defined as

\phantomsection\label{\detokenize{conduction:equation-imag-diel}}\begin{equation}\label{equation:conduction:imag_diel}
\begin{split}\varepsilon_2\left(\omega\right)=\frac{2e^2\pi}{\Omega\epsilon_0}\sum_{\mathbf{k},v,c}\left|\langle\psi_{\mathbf{k}}^{c}|\mathbf{\hat{q}}\cdot\mathbf{r}|\psi_{\mathbf{k}}^{v}\rangle\right|^2\delta\left(E_{\mathbf{k}}^{c}-E_{\mathbf{k}}^{v}-\hbar\omega\right) ,\end{split}
\end{equation}
where \(v\) and \(c\) denote valence and conduction bands
respectively, \(|\psi_{\mathbf{k}}^{n}\rangle\) is the \(n\)th
eigenstate at a given \(\mathbf{k}\)-point with a corresponding
energy \(E_{\mathbf{k}}^n\), \(\Omega\) is the cell volume,
\(\mathbf{\hat{q}}\) is the direction of polarization of the photon
and \(\hbar\omega\) its energy. Currently only the \(\Gamma\)
point is included in the sum over \(\mathbf{k}\)-points.

As the position operator is ill-defined in periodic boundary conditions,
this should instead be calculated using a momentum operator formalism,
where the two are related via {[}Read1991{]}:
\begin{equation*}
\begin{split}\langle\phi_f|\mathbf{r}|\phi_i\rangle = \frac{1}{i\omega m}\langle\phi_f|\mathbf{p}|\phi_i\rangle + \frac{1}{\hbar\omega}\langle\phi_f|\left[\hat{V}_{nl},\mathbf{r}\right]|\phi_i\rangle .\end{split}
\end{equation*}
The commutator term can then be found using the
identity {[}Motta2010{]}:
\begin{equation*}
\begin{split}\begin{aligned}
&&\left(\nabla_\mathbf{k}+\nabla_\mathbf{k'}\right)\left[\int e^{-i\mathbf{k}\cdot\mathbf{r}} V_{nl}\left(\mathbf{r},\mathbf{r'}\right) e^{i\mathbf{k'}\cdot\mathbf{r'}} d\mathbf{r}\ d\mathbf{r'}\right] \\
&=&i\int e^{-i\mathbf{k}\cdot\mathbf{r}}\left[V_{nl}\left(\mathbf{r},\mathbf{r'}\right)\mathbf{r'}-\mathbf{r}V_{nl}\left(\mathbf{r},\mathbf{r'}\right)\right] e^{i\mathbf{k'}\cdot\mathbf{r'}} d\mathbf{r}\ d\mathbf{r'} \nonumber,\end{aligned}\end{split}
\end{equation*}
where the derivative can either be calculated directly or using finite
differences in reciprocal space. Once the matrix elements have been
calculated in this manner, they can then be used to form a weighted
density of states according to equation \eqref{equation:conduction:imag_diel}.


\subsection{Calculating optical absorption spectra in ONETEP}
\label{\detokenize{conduction:calculating-optical-absorption-spectra-in-onetep}}
The calculation of matrix elements for optical absorption spectra is
activated by setting COND\_CALC\_OPTICAL\_SPECTRA to true. The matrix
elements are then calculated at the end of a conduction calculation in
both the valence and joint valence-conduction NGWF basis sets. Various
options can be modified, including the choice of calculating the matrix
elements in either the position or momentum representation, using the
parameter COND\_SPEC\_CALC\_MOM\_MAT\_ELS. For accurate results, the
position operator should only be used for molecules, where the
conduction NGWFs are sufficiently small compared to the size of the unit
cell that they do not overlap with any periodic copies. If using the
momentum formulation, the default behaviour is to also calculate the
commutator between the nonlocal potential and the position operator,
although setting COND\_SPEC\_CALC\_NONLOC\_COMM will switch this off.
Additionally, the method of calculation of the commutator can be
specified using COND\_SPEC\_CONT\_DERIV, so that either a continuous
derivative or finite difference method is employed. If using the finite
difference option, the finite difference shifting parameter can also be
specified using COND\_SPEC\_NONLOC\_COMM\_SHIFT.


\subsubsection{Outputs}
\label{\detokenize{conduction:outputs}}
If the input filename is seed.dat then the matrix elements will be
written to seed\_val\_OPT\_MAT\_ELS.txt and
seed\_joint\_OPT\_MAT\_ELS.txt. These contain the matrix elements
between all states in the \(x\), \(y\) and \(z\) directions,
and the energies of each state, as well as the transition energy, are
also printed. For calculations in the momentum representation, the real
and imaginary components of the matrix element are printed in the
additional two columns at the end.

{[}Clark2005{]} S. J. Clark, M. D. Segall, C. J. Pickard, P. J. Hasnip, M. J. Probert, K. Refson and M. C. Payne, Z. Kristallogr. \sphinxstylestrong{220}, 567 (2005).

{[}Skylaris2005{]} C.-K. Skylaris, P. D. Haynes, A. A. Mostofi and M. C. Payne, J. Phys. Condens. Matter \sphinxstylestrong{17}, 5757 (2005).

{[}Godby1986{]} R. W. Godby, M. Schlüter and L. J. Sham, Phys. Rev. Lett \sphinxstylestrong{56}, 2415 (1986).

{[}Gygi1989{]} F. Gygi and A. Baldereschi, Phys. Rev. Lett \sphinxstylestrong{62}, 2160 (1989).

{[}Ratcliff2011{]} L. E. Ratcliff, N. D. M. Hine and P. D. Haynes \sphinxstyleemphasis{In Preparation} (2011).

{[}Pickard1997{]} C. J. Pickard, Ph.D. thesis, University of Cambridge (1997).

{[}Read1991{]} A. J. Read and R. J. Needs, Phys. Rev. B \sphinxstylestrong{44}, 13071 (1991).

{[}Motta2010{]} C. Motta, M. Giantomassi, M. Cazzaniga, K. Gal-Nagy and X. Gonze, Comput. Mater. Sci. \sphinxstylestrong{50}, 698 (2010).


\section{Finite-temperature DFT calculations using the Ensemble-DFT method}
\label{\detokenize{onetep_edft_documentation:finite-temperature-dft-calculations-using-the-ensemble-dft-method}}\label{\detokenize{onetep_edft_documentation::doc}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Álvaro Ruiz Serrano, University of Southampton

\item[{Author}] \leavevmode
Extended to spin relaxation by Kevin Duff, University of Cambridge

\item[{Author}] \leavevmode
Extended to include Grand Canonical Ensemble by Arihant Bhandari, University of Southampton

\item[{Author}] \leavevmode
Extended to include Pulay mixing and input trial step by Gabriel Bramley, University of Southampton

\item[{Date}] \leavevmode
August 2013

\item[{Date}] \leavevmode
Extended by Kevin Duff April 2018

\item[{Date}] \leavevmode
Extended by Arihant Bhandari September 2020

\item[{Date}] \leavevmode
Extended by Gabriel Bramley November 2020

\end{description}\end{quote}


\subsection{Basic principles}
\label{\detokenize{onetep_edft_documentation:basic-principles}}
This manual describes how to run finite-temperature calculations using
ONETEP. A recent implementation uses a direct minimisation technique
based on the Ensemble-DFT method
{[}Marzari1997{]}. The Helmholtz free energy
functional is minimised in two nested loops. The inner loop performs a
line-search in the space of Hamiltonian matrices (in a similar fashion
as described in Ref. {[}Freysoldt2009{]}), for
a fixed set of NGWFs. Then, the outer loop optimises the NGWFs psinc
expansion coefficients for a fixed density kernel. For a more detailed
description and discussion of this method in ONETEP, see Ref.
{[}Ruiz-Serrano2013{]}.

Using the NGWF representation, the Helmholtz free energy functional
becomes:

\phantomsection\label{\detokenize{onetep_edft_documentation:equation-freeenergy2}}\begin{equation}\label{equation:onetep_edft_documentation:freeenergy2}
\begin{split}\begin{aligned}
A_{\mathcal{T}}\left[{\left\lbrace H_{\alpha\beta} \right\rbrace},{\left\lbrace \lvert\phi_\alpha\rangle \right\rbrace}\right]
= E\left[{\left\lbrace H_{\alpha\beta} \right\rbrace},{\left\lbrace \lvert\phi_\alpha\rangle \right\rbrace}\right] -
{\mathcal{T}}S\left[{\left\lbrace f_i \right\rbrace}\right].\end{aligned}\end{split}
\end{equation}
where \({\left\lbrace H_{\alpha\beta} \right\rbrace}\) is the NGWF
representation of the Hamiltonian matrix,
\({\left\lbrace \lvert\phi_\alpha\rangle \right\rbrace}\) is the current
set of NGWFs, \({\mathcal{T}}\) is the electronic temperature,
\(E\left[{\left\lbrace H_{\alpha\beta} \right\rbrace},{\left\lbrace \lvert\phi_\alpha\rangle \right\rbrace}\right]\)
is the energy functional and
\(S\left[{\left\lbrace f_i \right\rbrace}\right]\) is an entropy
term. The occupancies of the Kohn-Sham states,
\({\left\lbrace f_i \right\rbrace}\) are calculated from the energy
levels, \({\left\lbrace \epsilon_i \right\rbrace}\), using the
Fermi-Dirac distribution:
\begin{equation*}
\begin{split}\label{eq:fermidirac}
 f_i\left(\epsilon_i\right) = \left( 1 + \exp\left[\dfrac{\epsilon_i -
 \mu}{{k_\textrm{B}}{\mathcal{T}}}\right] \right)^{-1}.\end{split}
\end{equation*}
where \(\mu\) is the Fermi level. To obtain the energy eigenvalues,
\({\left\lbrace \epsilon_i \right\rbrace}\), the Hamiltonian matrix
is diagonalised as:
\begin{equation*}
\begin{split}\label{eq:hamdiag}
 H_{\alpha\beta} {M^\beta_i} = S_{\alpha\beta} {M^\beta_i} \epsilon_i,\end{split}
\end{equation*}
where \({\left\lbrace S_{\alpha\beta} \right\rbrace}\) are the
elements of the NGWF overlap matrix, and
\({\left\lbrace {M^\beta_i} \right\rbrace}\) are the
expansion coefficients of the Kohn-Sham eigenstates in the NGWF basis
set. At the moment, this is a cubic-scaling operation that requires
dealing dense matrices, which makes it memory-demanding.


\subsection{Free- and fixed-spin EDFT}
\label{\detokenize{onetep_edft_documentation:free-and-fixed-spin-edft}}
By default in spin polarized runs, the total occupancy of each spin
channel is held fixed; each spin channel has its own Fermi level
determined by this constraint. Alternatively the whole system can be
held at one Fermi level dictated by the conservation of the total number
of electrons in the system, allowing the net spin to freely relax.

Free-spin EDFT should be appropriate for most applications unless
there’s a reason to hold the system fixed at a given net spin. As with
any minimization with potentially many minima, the final state may
depend on initial conditions. As a special case, free-spin EDFT may not
be able to symmetry-break a system that wants to have any kind of spin
polarization but that is initialized to have 0 net spin. The general
advice for simple systems like basic ferromagnets (though this should
not replace good system-specific judgment) is to slightly over-specify
the expected net spin on each atom and hold the spin fixed for a few
iterations before being allowed to relax. For example a cobalt cluster
is expected to have a net spin per atom lower than that of an isolated
atom, that decreases to bulk-like as a function of cluster size. A good
initialization may be to give each atom atomic-like net spin and hold
the net spin fixed for 3-5 NGWF CG iterations, then allow it to relax.


\subsection{Compilation}
\label{\detokenize{onetep_edft_documentation:compilation}}
By default, ONETEP is linked against the Lapack library
{[}lapack\_web{]} for linear algebra. The Lapack
eigensolver DSYGVX {[}DSYGVX{]}, can only be executed in
one CPU at a time. Therefore, EDFT calculations with Lapack are limited
to small systems (a few tens of atoms). Calculations on large systems
are possible if, instead, ONETEP is linked against ScaLapack library
{[}scalapack\_web{]} during compilation time. The ScaLapack
eigensolver, PDSYGVX, can be run in parallel using many CPUs
simultaneously. Moreover, ScaLapack can distribute the storage of dense
matrices across many CPUs, thus allowing to increase the total memory
allocated to a given calculation in a systematic manner, simply by
requesting more processors. For the compilation against ScaLapack to
take effect, the flag \sphinxcode{-DSCALAPACK} must be specified during the
compilation of ONETEP.


\subsection{Pulay Mixing EDFT}
\label{\detokenize{onetep_edft_documentation:pulay-mixing-edft}}
In default EDFT, the Hamiltonian is updated using a damped fixed point
update routine:
\begin{equation*}
\begin{split}\label{linearmixing}
     H_{\alpha\beta}^{(m+1)} = H_{\alpha\beta}^{(m)} + \lambda \,  R[H_{\alpha\beta}^{(m)}]\end{split}
\end{equation*}
Where the \(\lambda\) defines the mixing parameter and residual is
defined as:
\begin{equation*}
\begin{split}\label{residual}
    R[H_{\alpha\beta}^{(m)}] = \tilde{H}_{\alpha\beta}^{(m)} - H_{\alpha\beta}^{(m)}\end{split}
\end{equation*}
Where \(\tilde{H}_{\alpha\beta}^{(m)}\) is the diagonlised
Hamiltonian obtained at step m. At a sufficiently low value of
\(\lambda\), most systems will achieve convergence, but at an
increasingly slow rate as the system increases in size. Convergence can
be accelerated using quasi-Newton update methods such as Broyden or
Pulay methods, the latter of which is implemented in EDFT as an
alternative to the damped fixed point method.

The implementation in ONETEP uses a similar logic to other DFT
implementations of Pulay’s method, except the Hamiltonian is optimised
instead of the density:
\begin{equation*}
\begin{split}H_{\alpha\beta}^{(m+1)} =  \sum_{j=m-n+1}^{m} c_j H_{\alpha\beta}^{(j)} +  \lambda \sum_{j=m-n+1}^{m} c_j R[H_{\alpha\beta}^{(j)}]\end{split}
\end{equation*}
Where the history length is defined \(n\) and the co-efficients
\(c_j\) are obtained through the procedure outlined by Ref.
{[}Kresse1996{]}. For the systems tested, this method
leads to improved convergence, especially for larger metallic systems.
Further information can be found in Ref. {[}Woods2019{]}.


\subsection{Increased Calculation Speed Using Fixed Step Sizes}
\label{\detokenize{onetep_edft_documentation:increased-calculation-speed-using-fixed-step-sizes}}
As described in the Section on Pulay mixing, \(\lambda\) defines the step
length taken at each inner loop iteration. In the default algorithm, an
optimal \(\lambda\) value which gives the greatest decrease in the
Lagrangian is determined by a line search routine. Although this
improves the robustness of the algorithm, the line search requires two
or more energy evaluations per inner loop step to obtain the optimum
\(\lambda\) value. If \(\lambda\) varies very little over the
course of the calculation, this can double the computational expense of
each inner loop iteration for a negligible increase in the accuracy for
each step.

Alternatively, one can fix the \(\lambda\) to a reasonable value for
a significant speed-up by ensuring only one energy evaluation is
performed per inner loop iteration. However, this option is less robust
than the default line search algorithm, as the fixed \(\lambda\)
value may produce either sub-optimal energy decreases or energy
increases for certain steps. Furthermore, if \(\lambda\) is chosen
to be too high, your answer may diverge from the ground state by taking
several consecutive positive Lagrangian steps (A warning will be
provided if this occurs too often). Conversely, convergence will be very
slow if \(\lambda\) is chosen to be too low. \(\lambda\) is set
with the \sphinxcode{edft\_trial\_step} keyword, which switches from the line
search algorithm if greater than 0, and uses the fixed \(\lambda\)
value specified.

User input values of \(\lambda\) can be determined by running a
standard EDFT calculation for a single NGWF iteration with line search
and plotting the ’step’ value printed at each iteration (in VERBOSE
output mode). The safest option is to choose a value close to the
minimum step value, but a slightly higher value can be selected,
especially if larger step values are common. The first two steps of your
calculation choose \(\lambda\) with line search regardless of your
input, as optimal step sizes for these iterations are significantly
larger than subsequent inner loop iterations. As such, these two
iterations should be disregarded from your \(\lambda\) value
selection analysis. As step sizes which yield stable convergence are
system dependent, it is recommended to manually determine different
\(\lambda\) values for systems with large differences in species or
size.


\subsection{Commands for the inner loop}
\label{\detokenize{onetep_edft_documentation:commands-for-the-inner-loop}}

\subsubsection{Basic setup}
\label{\detokenize{onetep_edft_documentation:basic-setup}}\begin{itemize}
\item {} 
\sphinxcode{edft: T/F} {[}Boolean, default \sphinxcode{edft: F}{]}. If true, it enables
Ensemble-DFT calculations.

\item {} 
\sphinxcode{edft\_maxit: n} {[}Integer, default \sphinxcode{edft\_maxit: 10}{]}. Number of
EDFT iterations in the ONETEP inner loop.

\item {} 
\sphinxcode{edft\_smearing\_width: x units} {[}Real physical, default
\sphinxcode{edft\_smearing\_width: 0.1 eV}{]}. Sets the value of the smearing
width, \({k_\textrm{B}}{\mathcal{T}}\), of the Fermi-Dirac
distribution. It takes units of energy (eV, Hartree) or temperature.
For example, \sphinxcode{edft\_smearing\_width: 1500 K} will set
\({\mathcal{T}}=\) 1500 degree Kelvin.

\item {} 
\sphinxcode{edft\_update\_scheme: damp\_fixpoint/pulay\_mix} {[}Character, default
\sphinxcode{dft\_update\_scheme: damp\_fixpoint}{]}. Defines the mixing scheme for
EDFT in the ONETEP inner loop.

\item {} 
\sphinxcode{edft\_ham\_diis\_size: x} {[}Integer, default
\sphinxcode{edft\_ham\_diis\_size: 10}{]}. Specifies the maximum number of
Hamiltonians used from previous iterations to generate the new guess
through Pulay mixing.

\item {} 
\sphinxcode{spin: x} {[}Real, default \sphinxcode{spin: 0.0}{]}. For EDFT runs this value
does not need to be an integer. Because we are considering an
ensemble of states it can have any real value between
\(-\frac{n_\mathrm{elec}}{2}\) to \(\frac{n_\mathrm{elec}}{2}\). Make sure you
have enough bands to cover the more populated spin channel.

\item {} 
\sphinxcode{edft\_spin\_fix} {[}Integer, default \sphinxcode{edft\_spin\_fix: -1}{]}. Control
for whether the net spin of the system should remain fixed at
\sphinxcode{spin}, or relax during the run. Any negative number will fix the
net spin. Nonnegative numbers \(n\) will hold the net spin fixed
for \(n\) iterations then let it relax for the rest of the
calculation.

\item {} 
\sphinxcode{edft\_trial\_step} {[}Integer, default \sphinxcode{edft\_trial\_step: 0}{]}. Sets
the value of \(\lambda\), which fixes the step size in the EDFT
inner loop, and switches off the line search for optimum
\(\lambda\) values. If set to 0, the normal line search routine
is used.

\end{itemize}


\subsubsection{Tolerance thresholds}
\label{\detokenize{onetep_edft_documentation:tolerance-thresholds}}\begin{itemize}
\item {} 
\sphinxcode{edft\_free\_energy\_thres: x units} {[}Real physical, default
\sphinxcode{edft\_free\_energy\_thres: 1.0e-6 Ha/Atom}{]}. Maximum difference in the
Helmholtz free energy functional per atom between two consecutive
iterations.

\item {} 
\sphinxcode{edft\_energy\_thres: x units} {[}Real physical, default
\sphinxcode{edft\_energy\_thres: 1.0e-6 Ha/Atom}{]}. Maximum difference in the
energy functional per atom between two consecutive iterations.

\item {} 
\sphinxcode{edft\_entropy\_thres: x units} {[}Real physical, default
\sphinxcode{edft\_entropy\_thres: 1.0e-6 Ha/Atom}{]}. Maximum difference in the
entropy per atom functional between two consecutive iterations.

\item {} 
\sphinxcode{edft\_rms\_gradient\_thres: x} {[}Real, default
\sphinxcode{edft\_rms\_gradient\_thres: 1.0e-4}{]}. Maximum RMS gradient
\(\dfrac{d A_{\mathcal{T}}}{d f_i}\).

\item {} 
\sphinxcode{edft\_commutator\_thres: x units} {[}Real physical, default
\sphinxcode{edft\_commutator\_thres: 1.0e-5 Hartree}{]}. Maximum value of the
Hamiltonian-Kernel commutator.

\item {} 
\sphinxcode{edft\_fermi\_thres: x units} {[}Real physical, default
\sphinxcode{edft\_fermi\_thres: 1.0e-3 Hartree}{]}. Maximum change in the Fermi
energy between two consecutive iterations.

\end{itemize}


\subsubsection{Advanced setup}
\label{\detokenize{onetep_edft_documentation:advanced-setup}}\begin{itemize}
\item {} 
\sphinxcode{edft\_extra\_bands: n} {[}Integer, default
\sphinxcode{edft\_extra\_bands: -1}{]}. Number of extra energy bands. The total
number of bands is equal to the number of NGWFs plus
\sphinxcode{edft\_extra\_bands}. When set to a negative number, no extra bands
are added.

\item {} 
\sphinxcode{edft\_round\_evals: n} {[}Integer, default
\sphinxcode{edft\_round\_evals: -1}{]}. When set to a positive integer value, the
occupancies that result from the Fermi-Dirac distribution are rounded
to \sphinxcode{n} significant figures. This feature can reduce some numerical
errors arising from the grid-based representation of the NGWFs.

\item {} 
\sphinxcode{edft\_write\_occ: T/F} {[}Boolean, default \sphinxcode{edft\_write\_occ: F}{]}. Save
fractional occupancies in a file.

\item {} 
\sphinxcode{edft\_max\_step: x} {[}Real, default \sphinxcode{edft\_max\_step: 1.0}{]}. Maximum
step during the EDFT line search.

\end{itemize}


\subsection{Commands for the outer loop}
\label{\detokenize{onetep_edft_documentation:commands-for-the-outer-loop}}
The standard ONETEP commands for NGWF optimisation apply to the EDFT
calculations as well. The only flag that is different is:
\begin{itemize}
\item {} 
\sphinxcode{ngwf\_cg\_rotate: T/F} {[}Integer, default \sphinxcode{ngwf\_cg\_rotate: T}{]}.
This flag is always true in EDFT calculations. It ensures that the
eigenvectors \({M^\beta_i}\) are rotated to the new
NGWF representation once these are updated.

\end{itemize}


\subsection{Restarting an EDFT calculation}
\label{\detokenize{onetep_edft_documentation:restarting-an-edft-calculation}}\begin{itemize}
\item {} 
\sphinxcode{write\_hamiltonian: T/F} {[}Boolean, default
\sphinxcode{write\_hamiltonian: F}{]}. Save the last Hamiltonian matrix on a file.

\item {} 
\sphinxcode{read\_hamiltonian: T/F} {[}Boolean, default
\sphinxcode{read\_hamiltonian: F}{]}. Read the Hamiltonian matrix from a file, and
continue the calculation from this point.

\item {} 
\sphinxcode{write\_tightbox\_ngwfs: T/F} {[}Boolean, default
\sphinxcode{write\_tightbox\_ngwfs: T}{]}. Save the last NGWFs on a file.

\item {} 
\sphinxcode{read\_tightbox\_ngwfs: T/F} {[}Boolean, default
\sphinxcode{read\_tightbox\_ngwfs: F}{]}. Read the NGWFs from a file and continue
the calculation from this point.

\begin{DUlineblock}{0em}
\item[] If a calculation is intended to be restarted at some point in the
future, then run the calculation with
\item[] \sphinxcode{write\_tightbox\_ngwfs: T}
\item[] \sphinxcode{write\_hamiltonian: T}
\item[] to save the Hamiltonian and the NGWFs on disk. Two new files will
be created, with extensions \sphinxcode{.ham} and \sphinxcode{.tightbox\_ngwfs},
respectively. Then, to restart the calculation, set
\item[] \sphinxcode{read\_tightbox\_ngwfs: T}
\item[] \sphinxcode{read\_hamiltonian: T}
\item[] to tell ONETEP to read the files that were previously saved on
disk. Remember to keep a backup of the output of the first run
before restarting the calculation.
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] the density kernel is not necessary to restart an EDFT calculation.
However, it is necessary to calculate the electronic properties of
the system, once the energy minimisation has completed. To save the
density kernel on a file, set: \sphinxcode{write\_denskern: T}
\item[] to generate a \sphinxcode{.dkn} file containing the density kernel. To read
in the density kernel, set
\item[] \sphinxcode{read\_denskern: T}
\end{DUlineblock}

\end{itemize}


\subsection{Controlling the parallel eigensolver}
\label{\detokenize{onetep_edft_documentation:controlling-the-parallel-eigensolver}}
Currently, only the ScaLapack PDSYGVX parallel eigensolver is available.
A complete manual to this routine can be found by following the link in
Ref. {[}PDSYGVX{]}. If ONETEP is interfaced to ScaLapack,
the following directives can be used:
\begin{itemize}
\item {} 
\sphinxcode{eigensolver\_orfac: x} {[}Real, default
\sphinxcode{eigensolver\_orfac: 1.0e-4}{]}. Precision to which the eigensolver
will orthogonalise degenerate Hamiltonian eigenvectors. Set to a
negative number to avoid reorthogonalisation with the ScaLapack
eigensolver.

\item {} 
\sphinxcode{eigensolver\_abstol: x} {[}Real, default
\sphinxcode{eigensolver\_abstol: 1.0e-9}{]}. Precision to which the parallel
eigensolver will calculate the eigenvalues. Set to a negative number
to use ScaLapack defaults.

\end{itemize}

The abovementioned directives are useful in calculations where the
ScaLapack eigensolver fails to orthonormalise the eigenvectors. In such
cases, the following error will be printed in the input file:

\sphinxcode{(P)DSYGVX in subroutine dense\_eigensolve returned info= 2}.

\begin{DUlineblock}{0em}
\item[] Many times (although not always) this error might cause the
calculation to fail. If this situation occurs, set
\item[] \sphinxcode{eigensolver\_orfac: -1}
\item[] \sphinxcode{eigensolver\_abstol: -1}
\item[] in the input file and restart the calculation. ScaLapack will not
reorthonormalise the eigenvectors. Instead, an external Löwdin
orthonormalisation process {[}Lowdin1950{]} will be
triggered. This is usually more efficient for larger systems.
\end{DUlineblock}


\subsection{Grand Canonical Ensemble DFT}
\label{\detokenize{onetep_edft_documentation:grand-canonical-ensemble-dft}}
In simulations of electrochemical electrodes, the electrons can freely
exchange between the electrode and the electrical circuit. So, there is
no constraint on the number of electrons \(N\). Rather, the
electrode potential \(U\) is fixed, with respect to a reference
electrochemical potential \(\mu_{ref}\) which fixes the chemical
potential of electrons \(\mu\):
\begin{equation*}
\begin{split}\mu = \mu_{ref} -eU\end{split}
\end{equation*}
Typical experiments use a standard hydrogen electrode as the reference
electrode with \(\mu_{ref}^{SHE}=-4.44\) eV. Once the chemical
potential of electrons is fixed, the number of electrons changes as a
dependent variable according to the Fermi-Dirac distribution in eq. .
\begin{equation*}
\begin{split}N = \sum_i f_i\end{split}
\end{equation*}
Thermodynamically, this corresponds to switching the electrons from the
finite-temperature, fixed-number canonical ensemble to the
finite-temperature, fixed-potential grand-canonical ensemble.
Correspondingly, the relevant free energy minimized at equilibrium is
the grand potential {[}Sundararaman2017{]}:
\begin{equation*}
\begin{split}\Omega = A -\mu N\end{split}
\end{equation*}
The following keywords are used for the grand-canonical ensemble DFT:
\begin{itemize}
\item {} 
\sphinxcode{edft\_grand\_canonical: T/F} {[}Boolean, default
\sphinxcode{edft\_grand\_canonical: F}{]}. Switch to fixed-potential
grand-canonical ensemble.

\item {} 
\sphinxcode{edft\_reference\_potential: x units} {[}Real physical, default
\sphinxcode{edft\_reference\_potential: -4.44 eV}{]}. Set the reference potential
\(\mu_{ref}\). If no units are given, atomic units are
considered: Ha (hartrees).

\item {} 
\sphinxcode{edft\_electrode\_potential: x units} {[}Real physical, default
\sphinxcode{edft\_electrode\_potential: 0.0 V}{]}. Set the electrode potential
\(U\). If no units are given, atomic units are considered: Ha/e,
hartrees per elementary charge.

\item {} 
\sphinxcode{edft\_nelec\_thres: x} {[}Real, default
\sphinxcode{edft\_nelec\_thres: 1.0e-06 per atom}{]}. Convergence threshold on the
change in number of electrons per spin channel per atom.

\end{itemize}

{[}Sundararaman2017{]} R. Sundararaman, W. Goddard, and T. Arias. J. Chem. Phys., 146(11):114104, 2017.

{[}Marzari1997{]} N. Marzari, D. Vanderbilt, and M. C. Payne. Phys. Rev. Lett., 79(7):1337\textendash{}1340, 1997.

{[}Freysoldt2009{]} C. Freysoldt, S. Boeck, and J. Neugebauer. Phys. Rev. B, 79(24):241103, 2009.

{[}Ruiz-Serrano2013{]} A. Ruiz-Serrano and C.-K. Skylaris. A variational method for density functional theory calculations on metallic systems with thousands of atoms. J. Chem. Phys., 139(5):054107, 2013.

{[}Lapack\_web{]} Lapack. \sphinxurl{http://www.netlib.org/lapack/}.

{[}DSYGVX{]} Lapack DSYGVX eigensolver. \sphinxurl{http://netlib.org/lapack/double/dsygvx.f}.

{[}Scalapack\_web{]} ScaLapack. \sphinxurl{http://www.netlib.org/scalapack/}.

{[}PDSYGVX{]} ScaLapack PDSYGVX eigensolver. \sphinxurl{http://www.netlib.org/scalapack/double/pdsygvx.f}.

{[}Lowdin1950{]} Per-Olov Lowdin. On the non-orthogonality problem connected with the use of atomic wave functions in the theory of molecules and crystals. J. Chem. Phys., 18(3):365\textendash{}375, 1950.

{[}Kresse1996{]} G. Kresse and J. Furthmüller. Efficient iterative schemes for \sphinxstyleemphasis{ab initio} total-energy calculations using a plane-wave basis set. Phys. Rev. B, 54:11169, 1996.

{[}Woods2019{]} N. Woods, M. Payne and P. Hasnip. Computing the self-consistent field in Kohn\textendash{}Sham density functional theory J. Phys. Condens. Matter, 31:453001, 2019.


\section{Running linear-scaling DFT calculations for metallic systems with the AQUA-FOE method}
\label{\detokenize{AQUA-FOE::doc}}\label{\detokenize{AQUA-FOE:running-linear-scaling-dft-calculations-for-metallic-systems-with-the-aqua-foe-method}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Jolyon Aarons, University of Southampton

\item[{Author}] \leavevmode
Chris-Kriton Skylaris, University of Southampton

\end{description}\end{quote}

This is a guide to performing FOE calculations on metals in ONETEP using
the EDFT functionality. The methodology will be explained briefly, but
for detailed information about how these methods work and are
implemented, appropriate references are presented. We provide a example
calculation, walk through and input files at the end of this document.
Finally, to perform these calculations, a recent (as of 2018) version of
ONETEP is required, for instance version 4.5.4.4, or the upcoming
version 5.0.


\subsection{Metals in ONETEP}
\label{\detokenize{AQUA-FOE:metals-in-onetep}}
Calculations on conductors have been possible in ONETEP with EDFT since
2013. In its default mode, EDFT will perform a diagonalisation of the
Hamiltonian matrix and form the density kernel matrix from the
eigenvectors and a Fermi-Dirac occupancy function of the eigenvalues. If
your calculations have fewer than 1000 atoms, this mode is probably your
best option. The method scales cubically with system size, however, and
when you have a few thousand atoms calculations are impractically slow
on current supercomputers.

On larger systems, it is possible that you will have sufficient sparsity
in the Hamiltonian matrix that a Fermi-Operator-Expansion based approach
to constructing the density kernel will be faster. The idea behind this
approach is that a power series expansion of the Fermi-Dirac
distribution function can be applied directly to the Hamiltonian matrix,
as matrix multiplications are linear operations. Hence, the density
kernel matrix can be constructed from matrix powers of the Hamiltonian
matrix, without diagonalisation. The main caveat with this is that
sparsity must be exploited, or such a method is likely to be slower than
the diagonalisation based alternative, due to the many matrix
multiplications that are required. Since sufficient sparsity is only
obtained for metals with more than about 1000 atoms, we recommend the
use of this method only for larger systems.

The way that we apply the matrix analogue of the Fermi-Dirac
distribution function,
\begin{equation*}
\begin{split}K=[I+\mathrm{exp}((H-\mu I)\,\beta)\,]^{-1},\end{split}
\end{equation*}
without diagonalisation or the poor conditioning of applying the above
operations directly is to firstly compute an expansion of a system of
electrons at an integer multiple (\(2^n\)) of the electronic
temperature, so that:

\phantomsection\label{\detokenize{AQUA-FOE:equation-khot}}\begin{equation}\label{equation:AQUA-FOE:khot}
\begin{split}K^\mathrm{HOT}=[I+\mathrm{exp}((H-\mu I)\beta/2^{n})\, ] \,^{-1}.\end{split}
\end{equation}
The advantage of applying an expansion to hotter electrons is that the
argument of the exponential function is reduced in magnitude, so fewer
terms in expansion of the Fermi-Dirac distribution function are needed
for a good approximation. In practice, we use a low order Chebyshev
approximation to equation \eqref{equation:AQUA-FOE:khot}. To recover \(K\), the density
kernel matrix at the target temperature, we need to anneal
\(K^\mathrm{HOT}\) by halving the temperature, \(n-1\) times.
This can be achieved by applying the matrix analogue of the hyperbolic
tangent double angle formula after noting that
\begin{equation*}
\begin{split}K^\mathrm{HOT}=\frac{1}{2}\left (I+\mathrm{tanh}\left((H-\mu I) \frac{\beta}{2^{n+1}}\right) \right ).\end{split}
\end{equation*}
The annealing formula is given as:

\phantomsection\label{\detokenize{AQUA-FOE:equation-anneal}}\begin{equation}\label{equation:AQUA-FOE:anneal}
\begin{split}K^\mathrm{HOT/2}=\frac{1}{2}\left( \frac{4K^\mathrm{HOT}-2I}{I + (2K^{\mathrm{HOT}}-I)^2}+I \right),\end{split}
\end{equation}
which we do not apply directly in practice (this would cost 1 matrix
product and 1 matrix solve / inversion), but expand equation
\eqref{equation:AQUA-FOE:anneal} as another Chebyshev polynomial expansion, which is cheaper
due to equation \eqref{equation:AQUA-FOE:anneal} being very well conditioned (we know that
the eigenvalues of the denominator are necessarily between 1.0 and 2.0).

The application of equation \eqref{equation:AQUA-FOE:khot} assumes that we know the chemical
potential, \(\mu\). In practice, we do not. We instead start with a
trial chemical potential and improve \(K\) in the sense that we
drive it towards the electron conserving chemical potential. We achieve
this by knowing how wrong we were at a given \(\mu_i\),
\begin{equation*}
\begin{split}\Delta N_e=N_e - \mathrm{trace}\left(K(\mu_i)\right),\end{split}
\end{equation*}
and by using hyperbolic trigonometry to correct by this by a change in
chemical potential, \(\Delta\mu\) without recalculating the
expansion:
\begin{equation*}
\begin{split}\left[I+\exp\left \{ (H-\mu I)\beta\pm\beta\Delta\mu I\right \}\right ]^{-1}=\frac{1}{2}\left(I+\frac{2K\pm\tanh\left(\frac{\beta\Delta\mu}{2}\right)I -I}
{I\pm \tanh\left(\frac{\beta\Delta\mu}{2}\right)\times\left(2K-I\right)}\right).\end{split}
\end{equation*}
Likewise with this equation, we do not apply it directly but expand it
as a Chebyshev polynomial to avoid an inversion. Once again, this works
well because we know that this is a well conditioned problem. To know
how much to adjust the chemical potential we can use the derivative:
\begin{equation*}
\begin{split}\frac{\partial{N_e}}{\partial{\mu}}=-\frac{\beta}{4}\left(1-\mathrm{trace}(K^2)\right),\end{split}
\end{equation*}
and the electron residual \(\Delta N_e\).

The final piece in this puzzle is to construct the electronic entropy,
which we find as a matrix, taking its trace to find the scalar
electronic entropy. We avoid calculating the Entropy as

\phantomsection\label{\detokenize{AQUA-FOE:equation-entropymatrix}}\begin{equation}\label{equation:AQUA-FOE:entropymatrix}
\begin{split}\mathbf{\mathcal{S}}=
\mathrm{tr}[
\mathbf{K}\ \mathrm{ln}(\mathbf{K})+[\mathbf{I}-\mathbf{K}]\
\mathrm{ln}(\mathbf{I}-\mathbf{K})] \,\,,\end{split}
\end{equation}
because this involves calculating two expensive matrix logarithms.
Instead we use a further expansion for this quantity, this time taking
that of the Fermi-Dirac entropy expression. When expanding this
expression as a Chebyshev expansion, many terms are required to reach a
good approximation at zero and one occupancy. To avoid this problem, we
expand a form which maintains the property that the single particle
entropy is zero at zero and one occupancy with fewer terms. This is:

\phantomsection\label{\detokenize{AQUA-FOE:equation-entapp}}\begin{equation}\label{equation:AQUA-FOE:entapp}
\begin{split}s(x) \simeq ax^2 + \frac{b}{c + dx -dx^2} - e -ax =y(x),\end{split}
\end{equation}
where \(a=1.96056\), \(b=0.0286723\), \(c=0.114753\),
\(d=1.98880\) and \(e=0.249860\). We then refine this with
further expansions.

In practice, because sparsity is imposed on the density kernel and
entropy matrices, we do not have perfectly accurate implicit
eigenvalues. Some of these may be above one, so when taking large powers
of the matrix, as we do in the power expansion of equation \eqref{equation:AQUA-FOE:entapp},
the (implicit) eigenvalues of the entropy may explode, causing a
problem. To detect and avoid this problem, we use a very simple
quadratic approximation to the entropy.

The quadratic
\begin{equation*}
\begin{split}f(x) = 3x^2 - 3x,\end{split}
\end{equation*}
the coefficients of 3 minimise the integral of
\(x*Ln(x) + (1-x)*Ln(1-x) - cx^2 - cx\) over {[}0:1{]}. The maximum
error of this approximation is at \(x=0.5\), where the error is
0.05685 or 8.2\% of the correct value at 0.5. This indicates that in the
very worst case where every eigenvalue of \(\mathbf{KS}\) is 0.5,
then the error on the entropy from this approximation is 8.2\%. The value
of this is that \(\mathbf{KSKS}\) is easy to calculate reliably,
compared with a high order series expansion… i.e. if there is an
eigenvalue of K which is a little above 1 because of noise due to
truncation, the corresponding eigenvalues in the entropy matrix can be
very large. This can accumulate in the entropy value, if there are many
of these greater than 1 eigenvalues, to give a completely wrong value.
We can, therefore, check the value of entropy we have calculated by
comparing it with this quadratic approximation. If the absolute
difference between the two values is less than 8.2 the high order value,
then we assume that things have gone well and do nothing. If this is not
the case, then there was a high amount of error accumulated and so we’ll
print a warning and a refined quadratic approximation (a quartic).

In practice, when we take all of these power expansions, we need to
consider the tensorial transformation properties of the quantities we
are considering, for instance: the Hamiltonian matrix,
\(H_{\alpha\beta}\) is covariant, so taking a power requires that we
raise the appropriate indices using the metric
: \((H_{\alpha\beta})^n=(H_{\alpha\gamma}S^{\gamma\delta})^{n} S_{\delta\beta}\).
In practice we can do this in one of two ways, either invert the metric
/ overlap matrix \(S^{\alpha\beta}=(S_{\alpha\beta})^{-1}\) and
multiply by the Hamiltonian to give a Hamiltonian matrix in the natural
representation (contra-covariant) or solve an approximate problem in the
style of Haydock \sphinxstyleemphasis{et al} {[}Gibson1993{]}. We then need
to store the mixed contra-covariant Hamiltonian matrix, which we choose
to represent in the sparsity pattern suggested by Haydock \sphinxstyleemphasis{et al}. This
is the covariant Hamiltonian matrix sparsity pattern by default, but the
user may specify an optional argument to effectively increase the
interaction regions of this sparsity pattern with respect to the
covariant case.

More information on our method may be found in
{[}Aarons2018{]}.


\subsection{Setting up a Calculation}
\label{\detokenize{AQUA-FOE:setting-up-a-calculation}}
The most important thing to understand firstly is that this method is
probably only sensible for large metallic systems. If your system has a
band-gap, it would be wise to explore standard insulating ONETEP (LNV)
first. This method should still work, but LNV ought to be much faster.

The calculation should perform EDFT as the electronic minimiser. Please
set

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{EDFT} \PYG{p}{:} \PYG{n}{T}
\end{sphinxVerbatim}

in your input file. As you will be performing a finite electronic
temperature calculation with the Fermi-Dirac occupancy distribution
function, it would also be wise to choose an electronic smearing
(temperature). The default value is 0.1 eV, which may well be sufficient
in your case. Please bear in mind that with FOE enabled, unlike with
EDFT with diagonalisation the calculation is likely to be faster with
higher electronic temperature. Depending on the property you wish to
probe, you may get away with a higher temperature, but it is very
unlikely that the smearing should be above 1.0 eV. Set the smearing as

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{EDFT\PYGZus{}SMEARING\PYGZus{}WIDTH} \PYG{p}{:} \PYG{l+m+mf}{0.25} \PYG{n}{eV} \PYG{o}{.}
\end{sphinxVerbatim}

You may also at this point wish to set some EDFT stopping criteria, as
the defaults are likely to be too tight for EDFT with FOE. It is
possible to tweak the FOE options to get under tight thresholds, but at
the expense of reduced performance.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{EDFT\PYGZus{}FREE\PYGZus{}ENERGY\PYGZus{}THRES} \PYG{p}{:} \PYG{l+m+mf}{1e\PYGZhy{}5} \PYG{n}{Ha}
\PYG{n}{EDFT\PYGZus{}COMMUTATOR\PYGZus{}THRES} \PYG{p}{:} \PYG{l+m+mf}{1e\PYGZhy{}4}
\end{sphinxVerbatim}

should be quite realistic in most cases and will certainly serve as an
adequate starting point.

The number of extra bands parameter in EDFT should always be set to the
maximum, which is done by setting:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{EDFT\PYGZus{}EXTRA\PYGZus{}BANDS} \PYG{p}{:} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}
\end{sphinxVerbatim}

This should be sufficient for the EDFT part of the calculation, next we
will need to configure the FOE. Firstly, please enable it in your
calculation with

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{FOE} \PYG{p}{:} \PYG{n}{T}
\end{sphinxVerbatim}

This alone will perform a FOE calculation as we have described in this
document, but unless you have already set a kernel truncation, then your
density kernel matrix will be dense and you might as well just run a
normal EDFT calculation with diagonalisation. One possible exception to
this is if you do not have access to Scalapack or a ONETEP binary
compiled against Scalapack, or your Scalapack distribution is poorly
optimised or broken. In this case it may still be preferable to avoid
the diagonalisation.

To achieve some sparsity in the density kernel matrix, we have various
options and strategies.
\begin{enumerate}
\item {} 
\begin{DUlineblock}{0em}
\item[] Just to use a geometric kernel truncation:
\item[] Here we enforce a simple sparsity pattern on the density kernel
matrix by ensuring that matrix elements resulting from NGWFs on
atoms separated by a large enough distance are zero.
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{kernel\PYGZus{}cutoff} \PYG{p}{:} \PYG{l+m+mi}{20} \PYG{n}{Ang}
\end{sphinxVerbatim}

a larger value will result in a more accurate answer, but also give a
less sparse matrix which will have performance implications. This
parameter is material-dependent and you are encouraged to play with
it to find a happy medium.

\item {} 
Use a sparsity pattern inspired by the power series expansions which
we use extensively in the FOE methods. The FOE method is based on the
idea that we only need a finite number of terms in the power
expansion to get sufficient accuracy. In the same spirit, we can
truncate the expansion to give a sparsity pattern of the density
kernel matrix as a low order power of the Hamiltonian matrix. In
ONETEP, this can currently be set to be the squared power by using:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{H2DENSKERN\PYGZus{}SPARSITY} \PYG{p}{:} \PYG{n}{T}
\end{sphinxVerbatim}

\end{enumerate}

If you opt for the second option, then the quadratic order term in the
expansion may not be a sufficiently accurate sparsity pattern to achieve
the accuracy you were hoping for, but higher order powers are likely to
be too dense to be useful and are not exposed to the user. Instead to
reach your desired tolerances, we recommend you consider using the
radius multiplier option.

This option extends the effective range of the Hamiltonian matrix (when
represented in contra-covarient, mixed form (as described above) and the
density kernel matrix is formed from the square of this increased range
matrix. The option is given in terms of a multiplier, which multiplies
the NGWF radius to produce the resulting sparsity patterns. This option
increases accuracy at the expense of performance and it is up to you as
a user to find an appropriate value. A starting point may be around 1.2
to 1.5 times:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{CONTRACOHAM\PYGZus{}RADMULT} \PYG{p}{:} \PYG{l+m+mf}{1.2}
\end{sphinxVerbatim}

It is worth pointing out here that you must also ensure your calculation
is converged with respect to plane wave kinetic energy cutoff and NGWF
radius, as well as number of NGWFs per atom. If you do opt for
Hamiltonian matrix squared sparsity in the density kernel matrix,
however, you will find that NGWF radius plays a particularly big role in
the accuracy of your calculation. This is because it is effectively the
parameter which controls the sparsity of your density kernel in this
mode. Increasing the radius multiplier will be cheaper (to an extent)
than increasing the NGWF radii, but you should make sure that your NGWF
radii are sufficient first!

The final parameter which is important to achieve your tolerances is the
\(\mu\)-tolerance in the chemical potential search. In practice this
should be \sphinxstyleemphasis{at least} an order of magnitude smaller than your EDFT energy
tolerances. You may find that you can improve the performance of your
calculations by adjusting this, but you will find that the gains will be
minor, because the number of extra matrix multiplications near to
convergence is minimal compared with the number far from the correct
chemical potential. This is set as:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{FOE\PYGZus{}MU\PYGZus{}TOL} \PYG{p}{:} \PYG{l+m+mf}{1e\PYGZhy{}6} \PYG{n}{eV}
\end{sphinxVerbatim}

Beyond this, there is little else to know, from a user perspective about
performing FOE calculations in ONETEP. A general point is that these
calculations tend to be expensive. If you are running a metallic system
which is big enough to exhibit exploitable sparsity in its density
kernel matrix, then you are probably looking at a system with thousands
of atoms. In this case you will need to be running on a supercomputer
and using a parallel version of ONETEP with as many cores as you can
use.

If you are looking for ways to speed up your calculations, look at
OpenMP / MPI parallelism rather than just MPI, also try to optimise your
convergence criteria to have the lowest values you can get away with
while maintaining your desired level of accuracy. You may also want to
look at the option of using fixed NGWFs and only optimising the density
kernel. If you go down this route, please ensure that you use a multiple
\(\zeta\) set of NGWFs and probably polarisation functions. All of
these extra points are really general ONETEP comments and information on
them can be found in the other tutorials on the ONETEP website.


\subsection{An Example}
\label{\detokenize{AQUA-FOE:an-example}}
As an example we will set up a single-point energy calculation on bulk
Magnesium, using PAW. We’ll opt for a decent cut-off energy of 700 eV
and the PBE exchange-correlation functional.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{task} \PYG{n}{singlepoint}
\PYG{n}{cutoff\PYGZus{}energy} \PYG{l+m+mi}{700} \PYG{n}{eV}
\PYG{n}{charge} \PYG{l+m+mi}{0}
\PYG{n}{xc\PYGZus{}functional} \PYG{n}{PBE}
\PYG{n}{paw} \PYG{p}{:} \PYG{n}{T}
\end{sphinxVerbatim}

We need to enable EDFT and set it up as we have described:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
!EDFT
edft : T
edft\PYGZus{}smearing\PYGZus{}width: 0.5 eV
edft\PYGZus{}maxit: 10
\end{sphinxVerbatim}

10 EDFT iterations may be too few, and 0.5 eV smearing may be too hot
for production calculations, but for the sake of a demonstration, they
speed things up a bit.

We also should opt for as much threading as we can get away with because
this will be made use of in every matrix product:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
!THEADING
threadsmax 8
threadsperfftbox 1
threadsnumfftboxes 8
threadspercellfft 8
threadsnummkl 8
\end{sphinxVerbatim}

For instance, if your supercomputer has two 8 core processors per node,
you could opt for 8-way OpenMP maximally, although in practice, you
might want to reduce this to 4-way, if you need the MPI ranks.

Now lets save some matrices and information:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
! properties
 do\PYGZus{}properties F

! I/O
 output\PYGZus{}detail VERBOSE
 timings\PYGZus{}level 1
 write\PYGZus{}xyz T
 write\PYGZus{}denskern T
 read\PYGZus{}denskern F
 write\PYGZus{}tightbox\PYGZus{}ngwfs T
 read\PYGZus{}tightbox\PYGZus{}ngwfs F
 write\PYGZus{}hamiltonian T
 read\PYGZus{}hamiltonian F
\end{sphinxVerbatim}

In practice it is a good idea to write everything, in case you need to
continue this calculation, but in the extreme case where your NGWFs and
matrices are too big to write to disk (not enough space or it’s taking
too long) then you can disable this.

Now we can set up NGWF optimisation:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
! NGWF optimization
 k\PYGZus{}zero 2.5
 maxit\PYGZus{}ngwf\PYGZus{}cg 25
\end{sphinxVerbatim}

and FOE:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{foe} \PYG{p}{:} \PYG{n}{T}
\PYG{n}{dense\PYGZus{}foe} \PYG{p}{:} \PYG{n}{F}
\PYG{n}{H2DENSKERN\PYGZus{}SPARSITY} \PYG{p}{:} \PYG{n}{T}
\end{sphinxVerbatim}

Before setting up the Mg:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species}
 \PYG{n}{Mg} \PYG{n}{Mg} \PYG{l+m+mi}{12} \PYG{l+m+mi}{4} \PYG{l+m+mf}{8.0}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}atomic\PYGZus{}set}
\PYG{n}{Mg} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{SOLVE}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}atomic\PYGZus{}set}
\end{sphinxVerbatim}

for instance. Or, if you wanted to set maxit\_ngwf\_cg to be zero and
run a fixed NGWF calculation, you could run a multiple \(\zeta\) +
polarisation calculation with:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species}
 \PYG{n}{Mg} \PYG{n}{Mg} \PYG{l+m+mi}{12} \PYG{l+m+mi}{13} \PYG{l+m+mf}{8.0}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species}

 \PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}atomic\PYGZus{}set}
\PYG{n}{Mg} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{SOLVE conf=2s2 2p6 3s2 3p0\textbar{}P}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}atomic\PYGZus{}set}
\end{sphinxVerbatim}

For more info on this, please see the pseudoatomic solver tutorial. Add
the PAW data:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}pot}
\PYG{n}{Mg} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{mg\PYGZus{}pbe\PYGZus{}v1\PYGZus{}abinit.paw}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}pot}
\end{sphinxVerbatim}

Finally lets add a simulation cell and some atoms:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{BLOCK} \PYG{n}{lattice\PYGZus{}cart}
\PYG{n}{ang}
 \PYG{l+m+mf}{13.2119999999999997}   \PYG{l+m+mf}{0.0000000000000213}   \PYG{l+m+mf}{0.0000000000000213}
  \PYG{l+m+mf}{0.0000000000000000}  \PYG{l+m+mf}{10.8379999999999992}   \PYG{l+m+mf}{0.0000000000000175}
  \PYG{l+m+mf}{0.0000000000000000}   \PYG{l+m+mf}{0.0000000000000000}  \PYG{l+m+mf}{10.4299999999999997}
\PYG{o}{\PYGZpc{}}\PYG{n}{ENDBLOCK} \PYG{n}{lattice\PYGZus{}cart}

\PYG{o}{\PYGZpc{}}\PYG{n}{BLOCK} \PYG{n}{positions\PYGZus{}abs}
\PYG{n}{ang}
\PYG{n}{Mg}         \PYG{l+m+mf}{3.30300}        \PYG{l+m+mf}{1.99300}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{1.65100}        \PYG{l+m+mf}{4.70200}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{3.30300}        \PYG{l+m+mf}{0.11500}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{1.65100}        \PYG{l+m+mf}{2.82500}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{0.00000}        \PYG{l+m+mf}{1.99300}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{4.95400}        \PYG{l+m+mf}{4.70200}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{0.00000}        \PYG{l+m+mf}{0.11500}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{4.95400}        \PYG{l+m+mf}{2.82500}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{3.30300}        \PYG{l+m+mf}{1.99300}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{1.65100}        \PYG{l+m+mf}{4.70200}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{3.30300}        \PYG{l+m+mf}{0.11500}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}         \PYG{l+m+mf}{1.65100}        \PYG{l+m+mf}{2.82500}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}         \PYG{l+m+mf}{0.00000}        \PYG{l+m+mf}{1.99300}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{4.95400}        \PYG{l+m+mf}{4.70200}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{0.00000}        \PYG{l+m+mf}{0.11500}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}         \PYG{l+m+mf}{4.95400}        \PYG{l+m+mf}{2.82500}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}         \PYG{l+m+mf}{3.30300}        \PYG{l+m+mf}{7.41200}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{1.65100}       \PYG{l+m+mf}{10.12100}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{3.30300}        \PYG{l+m+mf}{5.53400}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{1.65100}        \PYG{l+m+mf}{8.24400}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{0.00000}        \PYG{l+m+mf}{7.41200}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{4.95400}       \PYG{l+m+mf}{10.12100}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{0.00000}        \PYG{l+m+mf}{5.53400}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{4.95400}        \PYG{l+m+mf}{8.24400}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{3.30300}        \PYG{l+m+mf}{7.41200}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{1.65100}       \PYG{l+m+mf}{10.12100}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{3.30300}        \PYG{l+m+mf}{5.53400}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}         \PYG{l+m+mf}{1.65100}        \PYG{l+m+mf}{8.24400}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}         \PYG{l+m+mf}{0.00000}        \PYG{l+m+mf}{7.41200}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{4.95400}       \PYG{l+m+mf}{10.12100}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{0.00000}        \PYG{l+m+mf}{5.53400}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}         \PYG{l+m+mf}{4.95400}        \PYG{l+m+mf}{8.24400}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}         \PYG{l+m+mf}{9.90900}        \PYG{l+m+mf}{1.99300}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{8.25700}        \PYG{l+m+mf}{4.70200}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{9.90900}        \PYG{l+m+mf}{0.11500}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{8.25700}        \PYG{l+m+mf}{2.82500}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{6.60600}        \PYG{l+m+mf}{1.99300}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}        \PYG{l+m+mf}{11.56000}        \PYG{l+m+mf}{4.70200}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{6.60600}        \PYG{l+m+mf}{0.11500}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}        \PYG{l+m+mf}{11.56000}        \PYG{l+m+mf}{2.82500}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{9.90900}        \PYG{l+m+mf}{1.99300}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{8.25700}        \PYG{l+m+mf}{4.70200}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{9.90900}        \PYG{l+m+mf}{0.11500}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}         \PYG{l+m+mf}{8.25700}        \PYG{l+m+mf}{2.82500}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}         \PYG{l+m+mf}{6.60600}        \PYG{l+m+mf}{1.99300}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}        \PYG{l+m+mf}{11.56000}        \PYG{l+m+mf}{4.70200}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{6.60600}        \PYG{l+m+mf}{0.11500}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}        \PYG{l+m+mf}{11.56000}        \PYG{l+m+mf}{2.82500}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}         \PYG{l+m+mf}{9.90900}        \PYG{l+m+mf}{7.41200}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{8.25700}       \PYG{l+m+mf}{10.12100}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{9.90900}        \PYG{l+m+mf}{5.53400}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{8.25700}        \PYG{l+m+mf}{8.24400}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{6.60600}        \PYG{l+m+mf}{7.41200}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}        \PYG{l+m+mf}{11.56000}       \PYG{l+m+mf}{10.12100}        \PYG{l+m+mf}{0.00000}
\PYG{n}{Mg}         \PYG{l+m+mf}{6.60600}        \PYG{l+m+mf}{5.53400}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}        \PYG{l+m+mf}{11.56000}        \PYG{l+m+mf}{8.24400}        \PYG{l+m+mf}{2.60800}
\PYG{n}{Mg}         \PYG{l+m+mf}{9.90900}        \PYG{l+m+mf}{7.41200}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{8.25700}       \PYG{l+m+mf}{10.12100}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{9.90900}        \PYG{l+m+mf}{5.53400}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}         \PYG{l+m+mf}{8.25700}        \PYG{l+m+mf}{8.24400}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}         \PYG{l+m+mf}{6.60600}        \PYG{l+m+mf}{7.41200}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}        \PYG{l+m+mf}{11.56000}       \PYG{l+m+mf}{10.12100}        \PYG{l+m+mf}{5.21500}
\PYG{n}{Mg}         \PYG{l+m+mf}{6.60600}        \PYG{l+m+mf}{5.53400}        \PYG{l+m+mf}{7.82300}
\PYG{n}{Mg}        \PYG{l+m+mf}{11.56000}        \PYG{l+m+mf}{8.24400}        \PYG{l+m+mf}{7.82300}
\PYG{o}{\PYGZpc{}}\PYG{n}{ENDBLOCK} \PYG{n}{positions\PYGZus{}abs}
\end{sphinxVerbatim}

{[}Gibson1993{]} A. Gibson, R. Haydock and J. P. LaFemina. \sphinxstyleemphasis{Ab initio electronic-structure computations with the recursive method}, Phys. Rev. B. \sphinxstylestrong{47}, 9229 (1993)

{[}Aarons2018{]} J. Aarons and C.-K. Skylaris. \sphinxstyleemphasis{Electronic annealing Fermi operator expansion for DFT calculations on metallic systems}, J. Chem. Phys. \sphinxstylestrong{148}, 074107 (2018)


\section{Density mixing (Kernel-DIIS)}
\label{\detokenize{onetep_kernel_diis_documentation::doc}}\label{\detokenize{onetep_kernel_diis_documentation:density-mixing-kernel-diis}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Álvaro Ruiz Serrano, University of Southampton

\end{description}\end{quote}


\subsection{Basic principles}
\label{\detokenize{onetep_kernel_diis_documentation:basic-principles}}
This manual describes how to run density mixing (kernel DIIS)
calculations in ONETEP. Currently, kernel DIIS is an alternative to the
LNV density kernel optimisation in the ONETEP inner loop (where the
NGWFs are fixed). Please note that:
\begin{itemize}
\item {} 
The current code is experimental and might be unstable.

\item {} 
Kernel DIIS currently can only perform calculations on insulators,
where the constraint of idempotency of the density matrix holds
(i.e., the Kohn-Sham occupancies are integers, 1 for the valence
states and 0 for the conductions states.)

\item {} 
Kernel DIIS is cubic-scaling, always, even if the density matrix is
truncated and localised.

\item {} 
Use only in the rare occasions where LNV optimisation might not be
optimal.

\end{itemize}

Density mixing is a type of self-consistent cycle used to minimise the
total energy of the system. Currently, there are two types of mixing
implemented in ONETEP: density kernel mixing or Hamiltonian mixing. In
both cases, Hamiltonian diagonalisation is required, which makes the
method cubic-scaling. The current implementation includes the linear
mixing, ODA mixing {[}Cances2000{]}, {[}Cances2001{]}, Pulay mixing
{[}Pulay1980{]}, LiSTi {[}Wang2011{]} and LiSTb
{[}Chen2011{]} mixing schemes. Pulay, LiSTi and LiSTb offer
the best performance of all, but they must be used in conjunction with
linear mixing in order to obtain numerical stability.


\subsection{Compilation}
\label{\detokenize{onetep_kernel_diis_documentation:compilation}}
By default, ONETEP is linked against the Lapack library
{[}Lapack\_web{]} for linear algebra. The Lapack
eigensolver DSYGVX {[}DSYGVX{]}, can only be executed in
one CPU at a time. Therefore, kernel DIIS calculations with Lapack are
limited to small systems (a few tens of atoms). Calculations on large
systems are possible if, instead, ONETEP is linked against ScaLapack
library {[}Scalapack\_web{]} during compilation time. The
ScaLapack eigensolver, PDSYGVX {[}PDSYGVX{]}, can be run
in parallel using many CPUs simultaneously. Moreover, ScaLapack can
distribute the storage of dense matrices across many CPUs, thus allowing
to increase the total memory allocated to a given calculation in a
systematic manner, simply by requesting more processors. For the
compilation against ScaLapack to take effect, the flag \sphinxcode{-DSCALAPACK}
must be specified during the compilation of ONETEP.


\subsection{Commands for the inner loop}
\label{\detokenize{onetep_kernel_diis_documentation:commands-for-the-inner-loop}}

\subsubsection{Mixing schemes}
\label{\detokenize{onetep_kernel_diis_documentation:mixing-schemes}}
\begin{DUlineblock}{0em}
\item[] The keyword
\item[] \sphinxcode{kernel\_diis\_scheme: string}  {[}String, default \sphinxcode{kernel\_diis\_scheme: NONE}{]}
\end{DUlineblock}

is used to select the mixing method during the kernel-DIIS loop. By
default, this keyword takes the value “\sphinxcode{NONE}”, which disables kernel
DIIS and tells the program to proceed with the LNV optimisation. The
following options are available:
\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{kernel\_diis\_scheme: DKN\_LINEAR}
\item[] linear mixing of density kernels. The new input density kernel is
built from the \sphinxstyleemphasis{in} and \sphinxstyleemphasis{out} density kernels of the current
iteration as
\(K_in^{n+1} = (1-\lambda) K_{in}^{n} + \lambda K_{out}^{n}\).
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{kernel\_diis\_scheme: HAM\_LINEAR}
\item[] linear mixing of Hamiltonians. The new input Hamiltonian is built
from the and \sphinxstyleemphasis{out} Hamiltonians of the current iteration as
\(H_in^{n+1} = (1-\lambda) H_{in}^{n} + \lambda H_{out}^{n}\).
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{kernel\_diis\_scheme: DKN\_PULAY}
\item[] Pulay mixing of density kernels (see Ref.
{[}Pulay1980{]}). The new input density kernel is
built as a linear combination of the \sphinxstyleemphasis{output} density kernels of
the \(N_{mix}\) previous iterations as
\(K_in^{n+1} = \sum_{m=n-N_mix}^{n} \lambda_m
K_{out}^{m}\). Pulay mixing requires the storage of \(N_{mix}\)
matrices.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{kernel\_diis\_scheme: HAM\_PULAY}
\item[] Pulay mixing of Hamiltonians (see Ref.
{[}Pulay1980{]}). The new input Hamiltonian is built
as a linear combination of the \sphinxstyleemphasis{output} Hamiltonians of the
\(N_{mix}\) previous iterations as
\(H_in^{n+1} = \sum_{m=n-N_mix}^{n} \lambda_m H_{out}^{m}\).
Pulay mixing requires the storage of \(N_{mix}\) matrices.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{kernel\_diis\_scheme: DKN\_LISTI}
\item[] LiSTi mixing of density kernels (see Ref.
{[}Wang2011{]}). The new input density kernel is built
as a linear combination of the \sphinxstyleemphasis{output} density kernels of the
\(N_{mix}\) previous iterations as
\(K_in^{n+1} = \sum_{m=n-N_mix}^{n} \lambda_m K_{out}^{m}\).
LiSTi mixing requires the storage of \(4\times N_{mix}\)
matrices.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{kernel\_diis\_scheme: HAM\_LISTI}
\item[] LiSTi mixing of Hamiltonians (see Ref. {[}Wang2011{]}).
The new input Hamiltonian is built as a linear combination of the
\sphinxstyleemphasis{output} Hamiltonians of the \(N_{mix}\) previous iterations as
\(H_in^{n+1} = \sum_{m=n-N_mix}^{n} \lambda_m H_{out}^{m}\).
LiSTi requires the storage of \(4\times N_{mix}\) matrices.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{kernel\_diis\_scheme: DKN\_LISTB}
\item[] LiSTb mixing of density kernels (see Ref.
{[}Chen2011{]}). The new input density kernel is built
as a linear combination of the \sphinxstyleemphasis{output} density kernels of the
\(N_{mix}\) previous iterations as
\(K_in^{n+1} = \sum_{m=n-N_mix}^{n} \lambda_m K_{out}^{m}\).
LiSTb mixing requires the storage of \(4\times N_{mix}\)
matrices.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{kernel\_diis\_scheme: HAM\_LISTB}
\item[] LiSTb mixing of Hamiltonians (see Ref. {[}Chen2011{]}).
The new input Hamiltonian is built as a linear combination of the
\sphinxstyleemphasis{output} Hamiltonians of the \(N_{mix}\) previous iterations as
\(H_in^{n+1} = \sum_{m=n-N_mix}^{n} \lambda_m H_{out}^{m}\).
LiSTb mixing requires the storage of \(4\times N_{mix}\)
matrices.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{kernel\_diis\_scheme: DIAG}
\item[] Hamiltonian diagonalisation only - no mixing takes place. Strongly
NOT recommended.
\end{DUlineblock}

\end{itemize}

\sphinxstylestrong{NOTE}: linear mixing can be used simultaneously with Pulay, LiSTi or
LiSTb mixing to create a history of density kernels/Hamiltonians with
optimal numerical properties. See the keywords \sphinxcode{kernel\_diis\_coeff} and
\sphinxcode{kernel\_diis\_linear\_iter} in the section on basic principles  for more information.


\subsubsection{Basic setup: controlling the mix}
\label{\detokenize{onetep_kernel_diis_documentation:basic-setup-controlling-the-mix}}\begin{itemize}
\item {} 
\sphinxcode{kernel\_diis\_coeff: x} {[}Real, default
\sphinxcode{kernel\_diis\_coeff: 0.1}{]}. Linear-mixing \(\lambda\)
coefficient. Must be in the range \(\left[0,1\right]\). If set to
a negative value, the ODA method (see Refs.
{[}Cances2000{]}, {[}Cances2001{]}) will automatically calculate
the optimal value of \(\lambda\). The value of
\sphinxcode{kernel\_diis\_coeff} can be made arbitrarily small in order to
attain numerical stability. However, this can make convergence slow.
A small value can be used in order to create a history of matrices
before Pulay, LiSTi or LiSTb mixing. A value close to 1 will make the
calculation potentially unstable.

\item {} 
\sphinxcode{kernel\_diis\_linear\_iter: n} {[}Integer, default
\sphinxcode{kernel\_diis\_linear\_iter: 5}{]}. Number of linear mixing iterations
before Pulay, LiSTi or LiSTb mixing. This keyword will create and
store a history of \sphinxcode{n} previous matrices generated by linear mixing
before Pulay, LiSTi or LiSTb mixing begin. Required for large systems
in order to achieve stability.

\item {} 
\sphinxcode{kernel\_diis\_size: n} {[}Integer, default
\sphinxcode{kernel\_diis\_size: 10}{]}. Number of matrices (\(N_{mix}\)) to be
mixed with the Pulay, LiSTi or LiSTb schemes.

\item {} 
\sphinxcode{kernel\_diis\_maxit: n} {[}Integer, default
\sphinxcode{kernel\_diis\_maxit: 25}{]}. Maximum number of iterations during the
density mixing inner loop.

\end{itemize}


\subsubsection{Tolerance thresholds}
\label{\detokenize{onetep_kernel_diis_documentation:tolerance-thresholds}}\begin{itemize}
\item {} 
\sphinxcode{kernel\_diis\_threshold: x} {[}Real, default
\sphinxcode{kernel\_diis\_threshold: 1.0e-9}{]}. Numerical convergence threshold
for the DIIS inner loop. Use in conjunction with
\sphinxcode{kernel\_diis\_conv\_criteria}.

\item {} 
\sphinxcode{kernel\_diis\_conv\_criteria: string} {[}String, default
\sphinxcode{kernel\_diis\_conv\_criteria: 1000}{]}. Select the convergence criteria
for the DIIS inner loop.\sphinxcode{kernel\_diis\_conv\_criteria} takes a
string value 4 characters long. Each position acts as a logical
switch, and can only take the values “\sphinxcode{1}” (on) or “\sphinxcode{0}” (off).
The order is the following:
\begin{itemize}
\item {} 
Position 1: residual \(|K_{out} - K_{in}|\), if density kernel
mixing, or \(|H_{out}-H_{in}|\), if Hamiltonian mixing.

\item {} 
Position 2: Hamiltonian-density kernel commutator.

\item {} 
Position 3: band-gap variation between two consecutive iterations
(in Hartree).

\item {} 
Position 4: total energy variation between two consecutive
iterations (in Hartree).

\end{itemize}

For example, \sphinxcode{kernel\_diis\_conv\_thres: 1101} will enable criteria
1,2 and 4 and disable criterion 3.

\end{itemize}


\subsubsection{Advanced setup: level shifter}
\label{\detokenize{onetep_kernel_diis_documentation:advanced-setup-level-shifter}}
Extra stability can sometimes be achieved if the conduction energy
values are artificially increased. This technique is known as
level-shifting. See Ref. {[}Saunders1973{]}
for further details.
\begin{itemize}
\item {} 
\sphinxcode{kernel\_diis\_lshift: x units} {[}Real physical, default
\sphinxcode{kernel\_diis\_lshift: 1.0 Hartree}{]}. Energy shift of the conduction
bands.

\item {} 
\sphinxcode{kernel\_diis\_ls\_iter: n} {[}Integer, default
\sphinxcode{kernel\_diis\_ls\_iter: 0}{]}. Total number of DIIS iterations with
level-shifting enabled.

\end{itemize}


\subsection{Commands for the outer loop}
\label{\detokenize{onetep_kernel_diis_documentation:commands-for-the-outer-loop}}
The standard ONETEP commands for NGWF optimisation apply.


\subsection{Restarting a kernel DIIS calculation}
\label{\detokenize{onetep_kernel_diis_documentation:restarting-a-kernel-diis-calculation}}\begin{itemize}
\item {} 
\sphinxcode{write\_denskern: T/F} {[}Boolean, default \sphinxcode{write\_denskern: F}{]}. Save
the last density matrix on a file.

\item {} 
\sphinxcode{read\_denskern: T/F} {[}Boolean, default \sphinxcode{read\_denskern: F}{]}. Read
the density kernel matrix from a file, and continue the calculation
from this point.

\item {} 
\sphinxcode{write\_tightbox\_ngwfs: T/F} {[}Boolean, default
\sphinxcode{write\_tightbox\_ngwfs: T}{]}. Save the last NGWFs on a file.

\item {} 
\sphinxcode{read\_tightbox\_ngwfs: T/F} {[}Boolean, default
\sphinxcode{read\_tightbox\_ngwfs: F}{]}. Read the NGWFs from a file and continue
the calculation from this point.

\begin{DUlineblock}{0em}
\item[] If a calculation is intended to be restarted at some point in the
future, then run the calculation with
\item[] \sphinxcode{write\_tightbox\_ngwfs: T}
\item[] \sphinxcode{write\_denskern: T}
\item[] to save the density kernel and the NGWFs on disk. Two new files
will be created, with extensions \sphinxcode{.dkn} and \sphinxcode{.tightbox\_ngwfs},
respectively. Then, to restart the calculation, set
\item[] \sphinxcode{read\_tightbox\_ngwfs: T}
\item[] \sphinxcode{read\_denskern: T}
\item[] to tell ONETEP to read the files that were previously saved on
disk. Remember to keep a backup of the output of the first run
before restarting the calculation.
\end{DUlineblock}

\end{itemize}


\subsection{Controlling the parallel eigensolver}
\label{\detokenize{onetep_kernel_diis_documentation:controlling-the-parallel-eigensolver}}
Currently, only the ScaLapack PDSYGVX parallel eigensolver is available.
A complete manual to this routine can be found by following the link in
Ref. {[}PDSYGVX{]}. If ONETEP is interfaced to ScaLapack,
the following directives can be used:
\begin{itemize}
\item {} 
\sphinxcode{eigensolver\_orfac: x} {[}Real, default
\sphinxcode{eigensolver\_orfac: 1.0e-4}{]}. Precision to which the eigensolver
will orthogonalise degenerate Hamiltonian eigenvectors. Set to a
negative number to avoid reorthogonalisation with the ScaLapack
eigensolver.

\item {} 
\sphinxcode{eigensolver\_abstol: x} {[}Real, default
\sphinxcode{eigensolver\_abstol: 1.0e-9}{]}. Precision to which the parallel
eigensolver will calculate the eigenvalues. Set to a negative number
to use ScaLapack defaults.

\end{itemize}

The abovementioned directives are useful in calculations where the
ScaLapack eigensolver fails to orthonormalise the eigenvectors. In such
cases, the following error will be printed in the input file:

\sphinxcode{(P)DSYGVX in subroutine dense\_eigensolve returned info= 2}.

Many times (although not always) this error might cause the calculation
to fail.

{[}Cances2000{]} E. Cancès and C. Le Bris. Can we outperform the diis approach for electronic structure calculations? Int. J. Quantum Chem., 79(2):82, 2000.

{[}Cances2001{]} E. Cances. Self-consistent field algorithms for Kohn\textendash{}Sham models with fractional occupation numbers. J. Chem. Phys., 114(24):10616, 2001.

{[}Pulay1980{]} P. Pulay. Convergence acceleration of iterative sequences - the case of SCF iteration. Chem. Phys. Lett., 73(2):393, 1980.

{[}Wang2011{]} Y. A. Wang, C. Y. Yam, Y. K. Chen, and G. Chen. Linear-expansion shooting techniques for accelerating self-consistent field convergence. J. Chem. Phys., 134(24):241103, 2011.

{[}Chen2011{]} Y. K. Chen and Y. A. Wang. LISTb: a better direct approach to LIST. J. Chem. Theory Comput., 7(10):3045, 2011.

{[}Lapack\_web{]} Lapack. \sphinxurl{http://www.netlib.org/lapack/}.

{[}DSYGVX{]} Lapack DSYGVX eigensolver. \sphinxurl{http://netlib.org/lapack/double/dsygvx.f}.

{[}Scalapack\_web{]} ScaLapack. \sphinxurl{http://www.netlib.org/scalapack/}.

{[}PDSYGVX{]} ScaLapack PDSYGVX eigensolver. \sphinxurl{http://www.netlib.org/scalapack/double/pdsygvx.f}.

{[}Saunders1973{]} V. R. Saunders and I. H. Hillier. Level-shifting method for converging closed shell Hartree-Fock wave-functions. Int. J. Quantum Chem., 7(4):699, 1973.


\section{Empirical Dispersion Correction}
\label{\detokenize{VDW-correction::doc}}\label{\detokenize{VDW-correction:empirical-dispersion-correction}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Max Phipps, University of Southampton

\item[{Author}] \leavevmode
Arihant Bhandari, University of Southampton

\item[{Date}] \leavevmode
November 2020

\end{description}\end{quote}


\subsection{Theory}
\label{\detokenize{VDW-correction:theory}}

\subsubsection{Energy}
\label{\detokenize{VDW-correction:energy}}
The modification to the total DFT energy when correcting for
dispersion is given by,
\begin{quote}
\phantomsection\label{\detokenize{VDW-correction:equation-disp-corr}}\begin{equation}\label{equation:VDW-correction:disp_corr}
\begin{split}  E_{DFT-D} = E_{KS-DFT} + E_{disp}\end{split}
\end{equation}\end{quote}

where the dispersion energy correction is given by
raw-latex:{[}Vasp{]}, {[}Hill2009{]}:
\begin{quote}
\phantomsection\label{\detokenize{VDW-correction:equation-e-disp}}\begin{equation}\label{equation:VDW-correction:E_disp}
\begin{split}  E_{disp} = -\frac{1}{2}\cdot s_6\cdot \sum^{N_{at}}_{i=1} \sum^{N_{at}}_{j=1}
\sum_{L}^* \dfrac{C_{6,ij}}{R^6_{ij}} f_{damp}( R_{ij} ) g_{smooth}(R_{ij})\end{split}
\end{equation}\end{quote}

where:
\begin{itemize}
\item {} 
\(s_6\) is a DF-dependent global scaling factor,

\item {} 
\(C_{6,ij}\) is a dispersion coefficient for the atom pair
\(ij\),

\item {} 
\(L\) denotes all translations of the unit cell within the van
der Waals radial cutoff \(R_{cut}\),

\item {} 
\(*\) denotes \(i\ne j\) in \(L=0\)

\item {} 
\(R_{ij}\) is the distance \(| \overrightarrow{R^{0}_{i}} -
\overrightarrow{R^L_{j}} |\) between atom i in the parent cell
\(L=0\) and the atom j in all possible translations \(L\),

\item {} 
\(f_{damp}(R_{ij})\) is a damping function that is unity at large
distances and zero at small
distances {[}Hill2009{]}, {[}Grimme2006{]},

\item {} 
\(g_{smooth}(R_{ij})\) is smoothening function for truncating the
interactions beyond van der Waals radial cutoff.

\item {} 
The dispersion coefficients and the form of the damping function are
dependent upon the empirical vdW correction model adopted. The
damping functions for the different models are given below:

\end{itemize}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|\X{8}{100}|\X{40}{100}|\X{32}{100}|\X{20}{100}|}
\hline
\sphinxstylethead{\sphinxstyletheadfamily 
Index
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Description
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Damping function \(f_{damp}( R_{ij} )\)
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
vdW radii (\(R_{0,ij}\))
\unskip}\relax \\
\hline
1
&
Damping function of Elstner {[}Elstner2001{]}.
&
\((1-\exp(-c_{damp}(R_{ij}/R_{0,ij})^7))^4\)
&
\(\frac{{R_{0,i}}^3+{R_{0,j}}^3}{{R_{0,i}}^2+{R_{0,j}}^2}\)
\\
\hline
2
&
First damping function of Wu and Yang {[}Wu2002{]}.
&
\((1-\exp(-c_{damp}(R_{ij}/R_{0,ij})^3))^2\)
&
\(\frac{{R_{0,i}}^3+{R_{0,j}}^3}{{R_{0,i}}^2+{R_{0,j}}^2}\)
\\
\hline
3
&
Second damping function of Wu and Yang {[}Wu2002{]}.
&
\(\frac{1}{1+\exp(-c_{damp}(R_{ij}/R_{0,ij}-1))}\)
&
\(\frac{{R_{0,i}}^3+{R_{0,j}}^3}{{R_{0,i}}^2+{R_{0,j}}^2}\)
\\
\hline
4
&
Damping function of D2 correction of Grimme {[}Grimme2006{]}.
&
\(\frac{1}{1+\exp(-c_{damp}(R_{ij}/R_{0,ij}-1))}\)
&
\({R_{0,i}}+{R_{0,j}}\)
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

where \(c_{damp}\) is a damping constant (referred to as \(d\)
within the literature of Grimme {[}Grimme2006{]} and
\(c_{damp}\) by Hill {[}Hill2009{]}) and
\(R_{0,ij}\) is determined by the vdW radii of the atomic pair
\(i\) and \(j\).
\begin{itemize}
\item {} 
The smoothening function has the following form for all dispersion
models:
\begin{equation*}
\begin{split}g_{smooth}(R_{ij})=1-e^{-\left(R_{ij}-R_{cut}\right)^2}\end{split}
\end{equation*}
\item {} 
\begin{DUlineblock}{0em}
\item[] where, \(R_{cut}\) is the radial cutoff for van der Waals
interactions, and can be set by the following keyword in the input
file:
\item[] \sphinxcode{vdw\_radial\_cutoff: x units} {[}Real physical, default
\sphinxcode{vdw\_radial\_cutoff: 100 bohr}{]}.
\end{DUlineblock}

\end{itemize}


\subsubsection{Forces}
\label{\detokenize{VDW-correction:forces}}
During geometry optimization, the van der Waals forces are calculated
from the derivative of the dispersion energy with respect to the ionic
coordinates \(\{s_i\}\):
\begin{equation*}
\begin{split}\frac{\partial E_{disp}}{\partial s_i}  = -\frac{1}{2}\cdot s_6\cdot
\sum^{N_{at}}_{j=1} \sum_{L}^* \dfrac{C_{6,ij}}{R^6_{ij}} \left[f( R_{ij} )
g'(R_{ij})+g(R_{ij})\left(f'(R_{ij})-\frac{6f(R_{ij})}{R_{ij}}\right)\right]\frac{\partial
R_{ij}}{\partial s_i}\end{split}
\end{equation*}

\subsection{Activating the dispersion corrections}
\label{\detokenize{VDW-correction:activating-the-dispersion-corrections}}
Four vdW correction options have been implemented within ONETEP.
Activation of the vdW corrections within ONETEP is achieved using the

\sphinxcode{DISPERSION}

keyword followed by the dispersion index. eg. For the D2 correction of
Grimme {[}Grimme2006{]},

\sphinxcode{DISPERSION 4}

The exchange-correlation functionals available with optimized parameters
for the dispersion models are given below:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|\X{10}{100}|\X{20}{100}|\X{70}{100}|}
\hline
\sphinxstylethead{\sphinxstyletheadfamily 
Index
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Keyword
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Available XC functionals
\unskip}\relax \\
\hline
1
&
ELSTNER
&
BLYP, PBE, PW91, REVPBE, RPBE, XLYP.
\\
\hline
2
&
WUYANG1
&
BLYP, PBE, PW91, REVPBE, RPBE, XLYP.
\\
\hline
3
&
WUYANG2
&
BLYP, PBE, PW91, REVPBE, RPBE, XLYP.
\\
\hline
4
&
GRIMMED2
&
BLYP, PBE, B3LYP.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

The \(C_{6,ij}\) coefficients and the coefficients of the damping
function of dispersion corrections 1\textendash{}3 are optimized for each xc
functional to minimize the root mean square difference of the
interaction energy from the literature values for a selection of
dispersion-dominant biological complexes from the JSCH-2005 and S22
sets {[}Jurecka2006{]}\_{}` and the database of
Morgado {[}Morgado2007{]}. For the D2 correction of
Grimme the parameters are optimized as described in the
literature {[}Grimme2006{]}.

The \(s_6\) parameters are unity for dispersion corrections 1\textendash{}3 and
are fitted by least squares optimization of interaction energy error for
40 noncovalently bound complexes for the D2 correction of Grimme.

In the case of using an unoptimized functional not given within the
list, default unoptimized \(c_{damp}\), \(C_{6,ij}\)) and
\(R_{0,i}\) values are adopted for the damping functions of Elstner
or Wu and Yang as described by Hill {[}Hill2009{]} and a
default \(s_6\) value of 1.00 is adopted for Grimme’s D2 correction
model.


\subsection{Overriding dispersion correction parameters}
\label{\detokenize{VDW-correction:overriding-dispersion-correction-parameters}}
It is possible to override the default parameters of the dispersion
damping functions. This option allows the user to specify parameters for
elements and functionals for which values are not given. The
atom-dependent variables \(C_{6,i}\) (used to calculate
\(C_{6,ij}\)), \(R_{0,i}\) (related to the atomic vdW radius of
an atom \(i\)), and \(n_{eff}\) (used in the calculation of
\(C_{6,ij}\) for all damping functions excluding the D2 correction
of Grimme) are modified using the

\sphinxcode{vdw\_params}

block. This override block applies the parameter changes to atoms by
their atomic number (nzatom). eg. To override the dispersion parameters
associated with nitrogen,

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}block vdw\PYGZus{}params
! nzatom, c6coeff, radzero, neff
  7       21.1200  2.6200   2.5100
\PYGZpc{}endblock vdw\PYGZus{}params
\end{sphinxVerbatim}

To override the damping constant \(c_{damp}\) associated with a
damping function, the keyword

\sphinxcode{vdw\_dcoeff}

followed by the modified damping constant parameter is used. eg.

\sphinxcode{vdw\_dcoeff 11.0}


\subsection{Boundary Conditions}
\label{\detokenize{VDW-correction:boundary-conditions}}
The boundary conditions are set by the following keyword:

\sphinxcode{vdw\_bc P/O P/O P/O}

which accepts a string which should contain three characters (which may
be separated by spaces), specifying the BCs along the \(x\),
\(y\) and \(z\) directions of the simulation cell. ‘P’ for
periodic and ‘O’ for open. In case, the keyword is not specified, BCs
set same as

\sphinxcode{ion\_ion\_bc}.

{[}Vasp{]} \sphinxurl{https://www.vasp.at/wiki/index.php/DFT-D2}

{[}Hill2009{]} Q. Hill and C-K Skylaris, \sphinxstyleemphasis{Proc. R. Soc. A} 465(2103):669-683, 2009

{[}Grimme2006{]} S. Grimme, \sphinxstyleemphasis{J. Comput. Chem.} 27(15):1787-1799, 2006

{[}Elstner2001{]} M. Elstner, P. Hobza, T. Frauenheim, S. Suhai and E. Kaxiras, \sphinxstyleemphasis{J. Chem. Phys.} 114(12):5149-5155, 2001

{[}Wu2002{]} Q. Wu and W. Yang, \sphinxstyleemphasis{J. Chem. Phys.}, 116(2):515-524, 2002

{[}Jurecka2006{]} P. Jurečka, J. Šponer, J. Černýa and P. Hobza, \sphinxstyleemphasis{Phys. Chem. Chem. Phys.} 8:1985-1993, 2006

{[}Morgado2007{]} C. A. Morgado, J. P. McNamara, I. H. Hillier, N. A. Burton and M. A. Vincent \sphinxstyleemphasis{J. Chem. Theory Comput.} 3(5):1656-1664, 2007


\section{Using van der Waals Density Functionals}
\label{\detokenize{VDW-DF:using-van-der-waals-density-functionals}}\label{\detokenize{VDW-DF::doc}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Lampros Andrinopoulos, Imperial College London

\item[{Date}] \leavevmode
November 2012

\end{description}\end{quote}


\subsection{Activating vdW-DF}
\label{\detokenize{VDW-DF:activating-vdw-df}}
The van der Waals energy is calculated in ONETEP using the van der Waals
Density Functional method, developed by Dion \sphinxstyleemphasis{et al}
{[}Dion2004{]}.

The only input variable needed to activate the vdW-DF functional is to
set \sphinxcode{xc\_functional VDWDF}. If a \sphinxcode{vdW\_df\_kernel} file is not present
in the working directory, it will be automatically generated.


\subsection{Theory}
\label{\detokenize{VDW-DF:theory}}
The form for the exchange-correlation functional proposed by Dion \sphinxstyleemphasis{et
al} is:

\phantomsection\label{\detokenize{VDW-DF:equation-e-xc}}\begin{equation}\label{equation:VDW-DF:E_xc}
\begin{split}E_{xc} = E_{x}^{\rm{revPBE}} + E_c^{\rm{PW92}} + E_c^{\rm{nl}}\end{split}
\end{equation}
where the non-local exchange-correlation energy is given by:

\phantomsection\label{\detokenize{VDW-DF:equation-e-nl-dion}}\begin{equation}\label{equation:VDW-DF:E_nl_dion}
\begin{split}E_{c}^{\mathrm{nl}} = \frac{1}{2}\int\int d{\mathbf{r}}d{\mathbf{r}}'\rho({\mathbf{r}})\phi({\mathbf{r}},{\mathbf{r}}')\rho({\mathbf{r}}')\end{split}
\end{equation}
where \(\rho({\mathbf{r}})\) is the electron density at
\({\mathbf{r}}\) and \(\phi({\mathbf{r}},{\mathbf{r}}')\) is the
nonlocal exchange correlation kernel whose form is explained in
{[}Dion2004{]}.


\subsubsection{Non-local correlation energy}
\label{\detokenize{VDW-DF:non-local-correlation-energy}}
The direct calculation of the integral in the form of Eq. \eqref{equation:VDW-DF:E_nl_dion}
is very computationally expensive, as it involves a six-dimensional
spatial integral.

The algorithm proposed later by Roman-Perez and Soler
{[}Roman-Perez2009{]} improves the efficiency of the
calculation. They observed that with the form used by Dion \sphinxstyleemphasis{et al} for
\(\phi\), the above expression can be re-written as:
\begin{equation*}
\begin{split}E_{c}^{\mathrm{nl}} = \frac{1}{2}\int\int d{\mathbf{r}}d{\mathbf{r}}'\rho({\mathbf{r}})\phi(q,q',r)\rho({\mathbf{r}}')\end{split}
\end{equation*}
where \(r=|{\mathbf{r}}-{\mathbf{r}}'|\), and \(q\) and
\(q'\) are the values of a universal function
\(q_0[\rho({\mathbf{r}}),|\nabla \rho({\mathbf{r}})|]\) at
\({\mathbf{r}}\) and \({\mathbf{r}}'\). They thus proposed a way
to expand the kernel \(\phi\) using interpolating polynomials
\(p_\alpha(q)\) for chosen values \(q_\alpha\) of \(q\), and
tabulated functions \(\phi_{\alpha\beta}(r)\) for the kernel
corresponding to each pair of interpolating polynomials. The
interpolating polynomials \(p_{\alpha}\) are cubic splines that
evaluate to a Kronecker delta on each respective interpolating point. A
mesh of 20 interpolation points is used in Soler’s implementation. The
Soler form of the nonlocal energy can be written as:

\phantomsection\label{\detokenize{VDW-DF:equation-kernel}}\begin{equation}\label{equation:VDW-DF:kernel}
\begin{split}\phi(q_1,q_2,r) = \sum_{\alpha\beta}\phi_{\alpha\beta}(r) p_{\alpha}(q_1) p_{\beta}(q_2)\end{split}
\end{equation}
The universal function \(q_0({\mathbf{r}})\) is in practice given
by:

\phantomsection\label{\detokenize{VDW-DF:equation-q0}}\begin{equation}\label{equation:VDW-DF:q0}
\begin{split}q_0({\mathbf{r}}) = \Bigg(1 + \frac{\epsilon_c^{\rm{PW92}}}{\epsilon_x^{\rm{LDA}}} +
\frac{0.8491}{9}\Big(\frac{\nabla\rho}{2\rho k_F}\Big)^2\Bigg) k_F\end{split}
\end{equation}
with \(k_F=(3\pi^2\rho)^{1/3}\). The quantity \(q_0\) is first
“saturated” to limit its maximum value, according to:
\begin{equation*}
\begin{split}q_0^{\text{sat}}(\rho,{|\nabla{\rho}|}) = q_c \Bigg(1-\exp\Big(-\sum_{m=1}^{m_c}\frac{(q/q_c)^m}{m}\Big)\Bigg)\end{split}
\end{equation*}
where \(q_c\) is the maximum value of the mesh of
\(q_{\alpha}\).

To evaluate this, we first define a quantity
\(\theta_{\alpha}({\mathbf{r}}) = \rho({\mathbf{r}}) p_{\alpha}(q(\rho({\mathbf{r}}),\nabla\rho({\mathbf{r}}))\)
in real space. In terms of this, Eq. \eqref{equation:VDW-DF:E_nl_dion} can be written as:

\phantomsection\label{\detokenize{VDW-DF:equation-e-nl-real}}\begin{equation}\label{equation:VDW-DF:E_nl_real}
\begin{split}E_c^{\mathrm{nl}} = \frac{1}{2} \sum_{\alpha\beta} \int \int d{\mathbf{r}}d{\mathbf{r}}'
\theta_{\alpha}({\mathbf{r}}) \theta_{\beta}({\mathbf{r}}') \phi_{\alpha\beta}(r)\end{split}
\end{equation}
It can be shown that this can be written as a reciprocal space integral:

\phantomsection\label{\detokenize{VDW-DF:equation-e-nl}}\begin{equation}\label{equation:VDW-DF:E_nl}
\begin{split}    E_c^{\mathrm{nl}} = \frac{1}{2} \sum_{\alpha\beta}\int d\mathbf{k}
    \theta^{*}_{\alpha}(\mathbf{k})\theta_{\beta}(\mathbf{k})\phi_{\alpha\beta}(k)\end{split}
\end{equation}
Since the kernel is radially dependent in real space, it is only
dependent on the magnitude of the G-vectors, hence the kernel need only
be evaluated as a 1-dimensional function \(\phi_{\alpha\beta}(k)\)
for each \(\alpha\), \(\beta\).

The kernel \(\phi\) and its second derivatives are tabulated for a
specific set of radial points and transformed to reciprocal space. These
values are then used to interpolate the kernel at every point
\(\mathbf{k}\) in reciprocal space required to calculate Eq.
\eqref{equation:VDW-DF:E_nl}.


\subsubsection{Kernel}
\label{\detokenize{VDW-DF:kernel}}
This section details the evaluation of the NLXC kernel. The kernel
\(\phi({\mathbf{r}},{\mathbf{r}}')\) as specified by Dion \sphinxstyleemphasis{et al}
{[}Dion2004{]} is given by (in atomic units):
\begin{equation*}
\begin{split}\phi({\mathbf{r}},{\mathbf{r}}') = \frac{1}{\pi^2}\int_{0}^{\infty}a^2da
    \int_0^{\infty}b^2db W(a,b) T(\nu(a),\nu(b),\nu'(a),\nu'(b))\end{split}
\end{equation*}
where
\begin{equation*}
\begin{split}T(w,x,y,z) = \frac{1}{2}\Big[\frac{1}{w+x} + \frac{1}{y+z}\Big]\Big[\frac{1}{(w+y)(x+z)}+\frac{1}{(w+z)(y+x)}\Big],\end{split}
\end{equation*}
and
\begin{equation*}
\begin{split}\begin{aligned}
    W(a,b) = 2\Big[ & (3-a^2)b\cos b \sin a \\
                    + & (3-b^2)a\cos a \sin b   \\
                    + & (a^2+b^2-3)\sin a\sin b \\
                    - & 3ab\cos a \cos b \Big]/(a^3b^3),\end{aligned}\end{split}
\end{equation*}
and
\begin{equation*}
\begin{split}\nu(y) = 1- e^{-\gamma y^2/d^2}; \quad \nu'(y) = 1- e^{-\gamma y^2/d'^2};\end{split}
\end{equation*}
where \(d=|{\mathbf{r}}-{\mathbf{r}}'|q_0({\mathbf{r}})\),
\(d'=|{\mathbf{r}}-{\mathbf{r}}'|q_0(\mathbf{r'})\)

Following this chain of logic, it is clear that this the kernel can in
fact be considered as a function only of
\(|{\mathbf{r}}-{\mathbf{r}}'|\), \(q_0({\mathbf{r}})\) and
\(q_0({\mathbf{r}}')\), since all other variables are dummy
variables which are integrated over. The kernel can therefore be written
as

\phantomsection\label{\detokenize{VDW-DF:equation-phi-tab}}\begin{equation}\label{equation:VDW-DF:phi_tab}
\begin{split}\phi(r,q_0({\mathbf{r}}),q_0({\mathbf{r}}'))\end{split}
\end{equation}
This makes it possible to evaluate the integrals above so as to
tabulate the kernel values numerically for a pre-chosen set of radial
points and \(q_0\) values.


\subsubsection{Non-local potential}
\label{\detokenize{VDW-DF:non-local-potential}}
Starting from \eqref{equation:VDW-DF:E_nl}, one can evaluate the potential
\(v^{\mathrm{nl}}({\mathbf{r}})\) corresponding to this energy, by
evaluating all terms in \(\partial E_{\mathrm{nl}} /
\partial n({\mathbf{r}})\). The non-local potential
\(v_i^{\mathrm{nl}}\) at point \({\mathbf{r}}_i\) on the grid is
thus written explicitly in terms of the derivatives of the
\(\theta_{\alpha}\) quantities with respect to the values
\(\rho_j\) at all other points on the grid:

\phantomsection\label{\detokenize{VDW-DF:equation-v-nl}}\begin{equation}\label{equation:VDW-DF:v_nl}
\begin{split}v_i^{\mathrm{nl}} = \sum_{\alpha}(u_{\alpha i}{\frac{\partial{\theta_{\alpha i}}}{\partial{\rho_i}}}+\sum_j u_{\alpha j}
{\frac{\partial{\theta_{\alpha j}}}{\partial{\nabla\rho_j}}}{\frac{\partial{\nabla\rho_j}}{\partial{\rho_i}}})\end{split}
\end{equation}
This makes use of the quantities
\(u_\alpha({\mathbf{r}})= \sum_{\beta}\mathcal{F}(\theta_{\beta}(\mathbf{k})\phi_{\alpha\beta}(k))\):
which are already calculated in the evaluation of the energy.

Using the White and Bird {[}White1994{]} approach, Eq.
\eqref{equation:VDW-DF:v_nl} can be written as:

\phantomsection\label{\detokenize{VDW-DF:equation-v-nl-wnb}}\begin{equation}\label{equation:VDW-DF:v_nl_wnb}
\begin{split}v_{\mathrm{nl}}({\mathbf{r}}) = \sum_{\alpha} \Big(
  u_{\alpha}({\mathbf{r}}){\frac{\partial{\theta_{\alpha}({\mathbf{r}})}}{\partial{\rho({\mathbf{r}})}}}
  - \int\int i\mathbf{G}\cdot \frac{\nabla\rho({\mathbf{r}}')}{|\nabla\rho({\mathbf{r}}')|}
  {\frac{\partial{\theta_{\alpha}({\mathbf{r}}')}}{\partial{|\nabla\rho({\mathbf{r}}')|}}}e^{i\mathbf{G}\cdot ({\mathbf{r}}-{\mathbf{r}}')} d{\mathbf{r}}d\mathbf{G}
  \Big)\end{split}
\end{equation}
For this we need to calculate
\({\frac{\partial{\theta}}{\partial{\rho}}}\) and
\({\frac{\partial{\theta}}{\partial{{|\nabla{\rho}|}}}}\):

\phantomsection\label{\detokenize{VDW-DF:equation-dtheta-drho}}\begin{equation}\label{equation:VDW-DF:dtheta_drho}
\begin{split}\begin{aligned}
    {\frac{\partial{\theta_\alpha}}{\partial{\rho}}} &=p_\alpha + \rho {\frac{\partial{p_\alpha}}{\partial{\rho}}} \nonumber \\
                                               &=p_\alpha + \rho {\frac{\partial{p_\alpha}}{\partial{q}}}{\frac{\partial{q}}{\partial{\rho}}} \nonumber \\
                                               &=p_\alpha + \rho {\frac{\partial{p_\alpha}}{\partial{q}}} \frac{q}{k_F} {\frac{\partial{k_F}}{\partial{\rho}}} + \rho {\frac{\partial{p_\alpha}}{\partial{q}}} k_F ({\frac{\partial{{\varepsilon}_c}}{\partial{\rho}}}{\varepsilon}_x^{-1}-{\varepsilon}_c{\varepsilon}_x^{-2}{\frac{\partial{{\varepsilon}_x}}{\partial{\rho}}} - \frac{8}{3(3\pi^2)^{2/3}}\frac{Z}{4}(\nabla\rho)^2 \rho^{-11/3}) \nonumber \\
                                               &=p_\alpha + q/3{\frac{\partial{p_\alpha}}{\partial{q}}} + k_F\rho {\frac{\partial{p_\alpha}}{\partial{q}}} ({\frac{\partial{{\varepsilon}_c}}{\partial{\rho}}}{\varepsilon}_x^{-1}-{\varepsilon}_c{\varepsilon}_x^{-2}{\frac{\partial{{\varepsilon}_x}}{\partial{\rho}}}- \frac{2Z}{3(3\pi^2)^{2/3}} {|\nabla{\rho}|}^2\rho^{-11/3})\end{aligned}\end{split}
\end{equation}\phantomsection\label{\detokenize{VDW-DF:equation-dtheta-dgradrho}}\begin{equation}\label{equation:VDW-DF:dtheta_dgradrho}
\begin{split}    {\frac{\partial{\theta_\alpha}}{\partial{{|\nabla{\rho}|}}}} = \rho {\frac{\partial{p_\alpha}}{\partial{q}}} {\frac{\partial{q}}{\partial{{|\nabla{\rho}|}}}} = \frac{Z}{2\rho k_F} \rho {\frac{\partial{p_\alpha}}{\partial{q}}}{|\nabla{\rho}|}\end{split}
\end{equation}
Combining Eqs. \eqref{equation:VDW-DF:v_nl_wnb}, \eqref{equation:VDW-DF:dtheta_drho} and \eqref{equation:VDW-DF:dtheta_dgradrho} gives
us the final expression for the nonlocal potential.


\subsection{Overview of computational algorithm}
\label{\detokenize{VDW-DF:overview-of-computational-algorithm}}

\subsubsection{Module \sphinxstyleliteralintitle{nlxc\_mod}}
\label{\detokenize{VDW-DF:module-nlxc-mod}}
The main module for the calculation of the non-local energy and
potential is \sphinxcode{nlxc\_mod}. The tabulation of the kernel \(\phi\) is
performed only if a kernel file is not found, by \sphinxcode{vdwdf\_kernel}.

The input required to calculate the non-local energy and potential is
essentially just the density and its gradient on the fine grid. The
calculation of \(q\) and the Fourier transformed
\(\theta_\alpha\) from Eq. \eqref{equation:VDW-DF:E_nl} is performed first, in the
routine \sphinxcode{nlxc\_q0\_theta}. The derivatives of the
\(\theta_\alpha\)s with respect to the density and the module of
its gradient are calculated on-the-fly in the real-space loop for the
calculation of the non-local potential \(v_{nl}\) in Eq. \eqref{equation:VDW-DF:v_nl}. This
is to avoid storing unnecessary arrays. From Eq. \eqref{equation:VDW-DF:v_nl_wnb} two
transforms are required per \(\alpha\) value, a forward FFT,
followed by a backward FFT for calculating the non-local potential.

Subroutines to interpolate the polynomials as well as the kernel using
cubic splines are used (\sphinxcode{spline\_interp} and \sphinxcode{interpolate}). The
interpolating polynomials \(p_\alpha\) used are Kronecker deltas, so
they take the value 1 on the interpolating point and are zero at the
other points.


\subsubsection{Module \sphinxstyleliteralintitle{vdwdf\_kernel}}
\label{\detokenize{VDW-DF:module-vdwdf-kernel}}
The kernel \(\phi_{\alpha\beta}(k)\) is tabulated for 1024 radial
reciprocal space points and 20 \(q_0\) points. Gaussian quadrature
is used to calculate Eq. \eqref{equation:VDW-DF:phi_tab} and then the result is Fourier
transformed. The second derivatives of the kernel are calculated by
interpolation, and also tabulated. The default name of the file is
\sphinxcode{vdw\_df\_kernel}. The program will first check if this file exists: if
it does, it will be loaded in and need not be calculated. If it does
not, it will be generated from scratch (which only takes a few minutes)
and then it is written out for future re-use in the current working
directory.

\begin{DUlineblock}{0em}
\item[] The format of the \sphinxcode{vdw\_df\_kernel} file is:
\end{DUlineblock}


\bigskip\hrule\bigskip


\begin{DUlineblock}{0em}
\item[] \sphinxcode{N\_alpha}  \sphinxcode{N\_radial}
\item[] \sphinxcode{max\_radius}
\item[] \sphinxcode{q\_points(:)}
\item[] \sphinxcode{kernel(0:N\_radial,alpha,beta)}
\item[] \sphinxcode{kernel2(0:N\_radial,alpha,beta)}
\end{DUlineblock}

where \sphinxcode{kernel2} is the array of second derivatives of the kernel.

{[}Dion2004{]} M. Dion, H. Rydberg, E. Schröder, D. C. Langreth, and B. I. Lundqvist,
Phys. Rev. Lett. \sphinxstylestrong{92}, 246401 (2004).

{[}Roman-Perez2009{]} G. Román-Pérez and J. M. Soler, Phys. Rev. Lett. \sphinxstylestrong{103}, 096102 (2009).

{[}White1994{]} J. A. White and D. M. Bird, Phys. Rev. B \sphinxstylestrong{50}, 4954 (1994).


\section{Realspace local pseudopotential in ONETEP}
\label{\detokenize{realspace_local_pseudo:realspace-local-pseudopotential-in-onetep}}\label{\detokenize{realspace_local_pseudo::doc}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Jacek Dziedzic, University of Southampton

\item[{Author}] \leavevmode
Chris-Kriton Skylaris, University of Southampton

\end{description}\end{quote}


\subsection{Motivation}
\label{\detokenize{realspace_local_pseudo:motivation}}
In standard ONETEP the local pseudopotential is obtained in reciprocal
space by a discrete Fourier transform, by assuming the cell is
periodically repeated in space. However, there are certain use-cases,
where one is interested in the properties of an isolated (not
periodically repeated) system. This is especially true if other energy
terms, such the Hartree energy or the ion-ion energy are already
calculated with open boundary conditions, which is the case, e.g., for
implicit solvent calculations in ONETEP.


\subsection{Theory}
\label{\detokenize{realspace_local_pseudo:theory}}
Assume that \({v_{loc}\left(\vec{r}\right)}\) is located on an atom
\(A\) at a position \(\vec{R}_A\) and we want to determine the
contribution to the local pseudopotential coming from this atom. Owing
to the spherical symmetry of the potential, we have
\begin{equation*}
\begin{split}{v_{loc,A}\left(\vec{r}\right)}= v_{loc}\left(\vec{r}-\vec{R}_A\right) = v_{loc}\left(\vert\vec{r}-\vec{R}_A\vert\right).\end{split}
\end{equation*}
The local pseudopotential is given to us in terms of its continuous
Fourier coefficients,
\({\tilde{v}_{loc}\left(\vert\vec{g}\vert\right)}\), read from a
recpot file. To generate the pseudopotential at a point \(\vec{r}\)
in real space, we use the continuous Fourier transform:
\begin{equation*}
\begin{split}v_{loc}\left(\vec{r}-\vec{R}_A\right) = \frac{1}{{\left(2\pi\right)}^{3}}\int {\tilde{v}_{loc}\left(\vec{g}\right)}e^{i\vec{g}\cdot \left(\vec{r}-\vec{R}_A\right)}d\vec{g}=\int{\tilde{v}_{loc}\left(\vec{g}\right)}e^{i\vec{g}\cdot \vec{x}}d\vec{g},\end{split}
\end{equation*}
where we have set \(\vec{x}=\vec{r}-\vec{R}_A\). Expanding the
plane wave \(e^{i\vec{g}\cdot\vec{x}}\) in terms of localised
functions, we get
\begin{equation*}
\begin{split}{v_{loc,A}\left(\vec{r}\right)}=
\frac{1}{{\left(2\pi\right)}^{3}}
\int {\tilde{v}_{loc}\left(\vec{g}\right)}\cdot \left[ 4\pi
\sum_{l=0}^{\infty}
\sum_{m=-l}^{l} i^l
j_l\left( gx\right)
Z_{lm}\left(\Omega_{\vec{g}}\right)
Z_{lm}\left(\Omega_{\vec{x}}\right)
d\vec{g}
\right],\end{split}
\end{equation*}\phantomsection\label{\detokenize{realspace_local_pseudo:equation-eq4}}\begin{equation}\label{equation:realspace_local_pseudo:eq4}
\begin{split}{v_{loc,A}\left(\vec{r}\right)}=
\frac{1}{{\left(2\pi\right)}^{3}}
4\pi
\sum_{l=0}^{\infty}
\sum_{m=-l}^{l} i^l
Z_{lm}\left(\Omega_{\vec{x}}\right)
\underbrace{
\int {\tilde{v}_{loc}\left(\vec{g}\right)}j_l\left( gx\right)
Z_{lm}\left(\Omega_{\vec{g}}\right)
d\vec{g}}_{I_1}.\end{split}
\end{equation}
The orthogonality of harmonics means that all of the terms, except for
that of \(l=m=0\), disappear and, after a change of coordinates
(\(g^2\sin{\theta}\) being the Jacobian), we obtain a new expression
for the integral in (\eqref{equation:realspace_local_pseudo:eq4}):
\begin{equation*}
\begin{split}I_1=
\int\limits_{0}^{2\pi}
\int\limits_{0}^{\pi}
Z_{lm}\left(\Omega_{\vec{g}}\right)
Z_{00}
\sin{\theta}\,d\theta\,d\varphi
\cdot\int\limits_{0}^{\infty}{\tilde{v}_{loc}\left(g\right)}{}j_l\left( gx\right)g^2 dg.\end{split}
\end{equation*}
With \(Z_{00}=1/{\sqrt{4\pi}}\), the double integral simplifies to
1 and we obtain, after realizing that all terms except for \(l=0\)
disappear,
\begin{equation*}
\begin{split}{v_{loc,A}\left(\vec{r}\right)}=
\frac{1}{{\left(2\pi\right)}^{3}}
4\pi
\int {\tilde{v}_{loc}\left(g\right)}j_0\!\left( gx\right)g^2 dg
=
\frac{1}{{\left(2\pi\right)}^{3}}
4\pi
\int {\tilde{v}_{loc}\left(g\right)}\frac{\sin\left( g    x\right)}{gx}g^2\,dg.\end{split}
\end{equation*}
ONETEP uses a convention where an additional factor of \(4\pi\) is
needed when transforming between real and reciprocal space. Thus the
final formula for the local pseudopotential at a distance of \(x\)
from an atom of species \(s\) becomes

\phantomsection\label{\detokenize{realspace_local_pseudo:equation-eq7}}\begin{equation}\label{equation:realspace_local_pseudo:eq7}
\begin{split}{v^s_{loc}\left(x\right)}= \frac{2}{\pi}\int\limits_0^{\infty}
{\tilde{v}^s_{loc}\left(g\right)}\frac{\sin\left(gx\right)}{x}g\,dg.\end{split}
\end{equation}

\subsection{Implementation}
\label{\detokenize{realspace_local_pseudo:implementation}}
In practice, however, it is not possible to evaluate the integral
\eqref{equation:realspace_local_pseudo:eq7} with \(\infty\) as the upper limit, because
\({\tilde{v}^s_{loc}\left(g\right)}\) is defined in the recpot file
only up to a \(g_{max}\) of 100 Å\(^{-1}\). Furthermore, to
ensure the results are consistent with standard ONETEP, we must lower
this limit even more, to prevent aliasing, as high \(g\)’s will
not be representable on our reciprocal space grid. Thus, in practice we
evaluate

\phantomsection\label{\detokenize{realspace_local_pseudo:equation-eq8}}\begin{equation}\label{equation:realspace_local_pseudo:eq8}
\begin{split}{v^s_{loc}\left(x\right)}= \frac{2}{\pi}\int\limits_0^{g_{cut}}
{\tilde{v}^s_{loc}\left(g\right)}\frac{\sin\left(gx\right)}{x}g\,dg,\end{split}
\end{equation}
where \(g_{cut}=2\pi\max{\left(d_1,d_2,d_3\right)}\) (\(d_i\)
being the grid spacings of \sphinxcode{pub\_cell}) and will usually be in the
order of 20-30 \(a_0^{-1}\).

The integral is evaluated for \(x\)’s on a fine radial grid
running from \(0\) to the maximum possible distance, which is the
magnitude of the cell diagonal. The calculation is distributed across
nodes (each node deals with a portion of the fine radial grid). The
total pseudopotential for any point on the real space fine grid is
evaluated by interpolation from the fine radial grid and by summing over
all atoms. This calculation is distributed across nodes as well (each
node deals with its own slabs of the real space fine grid). The default
number of points in the radial grid is 100000 and can be changed with
the directive \sphinxcode{openbc\_pspot\_finetune\_nptsx}.

The integral \eqref{equation:realspace_local_pseudo:eq8} is difficult to evaluate numerically. One source of
difficulties is the oscillatory nature of \(\sin\left(gx\right)\).
For larger cells, where the maximum interesting \(x\) is in the
order of \(100\,a_0\), this oscillates so rapidly that the
resolution of the recpot file (0.05 Å\(^{-1}\)) is not enough and
it becomes necessary to interpolate
\({\tilde{v}^s_{loc}\left(g\right)}\), and the whole integrand,
between the \(g\)-points specified in the recpot file. The result of
the interpolation is stored on a fine radial \(g\)-grid, which is
\(f\) times as fine as the original radial \(g\)-grid of the
recpot file. \(f\) is determined automatically so that every full
period of \(\sin\left(gx\right)\) is sampled by at least 50 points.
For typical cells, this yields \(f\) in the order of 5-50, depending
on the cell size. Alternatively, \(f\) may be specified manually by
the \sphinxcode{openbc\_pspot\_finetune\_f} directive.

Another difficulty is caused by the singularity in
\({\tilde{v}^s_{loc}\left(g\right)}\) as \(g\to0\), where the
behaviour of \({\tilde{v}^s_{loc}\left(g\right)}\) approaches that
of \(-Z_s/g^2\). Although the integral is convergent, this
singularity cannot be numerically integrated in an accurate fashion. The
singularity also presents problems when interpolating between the
\(g\) points \textendash{} the usual cubic interpolation of
\sphinxcode{services\_1d\_interpolation} becomes inaccurate at low \(g\)’s.
The second problem is solved by subtracting the Coulombic potential,
\(-Z_s/g^2\), before interpolation to the fine radial \(g\)-grid
and then adding it back. The first problem is difficult to treat. An
approach where at low \(g\)’s
\({\tilde{v}^s_{loc}\left(g\right)}\) is assumed to be exactly equal
to \(-Z_s/g^2\) (which allows the low-\(g\) part of integral
(\eqref{equation:realspace_local_pseudo:eq8}) to be evaluated analytically) gives better results than
attempting to numerically integrate the singularity, but is not accurate
enough, leading to errors in the order of \(50-100\,\mu{}\)Ha in
the energy for a hydrogen atom test-case (with a total energy of ca.
0.477Ha. Attempting to fit \(A/g^2+B/g+C\) (which also allows
analytical integration at low \(g\)’s) gives similar results. The
numerical inaccuracy presents itself as a near-constant shift of the
obtained pseudopotential and clearly affects total energy.

To solve this problem, we observe that the local pseudopotential can be
split into a long-range part and a short-range part:
\begin{equation*}
\begin{split}{v^s_{loc}\left(x\right)}= {v^{s (long)}_{loc}\left(x\right)}+ {v^{s (short)}_{loc}\left(x\right)},\end{split}
\end{equation*}\begin{equation*}
\begin{split}{\tilde{v}^s_{loc}\left(g\right)}= {\tilde{v}^{s (long)}_{loc}\left(g\right)}+ {\tilde{v}^{s (short)}_{loc}\left(g\right)}.\end{split}
\end{equation*}
Following {[}Martyna1999{]}, we observe that
\({\tilde{v}^{s (long)}_{loc}\left(g\right)}=\frac{4\pi}{g^2}\exp{\left(\frac{-g^2}{4\alpha^2}\right)}\)
(where \(\alpha\) is an adjustable parameter, controllable with
\sphinxcode{openbc\_pspot\_finetune\_alpha}) which easily transforms to real space
to give
\({v^{s (long)}_{loc}\left(x\right)}=-\frac{\operatorname{erf}{\left(\alpha{}x\right)}}{x}\)
and is conveniently calculated in real space. The short-range part
(corresponding to high \(g\)’s) is
\({\tilde{v}^{s (long)}_{loc}\left(g\right)}={\tilde{v}^s_{loc}\left(g\right)}\cdot\left[1-\exp{\left(\frac{-g^2}{4\alpha^2}\right)}\right]\).
In this way, the integral (\eqref{equation:realspace_local_pseudo:eq8}) can be rewritten as

\phantomsection\label{\detokenize{realspace_local_pseudo:equation-eqsplit}}\begin{equation}\label{equation:realspace_local_pseudo:eqsplit}
\begin{split}{v^s_{loc}\left(x\right)}=
-\frac{\operatorname{erf}{\left(\alpha{}x\right)}}{x}+
\frac{2}{\pi}
\underbrace{
\int\limits_0^{g_{cut}}
{\tilde{v}^s_{loc}\left(g\right)}\cdot \left[ 1 - exp\left(\frac{-g^2}{4\alpha^2}\right) \right]
\cdot \frac{\sin\left(gx\right)}{x}g\,dg}_{I_s(x)}
.\end{split}
\end{equation}
Owing to the
\(\left[1-\exp{\left(\frac{-g^2}{4\alpha^2}\right)}\right]\) factor,
the integral \(I_s(x)\) is no longer singular at \(g=0\) and can
be accurately evaluated numerically, if \(\alpha\) is large enough.
Small values of \(\alpha\) make the numerical integration more
difficult (requiring larger values for \(f\)), because the
oscillations at low \(g\)’s are large in magnitude. Larger values
of \(\alpha\) allow for easy integration, but they cause the
long-range behaviour to “kick in” earlier. As this long-range behaviour
is calculated in real space, it lacks the oscillations that are present
in standard ONETEP because of a finite value for \(g_{cut}\). Even
though these oscillations are an artifact, obtaining a long-range
behaviour that is physically more correct, but without the oscillations,
leads to aliasing in reciprocal space and to a departure from the
results of standard ONETEP. For this reason we want \(\alpha\) to be
as small as possible, without negatively impacting the numerical
integration. The accuracy of the obtained method can be judged by
comparing the real space tail of the obtained pseudopotential with the
Coulombic potential. Since we expect the obtained pseudopotential to
oscillate slightly around \(-Z_s/x\), a good measure of accuracy,
which we will call \(b\), is the average value of
\(\dfrac{{v^s_{loc}\left(x\right)}-(-Z_s/x)}{-Z_s/x}\) over the tail
of the pseudopotential, from, say, 5\(a_0\) to the maximum
\(x\) for which \({v^s_{loc}\left(x\right)}\) is evaluated.
Ideally, \(b\) should be zero. Numerical inaccuracies will cause a
shift in \({v^s_{loc}\left(x\right)}\) which will present itself as
a finite, non-zero value of \(b\). Naïve numerical integration by a
direct calculation of (\eqref{equation:realspace_local_pseudo:eq8}) led, for our test-case, to \(b\) in
the order of 0.01, which can be reduced by an order of magnitude by
using a very fine radial \(g\)-grid (high value of \(f\)).
Subtracting out the Coulombic potential and integrating only the
difference between \({\tilde{v}^s_{loc}\left(g\right)}\) and the
Coulombic potential numerically, while integrating the remaining part
analytically reduced b to about 0.0005. Application of the proposed
formula (\eqref{equation:realspace_local_pseudo:eqsplit}) yielded \(b=5\cdot10^{-8}\) for
\(\alpha=0.5/l\) and \(b=3\cdot10^{-9}\) for
\(\alpha=0.1/l\) with a suitably large \(f\) to ease the
numerical integration at low \(g\) (\(l\) is the box length).
With the default value for \(f\), the total energy is not sensitive
(to more than 0.0001\%) to the choice of \(\alpha\), provided it is
in a resonable range of \(0.1/l - 2/l\). The value of \(0.3/l\)
was chosen as a default.

The calculation of the realspace local pseudo is implemented in
\sphinxcode{norm\_conserv\_pseudo.F90} in the subroutine
\sphinxcode{pseudo\_local\_on\_grid\_openbc} and its internal subroutine
\sphinxcode{internal\_Is\_of\_x}, which evaluates \(I_s(x)\). A typical
calculation would use default values for all the parameters. The
realspace local pseudo is off by default and is turned on automatically
when smeared ions or implicit solvent is in use. It can also be forced
to be on (for development tests) by using \sphinxcode{openbc\_pspot T}.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Directives controlling the calculation of the realspace local pseudo}\label{\detokenize{realspace_local_pseudo:id1}}
\sphinxaftercaption
\begin{tabular}[t]{|\X{40}{100}|\X{20}{100}|\X{40}{100}|}
\hline
\sphinxstylethead{\sphinxstyletheadfamily 
Directive
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Action
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Rationale for use
\unskip}\relax \\
\hline
\sphinxcode{openbc\_pspot T}
&
Forces the realspace pseudo to be used
&
Normally not needed, the realspace pseudo will be turned on when necessary. This directive allows turning it on even though the Hartree potential calculation and Ewald calculation proceed in reciprocal space, which might be useful for certain test calculations. A related directive, \sphinxcode{openbc\_ion\_ion T} may be used in conjuction, to replace Ewald with a direct Coulombic sum.
\\
\hline
\sphinxcode{openbc\_pspot\_finetune\_f} \(value\) {[}\(value\) is an integer.{]}
&
Sets the fineness parameter, \(f\), to \(value\).
&
Default value of -1 causes \(f\) to be determined automatically. Positive values can be used to increase \(f\) to obtain extra accuracy. Decreasing \(f\) will reduce accuracy and is not recommended.
\\
\hline
\sphinxcode{openbc\_pspot\_finetune\_nptsx} \(value\) {[}\(value\) is an integer.{]}
&
Sets the number of radial grid points (distinct values of \(x\)) to \(value\).
&
The default of 100000 should be enough, unless huge boxes are used, where it might make sense to increase it. Decreasing this value is not recommended, as it will impact accuracy.
\\
\hline
\sphinxcode{openbc\_pspot\_finetune\_alpha} \(value\) {[}\(value\) is a real.{]}
&
Sets the short-range-long-range crossover parameter \(\alpha\) to \(value/l\),  where \(l\) is the maximum dimension of the cell.
&
A default value of 0.3 should be OK for most applications. Increasing \(\alpha\) will reduce the numerical inaccuracy in \(I_s(x)\), but will cause the long-range behaviour to lack the oscillations of usual ONETEP and thus increase aliasing. Decreasing \(\alpha\) will make \(I_s(x)\) inaccurate, which can be helped, to a certain extent, by increasing \(f\).
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

{[}Martyna1999{]} G. J. Martyna and M. E. Tuckerman \sphinxstyleemphasis{J. Chem. Phys.} \sphinxstylestrong{110} (1999).


\section{Solvent and Electrolyte Model}
\label{\detokenize{implicit_solvation_v3::doc}}\label{\detokenize{implicit_solvation_v3:solvent-and-electrolyte-model}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Jacek Dziedzic, University of Southampton

\item[{Author}] \leavevmode
James C. Womack, University of Southampton

\item[{Author}] \leavevmode
Arihant Bhandari, University of Southampton

\item[{Author}] \leavevmode
Gabriel Bramley, University of Southampton

\item[{Date}] \leavevmode
September 2022

\end{description}\end{quote}

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{This manual pertains to ONETEP versions v6.0.0 and later}.
\item[] For older versions, see separate documentation on the ONETEP website.
\item[] \sphinxstylestrong{Major changes relative to v6.0.0:}
\end{DUlineblock}
\begin{itemize}
\item {} 
\sphinxstylestrong{Soft-sphere model added in v6.1.1.8}

\item {} 
\sphinxstylestrong{Self-consistent Continuum Solvation (SCCS) model added in
v6.1.11.0}

\item {} 
\sphinxstylestrong{Surface Accessible Volume added in v6.1.3.0}

\item {} 
\sphinxstylestrong{Conjugate gradient solver added in v6.1.3.6}

\end{itemize}

\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{WARNING to users of v6.1.3.0 and later.}
\item[] The method used to calculate the surface area of the dielectric cavity
was changed in version 6.1.3.0. The surface area is used to calculate
the \(\Delta G_{\textrm{npol}}\) component of the solvation. The
new method is more mathematically consistent, but gives approximately
20\% smaller values for the surface area. By default, we use the new
method, which means the value of \(\Delta G_{\textrm{solv}}\) and
may not agree with earlier versions. If you need full compatibility
with versions before 6.1.3, set \sphinxcode{is\_apolar\_sasa\_definition} to
\sphinxcode{isodensity}.
\end{DUlineblock}


\subsection{Overview of capabilities}
\label{\detokenize{implicit_solvation_v3:overview-of-capabilities}}
First and foremost, ONETEP implements the Minimal Parameter Solvent
Model (MPSM), first presented in Ref. {[}Dziedzic2011{]}. A more detailed description,
including guidelines on the choice of parameters, is given in Ref. {[}Dziedzic2013{]}.
MPSM offers a very accurate treatment of the polar (electrostatic)
solvation contribution, and a rather simple, yet still accurate,
treatment of the apolar terms: cavitation, dispersion and repulsion.
MPSM is based on the Fattebert and Gygi model (later extended by
Scherlis) {[}Scherlis2006{]}.

Two other models are available \textendash{} Fisicaro’s soft-sphere model (SSM)
{[}Fisicaro2017{]}, and Andreussi’s Self-Consistent Continuum
Solvation (SCCS) model {[}Andreussi2012{]}.

Implicit solvation calculations in ONETEP can be performed, regardless
of the choice of model, either in open boundary conditions (OBC) or in
periodic boundary conditions (PBC), with OBC assumed by default. The
solute can be immersed in pure solvent (necessitating the solution of
the Poisson equation (PE)) or in solvent with electrolyte (leading to
the Poisson-Boltzmann equation (PBE)). Solvation energies can be
calculated by running a calculation in vacuum first, followed by a
calculation in solvent. This can be done either automatically (“auto
solvation”) or manually. Apart from energy terms due to solvation,
ONETEP calculates solvation contributions to forces. It is thus possible
to perform in-solvent geometry optimisation and molecular dynamics (with
difficulty). Forces are currently not supported for PBC calculations
yet. Additional solvent exclusion regions can be specified to keep the
solvent from predefined regions of the simulation cell.


\subsection{The models}
\label{\detokenize{implicit_solvation_v3:the-models}}
ONETEP includes solvation effects by defining a smooth dielectric cavity
around the solute (“solute cavity”). In contrast to PCM-based
approaches, the transition from a dielectric permittivity of 1 (in the
immediate vicinity of the solute) to the bulk value of the solvent is
smooth, rather than discontinuous. Thus, there is no “cavity surface”,
strictly speaking, but rather a thin region of space where the
transition takes place. For MPSM and SCCS the cavity and the transition
are defined by a simple function relating the dielectric permittivity at
a point, \(\epsilon(\vec{r})\), to the electronic density there,
\(n(\vec{r})\), yielding an isodensity model. For SSM the transition
is also smooth, but the cavity is defined by atom-centered overlapping
spheres.

ONETEP offers two modes of operation \textendash{} one, where \(n(\vec{r})\) is
the \sphinxstyleemphasis{current} electronic density (“the self-consistently updated cavity
mode”), and another one, where \(n(\vec{r})\) is \sphinxstyleemphasis{fixed}, usually to
the converged in-vacuum density (“the fixed cavity mode”).

For MPSM the dielectric function \(\epsilon(\cdot)\), defined in
Ref. {[}Scherlis2006{]}, Eq. 7, and in Ref. {[}Dziedzic2011{]}, Eq. 1 depends on two parameters:
\(\rho_{0}\), the electronic density threshold, where the transition
takes place; and \(\beta\), which controls the steepness of the
change in \(\epsilon\). A physical constant,
\(\epsilon_{\infty}\), the bulk permittivity of the solvent
completes the description

For SCCS the dielectric function is defined in Ref. {[}Andreussi2012{]} in Eqs. 38-43. It
has two parameters: \(\rho_{\textit{min}}\) and
\(\rho_{\textit{max}}\). A physical constant, \(\epsilon_0\),
the bulk permittivity of the solvent completes the description.

For SSM the dielectric function is described in the section on the soft sphere cavity model below.

Once a solute cavity is constructed, the Poisson equation is then solved
to obtain the potential due to the molecular density in the
nonhomogeneous dielectric. A more general case, where electrolyte ions
can be added to the solvent (specified via concentrations), requires
solving the Poisson-Boltzmann equation.


\subsubsection{Solute cavity}
\label{\detokenize{implicit_solvation_v3:solute-cavity}}
In the MPSM and SCCS models the dielectric cavity is determined wholly
by the electronic density, freeing the model of any per-species
parameters (such as van der Waals radii). Thus, the cavity will change
shape every time the electronic density changes. From the physical point
of view this is good, since it means the density can respond
self-consistently to the polarisation of the dielectric and vice versa.
From the computational point of view this is rather inconvenient,
because it requires extra terms in the energy gradients (see e.g. Ref. {[}Scherlis2006{]},
Eqs. 5 and 14). Because these terms tend to vary rapidly over very
localised regions of space, their accurate calculation usually requires
unreasonably fine grids and becomes prohibitively difficult for larger
molecules.


\paragraph{Fixed cavity}
\label{\detokenize{implicit_solvation_v3:fixed-cavity}}
One workaround for the above problem, which is straightforward, but
introduces an approximation, consists in \sphinxstyleemphasis{fixing} the cavity and not
allowing it to change shape. This is realised by performing an in-vacuum
calculation first, then restarting the solvated calculation from the
converged in-vacuum density, and using this density to generate the
cavity that then remains fixed for the duration of the solvated
calculation. Both calculations are self-consistent (in the DFT sense),
only the cavity is \sphinxstyleemphasis{not} self-consistently updated in the in-solvent
calculation.

How good is this approximation? From experience, it yields solvation
energies within several percent of the accurate, self-consistent
calculation, cf. Ref. {[}Dziedzic2011{]}. More specifically, the error in solvation energy
is expected to be less than 3-4\% percent for charged species and less
than 1\% for neutral species.

If you can spare the computational resources, it would be good to test
it on a representative molecule, by comparing the solvation energy
against a calculation with a self-consistently updated cavity.

As the cavity remains fixed, the difficult extra terms no longer need to
be calculated, and the memory and CPU requirements are significantly
reduced (because the grid does not need to be made finer). It is thus
the recommended solution. The fixed cavity mode is activated by
\sphinxcode{is\_dielectric\_model FIX\_INITIAL}, which is the default setting.

If embedded mean field theory (EMFT) is in use alongside the implicit
solvent model, a choice can be made about whether the in-vacuum density
is calculated using the standard density kernel (calculated at the lower
level of theory), or the EMFT density kernel. In most situations, this
should not strongly affect results, especially if the active region in
EMFT is far from the edge of the cavity. This can be controlled using
the keyword \sphinxcode{is\_emft\_cavity}, which is false by default. This has only
been tested for the fixed cavity approach, and not the self-consistent
cavity approach. For more information, please see the EMFT
documentation.


\paragraph{Self-consistently updated cavity}
\label{\detokenize{implicit_solvation_v3:self-consistently-updated-cavity}}
If one insists on performing calculations with the solute cavity
self-consistently responding to changes in density (as in Ref. {[}Scherlis2006{]}), this
can be achieved by \sphinxcode{is\_dielectric\_model SELF\_CONSISTENT}. As mentioned
earlier, this is costly, because it almost always requires grids that
are finer than the default. The relevant grid (“fine grid”) can be made
finer by \sphinxcode{fine\_grid\_scale n}, with \(\texttt{\textit{n}}>2\)
(which is the default). Typically one would use 3, you might be able to
get away with 2.5, you might need 3.5 or even more. The memory and CPU
cost increase with the \sphinxstyleemphasis{cube} of this value, so, for instance, when
using \sphinxcode{fine\_grid\_scale 3.5} one would expect the computational cost to
increase by a factor of \({\left(3.5/2\right)}^3\approx5.36\).

Even when using much finer grids, the additional gradient term due to
the self-consistently updated cavity poses numerical difficulties. This
is especially true if the changes in the density are rapid. For this
reason, even if it is technically possible to run a calculation in
solvent \sphinxstyleemphasis{without} a preceding calculation in vacuum, it is not
recommended to do so \textendash{} the initial, dramatic changes in the density will
likely prove problematic. It will be much easier to run an in-vacuum
calculation to convergence, and to restart a calculation in solvent from
there. The auto solvation functionality (see section on this below)
makes this easy.


\paragraph{Soft Sphere Cavity Model}
\label{\detokenize{implicit_solvation_v3:soft-sphere-cavity-model}}
In addition to MPSM and SCCS, the soft sphere cavity model of Fisicaro
\sphinxstyleemphasis{et al.} (Ref. {[}Fisicaro2017{]}) has been implemented to provide a dielectric cavity
function closer to the standard per-species parametrisation models. This
feature is especially useful when the system under study requires
significantly different solvation radii for its constituent species.
This contrasts with MPSM, which applies the parameter controlling the
dielectric cavity shape (the isodensity contour) globally, which leads
to the dielectric cavity being too large/small for particular species
for a single input isodensity value.

The dielectric cavity within the soft sphere model is composed of a set
of interlocking, atom-centered spheres with radii assigned to each atom.
Much like MPSM, the dielectric function for each atom varies smoothly
from vacuum to bulk permitivity. The dielectric functions themselves are
defined by: i) the soft sphere radius set by default by Alvarez’s
database of van der Waals’ radii (Ref. {[}Alvarez2013{]}) or manually set in the
\sphinxcode{is\_soft\_sphere\_radii} block. The default radii can be uniformly
scaled using \sphinxcode{is\_soft\_sphere\_scale}. ii) The steepness of the
transition from vacuum to bulk permitivity is controlled by
\sphinxcode{is\_soft\_sphere\_delta}. To activate the soft sphere cavity model, set
\sphinxcode{is\_dielectric\_function} to ’soft\_sphere’. By default,
\sphinxcode{is\_soft\_sphere\_scale} is set to 1.33 and \sphinxcode{is\_soft\_sphere\_delta} to
0.5, as determined by minimizing the error of the solvation free energy
against empirical data for a set of small neutral, organic molecules.
These cavity radii may not give accurate solvation energies for heavier
elements/system types, and it is encouraged to perform further
parametrization to minimize error with respect to selected experimental
data.

Forces for the soft sphere cavity model are implemented, but not yet
tested thoroughly, so only single point energy calculations are
supported.


\subsubsection{Apolar terms: cavitation energy}
\label{\detokenize{implicit_solvation_v3:apolar-terms-cavitation-energy}}
All three models include the apolar cavitation term in the
solvent-accessible surface-area (SASA) approximation, thus assuming the
cavitation energy to be proportional to the surface area of the cavity,
the constant of proportionality being the (actual physical) surface
tension of the solvent, \(\gamma\), and the constant term being
zero. The cavitation energy term is calculated and added automatically,
unless \sphinxcode{is\_include\_apolar F} is explicitly stated. Surface tension of
the solvent has to be specified (otherwise the default for water near
room temperature (about 0.074 N/m) will be used). This can be done using
\sphinxcode{is\_solvent\_surf\_tension}. Keep in mind that the apolar term is
\sphinxstyleemphasis{scaled by default} to account for dispersion and repulsion (see
section on this below). The scaling is controlled by
\sphinxcode{is\_apolar\_scaling\_factor}, and the default is \sphinxstyleemphasis{not} unity.


\subsubsection{Apolar terms: dispersion-repulsion energy}
\label{\detokenize{implicit_solvation_v3:apolar-terms-dispersion-repulsion-energy}}
ONETEP includes a simple, approximate way for modeling solute-solvent
dispersion-repulsion apolar energy term. This greatly improves the
quality of obtained solvation energies for uncharged molecules,
particularly so if they are large. This term is reasonably approximated
with the same SASA approach that is used for cavitation, albeit with a
smaller, and negative, prefactor. In practice this is most easily
achieved by simply scaling the cavitation term down by a constant
multiplicative factor. A good scaling factor for MPSM, and presumably
for SSM, is 0.281705, which is what ONETEP uses by default (see Ref. {[}Dziedzic2011{]}
for justification). The keyword controlling this parameter is
\sphinxcode{is\_apolar\_scaling\_factor} (with the above default), and its argument
is a unitless value. For SCCS a value of 0.159722222 corresponds to the
“g03” fit in Ref. {[}Andreussi2012{]}, and a value of 0.034722222 corresponds to the “g09”
fit in same.


\subsubsection{Apolar terms: solvent sccessible volume (SAV)}
\label{\detokenize{implicit_solvation_v3:apolar-terms-solvent-sccessible-volume-sav}}
The accuracy of the implicit solvent model can be further improved by
adding the surface-accessible volume (SAV) to the apolar energy term:
\begin{equation*}
\begin{split}\Delta G_{apol} = \tau \gamma S + p V\end{split}
\end{equation*}
where \(\gamma\) is the physical surface tension (Section
on cavitation energy), \(\tau\) is the apolar scaling factor tuned by
\sphinxcode{is\_apolar\_scaling\_factor} in the SASA model (Section
on dispersion-repulsion energy), and \(p\) is the solvent pressure. This method is
activated by setting \sphinxcode{is\_apolar\_method} to ’SAV’. We note that the
scaling factors \(\tau\), \(p\), and (in the case of soft
sphere) \(f\), must be tuned to give accurate free energies of
solvation compared to the original SASA model. By minimising the mean
absolute error (MAE) of \(\Delta G_{solv}\) with respect to
experiment for a small set of neutral molecules, we found the optimum
scaling factors for water (\(\gamma=0.07415 \ Nm^{-1}\)) are:
\begin{itemize}
\item {} 
Soft Sphere: \(f=1.20\), \(\tau = 0.813\) and
\(p = -0.35 \ GPa\)

\item {} 
MPSM: \(\rho_0\)=0.00035, \(\tau = 0.684\) and
\(p = -0.35 \ GPa\)

\end{itemize}

Currently, these values are only fully optimised for the soft sphere
implicit solvent model, but the values provided for the MPSM provide a
starting estimate. We note that in this simple model, \(p\) does not
correspond to the physical pressure of the solvent and acts as a fitting
parameter to give optimum values of \(\Delta G_{solv}\), meaning it
can assume negative values.

Furthermore, if fixed PAOs are used in place of optimised NGWFs, the
optimum parameters change significantly. For the QZP basis, best
parameters for the soft sphere model and MPSM are:
\begin{itemize}
\item {} 
Soft Sphere: \(f=1.21\), \(\tau=0.861\) and
\(p=-0.35 \ GPa\)

\item {} 
MPSM: \(\rho_0=0.00035\), \(\tau=0.785\) and
\(p=-0.35 \ GPa\)

\end{itemize}

Larger or smaller fixed PAO basis sets may require slightly different
optimal parameters given the above values were calculated with the QZP
basis only.

In summary:
\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{polar, cavitation, dispersion and repulstion terms (SASA)}:
\item[] \sphinxcode{is\_include\_apolar T} (default)
\item[] \sphinxcode{is\_apolar\_method SASA} (default)
\item[] \sphinxcode{is\_apolar\_scaling\_factor 0.281705} (default)
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{polar, cavitation, dispersion and repulstion terms (SAV)}:
\item[] \sphinxcode{is\_include\_apolar T} (default)
\item[] \sphinxcode{is\_apolar\_method SAV}
\item[] \sphinxcode{is\_soft\_sphere\_scale 1.20} (optimised for soft sphere)
\item[] \sphinxcode{is\_apolar\_scaling\_factor 0.813} (optimised for soft sphere)
\item[] \sphinxcode{is\_solvent\_pressure -0.35 GPa} (optimised for soft sphere)
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{polar and cavitation terms only}:
\item[] \sphinxcode{is\_include\_apolar T} (default)
\item[] \sphinxcode{is\_apolar\_scaling\_factor 1.0}
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{polar term only}:
\item[] \sphinxcode{is\_include\_apolar F}
\end{DUlineblock}

\end{itemize}


\subsection{Practicalities}
\label{\detokenize{implicit_solvation_v3:practicalities}}

\subsubsection{DL\_MG solver}
\label{\detokenize{implicit_solvation_v3:dl-mg-solver}}
ONETEP uses a multigrid solver to solve the Poisson or Poisson-Boltzmann
equation. Currently this is done by interfacing to a solver called
DL\_MG {[}Anton2020{]}, {[}Womack\_2018{]}. DL\_MG is
distributed with ONETEP and is compiled in by default. If your version
does not include DL\_MG your calculation will stop with a descriptive
error message.

Solving the P(B)E is a memory- and time-consuming process, and you
should expect solvation calculations to take about 2-3 times longer
compared to standard ONETEP (also remembering that you will likely have
to run two calculations per result \textendash{} one in vacuum, and one in solvent).
The memory requirement of the solver grows linearly with the volume of
the system, meaning that padding with vacuum or with bulk solvent is not
free, in contrast to calculations not employing the multigrid solver.

The solver uses a multigrid approach to solve the P(B)E to second order.
To ensure the high-order accuracy necessary for solvation calculations,
the solver then applies a high-order defect correction technique, which
iteratively corrects the initial solution to a higher order. Consult
Ref. {[}Dziedzic2013{]} for more information on the defect correction approach used in
DL\_MG.


\subsubsection{Grid sizes}
\label{\detokenize{implicit_solvation_v3:grid-sizes}}

\paragraph{Under OBC}
\label{\detokenize{implicit_solvation_v3:under-obc}}
One limitation of DL\_MG is that the grid sizes it uses are not created
equal. Good grid sizes are divisible many times into grids twice as
small. For example a grid with 161 points (and so 160 grid-edges in
between them) is an excellent choice, since it divides into two grids
with 81 points (160 splits into two 80’s), these divide into two grids
with 41 points, which in turn divide into two grids with 21 points,
which divide into two grids with 11 points and so on. This lets the
solver use many multigrid levels, increasing efficiency. For contrast,
consider a grid with 174 points (and so 173 grid-edges). 173 is prime,
and this grid cannot be subdivided at all, making it a poor choice.

Knowing about these limitations, ONETEP will sometimes slightly reduce
(truncate) your fine grid dimensions when passing data to and from the
multigrid solver. This truncation always affects the right-hand side of
the grid, and by default between 1 and 7 grid lengths will be truncated,
to give DL\_MG enough flexibility. This is done automatically, and you
will be informed about the details like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ONETEP} \PYG{n}{fine} \PYG{n}{grid} \PYG{o+ow}{is} \PYG{l+m+mi}{126} \PYG{n}{x} \PYG{l+m+mi}{126} \PYG{n}{x} \PYG{l+m+mi}{126} \PYG{n}{gridpoints}\PYG{p}{,} \PYG{l+m+mf}{29.0000} \PYG{n}{x} \PYG{l+m+mf}{29.0000} \PYG{n}{x} \PYG{l+m+mf}{29.0000} \PYG{n}{bohr}\PYG{o}{.}
\PYG{n}{FD} \PYG{n}{multigrid} \PYG{o+ow}{is}     \PYG{l+m+mi}{121} \PYG{n}{x} \PYG{l+m+mi}{121} \PYG{n}{x} \PYG{l+m+mi}{121} \PYG{n}{gridpoints}\PYG{p}{,} \PYG{l+m+mf}{27.8492} \PYG{n}{x} \PYG{l+m+mf}{27.8492} \PYG{n}{x} \PYG{l+m+mf}{27.8492} \PYG{n}{bohr}\PYG{o}{.}
\end{sphinxVerbatim}

Here, ONETEP discarded three slabs, each just over 1 \(a_0\) thick,
from your system, at the highest values of \(x\), \(y\), and
\(z\).

Even though this is done automatically, it is your responsibility to
ensure that nothing of significance (read: any charge density) is in the
margin that is thrown away. If any of your NGWFs extend into the margin,
your calculation will be meaningless (and will likely stop with an
error). Due to \sphinxstyleemphasis{Fourier ringing}, tails of very small, but nonzero
charge density extend in all Cartesian directions from your system, even
outside the localisation spheres of the NGWFs. It is thus good practice
to pad your system with a little vacuum in all directions, say
10 \(a_0\). This is in addition to the margin lost due to
truncation.


\paragraph{Under PBC}
\label{\detokenize{implicit_solvation_v3:under-pbc}}
Under PBC, the grid used by the multigrid solver must have the same
dimensions as the simulation cell. This is necessary to ensure that the
solution from the solver has the correct periodicity. The approach of
truncating the grid (Section on grid sizes under OBC) to obtain a grid
which satisfies the grid size constraints of the multigrid solver cannot
therefore be used in periodic BCs. Instead, an appropriately sized grid
for use by the multigrid solver is obtained by \sphinxstyleemphasis{scaling} ONETEP’s fine
grid, changing the number and spacing of grid points, while maintaining
the same physical dimensions. This corresponds to slightly increasing
the scale factor for the fine grid (used, among other things, for
multigrid operations) with respect to the standard grid (determined by
the kinetic energy cutoff) along each coordinate direction to ensure
that the dimensions of the fine grid satisfy the requirements of the
solver (see Ref. {[}Anton2020{]} for details about these requirements).

This is done automatically, and you will be informed about the details
like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Grid} \PYG{n}{scale} \PYG{n}{modified} \PYG{n}{to} \PYG{n}{satisfy} \PYG{n}{multigrid} \PYG{n}{solver} \PYG{n}{grid} \PYG{n}{constraints}
         \PYG{n}{Grid} \PYG{n}{scale} \PYG{n}{values} \PYG{n}{after} \PYG{n}{modifification}\PYG{p}{:}         \PYG{l+m+mf}{2.09}  \PYG{l+m+mf}{2.09}  \PYG{l+m+mf}{2.00}
\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}\PYG{o}{*}
\PYG{p}{[}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{p}{]}
\PYG{n}{ONETEP} \PYG{n}{fine} \PYG{n}{grid} \PYG{o+ow}{is} \PYG{l+m+mi}{136} \PYG{n}{x} \PYG{l+m+mi}{136} \PYG{n}{x} \PYG{l+m+mi}{240} \PYG{n}{gridpoints}\PYG{p}{,} \PYG{l+m+mf}{32.4219} \PYG{n}{x} \PYG{l+m+mf}{32.7579} \PYG{n}{x} \PYG{l+m+mf}{60.0000} \PYG{n}{bohr}\PYG{o}{.}
\PYG{n}{FD} \PYG{n}{multigrid} \PYG{o+ow}{is}     \PYG{l+m+mi}{136} \PYG{n}{x} \PYG{l+m+mi}{136} \PYG{n}{x} \PYG{l+m+mi}{240} \PYG{n}{gridpoints}\PYG{p}{,} \PYG{l+m+mf}{32.4219} \PYG{n}{x} \PYG{l+m+mf}{32.7579} \PYG{n}{x} \PYG{l+m+mf}{60.0000} \PYG{n}{bohr}\PYG{o}{.}
\end{sphinxVerbatim}

Here, the grid was scaled by a factor of \(2.09\) along the
\(x\) and \(y\) coordinates, and no scaling was necessary for
the \(z\) coordinate. The two grids (ONETEP fine grid and the grid
seen by DL\_MG) are identical.

Changing the fine grid scale factor causes ONETEP to use the modified
fine grid throughout the calculation (not only when invoking the
multigrid solver). This has the unfortunate consequence that ONETEP must
perform additional work to interpolate and filter between the fine grid
and a slightly smaller “double grid”, which is used during other parts
of a ONETEP calculation. Normally this is avoided by making the fine and
double grids the same size, but is no longer possible when the fine grid
is modified for multigrid operations in PBCs.


\subsubsection{Auto solvation}
\label{\detokenize{implicit_solvation_v3:auto-solvation}}
An in-solvent calculation is almost universally preceded by a
calculation in vacuum. In the fixed cavity mode this is necessary to
generate the cavity from a converged in-vacuum calculation. In the
self-consistently updated cavity mode this helps mitigate stability
issues associated with the cavity updates (cf. Section on self-consistently updated cavity).
To make the procedure easier for users, ONETEP provides what is known as
“auto solvation” \textendash{} a mode of operation, where the two calculations (in
vacuum and in solvent) are automatically run in sequence.

\begin{DUlineblock}{0em}
\item[] To enable auto solvation (which is \sphinxstyleemphasis{off} by default), use
\sphinxcode{is\_auto\_solvation T}. This will automatically run an in-vacuum
calculation, followed by a calculation in solvent. Some input
parameters might have to be adjusted along the way, but this will
happen automatically and you will always be informed when this
happens. Once the calculation in solvent completes, a detailed
breakdown of the energies will be printed. It will look something like
this:
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Individual} \PYG{n}{components} \PYG{n}{of} \PYG{n}{total} \PYG{n}{energy} \PYG{o+ow}{in} \PYG{n}{solvent}\PYG{p}{:}     \PYG{n}{hartree}           \PYG{n}{kcal}\PYG{o}{/}\PYG{n}{mol}
\PYG{o}{\PYGZhy{}} \PYG{n}{Usual} \PYG{n}{non}\PYG{o}{\PYGZhy{}}\PYG{n}{electrostatic} \PYG{n}{DFT} \PYG{n}{terms}\PYG{p}{:}       \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{26.28930636174560}      \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{16496.788451}
\PYG{o}{\PYGZhy{}} \PYG{n}{Electrostatic} \PYG{n}{fixed} \PYG{n}{charge} \PYG{n}{energy}\PYG{p}{:}         \PYG{l+m+mf}{3.05443104938460}        \PYG{l+m+mf}{1916.684380}
\PYG{o}{\PYGZhy{}} \PYG{n}{Apolar} \PYG{n}{cavitation} \PYG{n}{energy}\PYG{p}{:}                  \PYG{l+m+mf}{0.02080496905999}          \PYG{l+m+mf}{13.055315}
\PYG{o}{\PYGZhy{}} \PYG{n}{Apolar} \PYG{n}{dispersion}\PYG{o}{\PYGZhy{}}\PYG{n}{repulsion} \PYG{n}{energy}\PYG{p}{:}       \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.01495721238146}          \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{9.385792}
 \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}} \PYG{n}{Total} \PYG{n}{energy} \PYG{o+ow}{in} \PYG{n}{solvent}\PYG{p}{:}                 \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{23.22902755568246}      \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{14576.434548}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] 
\item[] The above shows a breakdown of the total energy in solvent into the
usual DFT terms (except for electrostatic energy), the electrostatic
energy, the apolar cavitation energy and the apolar
dispersion-repulsion energy.
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Components} \PYG{n}{of} \PYG{n}{total} \PYG{n}{energy} \PYG{o+ow}{in} \PYG{n}{solvent}\PYG{p}{:}                \PYG{n}{hartree}           \PYG{n}{kcal}\PYG{o}{/}\PYG{n}{mol}
\PYG{o}{\PYGZhy{}} \PYG{n}{Usual} \PYG{n}{non}\PYG{o}{\PYGZhy{}}\PYG{n}{electrostatic} \PYG{n}{DFT} \PYG{n}{terms}\PYG{p}{:}       \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{26.28930636174560}      \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{16496.788451}
\PYG{o}{\PYGZhy{}} \PYG{n}{Electrostatic} \PYG{n}{energy}\PYG{p}{:}                      \PYG{l+m+mf}{3.05443104938460}        \PYG{l+m+mf}{1916.684380}
\PYG{o}{\PYGZhy{}} \PYG{n}{Apolar} \PYG{n}{energy} \PYG{n}{terms}\PYG{p}{:}                       \PYG{l+m+mf}{0.00584775667854}           \PYG{l+m+mf}{3.669523}
 \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}} \PYG{n}{Total} \PYG{n}{energy} \PYG{o+ow}{in} \PYG{n}{solvent}\PYG{p}{:}                 \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{23.22902755568246}      \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{14576.434548}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] 
\item[] In the above all the apolar terms have been summed together for
convenience.
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Calculation} \PYG{n}{of} \PYG{n}{free} \PYG{n}{energy} \PYG{n}{of} \PYG{n}{solvation}\PYG{p}{:}              \PYG{n}{hartree}           \PYG{n}{kcal}\PYG{o}{/}\PYG{n}{mol}
\PYG{o}{\PYGZhy{}} \PYG{n}{Total} \PYG{n}{energy} \PYG{o+ow}{in} \PYG{n}{solvent}\PYG{p}{:}         \PYG{p}{(}\PYG{o}{+}\PYG{p}{)}     \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{23.22902755568246}      \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{14576.434548}
\PYG{o}{\PYGZhy{}} \PYG{n}{Total} \PYG{n}{energy} \PYG{o+ow}{in} \PYG{n}{vacuum}\PYG{p}{:}          \PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{p}{)}     \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{23.20990671966879}      \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{14564.436043}
 \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}} \PYG{n}{Total} \PYG{n}{free} \PYG{n}{energy} \PYG{n}{of} \PYG{n}{solvation}\PYG{p}{:}           \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.01912083601367}         \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{11.998505}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] 
\item[] The above is a direct calculation of the free energy of solvation as a
difference of the in-solvent and in-vacuum energies.
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Components} \PYG{n}{of} \PYG{n}{polar} \PYG{n}{term} \PYG{o+ow}{in} \PYG{n}{f}\PYG{o}{.}\PYG{n}{e}\PYG{o}{.} \PYG{n}{of} \PYG{n}{solvation}\PYG{p}{:}        \PYG{n}{hartree}           \PYG{n}{kcal}\PYG{o}{/}\PYG{n}{mol}
\PYG{o}{\PYGZhy{}} \PYG{n}{Electrostatic}\PYG{p}{:}                            \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.06759943752720}         \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{42.419287}
\PYG{o}{\PYGZhy{}} \PYG{n}{Change} \PYG{o+ow}{in} \PYG{n}{nonelectrostatic} \PYG{n}{DFT} \PYG{n}{terms}\PYG{p}{:}      \PYG{l+m+mf}{0.04263084483500}          \PYG{l+m+mf}{26.751258}
 \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}} \PYG{n}{Polar} \PYG{n}{term} \PYG{o+ow}{in} \PYG{n}{f}\PYG{o}{.}\PYG{n}{e}\PYG{o}{.} \PYG{n}{of} \PYG{n}{solvation}\PYG{p}{:}          \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.02496859269221}         \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{15.668028}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] 
\item[] The above is the calculation of the polar term to solvation, as a sum
of the change in electrostatic energy between in-solvent and in-vacuum
and the change in the remaining DFT terms.
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Components} \PYG{n}{of} \PYG{n}{free} \PYG{n}{energy} \PYG{n}{of} \PYG{n}{solvation}\PYG{p}{:}               \PYG{n}{hartree}           \PYG{n}{kcal}\PYG{o}{/}\PYG{n}{mol}
\PYG{o}{\PYGZhy{}} \PYG{n}{Polar} \PYG{n}{term} \PYG{o+ow}{in} \PYG{n}{f}\PYG{o}{.}\PYG{n}{e}\PYG{o}{.} \PYG{n}{of} \PYG{n}{solvation}\PYG{p}{:} \PYG{p}{(}\PYG{o}{+}\PYG{p}{)}      \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.02496859269221}         \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{15.668028}
\PYG{o}{\PYGZhy{}} \PYG{n}{Apolar} \PYG{p}{(}\PYG{n}{cavitation}\PYG{p}{,} \PYG{n}{dis}\PYG{o}{.}\PYG{p}{,} \PYG{n}{rep}\PYG{o}{.}\PYG{p}{)}\PYG{p}{:} \PYG{p}{(}\PYG{o}{+}\PYG{p}{)}       \PYG{l+m+mf}{0.00584775667854}           \PYG{l+m+mf}{3.669523}
 \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}} \PYG{n}{Total} \PYG{n}{free} \PYG{n}{energy} \PYG{n}{of} \PYG{n}{solvation}\PYG{p}{:}           \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.01912083601367}         \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{11.998505}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] 
\item[] Finally, the total free energy of solvation is calculated as the sum
of the polar and apolar terms calculated earlier. This is usually what
you are after.
\end{DUlineblock}

Auto solvation relies on restart files to achieve a seamless transition
from the calculation in vacuum to the calculation in solvent. A
\sphinxcode{.vacuum\_dkn} and a \sphinxcode{.vacuum\_tightbox\_ngwfs} file will be written to
disk once the calculation in vacuum is completed (and also earlier, if
you used \sphinxcode{write\_denskern T} and/or \sphinxcode{write\_tightbox\_ngwfs T}). These
files are then read at the beginning of the calculation in solvent. This
makes restarting in-solvent geometry optimisation and molecular dynamics
runs very tricky \textendash{} this is not recommended in practice. Please ensure
such calculations run to completion without manual restarts.


\subsubsection{Manual solvation and restarts}
\label{\detokenize{implicit_solvation_v3:manual-solvation-and-restarts}}
Occasionally you might want to run a calculation in solvent without
automatically running a calculation in vacuum first. Perhaps you already
have the calculation in vacuum and you prefer to manually restart it in
solvent. This is known as “manual solvation”. To activate it, use (the
default is \sphinxcode{F}), and make sure to have \sphinxcode{is\_auto\_solvation F} (which
is the default).

Make sure you know how the solute cavity is generated in this case. If
this is a fresh calculation (not a restart), the cavity will be
generated from the initial guess density. This is probably not what you
want. In the fixed cavity mode, this will mean that you will be stuck
with a cavity that is not very realistic (coming from a guess). In the
self-consistently updated cavity mode, the cavity will adapt to the
subsequent changes to the density, but the initial, dramatic changes
might make this numerically unstable. Therefore, restarting from a
converged in-vacuum run is recommended instead.

If you ran an in-vacuum calculation to convergence earlier and you have
the requisite restart files, you can add \sphinxcode{read\_denskern T} and
\sphinxcode{read\_tightbox\_ngwfs T} to your input to effect a restart. ONETEP will
look for a \sphinxcode{.dkn} and a \sphinxcode{.tightbox\_ngwfs} file. The cavity will be
constructed from the density generated from these files, and the
calculation will also proceed from this DKN and NGWFs. If the in-vacuum
calculation you ran earlier was a part of an auto-solvation calculation,
you will need to rename or link the \sphinxcode{.vacuum\_dkn} and
\sphinxcode{.vacuum\_tightbox\_ngwfs} files to their \sphinxcode{.dkn} and
\sphinxcode{.tightbox\_ngwfs} counterparts.

If you need to restart an auto-solvation calculation which stopped in
the middle of the in-vacuum calculation, you can set the
\sphinxcode{is\_restart\_vac\_from\_vac} to \sphinxcode{T}. This allows you to restart the
in-vacuum calculation from the \sphinxcode{.vacuum\_dkn} and
\sphinxcode{.vacuum\_tightbox\_ngwfs} files.

Finally, if you want to restart an in-solvent calculation from an
unfinished in-solvent calculation, you have to be careful. This is
because you want the calculation to continue from the
partially-converged in-solvent density, while still constructing the
cavity from the converged in-vacuum density. To do this, use the
\sphinxcode{is\_separate\_restart\_files} keyword. Setting it to \sphinxcode{T} (the default
is \sphinxcode{F}) will instruct ONETEP to construct the solute cavity from the
\sphinxcode{.vacuum\_dkn} and \sphinxcode{.vacuum\_tightbox\_ngwfs} files, while the density
for continuing the calculation will be generated from the \sphinxcode{.dkn} and
\sphinxcode{.tightbox\_ngwfs} files.


\subsubsection{Solvation in PBC}
\label{\detokenize{implicit_solvation_v3:solvation-in-pbc}}
Implicit solvation operates under OBC by default. However, ONETEP allows
solvation calculations in PBC, with some caveats. Only fully periodic
BCs are supported, i.e. where the system is periodic along all
simulation cell directions. Support for mixed BCs (where OBC are applied
along some directions and PBC along others) is planned for the future,
but is not currently supported. If you intend to solvate slabs, surfaces
or wires, you would probably be best off using PBC and suitable padding.

Boundary conditions can be specified individually for the multigrid
solver, local pseudopotential, ion-ion interaction and the smeared ion
representation using the following keywords:
\begin{itemize}
\item {} 
\sphinxcode{multigrid\_bc},

\item {} 
\sphinxcode{pspot\_bc},

\item {} 
\sphinxcode{ion\_ion\_bc},

\item {} 
\sphinxcode{smeared\_ion\_bc}.

\end{itemize}

Each of these keywords accepts a string which should contain three
characters (which may be separated by spaces), specifying the BCs along
the \(x\), \(y\) and \(z\) directions of the simulation
cell. For \sphinxcode{multigrid\_bc} the characters may be \sphinxcode{O}, \sphinxcode{P} or \sphinxcode{Z},
corresponding to open (Coulombic), periodic and zero BCs, respectively.
“Zero” BCs are open BCs, but with the potential set to zero at the
boundary, rather than approximately computed. For \sphinxcode{pspot\_bc},
\sphinxcode{ion\_ion\_bc} and \sphinxcode{smeared\_ion\_bc}, the values can be \sphinxcode{O} or \sphinxcode{P},
defined as for \sphinxcode{multigrid\_bc}.

These keywords allow for flexible selection of mixtures of open and
periodic BCs, but currently only fully open and fully periodic BCs are
supported, corresponding to values of \sphinxcode{O O O} and \sphinxcode{P P P} (and
\sphinxcode{Z Z Z} to use zero BCs in the multigrid solver).


\paragraph{Key points on using the BC keywords}
\label{\detokenize{implicit_solvation_v3:key-points-on-using-the-bc-keywords}}\begin{itemize}
\item {} 
If \sphinxcode{multigrid\_bc} is set in an input file, but the implicit solvent
model is not activated (e.g. if other solvent model keywords are not
used) then the multigrid solver is used to compute the Hartree
potential in vacuum, without the smeared ion representation.

\item {} 
Setting \sphinxcode{smeared\_ion\_bc} is insufficient to activate the smeared
ion representation—you must also set \sphinxcode{is\_smeared\_ion\_rep} (or use
the full solvent model, e.g. via \sphinxcode{is\_implicit\_solvent}).

\item {} 
If BCs are not explicitly set using \sphinxcode{multigrid\_bc} and the
multigrid solver is activated (for example, by setting
\sphinxcode{is\_implicit\_solvent: T}), then the BCs for the multigrid solver
default to fully open BCs.

\item {} 
If BCs are not explicitly set using \sphinxcode{pspot\_bc} then the BCs for the
local pseudopotential are determined by the type of calculation being
performed and should respect previous defaults. Setting
\sphinxcode{openbc\_pspot: T} will set fully open BCs, as will setting
\sphinxcode{is\_implicit\_solvent: T} or \sphinxcode{is\_smeared\_ion\_rep: T}. In vacuum
(without smeared ions) the local pseudopotential defaults to fully
periodic BCs, unless the cutoff Coulomb approach is used, in which
case the BCs are determined by the value of the
\sphinxcode{coulomb\_cutoff\_type} keyword.

\item {} 
If BCs are not explicitly set using \sphinxcode{ion\_ion\_bc} then the BCs for
the ion-ion interaction are determined by the type of calculation
being performed and should respect previous defaults. Setting
\sphinxcode{openbc\_ion\_ion: T} will set fully open BCs, as will setting
\sphinxcode{is\_implicit\_solvent: T} or \sphinxcode{is\_smeared\_ion\_rep: T}. In vacuum
(without smeared ions) the ion-ion interaction defaults to fully
periodic BCs, but this can be changed (as normal) by using the cutoff
Coulomb or Martyna-Tuckerman approaches.

\item {} 
If \sphinxcode{smeared\_ion\_bc} is not explicitly set, then the BCs used for
smeared ions are the same as those used for the multigrid solver
(with the exception that zero BCs for the multigrid solver are
converted to open BCs for smeared ions).

\item {} 
It is possible to specify inconsistent BCs for different interaction
terms. A warning should be output if this is detected, but care is
necessary to avoid unphysical results.

\end{itemize}

In short: the boundary conditions selected by default in previous
versions of ONETEP should be respected if the new keywords are not
explicitly set. If the keywords are set, then care must be taken to
ensure that they are set consistently in order to obtain physically
realistic results. An effort has been made to prevent inconsistencies
between the setting of the new keywords for controlling BCs and earlier
keywords (such as \sphinxcode{openbc\_hartree}, \sphinxcode{openbc\_pspot} and
\sphinxcode{openbc\_ion\_ion}), but this has not been extensively tested.


\subsubsection{Smeared ions}
\label{\detokenize{implicit_solvation_v3:smeared-ions}}
The P(B)E is almost always solved for the molecular (total) density,
because we are interested in how the solvent polarises in response to
the total (valence electronic + core) charge density. The solution is
the molecular potential, and not the electronic potential. To reconcile
this with the usual DFT way of thinking in terms of valence-electronic
and core densities and potentials separately (which is needed e.g. in
the calculation of the NGWF gradient), a numerical trick known as the
smeared-ion formalism is used. In this formalism ionic cores are
modelled by narrow positive Gaussian distributions and the usual energy
terms are re-cast (cf. Ref. {[}Dziedzic2013{]}, Appendix):
\begin{itemize}
\item {} 
the usual Hartree energy is now replaced by the “molecular Hartree
energy” (also called electrostatic energy), that is, the
electrostatic energy of the molecule’s total charge distribution in
the potential this charge distribution generates, in the presence of
dielectric;

\item {} 
the local pseudopotential energy is corrected by an extra term that
takes the smeared-ion nature of the cores into account;

\item {} 
a self-interaction correction term is added to the total energy to
account for the added Gaussian distributions (each of them
self-interacts). This term does not depend on the electronic degrees
of freedom, but depends on the ionic positions;

\item {} 
a non-self-interaction correction term is added to the total energy
to account for the added Gaussian distributions (they interact with
each other). This term does not depend on the electronic degrees of
freedom, but depends on the ionic positions.

\end{itemize}

In principle, the total energy of the system is unchanged by the
application of the smeared-ion formalism, however, due to minor
numerical inaccuracies some discrepancies may be observed. These cancel
out when calculating energy differences between solvated and \sphinxstyleemphasis{in vacuo}
systems, \sphinxstylestrong{provided the smeared-ion formalism is used for the vacuum
calculation as well}. There is one parameter to the
smeared-ion formalism, \(\sigma\), which controls the width of the
Gaussians placed on the ions. See Ref. {[}Dziedzic2013{]} for more details on the choice
of this parameter. The default value is almost always OK.

The key takeaway message here is that you need to use smeared ions in
\sphinxstylestrong{both} the in-vacuum calculation and the in-solvent calculation to
ensure the energy expressions are comparable. To do that, add
\sphinxcode{is\_smeared\_ion\_rep T} to your input file(s). If you forget about this
in a solvation calculation () or if you do auto solvation
(\sphinxcode{is\_auto\_solvation T}) it will be added automatically for you, but a
warning will be produced. However, if you run manual solvation, you need
to remember to include \sphinxcode{is\_smeared\_ion\_rep T} in the in-vacuum
calculation \textendash{} ONETEP has no way of knowing you will follow this with an
in-solvent calculation.


\subsubsection{Forces}
\label{\detokenize{implicit_solvation_v3:forces}}
If you ask ONETEP to calculate forces, the force terms due to implicit
solvent will be automatically calculated and included. The formulas
employed are exact (to numerical accuracy) when a self-consistently
updated cavity is used. For the case of a fixed cavity, they are
approximate. The approximation is very good, but initial tests suggest
that you might not be able to converge geometries to typical thresholds
\textendash{} although the noise in the forces will be small, it might be enough
close to equilibrium to throw off the geometry optimiser. Keep this in
mind.

You should be able to do geometry optimisation and molecular dynamics
without any problems with implicit solvent, provided that you use
\sphinxcode{is\_auto\_solvation T}. Note that restarting these might be tricky if
they are interrupted during the in-solvent stage \textendash{} you will need to
ensure the correct restart files (the vacuum restart files) are used to
generate the solvent cavity upon restart,
cf. Section on manual solvation and restarts.

Smeared-ion forces in vacuum are also implemented. These are numerically
exact and practically negligible.

Solvation forces only work in OBC so far, but we plan to have a PBC
version soon.


\subsubsection{Exclusion regions}
\label{\detokenize{implicit_solvation_v3:exclusion-regions}}
This functionality enables excluding regions of space from the solvent.
Any excluded region has its dielectric permittivity set to exactly 1,
similarly to what happens in core regions (cf. \sphinxcode{is\_core\_width}). This
is useful for removing pockets of solvent that could otherwise appear in
buried cavities, which are inaccessible to the solvent, yet the
electronic density there is low enough to generate a dielectric with a
permittivity notably larger than 1.

The regions are specified in a \sphinxcode{\%block is\_dielectric\_exclusions},
which looks like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}block is\PYGZus{}dielectric\PYGZus{}exclusions
sphere 20.0 22.0 18.0 4.0             ! x, y, z of centre; r (all in a0)
box 13.0 16.0  20.5 29.0  13.0 15.0   ! xmin xmax  ymin ymax  zmin zmax (all in a0)
xcyl 18.4 20.7 7.0                    ! y, z, r (all in a0)
\PYGZpc{}endblock is\PYGZus{}dielectric\PYGZus{}exclusions
\end{sphinxVerbatim}

The above excludes the solvent from a sphere centred at
\((20,22,18)\,{a_0}{}\) with a radius of \(4\,{a_0}{}\), from a
box spanning from \((13,20.5,13)\,{a_0}{}\) to
\((16,29,15)\,{a_0}{}\), and from a cylinder oriented along the X
axis, passing through \(y=18.4\,{a_0}{}\), \(z=20.7\,{a_0}{}\)
and a radius of \(7\,{a_0}{}\). \sphinxcode{sphere}, \sphinxcode{box}, \sphinxcode{xcyl},
\sphinxcode{ycyl} and \sphinxcode{zcyl} are the only region shapes supported now. All
exclusion regions currently assume open boundary conditions \sphinxstylestrong{and do not
work in PBC}. You can have as many as 10000 regions specified in the
exclusion block.

It is crucial to ensure that discontinuities in the permittivity are
avoided, because they prevent the solver from converging. Usually,
exclusion regions can be chosen such that they merge quite smoothly with
regions where the dielectric is naturally 1 (or reasonably close). If
this is not possible, then the boundaries of the exclusion regions can
be smoothed. This is achieved using a Fermi-Dirac function,
\begin{equation*}
\begin{split}\varepsilon(d) = \varepsilon_\infty - \frac{\varepsilon_\infty - 1}{e^{d/d_0} + 1},\end{split}
\end{equation*}
where \(d\) is the distance to the exclusion region boundary (and
is negative if inside the exclusion region), and \(d_0\) is the
smearing length set by \sphinxcode{is\_dielectric\_exclusions\_smear}. By default,
this is set to 0 \(a_0\), giving hard-walled exclusion regions
(\(\varepsilon = 1\) inside and
\(\varepsilon = \varepsilon_\infty\) outside). But if exclusion
regions interface directly with solvent regions, it should be chosen to
be at least a couple of times larger than the multigrid spacing, so that
the permittivity becomes sufficiently continuous for the solver to
converge.


\subsubsection{Solvent Polarization}
\label{\detokenize{implicit_solvation_v3:solvent-polarization}}
The non-homogeneous Poisson equation:
\begin{equation*}
\begin{split}\nabla\cdot\left(\varepsilon \nabla v\right)=-4\pi n_{\rm tot}\end{split}
\end{equation*}
can be recast in the form of a solvent polarization density:
\begin{equation*}
\begin{split}\nabla\cdot \nabla v=-4\pi \left(n_{\rm tot}+n_{\rm pol}\right)\end{split}
\end{equation*}
Subtracting the two, the polarization density is calculated as
{[}Andreussi2012{]}:
\begin{equation*}
\begin{split}\begin{aligned}
n_{\rm pol}&=\frac{1}{4\pi}\nabla\cdot\left[\left(\varepsilon-1\right)\nabla v\right] \\
n_{\rm pol}&=\frac{1}{4\pi}\left[\left(\varepsilon-1\right)\nabla^2 v +\nabla\left(\varepsilon-1\right)\cdot\nabla v\right]\end{aligned}\end{split}
\end{equation*}
The polarization potential is calculated by solving the following
Poisson eq:
\begin{equation*}
\begin{split}\nabla\cdot\nabla v_{\rm pol}=-4\pi n_{\rm pol}\end{split}
\end{equation*}
This is done in properties calculation with
\sphinxcode{is\_solvation\_properties T} and 3-D grid data for \(n_{\rm pol}\)
and \(v_{\rm pol}\) is output.


\subsection{Keywords used in solvation calculations}
\label{\detokenize{implicit_solvation_v3:keywords-used-in-solvation-calculations}}

\subsubsection{Basic}
\label{\detokenize{implicit_solvation_v3:basic}}\begin{itemize}
\item {} 
\sphinxcode{is\_implicit\_solvent T/F} turns on/off the implicit solvent.
Default is off. Will be set automatically if auto solvation is used.

\item {} 
\sphinxcode{is\_include\_apolar T/F} turns on/off the apolar energy terms.
Default is on.

\item {} 
\sphinxcode{is\_apolar\_sasa\_definition density/isodensity} defines the method
used in the difference method which calculates the solvent accessible
surface area (SASA) of the dielectric cavity. \sphinxcode{density} calculates
the SASA by varying the electron density, and \sphinxcode{isodensity} uses
varying \(\rho_0\) values. \sphinxcode{density} is the recommended setting
unless backwards compatibility with old versions is desired. Warning
can be suppressed by defining this keyword. Default is \sphinxcode{density}, but
you will get a warning if it is not specified. Specify \sphinxcode{density} or
\sphinxcode{isodensity} explicitly to suppress warnings. Only affects MPSM and
SCCS. For SCCS \sphinxcode{density} is the only available option.

\item {} 
\sphinxcode{is\_apolar\_method SASA/SAV} sets the definition of the cavitation
term in terms of surface area or surface area with volume. Default is
\sphinxcode{SASA}.

\item {} 
\sphinxcode{is\_apolar\_scaling\_factor x} controls the scaling of the apolar
term with the aim of taking solute-solvent dispersion-repulsion into
account. The default is 0.281075, which is good for MPSM, but not
necessarily SCCS or SSM.

\item {} 
\sphinxcode{is\_smeared\_ion\_rep T/F} turns on/off the smeared-ion
representation. Default is off, but if ONETEP detects you’re running
a solvation calculation, it will turn it on for you and let you off
with a warning. When comparing results of two calculations (e.g.
results in vacuum and in solvent), always ensure this is set
identically in both calculations.

\item {} 
\sphinxcode{is\_density\_threshold x} sets the MPSM model parameter
\(\rho_{0}\) to \(x\) (atomic units). The default is 0.00035,
as per Ref. {[}Dziedzic2011{]}.

\item {} 
\sphinxcode{is\_solvation\_beta x} sets the MPSM model parameter \(\beta\)
to \(x\) (no unit). The default is 1.3, as per Ref. {[}Dziedzic2011{]}.

\item {} 
\sphinxcode{is\_bulk\_permittivity x} sets the physical constant \textendash{} solvent bulk
permittivity \(\epsilon_{\infty}\) to \(x\) (no unit). The
default is 78.54 (suitable for water near room temperature and
pressure and at low frequencies) if implicit solvent is on, and 1.0
is implicit solvent is off.

\item {} 
\sphinxcode{is\_solvent\_surf\_tension x} sets the physical constant \textendash{} solvent
surface tension \(\gamma\) to \(x\) (unit must be supplied).
The default is 0.07415 N/m (which is suitable for water near room
temperature).

\item {} 
\sphinxcode{is\_solvent\_pressure x} sets the pressure used to calculate the
SAV contribution to the apolar term. Does not correspond to physical
water pressure and is optimised to obtain minimal errors with respect
to experimental free energies of solvation. Default is -0.35 GPa
(which is suitable for water near room temperature).

\item {} 
\sphinxcode{is\_dielectric\_model FIX\_INITIAL/SELF\_CONSISTENT} picks either the
fixed cavity or the self-consistently updated cavity, as described in
the section on the solute cavity.

\item {} 
\sphinxcode{is\_auto\_solvation x} automatically runs an in-vacuum calculation
before any solvation calculation, thus relieving the user from the
burden of manually restarting calculations. This attempts to
automatically control the directives for restarting, running two
calculations (vacuum and solvated) in succession. Using this
directive is a must when doing implicit-solvent geometry
optimisation, implicit-solvent molecular dynamics, implicit-solvent
transition state search or implicit-solvent forcetest. This directive
is compatible with conduction calculations.

\item {} 
\sphinxcode{is\_dielectric\_function FGF/SOFT\_SPHERE/ANDREUSSI} Defines the
function used to create dielectric cavity. Switches between the
charge density based MPSM (\sphinxcode{FGF}), the atomic radius-based soft
sphere model (\sphinxcode{SOFT\_SPHERE}) and SCCS (\sphinxcode{ANDREUSSI}).

\item {} 
\sphinxcode{is\_density\_min\_threshold x} Only applies to SCCS. Sets the
parameter \(\rho_{\textrm{min}}\). The default is 0.0001, which
corresponds to the “g03” fit in Ref. {[}Andreussi2012{]}.

\item {} 
\sphinxcode{is\_density\_max\_threshold x} Only applies to SCCS. Sets the
parameter \(\rho_{\textrm{max}}\). The default is 0.0050, which
corresponds to the “g03” fit in Ref. {[}Andreussi2012{]}.

\item {} 
\sphinxcode{is\_soft\_sphere\_scale x} Only applies to SSM. Scales the default
Alvarez vdW radii provided in ONETEP. The default is 1.33. This does
not apply to radii defined in the \sphinxcode{is\_soft\_sphere\_radii} block.

\item {} 
\sphinxcode{is\_soft\_sphere\_delta x} Only applies to SSM. Controls the
steepness of the transition from vacuum to the bulk permitivity
value. This applies to both default radii and those specified in the
\sphinxcode{is\_soft\_sphere\_radii} block. The default is 0.5.

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{is\_soft\_sphere\_radii} Only applies to SSM. Block sets the soft
sphere radii for species defined. These values are unaffected by
the scaling factor defined in \sphinxcode{is\_soft\_sphere\_scale}. Undefined
species will use the default values defined by Alvarez vdW (Ref. {[}Alvarez2013{]}).
Units bohr. e.g.
\item[] \sphinxcode{\%block is\_soft\_sphere\_radii}
\item[] \sphinxcode{Li 2.5}
\item[] \sphinxcode{Pt 4.6}
\item[] \sphinxcode{\%endblock is\_soft\_sphere\_radii}
\end{DUlineblock}

\end{itemize}


\subsubsection{Advanced}
\label{\detokenize{implicit_solvation_v3:advanced}}
The default settings usually work fine and the advanced settings should
only be changed if you know what you’re doing.
\begin{itemize}
\item {} 
\sphinxcode{is\_bc\_coarseness x} changes the size of the blocks into which
charge is coarsened when boundary conditions are calculated. The
default is 5. Smaller values may subtly increase accuracy, but will
incur a computational cost that grows as \(x^{-3}\). This can be
perfectly acceptable for smaller molecules. For larger molecules
(1000 atoms and more) use 7 or more to reduce computational cost. For
the effect of this parameter on accuracy, cf. Ref. {[}Dziedzic2013{]}.

\item {} 
\sphinxcode{is\_bc\_surface\_coarseness x} changes the size of the surface
blocks onto which charge is interpolated when boundary conditions are
calculated. The default is 1 and is recommended. Larger values will
improve computational cost (that grows as \(x^{-2}\)), but may
decrease accuracy, especially for charged molecules. If the
calculation of BCs becomes a bottleneck, prefer tweaking
\sphinxcode{is\_bc\_coarseness x} instead.

\item {} 
\sphinxcode{is\_bc\_allow\_frac\_charge T/F} (new in v6.1.1.28) when set to \sphinxcode{T},
the calculation of boundary conditions for the multigrid solver will
not check if the coarse-grained charge is close to an integer. This
can be used in rare cases where you know this is not going to be a
problem. The default is \sphinxcode{F}.

\item {} 
\sphinxcode{is\_separate\_restart\_files T/F} allows the set of restart files
used to construct the solute cavity in solvent to be distinct from
the set of restart files used to construct the initial density. This
is useful if you need to restart a solvated calculation, but still
want to construct the cavity from the converged vacuum density, and
not the partially-converged solvated density.
See section on manual solvation and restarts.

\item {} 
\sphinxcode{is\_restart\_vac\_from\_vac T/F} allows the in-vacuum calculation as
part of an auto-solvation calculation to be restarted from
\sphinxcode{.vacuum\_dkn} and \sphinxcode{.vacuum\_tightbox\_ngwfs} files, rather than the
usual \sphinxcode{.dkn} and \sphinxcode{.tightbox\_ngwfs} files.
See section on manual solvation and restarts.

\item {} 
\sphinxcode{is\_solvation\_properties T/F} when set to \sphinxcode{T} it will produce
scalarfields of quantities relevant in solvation during a properties
calculation. This is useful for visualising potentials, densities,
Boltzmann ion concentrations, electrolyte accessibilities, etc.
Ensure you supplied \sphinxcode{dx\_format T} and/or \sphinxcode{cube\_format T} and/or
\sphinxcode{grd\_format T}.

\item {} 
\sphinxcode{is\_smeared\_ion\_width x} sets the width of the smeared-ion
Gaussians, \(\sigma\), to \(x\) (in units you supply). The
default is 0.8 \(a_0\) and should be OK for most calculations.
Results should not depend on this parameter, but only if it’s within
rather narrow limits of sensibility. Too high values (anything larger
than 1.0, roughly) are seriously unphysical, as they will lead to
cores whose Gaussian tails stick out of the electronic density,
especially for hydrogen atoms. This is very bad, since it does not
change the energy \sphinxstyleemphasis{in vacuo} (the effect of the smearing, regardless
of \(\sigma\), is cancelled by the correction terms to energy),
but changes the energy in solution (by polarising the solvent
differently in reality the cores are screened by the electrons). Too
low values (anything smaller than 0.6, roughly), on the other hand,
will lead to Gaussians so thin and tall that they will become very
difficult for the multigrid solver to treat, requiring high orders
and unreasonably fine grids to obtain multigrid convergence. See
Ref. {[}Dziedzic2013{]} for more details.

\item {} 
\sphinxcode{fine\_grid\_scale x} makes the ONETEP fine grid \(x\) (no unit)
times as fine as the coarse grid, \(x\) does not have to be an
integer. The solution of the P(B)E and associated finite-difference
operations are performed on the fine grid (or its subset, for OBC).
Increasing \sphinxcode{fine\_grid\_scale} allows making this grid finer without
unnecessarily increasing the kinetic energy cutoff of the
calculation. The default is 2. Memory and computational effort
increase with the cube of \(x\).

\item {} 
\sphinxcode{is\_dielectric\_exclusions\_smear x} sets the smearing for dielectric
exclusion regions to \(x\) (in the units you supply). See
section on exclusion regions.

\item {} 
\sphinxcode{is\_emft\_cavity T/F} if EMFT is enabled at the same time as
implicit solvent, this controls whether the solvent cavity is
determined using the standard density kernel (at the lower level of
theory), or the EMFT kernel. The default is \sphinxcode{F}. See EMFT
documentation for more details.

\end{itemize}


\subsubsection{Fine control over DL\_MG}
\label{\detokenize{implicit_solvation_v3:fine-control-over-dl-mg}}
These keywords enable fine control over the behaviour of the DL\_MG
solver. See Ref. {[}Anton2020{]} for more details, particularly regarding convergence
control.
\begin{itemize}
\item {} 
\sphinxcode{mg\_use\_cg T/F} (new in v6.3.1.6) Turns on the conjugate gradient
solver. This generally increases the stability of the solver, but is
likely to reduce performance. It might be useful to turn this on if
you have problems converging difficult cases \textendash{} particularly in
Poisson-Boltzmann solvation.

\item {} 
\sphinxcode{mg\_use\_error\_damping T/F} can be used to turn on/off error damping
in the defect correction procedure. This is often necessary when
solving the full (non-linearised) Poisson-Boltzmann equation, but
will likely not do much for the linearised Poisson-Boltzmann equation
or for the Poisson equation. Accordingly, the default depends on
\sphinxcode{is\_pbe} and is \sphinxcode{F} for \sphinxcode{is\_pbe NONE} and
\sphinxcode{is\_pbe LINEARISED}, and \sphinxcode{T} for \sphinxcode{is\_pbe FULL}.

\item {} 
\sphinxcode{mg\_continue\_on\_error T/F} if \sphinxcode{T}, instructs the multigrid solver
not to abort if a solution to the P(B)E cannot be converged to
desired tolerances, and instead to return an underconverged solution.
This can be useful for particularly stubborn cases, especially in
Boltzmann solvation. Default is \sphinxcode{F} when solving the Poisson
equation and \sphinxcode{T} if solving the Poisson-Boltzmann equation. If you
want to turn it on for Boltzmann solvation, you will very likely need
to increase \sphinxcode{is\_pbe\_energy\_tolerance} by a very large amount.

\item {} 
\sphinxcode{mg\_defco\_fd\_order x} sets the discretization order used when
solving the P(B)E to \(x\) (no unit). Available values are 2, 4,
6, 8, 10 and 12, the default is 8. With 2 no defect correction is
performed. Values of 4 and above employ defect correction. The lowest
values (2 and 4) are not recommended, because they offer poor
accuracy. Generally the largest value (12) will offer best accuracy,
but this has to be weighed against a likely drop in performance
(higher orders often take longer) and possibility of Gibbs-like
phenomena that may occur when high orders are used with
steeply-changing dielectric permittivity, as is the case for larger
values of \(\beta\). 8 or 10 is a good starting value. Results
should not depend on the choice of this parameter, but performance
and multigrid convergence will. See the troubleshooting section below
for details. See Ref. {[}Dziedzic2013{]} for more details.

\item {} 
\sphinxcode{mg\_max\_iters\_vcycle x} sets the maximum number of multigrid
V-cycle iterations to \(x\) (no unit). The default is 50. See
Ref. {[}Womack2018{]} for a description of the solver, including the V-cycle scheme
employed.

\item {} 
\sphinxcode{mg\_max\_iters\_defco x} sets the maximum number of high-order defect
correction iterations to \(x\) (no unit). The default is 30. See
Ref. {[}Womack2018{]} for a description of the solver, including the defect
correction procedure.

\item {} 
\sphinxcode{mg\_max\_iters\_newton x} sets the maximum number of Newton method
iterations to \(x\) (no unit). The default is 30. This is only
relevant when solving the non-linear PBE. See Ref. {[}Womack2018{]} for a description
of the inexact-Newton method employed by the solver in this scenario.

\item {} 
\sphinxcode{mg\_max\_iters\_cg x} (new in v6.3.1.6) sets the maximum number of
iterations for conjugate gradients to \(x\) (no unit). The
default is 50. This is only relevant when \sphinxcode{mg\_use\_cg} is \sphinxcode{T}.

\item {} 
\sphinxcode{mg\_max\_res\_ratio x} sets the threshold for the consecutive
residual ratio which determines when the multigrid solver gives up
(positive real value, no unit, the default is 0.999). This should not
require tuning.

\item {} 
\sphinxcode{mg\_vcyc\_smoother\_iter\_pre x} sets the number of V-cycle smoother
iterations pre-smoothing (integer, no unit, the default is 2).
Difficult systems, particularly in PBCs, might benefit from an
increase of this value to 4 or 8.

\item {} 
\sphinxcode{mg\_vcyc\_smoother\_iter\_post x} sets the number of V-cycle smoother
iterations post-smoothing (integer, no unit, the default is 1).
Difficult systems, particularly in PBCs, might benefit from an
increase of this value to 4 or 8.

\item {} 
\sphinxcode{mg\_tol\_res\_rel} \(x\) Set the relative tolerance in the norm
of the residual for the defect correction procedure to \(x\) (no
units, the default is 1.0e-2).

\item {} 
\sphinxcode{mg\_tol\_res\_abs} \(x\) Set the absolute tolerance in the norm
of the residual for the defect correction procedure to \(x\)
(atomic units, the default is 5.0e-2).

\item {} 
\sphinxcode{mg\_tol\_pot\_rel} \(x\) Set the relative tolerance in the norm
of the potential for the defect correction procedure to \(x\) (no
units, the default is 1.0e-6).

\item {} 
\sphinxcode{mg\_tol\_pot\_abs} \(x\) Set the absolute tolerance in the norm
of the potential for the defect correction procedure to \(x\)
(atomic units, the default is 1.0e-6).

\item {} 
\sphinxcode{mg\_tol\_vcyc\_rel} \(x\) Set the relative tolerance for the norm
of the residual in multigrid V-cycle iterations to \(x\) (no
units, the default is 1.0e-8).

\item {} 
\sphinxcode{mg\_tol\_vcyc\_abs} \(x\) Set the absolute tolerance for the norm
of the residual in multigrid V-cycle iterations to \(x\) (atomic
units, the default is 1.0e-5).

\item {} 
\sphinxcode{mg\_tol\_newton\_rel} \(x\) Set the relative tolerance for the
norm of the residual in Newton method iterations to \(x\) (only
applies when solving the nonlinear PBE, no units, the default is
1.0e-8).

\item {} 
\sphinxcode{mg\_tol\_newton\_abs} \(x\) Set the absolute tolerance for the
norm of the residual in Newton method iterations to \(x\) (only
applies when solving the nonlinear PBE, atomic units, the default is
1.0e-5).

\item {} 
\sphinxcode{mg\_tol\_cg\_res\_rel} \(x\) (new in v6.3.1.6) Set the relative
tolerance in the norm of the residual for the conjugate gradients to
\(x\) (no units, the default is 1.0e-2). This is only relevant
when \sphinxcode{mg\_use\_cg} is \sphinxcode{T}.

\item {} 
\sphinxcode{mg\_tol\_cg\_res\_abs} \(x\) (new in v6.3.1.6) Set the absolute
tolerance in the norm of the residual for the conjugate gradients to
\(x\) (atomic units, the default is 5.0e-2). This is only
relevant when \sphinxcode{mg\_use\_cg} is \sphinxcode{T}.

\end{itemize}


\subsubsection{Expert}
\label{\detokenize{implicit_solvation_v3:expert}}
These will only be listed here and not discussed. The last three
keywords are discussed in a separate document devoted to the real space
local pseudopotential (see ONETEP website).
\begin{itemize}
\item {} 
\sphinxcode{mg\_granularity\_power},

\item {} 
\sphinxcode{is\_surface\_thickness},

\item {} 
\sphinxcode{is\_bc\_threshold},

\item {} 
\sphinxcode{is\_core\_width},

\item {} 
\sphinxcode{is\_check\_solv\_energy\_grad},

\item {} 
\sphinxcode{openbc\_pspot\_finetune\_nptsx},

\item {} 
\sphinxcode{openbc\_pspot\_finetune\_f},

\item {} 
\sphinxcode{openbc\_pspot\_finetune\_alpha}.

\end{itemize}


\subsection{Boltzmann solvation (solute with electrolyte)}
\label{\detokenize{implicit_solvation_v3:boltzmann-solvation-solute-with-electrolyte}}
ONETEP has the ability to perform Poisson-Boltzmann implicit solvent
calculations, that is, to include electrolyte in the implicit solvent.
The electrolyte is represented by point particles (“Boltzmann ions”),
which interact with one another only in the mean-field sense, and affect
the reaction field, providing a rudimentary model of screening. The
model is described in Ref. {[}Dziedzic2020{]} and Ref. {[}Bhandari2020{]}. Users would be well-advised to
read these first.

Boltzmann solvation calculations in ONETEP can be performed in OBC and
in PBC alike. In PBC care must be taken to suitably neutralise the
simulation cell so that the electrostatic energy does not diverge.
ONETEP offers a number of schemes to achieve this, including a novel
NECS scheme \textendash{} see \sphinxcode{is\_pbe\_neutralisation\_scheme} in
the section on keywords controlling Boltzmann solvation and carefully read Ref. {[}Bhandari2020{]}.

The inclusion of the electrolyte leads to the well-known nonlinear
Poisson-Boltzmann equation. ONETEP (or rather DL\_MG) can solve this
equation as is, or the linearised approximation can be used \textendash{} see
\sphinxcode{is\_pbe} in the section on Boltzmann solvation keywords.

Because Boltzmann ions are point particles, they tend to concentrate in
the immediate vicinity of the solute, often reaching unphysical
concentrations. A number of ways have been proposed to address this
problem. ONETEP implements a steric potential approach to keep the
Boltzmann ions sufficiently far from the solute \textendash{} see Ref. {[}Dziedzic2020{]} and
\sphinxcode{is\_pbe\_steric\_pot\_type} in the section on Boltzmann solvation keywords
for a description.

In the presence of the electrolyte a number of additional terms appear
in the grand potential. These are clearly listed in the output if auto
solvation is used:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Individual} \PYG{n}{components} \PYG{n}{of} \PYG{n}{total} \PYG{n}{energy} \PYG{o+ow}{in} \PYG{n}{solvent}\PYG{p}{:}     \PYG{n}{hartree}           \PYG{n}{kcal}\PYG{o}{/}\PYG{n}{mol}
\PYG{o}{\PYGZhy{}} \PYG{n}{Usual} \PYG{n}{non}\PYG{o}{\PYGZhy{}}\PYG{n}{electrostatic} \PYG{n}{DFT} \PYG{n}{terms}\PYG{p}{:}       \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{26.31256445391999}      \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{16511.383124}
\PYG{o}{\PYGZhy{}} \PYG{n}{Electrostatic} \PYG{n}{fixed} \PYG{n}{charge} \PYG{n}{energy}\PYG{p}{:}         \PYG{l+m+mf}{3.11407548141888}        \PYG{l+m+mf}{1954.111825}
\PYG{o}{\PYGZhy{}} \PYG{n}{Electrostatic} \PYG{n}{mobile} \PYG{n}{charge} \PYG{n}{energy}\PYG{p}{:}       \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.00000610048106}          \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.003828}
\PYG{o}{\PYGZhy{}} \PYG{n}{Accessibility} \PYG{p}{(}\PYG{n}{steric}\PYG{p}{)} \PYG{n}{correction}\PYG{p}{:}         \PYG{l+m+mf}{0.00000440501188}           \PYG{l+m+mf}{0.002764}
\PYG{o}{\PYGZhy{}} \PYG{n}{Osmotic} \PYG{n}{pressure} \PYG{n}{contribution}\PYG{p}{:}            \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.00045050433991}          \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.282696}
\PYG{o}{\PYGZhy{}} \PYG{n}{Ionic} \PYG{n}{atmosph}\PYG{o}{.} \PYG{n}{rearrangement} \PYG{n}{entropy}\PYG{p}{:}     \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.00082199171218}          \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.515808}
\PYG{o}{\PYGZhy{}} \PYG{n}{Chemical} \PYG{n}{potential} \PYG{n}{contribution}\PYG{p}{:}           \PYG{l+m+mf}{0.00082978766243}           \PYG{l+m+mf}{0.520700}
\PYG{o}{\PYGZhy{}} \PYG{n}{Apolar} \PYG{n}{cavitation} \PYG{n}{energy}\PYG{p}{:}                  \PYG{l+m+mf}{0.02130850899275}          \PYG{l+m+mf}{13.371291}
\PYG{o}{\PYGZhy{}} \PYG{n}{Apolar} \PYG{n}{dispersion}\PYG{o}{\PYGZhy{}}\PYG{n}{repulsion} \PYG{n}{energy}\PYG{p}{:}       \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.01531921982762}          \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{9.612955}
 \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}} \PYG{n}{Total} \PYG{n}{energy} \PYG{o+ow}{in} \PYG{n}{solvent}\PYG{p}{:}                 \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{23.19294408719482}      \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{14553.791830}
\end{sphinxVerbatim}

Similarly, the calculation of the free energy of solvation will include
additional terms due to the electrolyte:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Components} \PYG{n}{of} \PYG{n}{free} \PYG{n}{energy} \PYG{n}{of} \PYG{n}{solvation}\PYG{p}{:}               \PYG{n}{hartree}           \PYG{n}{kcal}\PYG{o}{/}\PYG{n}{mol}
\PYG{o}{\PYGZhy{}} \PYG{n}{Polar} \PYG{n}{term} \PYG{o+ow}{in} \PYG{n}{f}\PYG{o}{.}\PYG{n}{e}\PYG{o}{.} \PYG{n}{of} \PYG{n}{solvation}\PYG{p}{:} \PYG{p}{(}\PYG{o}{+}\PYG{p}{)}      \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.04757925126662}         \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{29.856430}
\PYG{o}{\PYGZhy{}} \PYG{n}{Apolar} \PYG{p}{(}\PYG{n}{cavitation}\PYG{p}{,} \PYG{n}{dis}\PYG{o}{.}\PYG{p}{,} \PYG{n}{rep}\PYG{o}{.}\PYG{p}{)}\PYG{p}{:} \PYG{p}{(}\PYG{o}{+}\PYG{p}{)}       \PYG{l+m+mf}{0.00598928916514}           \PYG{l+m+mf}{3.758336}
\PYG{o}{\PYGZhy{}} \PYG{n}{Non}\PYG{o}{\PYGZhy{}}\PYG{n}{es}\PYG{o}{.} \PYG{n}{electrolyte} \PYG{n}{terms}\PYG{p}{:}       \PYG{p}{(}\PYG{o}{+}\PYG{p}{)}      \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.00044440385885}          \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.278868}
\PYG{o}{\PYGZhy{}} \PYG{n}{Energy} \PYG{n}{of} \PYG{n}{pure} \PYG{n}{electrolyte}\PYG{p}{:}      \PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{p}{)}      \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.00048258128208}          \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.302824}
 \PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}
\PYG{o}{\PYGZhy{}} \PYG{n}{Total} \PYG{n}{free} \PYG{n}{energy} \PYG{n}{of} \PYG{n}{solvation}\PYG{p}{:}           \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.04154568419718}         \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{26.070310}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] 
\item[] If you chose not to use auto solvation, you will have to rely on the
ENERGY COMPONENTS table to find the individual terms, while the energy
of pure electrolyte will be printed out for you at the end of the
in-solvent calculation.
\end{DUlineblock}


\subsubsection{Keywords controlling Boltzmann solvation}
\label{\detokenize{implicit_solvation_v3:keywords-controlling-boltzmann-solvation}}
The following keywords control the Poisson-Boltzmann implicit solvation
functionality, which allows performing calculations in implicit solvent
containing electrolyte represented by Boltzmann ions.
\begin{itemize}
\item {} 
\sphinxcode{is\_pbe NONE/LINEARISED/FULL} chooses the equation to be solved in
implicit solvation. \sphinxcode{NONE} chooses the (generalised) Poisson
equation, which corresponds to solvation in the absence of an
electrolyte. \sphinxcode{LINEARISED} chooses the linearised Poisson-Boltzmann
equation (LPBE), which is a simplified treatment of electrolyte.
\sphinxcode{FULL} chooses the full, non-linear Poisson-Boltzmann equation
(NLPBE), which deals with the electrolyte without the simplifications
offered by linearisation. The default is \sphinxcode{NONE}.

\end{itemize}

Except where noted \sphinxstylestrong{(*)}, all the below keywords only have an effect
if \sphinxcode{is\_pbe} is \sphinxstyleemphasis{not} \sphinxcode{NONE}. Similarly, except where noted \sphinxstylestrong{(*)},
all the defaults given below only apply to calculations where \sphinxcode{is\_pbe}
is \sphinxstyleemphasis{not} \sphinxcode{NONE}.
\begin{itemize}
\item {} 
\sphinxcode{is\_pbe\_temperature T} sets the temperature of the Boltzmann ions
to \sphinxcode{T} (in K). The default is 300 K.

\item {} 
\sphinxcode{is\_pbe\_bc\_debye\_screening T/F} includes (\sphinxcode{T}) or does not
include (\sphinxcode{F}) the effect of Debye screening in the calculation of
Dirichlet boundary conditions for calculations in solvent. This only
has an effect in OBC. With Debye screening an additional
multiplicative factor of
\(\exp{\left(-r/\lambda_{\textrm{D}}\right)}\), where
\(\lambda_{\textrm{D}}\) is the Debye length, is included in the
boundary conditions. This is exact for LPBE and an approximation in
NLPBE. Turning off Debye screening will cause ONETEP to use BCs that
are appropriate for the case of no electrolyte, which will be
unphysical. The default is \sphinxcode{T}.

\item {} 
\sphinxcode{is\_pbe\_exp\_cap c} \textendash{} sets the exponential cap to \(c\) (no
unit). This is only relevant to \sphinxcode{is\_pbe FULL}. In solving the NLPBE
it is a well-known issue that the exponential factors that appear in
certain expressions (e.g. for the Boltzmann ion concentration) are
prone to exploding (in the usual floating-point representation) when
the value of the argument to the \(\exp\) function is large. To
retain numerical stability, the arguments to the \(\exp\)
function are typically capped, i.e. they are not allowed to exceed a
predefined constant. The default in ONETEP is \(0.0\), which
means \(c\) is set to the default cap in DL\_MG, which is
currently \(50.0\). Specifying any value other than \(0.0\)
will cause ONETEP to discard the default provided by DL\_MG and to
use the user-specified value.

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{is\_pbe\_neutralisation\_scheme scheme} chooses a specified
neutralisation scheme.
\item[] \sphinxstylestrong{(*)} This keyword and its defaults can also apply to
\sphinxcode{is\_pbe NONE}. This is only relevant for PBC calculations with
non-zero total solute charge. In this scenario the total system
charge (solute + electrolyte) must be zero for the electrostatic
energy not to diverge. There are many ways of ensuring charge
neutrality. ONETEP implements the following:
\end{DUlineblock}
\begin{itemize}
\item {} 
\sphinxcode{NONE} ignores charge neutralisation. This is only meaningful
for OBC or when the system is charge-neutral. This is the default
in OBC.

\item {} 
\sphinxcode{JELLIUM} applies the common jellium neutralisation, shifting
the charge density by its negative average, so that the average
density is zero. This is the default for PBC with no electrolyte
(\sphinxcode{is\_pbe NONE}).

\item {} 
\sphinxcode{ACCESSIBLE\_JELLIUM} applies a modified jellium neutralisation
(cf. Ref. {[}Bhandari2020{]}, Sec. 3.3). This is only applicable when \sphinxcode{is\_pbe} is
\sphinxstyleemphasis{not} \sphinxcode{NONE}.

\item {} 
\sphinxcode{COUNTERIONS\_AUTO} applies neutralisation by electrolyte
concentration shift (NECS) (cf. Ref. {[}Bhandari2020{]}, Sec. 3.1) with optimal
shift parameters (cf. Ref. {[}Bhandari2020{]}, Eqs. 14 and 15). This is the default
in PBC with electrolyte (\sphinxcode{is\_pbe LINEARISED} or
\sphinxcode{is\_pbe FULL}).

\item {} 
\sphinxcode{COUNTERIONS\_AUTO\_LINEAR} applies neutralisation by electrolyte
concentration shift (NECS) (cf. Ref. {[}Bhandari2020{]}, Sec. 3.1) with shift
parameters derived from a linear approximation (cf. Ref. {[}Bhandari2020{]},
Eq. 18).

\item {} 
\sphinxcode{COUNTERIONS\_FIXED} applies neutralisation by electrolyte
concentration shift (NECS) (cf. Ref. {[}Bhandari2020{]}, Sec. 3.1) with shift
parameters specified by the user via \sphinxcode{\%block\_sol\_ions}.

\end{itemize}

\item {} 
\sphinxcode{is\_pbe\_energy\_tolerance E} sets the tolerance for the discrepancy
between two expressions for the mean-field contribution to the grand
potential to \(E\) (in units you supply). The two expressions are
(A): Ref. {[}Bhandari2020{]}, Eq. 5, where individual terms are calculated according to
Eqs. 10, 12, 13, 15, and 16 \sphinxstyleemphasis{except} for the fixed electrostatic term
(first term in brackets in Eq. 10), which is excluded here; and (B)
Ref. {[}Bhandari2020{]}, Eq. 31 (for PBC) or Eq. 35 (for OBC) \sphinxstyleemphasis{except} for the fixed
electrostatic term (first term in brackets in Eq. 10), which is also
excluded here. For \sphinxcode{is\_pbe FULL} we expect the two expressions to
be identical (modulo numerical noise). For \sphinxcode{is\_pbe LINEARISED} we
expect the two expressions to be identical to first order (modulo
numerical noise). The check is useful for detecting poorly converged
solutions of the PBE. The default is \(0.001\) kcal/mol for
\sphinxcode{is\_pbe FULL}, and \(0.05\) kcal/mol for \sphinxcode{is\_pbe LINEARISED}.
Normally you should not need to adjust this parameter. However, it
might need to be increased, perhaps dramatically, if you set
\sphinxcode{mg\_continue\_on\_error T}.

\item {} 
\sphinxcode{is\_pbe\_steric\_pot\_type X/H/M/S} specifies the type of steric
potential that will affect Boltzmann ions. This is to prevent them
from unphysically concentrating in the immediate vicinity of the
solute. The available options are:
\begin{itemize}
\item {} 
\sphinxcode{X} no steric potential. This is not recommended, except in
contrived test cases. This is currently the default, but this
might change later.

\item {} 
\sphinxcode{H} hard-core potential (see below). The hard-core potential is
infinite within the radial cutoff \(r_{\textrm{c}}\), and zero
elsewhere. Numerically this is realised by setting the
accessibility to \(\gamma=0\) within the radial cutoff, and to
\(\gamma=1\) elsewhere. This choice can pose numerical
difficulties because of the infinite steepness, and is not
recommended.

\item {} 
\sphinxcode{M} smoothed hard-core potential (see below). \sphinxstylestrong{This is the
recommended choice}. Here the accessibility is defined as
\(\gamma=\frac{1}{2} + \frac{1}{2} \operatorname{erf}{(\frac{r-r_{\textrm{c}}}{\sigma})}\),
with values below \(10^{-7}\) then set to \(10^{-90}\).
The potential, as always, is \(-kT \ln{\gamma}\). Here,
\(r_{\textrm{c}}\) is the radial cutoff, \(\sigma\) is the
smearing parameter.

\item {} 
\sphinxcode{S} soft-core potential, that is, a potential of the form
\(Ar^{-12}\operatorname{erf}{(\alpha{}r)}^{12}\) (see the
\sphinxcode{is\_sc\_} keywords below). This potential does not seem to work
well (too soft) and is not recommended.

\end{itemize}

For both hard-core steric potentials the radial cutoff
\(r_{\textrm{c}}\) is determined as a sum of two components: the
solvent radial cutoff \(r_{\textrm{c}}^{\textrm{solvent}}\), and
the solute radial cutoff \(r_{\textrm{c}}^{\textrm{solute}}\).
The solvent radial cutoff is set by the \sphinxcode{species\_solvent\_radius}
block, with one value per \sphinxstyleemphasis{solute} (sic!) species. The solute radial
cutoff is determined through \sphinxcode{is\_hc\_steric\_dens\_isovalue} and also
depends on the solute species (see below). The solute cutoff is
determined for each species separately, by examining the radial
valence-electronic density profile coming from the pseudoatomic
solver. The radial density is scanned from infinity to zero for a
value equal to or larger than \(n_0\) (specified via
\sphinxcode{is\_hc\_steric\_dens\_isovalue}). The radial coordinate of this value
is taken as \(r_{\textrm{c}}^{\textrm{solute}}\). If
\sphinxcode{is\_hc\_steric\_dens\_isovalue} is negative,
\(r_{\textrm{c}}^{\textrm{solute}}=0\). Thus, the solute radial
cutoff is constant, and does depend on the current electronic
density, only on the output of the atomic solver.

\item {} 
\sphinxcode{is\_hc\_steric\_dens\_isovalue n\_0} sets the density isovalue used to
determine \(r_{\textrm{c}}^{\textrm{solute}}\) to \(n_0\)
atomic units. The default is 0.003. This only applies to
\sphinxcode{is\_pbe\_steric\_pot\_type H/M}.

\item {} 
\sphinxcode{is\_hc\_steric\_smearing \textbackslash{}sigma} sets the smearing width for the
smoothed hard-core cutoff (\sphinxcode{is\_pbe\_steric\_pot\_type M}) to
\(\sigma\) (in units you supply). The default is
0.4 \(a_0\).

\item {} 
\sphinxcode{is\_sc\_steric\_magnitude A} sets the magnitude of the soft-core
steric potential to \(A\) (in units you supply, dimension: energy
\(\times\) distance\(^{12}\)). Default is negative, to
force users not to forget this parameter. This only applies to
\sphinxcode{is\_pbe\_steric\_pot\_type S}, which you should not be using anyway.

\item {} 
\sphinxcode{is\_sc\_steric\_smoothing\_alpha \textbackslash{}alpha} sets the smoothing parameter
of the soft-core steric potential to \(\alpha\) (in units you
supply, dimension: inverse distance). Default is
1.5 \({a_0}^{-1}\). This only applies to
\sphinxcode{is\_pbe\_steric\_pot\_type S}, which you should not be using anyway.

\item {} 
\sphinxcode{is\_sc\_steric\_cutoff r\_\{\textbackslash{}textrm\{c\}\}} sets the radial cutoff for the
soft-core steric potential to \(r_{\textrm{c}}\) (in units you
supply). Since the range of this potential is technically infinite,
we truncate it to zero beyond a specified distance,
\(r_{\textrm{c}}\). This only applies to
\sphinxcode{is\_pbe\_steric\_pot\_type S}, which you should not be using anyway.

\item {} 
\sphinxcode{is\_steric\_write T/F} if set to \sphinxcode{T}, the steric potential and
associated accessibility will be written out as scalarfields when
initialised. Ensure you supplied \sphinxcode{dx\_format T} and/or
\sphinxcode{cube\_format T} and/or \sphinxcode{grd\_format T}.

\item {} 
\sphinxcode{sol\_ions} is a block describing the Boltzmann ions in the system.
The format for \(n\) Boltzmann ions is as follows:

\begin{DUlineblock}{0em}
\item[] \sphinxcode{\%block sol\_ions}
\item[] \sphinxcode{ion\_species\_1 charge\_1 conc\_1 x\_1}
\item[] \sphinxcode{ion\_species\_2 charge\_2 conc\_2 x\_2}
\item[] \sphinxcode{...}
\item[] \sphinxcode{ion\_species\_n charge\_n conc\_n x\_n}
\item[] \sphinxcode{\%endblock sol\_ions}
\item[] Here, \sphinxcode{ion\_species\_i} is the name of the species of
Boltzmann ion \(i\) (which is irrelevant from the physical
point of view), \sphinxcode{charge\_i} is the charge on species
\(i\), \sphinxcode{conc\_i} is the concentration of that species (in
mol/L), and \sphinxcode{x\_i}, which is optional, is a NECS shift
parameter for species \(i\), relevant only for
\sphinxcode{is\_pbe\_neutralisation\_scheme COUNTERIONS\_FIXED}. For example, to
define a 1M NaCl electrolyte, you would use:
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] \sphinxcode{\%block sol\_ions}
\item[] \sphinxcode{Na +1 1.0}
\item[] \sphinxcode{Cl +1 1.0}
\item[] \sphinxcode{\%endblock sol\_ions}
\end{DUlineblock}

\item {} 
\sphinxcode{species\_solvent\_radius} defines the solvent radial cutoff
\(r_{\textrm{c}}^{\textrm{solvent}}\) for every \sphinxstyleemphasis{solute} (sic!)
species, as follows:

\begin{DUlineblock}{0em}
\item[] \sphinxcode{\%block species\_solvent\_radius}
\item[] \sphinxcode{species\_1 r\_1}
\item[] \sphinxcode{species\_2 r\_2}
\item[] \sphinxcode{...}
\item[] \sphinxcode{species\_n r\_n}
\item[] \sphinxcode{\%endblock species\_solvent\_radius}
\item[] For example, to keep all the Boltzmann ions an extra
\(3.5~{a_0}\) away from your methane solute, you would use:
\item[] \sphinxcode{\%block species\_solvent\_radius}
\item[] \sphinxcode{C 3.5}
\item[] \sphinxcode{H 3.5}
\item[] \sphinxcode{\%endblock species\_solvent\_radius}
\end{DUlineblock}

\end{itemize}


\subsection{Various hints for a successful start}
\label{\detokenize{implicit_solvation_v3:various-hints-for-a-successful-start}}\begin{itemize}
\item {} 
Use one of the examples provided on the ONETEP website as a starting
point.

\item {} 
Make sure both your vacuum and solvated calculations use smeared
ions.

\item {} 
Make sure the parameters of both your vacuum and solvated
calculations are identical (box sizes, KE cutoffs, \sphinxcode{k\_zero},
\sphinxcode{mg\_defco\_fd\_order}, \sphinxcode{is\_smeared\_ion\_width},
\sphinxcode{is\_bc\_coarseness}, \sphinxcode{is\_bc\_surface\_coarseness}). Or just use
\sphinxcode{is\_auto\_solvation T}.

\item {} 
Choose \sphinxcode{FIX\_INITIAL} over \sphinxcode{SELF\_CONSISTENT} for
\sphinxcode{is\_dielectric\_model}.

\item {} 
Use an \sphinxcode{mg\_defco\_fd\_order} of 8 and \sphinxcode{is\_smeared\_ion\_width} of
0.8. Specify them explicitly, as the defaults may change in the
future.

\item {} 
Do not mess with expert directives.

\item {} 
In OBC, have at least about 10 bohr of vacuum/solvent around the
edges of your molecule’s NGWFs (not atomic positions) on each side of
the simulation cell, \sphinxstyleemphasis{after taking the truncation into account} \textendash{}
cf. section on grid sizes under OBC.

\item {} 
Always start your calculation in solution as a restart from a fully
converged \sphinxstyleemphasis{in vacuo} calculation. Or just use
\sphinxcode{is\_auto\_solvation T}.

\end{itemize}


\subsection{Troubleshooting: Problems, causes and solutions}
\label{\detokenize{implicit_solvation_v3:troubleshooting-problems-causes-and-solutions}}\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{Problem A}: ONETEP crashes (e.g. catching \sphinxcode{SIGKILL} or
\sphinxcode{SIGSEGV}) when evaluating the boundary conditions or solving the
P(B)E.
\item[] \sphinxstylestrong{Cause (A1)}: You’ve run out of memory and the OOM killer killed
the calculation. Solving the P(B)E often represents the peak memory
usage of the calculation.
\item[] \sphinxstylestrong{Solution (A1)}: Increase available memory (perhaps by shifting
the MPI/OMP balance towards more threads and fewer MPI processes)
or decrease box size or decrease grid fineness.
\item[] \sphinxstylestrong{Cause (A2)}: You’ve run out of global stack space. Solving the
P(B)E often represents the peak stack usage of the calculation.
\item[] \sphinxstylestrong{Solution (A2)}: Increase stack size using \sphinxcode{ulimit -s}. Make
sure you do that on compute nodes, not the login node. Or,
preferably, use \sphinxcode{onetep\_launcher} and its \sphinxcode{-s} parameter.
\sphinxstylestrong{Cause (A3)}: You’ve run out of per-thread stack space. Solving
the P(B)E often represents the peak per-thread stack usage of the
calculation.
\item[] \sphinxstylestrong{Solution (A3)}: Increase per-thread stack size using
\sphinxcode{ulimit -s}. Make sure you do that on compute nodes, not the
login node. Or, preferably, use \sphinxcode{onetep\_launcher} and its \sphinxcode{-o}
parameter.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{Problem B}: Multigrid calculation does not converge (error
message from DL\_MG) or converges very slowly (as evidenced by the
contents of a log file with a filename ending in
\sphinxcode{\_dl\_mg\_log.txt}).
\item[] \sphinxstylestrong{Cause (B1)}: (Only applies to OBC calculations) Charge is not
correctly localized (cell is too small or molecule otherwise too
close to cell edge).
\item[] \sphinxstylestrong{Solution (B1)}: Check and fix the cell size, paying attention to
the margin between the DL\_MG grid and fine grid.
\item[] \sphinxstylestrong{Cause (B2)}: Dielectric permittivity too steeply changing on the
cavity boundary for the current grid size, finite differences
struggling to approximate the changes. This is often the culprit if
the calculation ran fine \sphinxstyleemphasis{in vacuo} but struggles in solvent.
\item[] \sphinxstylestrong{Solution (B2)}: Preferable, but painful, solution is to make the
grid finer (\sphinxcode{fine\_grid\_scale}). Otherwise an increase or decrease
of discretisation order may help (make sure it stays consistent
across your calculations, though). A parameterisation with lower
\sphinxcode{is\_solvation\_beta} and \sphinxcode{is\_density\_threshold} will usually
help (make sure it stays consistent across your calculations,
though).
\item[] \sphinxstylestrong{Cause (B3)}: The smearing width is too small, making the smeared
cores too thin and tall, which is difficult for the finite
differences. This is often the culprit if the calculation also
struggles \sphinxstyleemphasis{in vacuo}.
\item[] \sphinxstylestrong{Solution (B3)}: Increasing \sphinxcode{is\_smeared\_ion\_width} will help
(but mind the consequences), if it was too small in the first
place. Increasing the discretisation order will help (especially if
you’ve been using less than 10), but might lead to a similar
problem (Cause (B2)) in solution.
\item[] \sphinxstylestrong{Cause (B4)}: Too lax thresholds for convergence of the defect
correction in DL\_MG.
\item[] \sphinxstylestrong{Solution (B4)}: To tighten the convergence threshold of the
defect correction in DL\_MG, adjust the values of
\sphinxcode{mg\_tol\_res\_rel}, \sphinxcode{mg\_tol\_res\_abs}, \sphinxcode{mg\_tol\_pot\_rel} and
\sphinxcode{mg\_tol\_pot\_abs}.
\item[] \sphinxstylestrong{Cause (B5)}: Too few defect correction iterations in DL\_MG.
\item[] \sphinxstylestrong{Solution (B5)}: To increase the number of defect correction
iterations in DL\_MG, use \sphinxcode{mg\_max\_iters\_defco}, try 200 for good
measure.
\item[] \sphinxstylestrong{Cause (B6)}: Too few smoother iterations in DL\_MG, particularly
if this is a Boltzmann calculation.
\item[] \sphinxstylestrong{Solution (B6)}: Increase the number of smoother iterations in
DL\_MG to 2 or 4 using {}`{}` mg\_vcyc\_smoother\_iter\_pre{}`{}` and
\sphinxcode{mg\_vcyc\_smoother\_iter\_post}.
\item[] \sphinxstylestrong{Cause (B7)}: Too few V-cycle iterations in DL\_MG.
\item[] \sphinxstylestrong{Solution (B7)}: Increase the number of V-cycle iterations in
DL\_MG using \sphinxcode{mg\_max\_iters\_vcyc}, try 200 for good measure.
\item[] \sphinxstylestrong{Cause (B8)}: Too few Newton iterations in DL\_MG. This only
applies if you are solving the NLPBE in Boltzmann solvation.
\item[] \sphinxstylestrong{Solution (B8)}: Increase the number of Newton iterations using
\sphinxcode{mg\_max\_iters\_newton}, try 100 for good measure.
\item[] \sphinxstylestrong{Cause (B9)}: Problem is too difficult for the solver \textendash{} e.g.
grids are not fine enough, the dielectric cavity has a steep
boundary (usually happens when underconverged densities are used to
generate it), Boltzmann-ionic concentrations changing too steeply,
etc.
\item[] \sphinxstylestrong{Solution (B9)}: Try using the conjugate gradient approach \textendash{} add
\sphinxcode{mg\_use\_cg T} to your input file. This is only available in
versions v6.1.3.6 and newer.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxstylestrong{Problem C}: Calculation struggles to converge LNV or NGWFs or
does not converge at all. RMS gradient stalls.
\item[] \sphinxstylestrong{Cause (C1)}: If you’re using
\sphinxcode{is\_dielectric\_model SELF\_CONSISTENT}, then this is normal,
unless your grid is ridiculously fine (you will need
\sphinxcode{psinc\_spacing 0.5} and \sphinxcode{fine\_grid\_scale 3} or better, as a
rule of thumb).
\item[] \sphinxstylestrong{Solution (C1)}: Use \sphinxcode{is\_dielectric\_model FIX\_INITIAL} if
possible. If you are sure you need
\sphinxcode{is\_dielectric\_model SELF\_CONSISTENT}, make the grid finer and
have a lot of memory.
\item[] \sphinxstylestrong{Cause (C2)}: Density kernel is not converged enough.
\item[] \sphinxstylestrong{Solution (C2)}: \sphinxcode{Try minit\_lnv 6} and \sphinxcode{maxit\_lnv 6} (for
smaller molecules) or \sphinxcode{minit\_lnv 10} and \sphinxcode{maxit\_lnv 10} (for
large molecules).
\end{DUlineblock}

\end{itemize}


\subsection{Frequently asked questions}
\label{\detokenize{implicit_solvation_v3:frequently-asked-questions}}

\subsubsection{What are the values for the model parameters?}
\label{\detokenize{implicit_solvation_v3:what-are-the-values-for-the-model-parameters}}
Two sets of values for MPSM will be proposed here. The first one will be
called high-beta parameterisation. It offers the best quality (in terms
of r.m.s. error from experiment) for both charged and neutral species.
The drawback is that the high value of \(\beta\) means the multigrid
convergence is poor and it often takes a while to converge. Or it may
not converge. This should be your first choice \sphinxstylestrong{only} if accuracy
trumps anything else. The parameters are:

\begin{DUlineblock}{0em}
\item[] \sphinxcode{is\_solvation\_beta 1.6}
\item[] \sphinxcode{is\_density\_threshold 0.00055}
\end{DUlineblock}

The second parameterisation, called low-beta should pose no problems to
the multigrid solver under any circumstances. Quality should be only
marginally worse for anions and neutrals and comparable or better for
cations. These are the default parameters, and they are:

\begin{DUlineblock}{0em}
\item[] \sphinxcode{is\_solvation\_beta 1.3}
\item[] \sphinxcode{is\_density\_threshold 0.00035}
\end{DUlineblock}

Both parameterisations assume \sphinxcode{is\_bulk\_permittivity 78.54}, which is
suitable for water. It should be noted that the model is deficient in
its treatment of anions, consistently underestimating the magnitude of
the solvation effect by 10-25\%. Work is ongoing to fix this, until then
a different parameterisation may be used if one is only interested in
anionic species.


\subsubsection{Can you do solvents other than water?}
\label{\detokenize{implicit_solvation_v3:can-you-do-solvents-other-than-water}}
Yes, provided you know the dielectric permittivity of the solvent and
its surface tension. Accuracy has not been extensively tested, but it
should work.


\subsubsection{Can you do mixed boundary conditions?}
\label{\detokenize{implicit_solvation_v3:can-you-do-mixed-boundary-conditions}}
Not yet, but we might in the future.


\subsubsection{Is implicit solvation compatible with conduction calculations?}
\label{\detokenize{implicit_solvation_v3:is-implicit-solvation-compatible-with-conduction-calculations}}
Yes, to the best of our knowledge.


\subsubsection{Is implicit solvation compatible with PAW?}
\label{\detokenize{implicit_solvation_v3:is-implicit-solvation-compatible-with-paw}}
Yes, to the best of our knowledge.


\subsection{Known issues and untested functionality}
\label{\detokenize{implicit_solvation_v3:known-issues-and-untested-functionality}}\begin{itemize}
\item {} 
PBC are not yet currently compatible with the
\sphinxcode{is\_dielectric\_exclusions} block.

\item {} 
PBC have not been tested in self-consistent cavity mode—only fixed
cavity calculations are guaranteed to work.

\item {} 
Forces and geometry optimisation have not been tested when using
implicit solvent under PBC—only energy calculations are guaranteed to
work.

\end{itemize}


\subsection{Contact}
\label{\detokenize{implicit_solvation_v3:contact}}
General questions about implicit solvation in ONETEP should be directed
to Jacek Dziedzic (\sphinxcode{J.Dziedzic{[}-at-{]}soton.ac.uk}). Questions regarding
Boltzmann (electrolyte) solvation should be directed to Arihant Bhandari
(\sphinxcode{A.Bhandari{[}-at-{]}soton.ac.uk}).

{[}Dziedzic2011{]} J. Dziedzic, H. H. Helal, C.-K. Skylaris, A. A. Mostofi, and M. C. Payne, \sphinxstyleemphasis{Minimal parameter implicit solvent model for ab initio electronic-structure calculations}, EPL \sphinxstylestrong{95} (2011).

{[}Dziedzic2013{]} J. Dziedzic, S. J. Fox, T. Fox, C. S. Tautermann, and C.-K. Skylaris, \sphinxstyleemphasis{Large-Scale DFT Calculations in Implicit Solvent \textendash{} A Case Study on the T4 Lysozyme L99A/M102Q Protein}, International Journal of Quantum Chemistry \sphinxstylestrong{113} issue 6 (2013).

{[}Scherlis2006{]} D. A. Scherlis, J.-L. Fattebert, F. Gygi, M. Cococcioni, and N. Marzari, \sphinxstyleemphasis{A unified electrostatic and cavitation model for first-principles molecular dynamics in solution}, J. Chem. Phys. \sphinxstylestrong{124} (2006).

{[}Fisicaro2017{]} G. Fisicaro, L. Genovese, O. Andreussi, S. Mandal, N. Nair, N. Marzari and S. Goedecker, \sphinxstyleemphasis{Soft-Sphere Continuum Solvation in Electronic-Structure Calculations}, J. Chem. Theory Comput. \sphinxstylestrong{13} (2017).

{[}Alvarez2013{]} S. Alvarez \sphinxstyleemphasis{A cartography of the van der Waals territories}, Dalton Trans. \sphinxstylestrong{42} (2013).

{[}Anton2020{]} L. Anton, J. Womack, and J. Dziedzic, \sphinxstyleemphasis{DL\_MG multigrid solver} (2020) \sphinxurl{http://www.dlmg.org}

{[}Womack2018{]} J. C. Womack, L. Anton, J. Dziedzic, P. J. Hasnip, M. I. J. Probert, and C.-K. Skylaris, J. Chem. Theory Comput. \sphinxstylestrong{14}, 1412 (2018).

{[}Andreussi2012{]} O. Andreussi, I. Dabo and N. Marzari, \sphinxstyleemphasis{Revised self-consistent continuum solvation in electronic-structure calculations}, J. Chem. Phys. \sphinxstylestrong{136} (2012).

{[}Dziedzic2020{]} J. Dziedzic, A. Bhandari, L. Anton, C. Peng, J. C. Womack, M. Famili, D. Kramer, and C.-K. Skylaris, \sphinxstyleemphasis{Practical Approach to Large-Scale Electronic Structure Calculations in Electrolyte Solutions via Continuum-Embedded Linear-Scaling Density Functional Theory}, J. Phys. Chem. C \sphinxstylestrong{124} (2020).

{[}Bhandari2020{]} A. Bhandari, L. Anton, J. Dziedzic, C. Peng, D. Kramer, and C.-K. Skylaris, \sphinxstyleemphasis{Electronic Structure Calculations in Electrolyte Solutions: Methods for Neutralization of Extended Charged Interfaces}, J. Chem. Phys. \sphinxstylestrong{153} (2020).


\section{Spherical wave resolution of identity (SWRI), Hartree-Fock exchange (HFx), hybrid functionals and distributed multipole analysis (DMA)}
\label{\detokenize{hfx::doc}}\label{\detokenize{hfx:spherical-wave-resolution-of-identity-swri-hartree-fock-exchange-hfx-hybrid-functionals-and-distributed-multipole-analysis-dma}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Jacek Dziedzic, University of Southampton

\item[{Author}] \leavevmode
James C. Womack, University of Southampton

\item[{Date}] \leavevmode
June 2020

\end{description}\end{quote}

This manual pertains to ONETEP versions v5.3.4.0 and later.


\subsection{The basics}
\label{\detokenize{hfx:the-basics}}
ONETEP offers linear-scaling calculation of Hartree-Fock exchange (HFx)
and linear-scaling distributed multipole analysis (DMA) through a
variant of density fitting. In this approach products of two NGWFs are
approximated (fitted) using an auxiliary basis of spherical waves
centred on the atoms on which the two NGWFs reside. Before the expansion
can be performed, an overlap matrix between spherical waves on all
centres whose NGWFs overlap needs to be calculated. The resultant matrix
will be termed the \sphinxstyleemphasis{metric matrix}, and the process through which it is
obtained will be termed \sphinxstyleemphasis{spherical wave resolution of identity (SWRI)}.
Understanding the keywords controlling SWRI is thus essential for any
calculation involving HFx or DMA.


\subsection{Limitations}
\label{\detokenize{hfx:limitations}}
All calculations using SWRI have these limitations:
\begin{itemize}
\item {} 
Open boundary conditions (OBCs) are assumed in all uses of SWRI. If
your calculation uses OBCs (via cut-off Coulomb, Martyna-Tuckerman or
multigrid {[}Hine2011{]}), this is a non-issue. If your
calculation technically uses PBCs, but you have sufficient vacuum
padding in every direction (effectively making it approximately OBC),
this is a non-issue. If your system is truly extended in any
direction (at least one NGWF sphere sticks out of the cell and wraps
around), this is an issue, as neither HFx nor DMA will work
(producing nonsense). This is not checked!

\item {} 
All species must have identical NGWF radii. Without this
simplification the numerical methods used in SWRI would get ugly.
Typically this is a non-issue, just increase the NGWF radii to the
largest value. This might admittedly be an issue if you have a single
species that requires a large NGWF radius. This is checked against
and ONETEP will not let you do SWRI unless all NGWF radii are
identical.

\item {} 
Although well-controllable, density fitting is an approximation.
Using settings that are too crude can lead to inaccurate results and
poor NGWF convergence.

\item {} 
HFx is incompatible with PAW and ONETEP will refuse to use both
simultaneously.

\item {} 
HFx and DMA are incompatible with complex NGWFs and ONETEP will
refuse to use both.

\item {} 
HFx does not work with atoms that have 0 NGWFs, although this is
hardly a limitation.

\end{itemize}


\subsection{Spherical wave resolution of identity}
\label{\detokenize{hfx:spherical-wave-resolution-of-identity}}

\subsubsection{Generating the metric matrix}
\label{\detokenize{hfx:generating-the-metric-matrix}}
Calculation of the metric matrix {[}Dziedzic2013{]} (Sec. II.D.1) is
challenging. This is because products of spherical waves (SWs) and
products of a spherical wave with a potential of a spherical wave
(SWpot) oscillate rapidly and cannot be reliably integrated on a
Cartesian or radial grid. ONETEP calculates the elements of the metric
matrix by a piecewise approximation of SWs and SWpots with high-order
Chebyshev polynomials. Once this is done, their overlaps can be
calculated by overlapping a large number of polynomials, which is easy,
but time consuming.

For a fixed set of atomic positions and chosen NGWF radii the metric
matrix needs only be calculated once, this is done during
initialisation. The metric matrix does not depend on the NGWFs
themselves or even the number of NGWFs per atom.

In ONETEP versions prior to 5.1.2.3, metric matrix elements are
evaluated using the method described in Ref. {[}Dziedzic2013{]} (section II.D.1), i.e. by
3-D integration over piecewise expansions of SWs/SWpots in Chebyshev
polynomials. This is the “3-D Chebyshev” (3Dc) scheme.

For versions \(\ge\) 5.1.2.3, an alternative metric matrix scheme is
available in which metric matrix elements are decomposed into products
of 2-D numerical and 1-D analytic integrals. This is the “2-D numerical,
1-D analytic” (2Dn-1Da) scheme.

The separation of the 3-D integral in the 2Dn-1Da scheme is made
possible by expressing metric matrix elements for each atom pair in a
\sphinxstyleemphasis{molecular} coordinate frame with the \(z\)-axis pointing along the
vector between atomic centres and with a set of SWs aligned in this
coordinate system. When expressed in spherical polar coordinates, the
1-D integration (over the azimuthal angle, \(\phi\)) is simple to
evaluate analytically. The integration over \((r,\theta)\) can be
performed by the same approach used in the 3Dc method, i.e. evaluating
integrals over piecewise expansions of the \((r,\theta)\)-dependent
parts of the SWs and SWpots in Chebyshev polynomials.

To obtain the metric matrix in the original set of SWs, which are
aligned parallel to the \(z\)-axis of a \sphinxstyleemphasis{global} (simulation cell)
coordinate frame, the SWs in the molecular coordinate frame must be
represented in terms of the SWs in the global coordinate frame. This is
achieved by applying a rotation matrix to the real-spherical harmonic
(RSH) components of the SWs/SWpots associated with each atom pair.

For versions \(\ge\) 5.1.5.0, the 2Dn-1Da scheme is the default for
evaluating the electrostatic metric matrix. The 3Dc scheme remains the
default for the overlap metric matrix (\sphinxcode{O}), since overlap metric
matrix evaluation is not currently supported in the 2Dn-1Da scheme.

Use of the 2Dn-1Da scheme to evaluate the electrostatic metric matrix is
strongly recommended, as it reduces the computational cost (in terms of
memory and execution time) of evaluating the matrix by orders of
magnitude compared to the 3Dc scheme (with no apparent loss of
accuracy).

To set up SWRI (for both 2Dn-1Da and 3Dc schemes), define the following
block:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}block swri
  *myname* :math:{}`l\PYGZus{}\PYGZob{}\PYGZbs{}textrm\PYGZob{}max\PYGZcb{}\PYGZcb{}{}` :math:{}`q\PYGZus{}\PYGZob{}\PYGZbs{}textrm\PYGZob{}max\PYGZcb{}\PYGZcb{}{}` *metric* :math:{}`N\PYGZus{}\PYGZob{}\PYGZbs{}textrm\PYGZob{}i\PYGZcb{}\PYGZcb{}{}` :math:{}`N\PYGZus{}\PYGZob{}\PYGZbs{}textrm\PYGZob{}o\PYGZcb{}\PYGZcb{}{}` *flags*
\PYGZpc{}endblock swri
\end{sphinxVerbatim}

Replace \sphinxstyleemphasis{{}`{}`myname{}`{}`} with a user-readable name for the SWRI, you will
use it later to tell HFx or DMA which SWRI to use (as you can have more
than one SWRI).

{[}lmax{]} \(l_{\textrm{max}}\) is the maximum angular momentum in the
SW basis. Supported values are 0 (s-like SWs only), 1 (s- and SWs),
2 (s-, p- and d-like SWs), 3 (s-, p-, d- and f-like SWs) and 4 (you get
the idea). For HFx choose 2 for a crude calculation, 3 for good quality,
and 4 for extreme quality. 0 and 1 will likely be too crude to fully
NGWF-converge. Expect 2 to recover more than 99\% of HFx energy, and 3 to
recover about 99.7\%. See {[}Dziedzic2013{]} (Fig. 8) for an
illustrative guide. For DMA choose 0 if you’re only interested in atomic
charges, 1 if you want charges and dipoles, and 2 if you want charges,
dipoles and quadrupoles. There is no point in using 3 or 4 for DMA. Be
aware that the computational cost grows as
\({\mathcal{O}}(l^4_{\textrm{max}})\) (for the entire calculation),
and the memory requirement grows as
\({\mathcal{O}}(l^4_{\textrm{max}})\) (for the entire calculation).

{[}qmax{]} \(q_{\textrm{max}}\) is the number of Bessel (radial)
functions in the SW basis. Adding more Bessel functions increases the
size of the basis (linearly) and improves quality. However, each
subsequent Bessel function oscillates more rapidly and beyond a certain
point (at about 15 Bessel functions) they become difficult to represent
on Cartesian grids of typical fineness. As a guide, use 7 for a crude
calculation, 10 for reasonable accuracy and 14 for extreme accuracy.
Again, see {[}Dziedzic2013{]} (Fig. 8) to see a graphical
representation of the impact of this setting on accuracy. There is no
upper limit on the value of this parameter; however, ONETEP will refuse
to include Bessel functions that oscillate too rapidly for your KE
cutoff \textendash{} you will get a warning and high-numbered Bessel functions will
be removed from the basis. The computational cost grows as
\({\mathcal{O}}(q^2_{\textrm{max}})\), and so does the memory
requirement. Replace \sphinxstyleemphasis{{}`{}`metric{}`{}`} with \sphinxcode{V} to use the electrostatic
metric in the SWRI, or with \sphinxcode{O} to use the overlap metric. Specifying
\sphinxcode{VO} or \sphinxcode{OV} will generate both metric matrices, although that is
not usually done. In general, prefer the electrostatic metric \textendash{} the
error in the energy due to the density fitting approximation is then
second-order in the fitting error, while for the overlap metric it is
first-order.

As mentioned above, for ONETEP versions \(\ge 5.1.5.0\) the
electrostatic metric (\sphinxcode{V}) is evaluated by default using the more
efficient 2Dn-1Da scheme. The overlap metric (\sphinxcode{O}) cannot (currently)
be evaluated using this scheme, so is evaluated using the more costly
3Dc scheme. Since only a single metric matrix scheme may be used at a
time, if both metric matrices are requested (\sphinxcode{VO} or \sphinxcode{OV}) then
ONETEP will fall back to the 3Dc scheme. In this situation, it is worth
considering whether your calculation can be run with only the
electrostatic metric in order to take advantage of the more efficient
2Dn-1Da scheme.

\(N_{\textrm{i}}\) is the number of intervals into which the
integration domain will be divided along each axis for the purpose of
Chebyshev interpolation. In the 3Dc scheme, this is the localisation
sphere of an SW (an NGWF sphere, see
{[}Dziedzic2013{]} (Sec. II.D.1)), while in the 2Dn-1Da scheme this
is a half-disc with the same radius. For 3Dc, 8 is the bare minimum, 10
is crude, 12 is accurate and 14 is extremely accurate. You should
avoiding going overboard (recommended value is 12), since the
computational cost grows as \({\mathcal{O}}(N^3_{\textrm{i}})\)
(only for the SWRI stage, the remainder of the calculation is not
sensitive to this value). The memory requirement grows as
\({\mathcal{O}}(N^3_{\textrm{i}})\) (only for the SWRI stage). See
{[}Dziedzic2013{]} (Fig. 5) to see how the accuracy of the metric
matrix depends on this parameter when using the 3Dc scheme. For 2Dn-1Da,
the computational cost (\({\mathcal{O}}(N^{2}_{\textrm{i}})\)) and
memory requirements (\({\mathcal{O}}(N^{2}_{\textrm{i}})\)) are
considerably lower, so it is practical to use \(N_{\textrm{i}}=14\)
or larger for routine calculations. In this case, it is recommended to
use 12 or greater. In particular, very crude (less than 10) values
should be avoided when using 2Dn-1Da. Testing of DMA with the 2Dn-1Da
scheme suggests that the 2Dn-1Da scheme is more sensitive than 3Dc to
lower values of \(N_{\textrm{i}}\) (i.e. larger errors are produced
in multipole moments compared to values converged with respect to
\(N_{\textrm{i}}\) and \(N_{\textrm{o}}\)).
\(N_{\textrm{o}}\) is the order of Chebyshev polynomials used in the
interpolation. Just like for \(N_{\textrm{i}}\), for the 3Dc scheme
8 is the bare minimum, 10 is crude, 12 is accurate and 14 is extremely
accurate. Again, you should avoid going overboard (recommended
value %
\begin{footnote}[1]\sphinxAtStartFootnote
There is a caveat here when using the overlap metric (which you
shouldn’t be doing anyway). At the boundary of the NGWF localisation
region a SW has a derivative discontinuity, while a SWpot is smooth
together with its derivative. This discontinuity is poorly
approximated with high-order polynomials (Runge effect), and the
problem becomes worse when the number of intervals is small. The
setting \(N_{\textrm{i}}\)=12, \(N_{\textrm{o}}\)=12 is a
poor choice in this case. When using the overlap metric, always use
the lowest possible Chebyshev order (2, a parabola) and a large
number of intervals to compensate. A decent setting, and with a
comparable cost, would be \(N_{\textrm{i}}\)=72,
\(N_{\textrm{o}}\)=2. Of course you should not be using the
overlap metric in the first place!
%
\end{footnote} is 12), since the computational cost grows as
\({\mathcal{O}}(N^4_{\textrm{o}})\) (only for the SWRI stage, the
remainder of the calculation is not sensitive to this value). The memory
requirement grows as \({\mathcal{O}}(N^3_{\textrm{o}})\) (only for
the SWRI stage). See {[}Dziedzic2013{]} (Fig. 5) to see how the
accuracy of the metric matrix depends on this parameter when using the
3Dc scheme. For 2Dn-1Da, the computational cost
(\({\mathcal{O}}(N^{3}_{\textrm{o}})\)) and memory requirements
(\({\mathcal{O}}(N^{2}_{\textrm{o}})\)) are again considerably
lower, so it is practical to use \(N_{\textrm{o}}=14\) or larger for
routine calculations. In this case, it is recommended to use 12 or
greater. For the reasons outlined above for \(N_{\textrm{i}}\), very
crude (less than 10) values of \(N_{\textrm{o}}\) should be avoided
when using 2Dn-1Da. For DMA, which is performed during a properties
calculation %
\begin{footnote}[2]\sphinxAtStartFootnote
Unless you’re doing QM/MM calculations with polarisable embedding.
%
\end{footnote}, crude settings will simply lead to less accurate
multipoles. In HFx, on the other hand, settings that are too crude would
prevent convergence because the exchange matrix would not be
sufficiently symmetric. ONETEP will abort your calculation if the
exchange matrix is later found to not be symmetric to at least 3.4
digits. To avoid frustration, do not go below \(N_{\textrm{i}}=10\),
\(N_{\textrm{o}}=10\).

For the 2Dn-1Da scheme, the cost of evaluating the metric matrix is
typically significantly smaller than the overall cost of the subsequent
calculation. In this case, it is practical to routinely use higher
\(N_{\textrm{i}}\) and \(N_{\textrm{o}}\) values
(e.g. \(N_{\textrm{i}} = N_{\textrm{o}} = 14\) or \(16\)).

Generating the metric matrix can be costly (particularly when using the
3Dc scheme). When restarting calculations that crashed, ran out of
walltime, for restarts to do properties, or re-runs with different
settings it makes sense to save the metric matrix to a file and re-use
it during restarts. A metric matrix can be reused as long as the
positions of the atoms and the NGWF radii did not change. \sphinxstyleemphasis{{}`{}`flags{}`{}`} is
a combination of one or more letters or numbers: \sphinxcode{W}, \sphinxcode{R}, \sphinxcode{P},
\sphinxcode{Q}, \sphinxcode{X}, \sphinxcode{E}, \sphinxcode{D}, \sphinxcode{2}, \sphinxcode{3}, controlling the behaviour of
ONETEP during SWRI. The following flags instruct ONETEP to perform
particular actions:
\begin{itemize}
\item {} 
\sphinxcode{W} \textendash{} writes the metric matrix to a file, once it has been
calculated in its entirety. The file will have the extension
\sphinxcode{.vmatrix} for the electrostatic metric matrix, and \sphinxcode{.omatrix}
for the overlap metric matrix. This is highly recommended.

\item {} 
\sphinxcode{R} \textendash{} reads the metric matrix from a file, instead of calculating
it. The file will have the extension \sphinxcode{.vmatrix} for the
electrostatic metric matrix, and \sphinxcode{.omatrix} for the overlap metric
matrix. This is highly recommended for restart calculations. ONETEP
will not allow you to use this flag when it knows the ions will move
(\sphinxcode{TASK : GEOMETRYOPTIMIZATION, TRANSITIONSTATESEARCH, MOLECULARDYNAMICS,
PHONON, FORCETEST}), as the metric matrix gets invalidated once an ion
moves.

\item {} 
\sphinxcode{P} \textendash{} will instruct ONETEP to print the metric matrix in text form
straight to the output. This can be useful for visual inspection and
debugging, although be aware that for larger systems the output can
be bulky.

\item {} 
\sphinxcode{Q} \textendash{} will instruct ONETEP to quit immediately after the metric
matrix is calculated (and potentially written and/or printed). This
can be useful if the SWRI stage is run separately from the main
calculation, e.g. on a large number of CPU cores that would be
excessive for the main calculation.

\item {} 
\sphinxcode{X} \textendash{} means “none of the above” and should be used if you don’t
intend to write, read, print the metric matrix and you don’t want
ONETEP to quit at this stage.

\end{itemize}

The remaining flags change how the SWRI is performed:
\begin{itemize}
\item {} 
\sphinxcode{2} \textendash{} forces use of the 2Dn-1Da metric matrix evaluation scheme,
overriding the default selection. Note that the 2Dn-1Da scheme is
currently only available for evaluation of the electrostatic metric
matrix (\sphinxcode{V}) and ONETEP will abort with an error if the \sphinxcode{2} flag
is used in combination with the overlap metric matrix (\sphinxcode{O}).

\item {} 
\sphinxcode{3} \textendash{} forces use of the 3Dc metric matrix evaluation scheme,
overriding the default selection.

\end{itemize}

The \sphinxcode{2} and \sphinxcode{3} flags only have effect when computing the metric
matrix. When reading the matrix from disk in full (\sphinxcode{R} flag), the
flags have no effect, as the matrix has already been precomputed. When
reading the matrix in part from atomblocks (see below), the flags will
only affect atomblocks that are not read from disk (i.e. need to be
computed).

By using \sphinxcode{W} and \sphinxcode{R} you can re-use a fully calculated metric
matrix. For large jobs which take many CPU-core-hours you may want to
re-use \sphinxstyleemphasis{partial} results simply because you may not have enough walltime
to run the SWRI calculation to completion. By default ONETEP writes
partial results (metric matrix atomblocks) to files
(\sphinxcode{*.{[}vo{]}matrixblock}) as it churns through the calculation. These
matrixblocks will be automatically read from files if they can be found
\textendash{} i.e. before starting to calculate a block, ONETEP will always first
look for a corresponding file to try and avoid the calculation,
regardless of your \sphinxstyleemphasis{{}`{}`flags{}`{}`}. Thus, if your SWRI calculation is
interrupted, retain the matrixblock files to make the next run complete
faster. If you wrote the completed matrix to a file, there is no point
in keeping the matrixblock files and you should delete them to save disk
space. If you would rather not have to delete them manually, specify
\sphinxcode{E} (for “erase”) in \sphinxstyleemphasis{{}`{}`flags{}`{}`} and they will not be kept (or indeed
written to). Each matrixblock file encodes the position of the two atoms
between which it is calculated in the filename. This proves useful in
TASK PHONON calculations and TASK GEOMETRYOPTIMIZATION calculations with
some atoms fixed \textendash{} atomblocks between pairs of atoms that did not move
will not be recalculated needlessly, but rather reloaded from files,
unless you specify \sphinxcode{E}. Finally, the expert option \sphinxcode{D} instructs
ONETEP to disassemble the fully calculated metric matrix into atomblocks
(best used in combination with \sphinxcode{R} and \sphinxcode{Q}). This can be useful if
you saved the metric matrix to a file, deleted the matrixblock files,
and later change your mind.


\subsubsection{Examples}
\label{\detokenize{hfx:examples}}

\bigskip\hrule\bigskip


This creates an SWRI called \sphinxcode{for\_hfx}, with an expansion up to
\(l\)=3, 10 Bessel functions, using the electrostatic metric.
Chebyshev interpolation will use 12 intervals and 12-order polynomials.
The metric matrix will be written to a file. That would be standard for
a HFx calculation.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{swri}
  \PYG{n}{for\PYGZus{}hfx} \PYG{l+m+mi}{3} \PYG{l+m+mi}{10} \PYG{n}{V} \PYG{l+m+mi}{12} \PYG{l+m+mi}{12} \PYG{n}{W}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{swri}
\end{sphinxVerbatim}


\bigskip\hrule\bigskip


Like above, but will read the metric matrix from a file instead of
calculating it.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{swri}
  \PYG{n}{for\PYGZus{}hfx} \PYG{l+m+mi}{3} \PYG{l+m+mi}{10} \PYG{n}{V} \PYG{l+m+mi}{12} \PYG{l+m+mi}{12} \PYG{n}{R}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{swri}
\end{sphinxVerbatim}


\bigskip\hrule\bigskip


This creates an SWRI called \sphinxcode{for\_dma}, with an expansion up to
\(l\)=2, 12 Bessel functions, using the electrostatic metric.
Chebyshev interpolation will use 10 intervals and 12-order polynomials.
The metric matrix will not be written to a file. That would be standard
for a DMA calculation.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{swri}
  \PYG{n}{for\PYGZus{}dma} \PYG{l+m+mi}{2} \PYG{l+m+mi}{12} \PYG{n}{V} \PYG{l+m+mi}{10} \PYG{l+m+mi}{12} \PYG{n}{X}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{swri}
\end{sphinxVerbatim}


\bigskip\hrule\bigskip


This creates an SWRI called \sphinxcode{hiqh\_qual}, with an expansion up to
\(l\)=4, 16 Bessel functions (extremely large and accurate SW
basis set), using the overlap metric (not the best choice). Chebyshev
interpolation will use 60 intervals and 2-order polynomials (parabolas).
The metric matrix will be written to a file, printed out in text form,
the matrixblock files will be erased, and ONETEP will quit.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{swri}
  \PYG{n}{high\PYGZus{}qual} \PYG{l+m+mi}{4} \PYG{l+m+mi}{16} \PYG{n}{O} \PYG{l+m+mi}{60} \PYG{l+m+mi}{2} \PYG{n}{WPEQ}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{swri}
\end{sphinxVerbatim}


\bigskip\hrule\bigskip


This creates an SWRI called \sphinxcode{for\_hfx\_and\_dma}, with an expansion up to
\(l\)=2, 9 Bessel functions, using the electrostatic metric.
Chebyshev interpolation will use 14 intervals and 14-order polynomials.
The 2Dn-1Da metric matrix evaluation scheme has been explicitly selected
(for versions \(\ge\) 5.1.5.0, this would not be necessary, as
2Dn-1Da is the default for the electrostatic metric). The resulting
metric matrix will be written to a file and the matrixblock files will
be erased.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{swri}
  \PYG{n}{for\PYGZus{}hfx\PYGZus{}and\PYGZus{}dma} \PYG{l+m+mi}{2} \PYG{l+m+mi}{9} \PYG{n}{V} \PYG{l+m+mi}{14} \PYG{l+m+mi}{14} \PYG{n}{WE2}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{swri}
\end{sphinxVerbatim}


\bigskip\hrule\bigskip


As above, but with the 3Dc metric matrix scheme explicitly selected.
This will likely be very costly compared to using the 2Dn-1Da scheme.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{swri}
  \PYG{n}{for\PYGZus{}hfx\PYGZus{}and\PYGZus{}dma} \PYG{l+m+mi}{2} \PYG{l+m+mi}{9} \PYG{n}{V} \PYG{l+m+mi}{14} \PYG{l+m+mi}{14} \PYG{n}{WE3}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{swri}
\end{sphinxVerbatim}


\bigskip\hrule\bigskip



\subsubsection{Choosing which species participate in a SWRI}
\label{\detokenize{hfx:choosing-which-species-participate-in-a-swri}}
For every SWRI defined like above you need to specify which atomic
species participate in it. This allows performing an SWRI for a
subsystem, e.g. doing DMA only for atoms of a solute in the presence of
a solvent, but not for atoms of the solvent itself. In such a scenario
atomblocks only need to be calculated between atoms such that at least
one atom belongs to the SWRI. For HFx this is less meaningful, and you
will want to list all your species in the block. Note how the block name
\sphinxstylestrong{includes the name} of the SWRI defined above and may look like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}swri}\PYG{o}{\PYGZhy{}}\PYG{n}{for\PYGZus{}hfx}
\PYG{n}{H}
\PYG{n}{O}
\PYG{n}{C}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}swri}\PYG{o}{\PYGZhy{}}\PYG{n}{for\PYGZus{}hfx}
\end{sphinxVerbatim}

if your SWRI was called \sphinxcode{for\_hfx} and your system is composed of
species H, O and C.


\subsubsection{Advanced SWRI options}
\label{\detokenize{hfx:advanced-swri-options}}
\sphinxcode{swri\_verbose (logical)} \textendash{} set this to \sphinxcode{T} to get detailed
information on matrixblock I/O. Useful when you want to know where
ONETEP is looking for matrixblock files and whether each file was
succesfully loaded or not. This is output from all MPI ranks, so can
make the output cluttered. Default: \sphinxcode{F}.

\sphinxcode{swri\_cheb\_batchsize (integer)} \textendash{} sets the size of the batches in
which SWs are processed in the calculation of the metric matrix. For the
3Dc scheme, the default is 12. Increasing this value can improve
efficiency (by better balancing threads), but will increase memory load.
Keep this divisible by the number of OMP threads for best performance.
For the 2Dn-1Da scheme, batching has little benefit and can lead to
significant load imbalance across MPI processes for larger systems.
Thus, the default for 2Dn-1Da is the number of SWs in the auxiliary
basis set. For both schemes, if this value is set larger than the number
of SWs in the auxiliary basis set, it will be capped accordingly.

\sphinxcode{swri\_assembly\_prefix (string)} \textendash{} sets the prefix for the matrixblock
files that are assembled into the metric matrix. The default is the
rootname of your ONETEP input. Adjusting this can be useful if you keep
a large number of matrixblock files in one directory and have multiple
calculations, in different directories, using these matrixblock files.

\sphinxcode{swri\_proximity\_sort\_point (string of three values in bohr)} \textendash{} metric
matrix blocks are evaluated in order, with blocks between atoms closest
to a predefined point done first. This is useful if you have a giant
SWRI calculation (say for a solute and a few solvation shells) and would
like other calculations to start using first matrix blocks as soon as
possible (e.g. for calculations on just the solute). Using this keyword
you can choose the point for sorting the atomblocks. The default is
\sphinxcode{0.0 0.0 0.0}. A unit of bohr is implicitly added (do not specify it).

\sphinxcode{swri\_swop\_smoothing, swri\_overlap\_indirect, swri\_improve\_inverse} \textendash{}
these are experimental features, do not use these.


\subsection{Hartree-Fock exchange}
\label{\detokenize{hfx:hartree-fock-exchange}}
Now that you have SWRI set up, a basic HFx (or hybrid functional)
calculation should be simple to set up. The following three keywords are
mandatory and do not provide defaults:

\sphinxcode{hfx\_use\_ri (string)} \textendash{} tells HFx which SWRI to use. Specify the name
used in the SWRI block, e.g. \sphinxcode{hfx\_use\_ri for\_hfx}.

\sphinxcode{hfx\_max\_l (integer)} \textendash{} specifies the maximum angular momentum in the
SW basis. In most scenarios this will be equal to
\(l_{\textrm{max}}\) that you specified in the SWRI block. Read the
description of \(l_{\textrm{max}}\) (Sec. {[}lmax{]}) to understand the
meaning of this parameter. You can use a \sphinxstyleemphasis{lower} value than the one
specified in the SWRI block if you want to use only a subset of the SW
basis set (e.g. for benchmarking, or doing DMA with a lower
\(l_{\textrm{max}}\) than you use for HFx), but not for HFx (where
you must use the same value that you used in the SWRI block).

\sphinxcode{hfx\_max\_q (integer)} \textendash{} specifies the number of Bessel functions in
the SW basis for each angular momentum channel. In most scenarios this
will be equal to \(q_{\textrm{max}}\) that you specified in the SWRI
block. Read the description of \(q_{\textrm{max}}\) (Sec. {[}qmax{]}) to
understand the meaning of this parameter. You can use a \sphinxstyleemphasis{lower} value
than the one specified in the SWRI block if you want to use only a
subset of the SW basis set (e.g. for benchmarking, or doing DMA with a
lower \(q_{\textrm{max}}\) than you use for HFx), but not for HFx
(where you must use the same value that you used in the SWRI block).

With the above set up, the last step is to choose a suitable functional
through \sphinxcode{xc\_functional}. The following hybrid functionals use HFx:
\sphinxcode{B1LYP}, \sphinxcode{B1PW91}, \sphinxcode{B3LYP}, \sphinxcode{B3PW91}, \sphinxcode{PBE0}, \sphinxcode{X3LYP}. For a
pure Hartree-Fock calculation use \sphinxcode{HF}.

\begin{DUlineblock}{0em}
\item[] The following two keywords might be handy:
\item[] \sphinxcode{hfx\_cutoff (physical)} \textendash{} specifies the distance-based cutoff for
all HFx interactions. The default is 1000 bohr, which effectively
corresponds to no truncation. In the absence of truncation ONETEP’s
HFx implementation scales as \({\mathcal{O}}(N^2)\), so you are
advised to use HFx truncation even if you do not use density kernel
truncation. Exchange interactions are rather short-ranged, and for
systems with a band-gap it should be safe to truncate them at
20\(a_0\). See {[}Dziedzic2013{]} (Figs. 19, 20) for more
details. Do not use a value smaller than twice the NGWF radius.
\end{DUlineblock}

\sphinxcode{hfx\_metric (string)} \textendash{} selects the metric actually used for HFx
calculations. The default is \sphinxcode{electrostatic}. The other option is
\sphinxcode{overlap}. The appropriate metric matrix must have been included at
the SWRI stage (\sphinxcode{V} or \sphinxcode{O}, respectively).

Other HFx-related keywords (\sphinxcode{hfx\_nlpp\_for\_exchange},
\sphinxcode{hfx\_read\_xmatrix} and \sphinxcode{hfx\_write\_xmatrix}) correspond to
experimental features and should not be used.


\subsubsection{Example}
\label{\detokenize{hfx:example}}
The following is a bare-bones example for a reasonably good-quality HFx
calculation on a slightly distorted water molecule. That should converge
in 11 NGWF iterations within 1.5 minute on a desktop machine (2 MPI
ranks, 4 OMP threads each), requiring about 4 GiB of RAM.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{xc\PYGZus{}functional} \PYG{n}{B3LYP}
\PYG{n}{cutoff\PYGZus{}energy} \PYG{l+m+mi}{800} \PYG{n}{eV}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{swri}
  \PYG{n}{for\PYGZus{}hfx} \PYG{l+m+mi}{3} \PYG{l+m+mi}{10} \PYG{n}{V} \PYG{l+m+mi}{10} \PYG{l+m+mi}{10} \PYG{n}{WE}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{swri}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}swri}\PYG{o}{\PYGZhy{}}\PYG{n}{for\PYGZus{}hfx}
\PYG{n}{O}
\PYG{n}{H}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}swri}\PYG{o}{\PYGZhy{}}\PYG{n}{for\PYGZus{}hfx}

\PYG{n}{hfx\PYGZus{}use\PYGZus{}ri} \PYG{n}{for\PYGZus{}hfx}
\PYG{n}{hfx\PYGZus{}max\PYGZus{}l} \PYG{l+m+mi}{3}
\PYG{n}{hfx\PYGZus{}max\PYGZus{}q} \PYG{l+m+mi}{10}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{lattice\PYGZus{}cart}
  \PYG{l+m+mf}{25.00}     \PYG{l+m+mf}{0.00}     \PYG{l+m+mf}{0.00}
   \PYG{l+m+mf}{0.00}    \PYG{l+m+mf}{25.00}     \PYG{l+m+mf}{0.00}
   \PYG{l+m+mf}{0.00}     \PYG{l+m+mf}{0.00}    \PYG{l+m+mf}{25.00}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{lattice\PYGZus{}cart}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{positions\PYGZus{}abs}
\PYG{n}{ang}
\PYG{n}{O} \PYG{l+m+mf}{5.79564200} \PYG{l+m+mf}{7.40742600} \PYG{l+m+mf}{6.63194300}
\PYG{n}{H} \PYG{l+m+mf}{5.19938100} \PYG{l+m+mf}{8.05407400} \PYG{l+m+mf}{6.24141400}
\PYG{n}{H} \PYG{l+m+mf}{5.16429100} \PYG{l+m+mf}{6.74016800} \PYG{l+m+mf}{6.88482600}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{positions\PYGZus{}abs}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species}
\PYG{n}{O} \PYG{n}{O} \PYG{l+m+mi}{8} \PYG{l+m+mi}{4} \PYG{l+m+mf}{8.0}
\PYG{n}{H} \PYG{n}{H} \PYG{l+m+mi}{1} \PYG{l+m+mi}{1} \PYG{l+m+mf}{8.0}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}pot}
\PYG{n}{O} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{oxygen.recpot}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{hydrogen.recpot}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}pot}
\end{sphinxVerbatim}


\subsection{DMA}
\label{\detokenize{hfx:dma}}
DMA (Distributed Multipole Analysis) is a technique for partitioning
charge density into single 10000 atom contributions and finding a set of
point multipoles that most accurately represent this charge density. The
point multipoles are usually, although not universally, atom-centered \textendash{}
this is the case in ONETEP. DMA was proposed by Rein
{[}Rein1973{]} and has been pioneered and popularised by Stone
{[}Stone1981{]} and Alderton
{[}Stone1985{]}. It is typically performed in a
Gaussian basis set {[}Stone1998{]}, {[}Stone2005{]}, but ONETEP uses a
version adapted to the NGWF basis. More details on our approach can be
found in Refs. {[}Dziedzic2016{]}, {[}Vitale2015{]}.

DMA in ONETEP first uses SWRI (cf. earlier Sections) to expand NGWF-NGWF
overlaps (not exactly atom-pair densities, because there is no density
kernel there) in an auxiliary SW basis set. Depending on the metric,
this density fitting will strive to either minimise the difference in
electronic density between the original density and the fit (for the
overlap metric), or the electrostatic energy of the difference in
densities interacting with itself (for the electrostatic metric). The
use of electrostatic metric is preferred. Once the NGWF-NGWF overlaps
are expressed in an SW basis, owing to certain properties of SWs and to
the fact that in ONETEP they are chosen to be atom-centered, it becomes
easy to find atom-centered point multipoles that yield the (exactly)
equivalent potential. This stage is termed spherical wave expansion
(SWX) and its result are atom-centered point multipoles that are the
best fit to the original electronic density (under the assumed metric).
Apart from calculating electronic multipoles, ONETEP’s DMA also
calculates total (electronic + ionic core) atom-centered multipoles.
Also calculated are the total multipoles of the system (e.g.. the
molecular dipole or quadrupole), suitably averaged over all the atoms
that were part of the SWRI. For non 10000 neutral molecules the value of
the dipole depends on the point where it is calculated (similarly for
higher multipoles), and so the total multipoles are calculated \sphinxstyleemphasis{at a
reference point} of your choosing.

DMA in ONETEP is performed in two contexts. The most common is during a
\sphinxcode{task properties} calculation (“properties-DMA”). The other use of DMA
is in QM/MM calculations using ONETEP and tinker (tinktep approach,
cf. {[}Dziedzic2016{]}, “polemb-DMA”). Some DMA keywords
pertain to both contexts, and some pertain only to one of them \textendash{} this
will be carefully highlighted. It is possible to mix the two to a
reasonable degree (i.e. to perform QM/MM with one set of DMA parameters,
and properties-DMA at the end of the run, with another set of
parameters). By “reasonable degree” I mean that some of the parameters
are shared.


\subsubsection{DMA: minimal set-up}
\label{\detokenize{hfx:dma-minimal-set-up}}
To use DMA, first set up SWRI (cf. earlier Sections). Now that you have
SWRI set up, a basic calculation using DMA should be simple to set up.
First, specify \sphinxcode{dma\_calculate T} to enable DMA, as it is off by
default. Once you’ve done that, the following keywords \sphinxstylestrong{become
mandatory}:

\sphinxcode{dma\_use\_ri (string)} \textendash{} tells DMA which SWRI to use. Specify the name
used in the corresponding SWRI block, e.g. \sphinxcode{dma\_use\_ri for\_dma}.

\sphinxcode{dma\_max\_l (integer)} \textendash{} specifies the maximum angular momentum in the
SW basis used in DMA. In most scenarios this will be equal to
\(l_{\textrm{max}}\) that you specified in the SWRI block. Read the
description of \(l_{\textrm{max}}\) (Sec. {[}lmax{]}) to understand the
meaning of this parameter. You can use a lower value than the one
specified in the SWRI block if you want to use only a subset of the SW
basis set (e.g. for benchmarking). This keyword only affects
properties-DMA, the equivalent for polemb-DMA is \sphinxcode{pol\_emb\_dma\_max\_l}.
This keyword needs to be specified even if you do not plan to use
properties-DMA (in that case, specify 0). If you only care about
atom-centered charges, specify 0. If you care about atom-centered
charges and dipoles, specify 1. If you care about atom-centered charges,
dipoles and quadrupoles, specify 2.

\sphinxcode{dma\_max\_q (integer)} \textendash{} specifies the number of Bessel functions in
the SW basis for each angular momentum channel to be used in DMA. In
most scenarios this will be equal to \(q_{\textrm{max}}\) that you
specified in the SWRI block. Read the description of
\(q_{\textrm{max}}\) (Sec. {[}qmax{]}) to understand the meaning of this
parameter. You can use a lower value than the one specified in the SWRI
block if you want to use only a subset of the SW basis set (e.g. for
benchmarking). This keyword only affects properties-DMA, the equivalent
for polemb-DMA is \sphinxcode{pol\_emb\_dma\_max\_q}. This keyword needs to be
specified even if you do not plan to use properties-DMA (in that case,
specify 0).


\subsubsection{Non-mandatory keywords affecting both properties-DMA and polemb-DMA}
\label{\detokenize{hfx:non-mandatory-keywords-affecting-both-properties-dma-and-polemb-dma}}
\sphinxcode{dma\_metric (string)} \textendash{} selects the metric used for DMA calculations.
The current default is \sphinxcode{electrostatic}. The other option is
\sphinxcode{overlap}. The appropriate metric matrix must have been included at
the SWRI stage (\sphinxcode{V} or \sphinxcode{O}, respectively). This keyword affects both
properties-DMA and polemb-DMA.

\sphinxcode{dma\_bessel\_averaging (boolean)} \textendash{} specifies whether all DMA-based
multipoles are to be averaged over an even-odd pair of
\(q_{\textrm{max}}\). Multipoles obtained with DMA display an
oscillatory behaviour when plotted as a function of
\(q_{\textrm{max}}\). This has to do with how the Bessel functions
sample the radial profile of NGWFs. In essence, for all even
\(q_{\textrm{max}}\) a particular multipole will be overestimated,
while for all odd \(q_{\textrm{max}}\) the same multipole will be
underestimated (or the other way round). Other multipoles will be
affected similarly (except in reverse) to compensate. This oscillatory
behaviour decays as the quality of the SW basis is increased, but the
decay is slow. Much more stable multipoles are obtained by averaging the
results of two SWX runs \textendash{} one with the \(q_{\textrm{max}}\) the user
specified in \sphinxcode{dma\_max\_q}, and one with \(q_{\textrm{max}}\) that
is less by one. This even-odd averaging can be performed automatically
by specifying \sphinxcode{dma\_bessel\_averaging T}, and this is done by default.
When this option is enabled, output files include multipoles obtained
with both SWX qualities, followed by the average, except for the
\sphinxcode{.dma\_multipoles\_gdma\_like.txt} file, which will contain only the
final, averaged multipoles. There is no extra effort associated with
this option at the SWRI stage, and the effort of the SWX stage (which is
usually much, much lower) is practically doubled (two separate SWXs have
to be performed). This keyword affects both properties-DMA and
polemb-DMA.

\sphinxcode{dma\_scale\_charge (boolean)} \textendash{} specifies DMA charge-scaling is to be
performed (default) or not. This an important option. The multipoles
obtained with DMA are always approximate. The total DMA monopole
(charge) will be close to, but not exactly equal to, the total charge of
the system (or its subset, if DMA’s SWRI did not encompass all atoms).
This means that the total DMA monopole of a nominally neutral system
will not be exactly zero, but typically a very small fraction of an
electron. This is inconvenient, because it formally breaks the
translational invariance of the total dipole, which begins to depend,
very slightly, on the reference point where it is calculated. The
easiest workaround is to scale, \sphinxstyleemphasis{a posteriori}, the DMA monopole by the
ratio of expected charge to the obtained DMA charge. This scaling is
factor will be very close to zero (e.g. 0.9998), unless your SW basis
set is very crude (single-digit \(q_{\textrm{max}}\), etc.). The
“expected” (electronic) charge either obtained automatically (by
default), or can be specified manually using
\sphinxcode{dma\_target\_num\_val\_elec}. When not specified manually, the expected
electronic charge is determined as follows. If DMA’s SWRI encompasses
all atoms (“full-system DMA”), it is equal to the total number of
valence electrons in the system (obtained from
\(\textrm{Tr}\left[\mathbb{KS}\right]\)). If DMA’s SWRI does not
encompass all atoms (“subsystem DMA”), Mulliken analysis is performed
every time charge-scaling needs to be done (essentially at every LNV
step, or twice per LNV step when Bessel averaging is used), and Mulliken
charges of all atoms within DMA’s SWRI are summed to obtain the expected
electronic charge. Using DMA charge-scaling is recommended (hence it’s
on by default), but care must be taken when using it with polemb-DMA
(there are no issues with properties-DMA). The following issues and
limitations arise. (1) In polemb-DMA the DMA multipoles enter LNV and
NGWF gradient expressions. The quantity
\(\textrm{Tr}\left[\mathbb{KS}\right]\) is not strictly a constant,
and has non 10000 zero DKN and NGWF derivatives, leading to additional
terms in LNV and NGWF gradients when charge-scaling is used. These extra
terms have been implemented for LNV gradients, but \sphinxstyleemphasis{not} for NGWF
gradients, where they become really hairy (these are under development).
Hence the threefold combination of polemb-DMA, charge-scaling and NGWF
optimisation is not permitted (will refuse to run). (2) The threefold
combination of polemb-DMA, charge-scaling and
\sphinxcode{dma\_target\_num\_val\_elec} is not permitted (will refuse to run),
regardless of whether NGWF optimisation is used or not. This is because
the expected number of electrons becomes constant (user-specified value)
in this scenario, which is incompatible with the charge-scaling
corrections accounting for \(\textrm{Tr}\left[\mathbb{KS}\right]\).
Long story short: use DMA charge-scaling for properties-DMA, but not for
polemb-DMA. This keyword affects both properties-DMA and polemb-DMA.

\sphinxcode{dma\_target\_num\_val\_elec (integer)} \textendash{} specifies the expected number of
valence electrons for DMA. This keyword should only be used when DMA
charge-scaling is in effect (see above), and only if the automatic
determination of the expected number of electrons (see above) in the
part of your system seen by DMA is not satisfactory. The default is for
this keyword to be omitted. This keyword affects both properties-DMA and
polemb-DMA.

\sphinxcode{polarisation\_simcell\_refpt (real real real)}. The default is
\sphinxcode{0.0 0.0 0.0}. Specifies the reference point in the simulation cell
(in bohr) at which total DMA multipoles are calculated. This is mostly
useful if your system (strictly speaking: your DMA subsystem) is not
charge-neutral and you are interested in the value of the total dipole.
When the system is non 10000 neutral, the total dipole is not
translation invariant, and a reference point for calculating it needs to
be specified. This keyword specifies this reference. Also note that when
a simcell full-density polarisation calculation is performed (via
\sphinxcode{task properties} and \sphinxcode{polarisation\_simcell\_calculate}), this
keyword also adjusts this calculation’s reference point. This keyword
affects both properties-DMA and polemb-DMA.

\sphinxcode{dma\_precise\_gdma\_output (boolean)}. The default is on (\sphinxcode{T}). One of
the files output by DMA is the \sphinxcode{.dma\_multipoles\_gdma\_like.txt} file,
which is formatted as to be compatible with the output generated by
Stone’s GDMA program. This output can be directly used by other programs
expecting input in this format. The original GDMA format is fixed-form,
meaning the precision of the output multipoles is rather restricted by
the number of digits that can be output. In polemb-DMA mode this
precision is insufficient to accurately drive the MM calculation
performed by an external program (tinker). Specifying
\sphinxcode{dma\_precise\_gdma\_output T} instructs ONETEP to output multipoles with
the additional necessary precision, but breaks strict compatibility with
the GDMA format. If the external program you use to parse the GDMA file
is aware of that (e.g. tinker can be suitably patched), this is fine. If
you have no control over the external program and need ONETEP to adhere
strictly to the GDMA format, use \sphinxcode{dma\_precise\_gdma\_output F}.


\paragraph{Expert, non-mandatory keywords affecting both properties-DMA and polemb-DMA}
\label{\detokenize{hfx:expert-non-mandatory-keywords-affecting-both-properties-dma-and-polemb-dma}}
Just don’t. These are used for experimental purposes, particularly in
QM/MM.

\sphinxcode{dma\_multipole\_scaling (real)} \textendash{} causes all DMA multipoles to be
scaled by a constant. This affects both the output multipoles and the
multipoles used internally in polemb expressions. Whenever necessary
(during charge-scaling, in gradients) this scaling is temporarily undone
internally for consistency. This keyword affects both properties-DMA and
polemb-DMA.

\sphinxcode{dma\_dipole\_scaling (real)} \textendash{} causes all DMA dipoles to be scaled by a
constant. This affects both the output dipoles and the dipoles used
internally in polemb expressions. Whenever necessary (essentially in
gradients) this scaling is temporarily undone internally for
consistency. This keyword affects both properties-DMA and polemb-DMA.

\sphinxcode{dma\_quadrupole\_scaling (real)} \textendash{} causes all DMA quadrupoles to be
scaled by a constant. This affects both the output quadrupoles and the
quadrupoles used internally in polemb expressions. Whenever necessary
(essentially in gradients) this scaling is temporarily undone internally
for consistency. This keyword affects both properties-DMA and
polemb-DMA.


\subsubsection{Non-mandatory keywords affecting only properties-DMA}
\label{\detokenize{hfx:non-mandatory-keywords-affecting-only-properties-dma}}
\sphinxcode{dma\_output\_potential (boolean)}. The default is off (\sphinxcode{F}). When
turned on (\sphinxcode{T}), during properties-DMA the electrostatic potential due
to all DMA \sphinxstyleemphasis{electronic} multipoles is calculated on the \(z=0\) and
\(z=z_\textrm{max}\) faces of the simulation cell (on all fine-grid
points lying on those faces). This potential is output to text files.
This is useful for assessing the quality of the DMA approximation to the
full, distributed charge density. If DMA’s SWRI does not span the entire
system, the output potential is only due to those atoms included in
DMA’s SWRI. This keyword affects only properties-DMA.

\sphinxcode{dma\_output\_potential\_reference (boolean)}. The default is off
(\sphinxcode{F}). When turned on (\sphinxcode{T}) \sphinxstyleemphasis{and} \sphinxcode{dma\_output\_potential} \sphinxstyleemphasis{is also
on}, during properties-DMA the reference electrostatic potential due to
the full, distributed \sphinxstyleemphasis{electronic} density is calculated on the
\(z=0\) and \(z=z_\textrm{max}\) faces of the simulation cell
(on all fine-grid points lying on those faces). This potential is output
to text files. This is useful to obtain a reference for assessing the
quality of the DMA approximation to the full, distributed charge density
(see above). Regardless of whether DMA’s SWRI spans the entire system or
not, the output potential is due to \sphinxstyleemphasis{all} electrons in the system. Thus,
the two sets of potentials are only comparable in full-system DMA. The
reference potential is calculated by a pointwise integration over the
entire volume (fine-grid) \sphinxstyleemphasis{for every point on the two faces}, which is a
time-consuming process, so use sparingly. This keyword affects only
properties-DMA.


\subsubsection{Non-mandatory keywords affecting only polemb-DMA}
\label{\detokenize{hfx:non-mandatory-keywords-affecting-only-polemb-dma}}
Refer to the separate documentation for polarisable embedding in ONETEP.


\subsubsection{Example}
\label{\detokenize{hfx:id19}}
The following is a bare-bones example for a reasonably good-quality
properties-DMA calculation on a slightly distorted water molecule. That
should converge in 11 NGWF iterations within 1 minute on a desktop
machine (2 MPI ranks, 4 OMP threads each), requiring about 3 GB of peak
RAM.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{xc\PYGZus{}functional} \PYG{n}{PBE}
\PYG{n}{cutoff\PYGZus{}energy} \PYG{l+m+mi}{800} \PYG{n}{eV}

\PYG{n}{do\PYGZus{}properties} \PYG{n}{T}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{swri}
  \PYG{n}{for\PYGZus{}dma} \PYG{l+m+mi}{2} \PYG{l+m+mi}{14} \PYG{n}{V} \PYG{l+m+mi}{12} \PYG{l+m+mi}{12} \PYG{n}{WE}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{swri}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}swri}\PYG{o}{\PYGZhy{}}\PYG{n}{for\PYGZus{}dma}
\PYG{n}{O}
\PYG{n}{H}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}swri}\PYG{o}{\PYGZhy{}}\PYG{n}{for\PYGZus{}dma}

\PYG{n}{dma\PYGZus{}calculate} \PYG{n}{T}
\PYG{n}{dma\PYGZus{}use\PYGZus{}ri} \PYG{n}{for\PYGZus{}dma}
\PYG{n}{dma\PYGZus{}metric} \PYG{n}{electrostatic}
\PYG{n}{dma\PYGZus{}max\PYGZus{}l} \PYG{l+m+mi}{2}
\PYG{n}{dma\PYGZus{}max\PYGZus{}q} \PYG{l+m+mi}{14}

\PYG{n}{dma\PYGZus{}scale\PYGZus{}charge} \PYG{n}{T}
\PYG{n}{dma\PYGZus{}bessel\PYGZus{}averaging} \PYG{n}{T}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{lattice\PYGZus{}cart}
  \PYG{l+m+mf}{25.00}     \PYG{l+m+mf}{0.00}     \PYG{l+m+mf}{0.00}
   \PYG{l+m+mf}{0.00}    \PYG{l+m+mf}{25.00}     \PYG{l+m+mf}{0.00}
   \PYG{l+m+mf}{0.00}     \PYG{l+m+mf}{0.00}    \PYG{l+m+mf}{25.00}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{lattice\PYGZus{}cart}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{positions\PYGZus{}abs}
\PYG{n}{ang}
\PYG{n}{O} \PYG{l+m+mf}{5.79564200} \PYG{l+m+mf}{7.40742600} \PYG{l+m+mf}{6.63194300}
\PYG{n}{H} \PYG{l+m+mf}{5.19938100} \PYG{l+m+mf}{8.05407400} \PYG{l+m+mf}{6.24141400}
\PYG{n}{H} \PYG{l+m+mf}{5.16429100} \PYG{l+m+mf}{6.74016800} \PYG{l+m+mf}{6.88482600}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{positions\PYGZus{}abs}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species}
\PYG{n}{O} \PYG{n}{O} \PYG{l+m+mi}{8} \PYG{l+m+mi}{4} \PYG{l+m+mf}{8.0}
\PYG{n}{H} \PYG{n}{H} \PYG{l+m+mi}{1} \PYG{l+m+mi}{1} \PYG{l+m+mf}{8.0}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}pot}
\PYG{n}{O} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{oxygen.recpot}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{H} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{hydrogen.recpot}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}pot}
\end{sphinxVerbatim}

\sphinxstylestrong{Expected results}:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstylethead{\sphinxstyletheadfamily 
Description
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Dipole (au)
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Dipole (debye)
\unskip}\relax \\
\hline
Full density (cores + NGWFs)
&
0.7564
&
\sphinxstylestrong{1.9226}
\\
\hline
DMA (point multipoles, \(q_{\textrm{max}}\)=14)
&
0.7477
&
1.9005
\\
\hline
DMA (point multipoles, \(q_{\textrm{max}}\)=13)
&
0.7680
&
1.9519
\\
\hline
DMA (point multipoles, Bessel-averaged)
&
0.7578
&
\sphinxstylestrong{1.9261}
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Table:  Dipole moment of distorted water molecule. Comparison of
accuracy: full density vs. DMA point multipoles.


\subsection{Advanced options}
\label{\detokenize{hfx:advanced-options}}

\subsubsection{Making Hartree-Fock exchange faster or less memory-hungry}
\label{\detokenize{hfx:making-hartree-fock-exchange-faster-or-less-memory-hungry}}
Hartree-Fock exchange is not fast, although we’ve made great
improvements in v5.3.4.0. For small systems (\(<200\)  atoms), with
a bit of luck, it will be an order of magnitude slower than GGA
calculations. For large systems (\(\approx{}1000\) atoms) expect it
to be two orders of magnitude slower.

The main way to improve performance is by using more RAM \textendash{} this is
because there are plenty of opportunities for caching some results that
would otherwise have to be recomputed. If HFx was to cache everything,
it would quickly exhaust all available RAM, even on well-equipped
machines. Therefore, there are limits in place for each of the caches.
These limits are expressed in MiB (1048576 bytes) and are \sphinxstylestrong{per MPI rank}.

Remember that OMP threads can share memory, while MPI ranks cannot. This
means that the key to obtaining high performance with HFx is to \sphinxstylestrong{use as many OMP threads as possible}. In
most HPC settings this will mean using only 2 MPI ranks per node (one
MPI rank per NUMA region, most HPC nodes have two NUMA regions). For
example on Iridis5, with 40 CPU cores on each node, best performance is
obtained by using 2 MPI ranks, with 20 OMP threads each, on every node.
This is in contrast to non-HFx calculations, which typically achieve
peak performance for 4-5 OMP threads. HFx is well-optimised for high
thread counts. By reducing the number of MPI ranks, you allow each rank
to use more RAM. This is the key to success. Don’t worry about the drop
in performance of the non-HFx part, it will be dwarfed by the gain in
HFx efficiency.

The easiest way to control how much RAM HFx can use is via the parameter
\sphinxcode{hfx\_memory\_limit}. The default value is 4096, meaning HFx will not
ask for more than 4 GiB of RAM \sphinxstylestrong{per MPI rank}. This is \sphinxstyleemphasis{in addition} to any memory use
from the rest of ONETEP. If you can spare more RAM, definitely tell this
to the HFx engine by saying e.g.

\sphinxcode{hfx\_memory\_limit 16384! I have 16 GiB per MPI rank to spare}.

The HFx engine will automatically distribute this RAM across the three
main caches. Or, more specifically, it will first consume the amount of
RAM absolutely needed for core HFx functionality, and \sphinxstyleemphasis{then} distribute
the rest to the three caches. You will get a banner informing you about
how much memory went into satisfying the minimum requirements:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{\textbar{}}  \PYG{n}{HFx} \PYG{n}{TEFCI} \PYG{n}{engine}\PYG{p}{:} \PYG{n}{minimum} \PYG{n}{requirements}            \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{Estimated} \PYG{n}{memory} \PYG{n}{requirement} \PYG{n}{per} \PYG{n}{MPI} \PYG{n}{rank}         \PYG{o}{\textbar{}}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{\textbar{}}  \PYG{n}{Radial} \PYG{n}{Bessel} \PYG{n}{lookup}                \PYG{p}{:}   \PYG{l+m+mf}{30.52} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{Dd} \PYG{n}{NGWFs} \PYG{n+nb}{hash} \PYG{n}{table}                 \PYG{p}{:}    \PYG{l+m+mf}{1.66} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{All} \PYG{n}{remote} \PYG{n}{NGWFs} \PYG{n+nb}{hash} \PYG{n}{table}         \PYG{p}{:}   \PYG{l+m+mf}{37.38} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{dlists} \PYG{n+nb}{hash} \PYG{n}{table}                   \PYG{p}{:}    \PYG{l+m+mf}{6.53} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{coeffs} \PYG{n+nb}{hash} \PYG{n}{table} \PYG{p}{(}\PYG{n}{estimate}\PYG{p}{)}        \PYG{p}{:}   \PYG{l+m+mf}{26.93} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{V} \PYG{n}{metric} \PYG{n}{matrix} \PYG{n+nb}{hash} \PYG{n}{table}          \PYG{p}{:}  \PYG{l+m+mf}{377.59} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{f} \PYG{n}{auxiliary} \PYG{n}{term}                    \PYG{p}{:}  \PYG{l+m+mf}{131.78} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{P} \PYG{n}{term} \PYG{o+ow}{in} \PYG{n}{NGWF} \PYG{n}{gradient}             \PYG{p}{:}  \PYG{l+m+mf}{131.78} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{Q} \PYG{n}{term} \PYG{o+ow}{in} \PYG{n}{NGWF} \PYG{n}{gradient}             \PYG{p}{:}  \PYG{l+m+mf}{238.88} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{My} \PYG{n}{kets} \PYG{o+ow}{in} \PYG{n}{NGWF} \PYG{n}{grad}\PYG{o}{.} \PYG{p}{(}\PYG{n}{estimate}\PYG{p}{)}    \PYG{p}{:}   \PYG{l+m+mf}{78.09} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{Local} \PYG{n}{kets} \PYG{o+ow}{in} \PYG{n}{NGWF} \PYG{n}{grad}\PYG{o}{.} \PYG{p}{(}\PYG{n}{estim}\PYG{o}{.}\PYG{p}{)}   \PYG{p}{:}   \PYG{l+m+mf}{43.20} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{K}\PYG{o}{\PYGZca{}}\PYG{p}{\PYGZob{}}\PYG{n}{CD}\PYG{p}{\PYGZcb{}} \PYG{n+nb}{hash} \PYG{n}{table}                   \PYG{p}{:}    \PYG{l+m+mf}{3.88} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{K}\PYG{o}{\PYGZca{}}\PYG{p}{\PYGZob{}}\PYG{n}{AB}\PYG{p}{\PYGZcb{}} \PYG{n+nb}{hash} \PYG{n}{table}                   \PYG{p}{:}    \PYG{l+m+mf}{3.60} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{tcK}\PYG{o}{\PYGZca{}}\PYG{n}{A\PYGZus{}B} \PYG{n+nb}{hash} \PYG{n}{table}                  \PYG{p}{:}    \PYG{l+m+mf}{3.60} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{tcK}\PYG{o}{\PYGZca{}}\PYG{n}{B\PYGZus{}A} \PYG{n+nb}{hash} \PYG{n}{table}                  \PYG{p}{:}    \PYG{l+m+mf}{3.60} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{\textbar{}}  \PYG{n}{Estimated} \PYG{n}{peak} \PYG{n}{total} \PYG{n}{per} \PYG{n}{MPI} \PYG{n}{rank}   \PYG{p}{:}    \PYG{l+m+mf}{1.09} \PYG{n}{GB}  \PYG{o}{\textbar{}}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\end{sphinxVerbatim}

In the event that the memory limit specified with \sphinxcode{hfx\_memory\_limit}
is below even the minimum requirement (1.09 GB in the example above),
you will get an error message explaining how much more RAM you would
need to continue. Be aware of two things: (1) calculations with not much
(or no) memory above the minimum requirement will be very slow, (2) the
above is only an estimate. Under some circumstances HFx may consume
slightly more memory, but not much. If you run out of memory, it is
usually the NGWF gradient calculation (its non-HFx part) that breaks the
camel’s back.

Another banner informs you about how the remaining RAM is divided across
the three caches (“hash tables”). It may look like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{\PYGZhy{}} \PYG{n}{Adjusting} \PYG{n}{cache} \PYG{n}{sizes} \PYG{n}{according} \PYG{n}{to} \PYG{n}{weights}\PYG{p}{:} \PYG{l+m+mf}{0.6250}\PYG{p}{,} \PYG{l+m+mf}{0.3125}\PYG{p}{,} \PYG{l+m+mf}{0.0625}\PYG{o}{.}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{\textbar{}}  \PYG{n}{HFx} \PYG{n}{TEFCI} \PYG{n}{engine}\PYG{p}{:} \PYG{n}{user}\PYG{o}{\PYGZhy{}}\PYG{n}{adjustable} \PYG{n}{requirements}    \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{Estimated} \PYG{n}{memory} \PYG{n}{requirement} \PYG{n}{per} \PYG{n}{MPI} \PYG{n}{rank}         \PYG{o}{\textbar{}}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{\textbar{}}  \PYG{n}{SWOP} \PYG{n+nb}{hash} \PYG{n}{table}                     \PYG{p}{:}    \PYG{l+m+mf}{3.61} \PYG{n}{GB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{Expansions} \PYG{n+nb}{hash} \PYG{n}{table}               \PYG{p}{:}    \PYG{l+m+mf}{1.81} \PYG{n}{GB}  \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}  \PYG{n}{AD} \PYG{n}{NGWF} \PYG{n}{products} \PYG{n+nb}{hash} \PYG{n}{table}         \PYG{p}{:}  \PYG{l+m+mf}{369.00} \PYG{n}{MB}  \PYG{o}{\textbar{}}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{\textbar{}}  \PYG{n}{Estimated} \PYG{n}{peak} \PYG{n}{total} \PYG{n}{per} \PYG{n}{MPI} \PYG{n}{rank}   \PYG{p}{:}    \PYG{l+m+mf}{5.77} \PYG{n}{GB}  \PYG{o}{\textbar{}}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{\PYGZhy{}} \PYG{n}{Peak} \PYG{n}{memory} \PYG{n}{use} \PYG{n}{capped} \PYG{n}{at} \PYG{l+m+mf}{6998.2} \PYG{n}{MB} \PYG{n}{per} \PYG{n}{MPI} \PYG{n}{rank}\PYG{o}{.}
\end{sphinxVerbatim}

Here the user specified \sphinxcode{hfx\_memory\_limit 7000} and HFx distributed
the remaining 5.77 GB across the three caches with a default set of
weights that is 10:5:1
(\(=\frac{10}{16}:\frac{5}{16}:\frac{1}{16}=0.6250:0.3125:0.0625\)).
This is an empirically determined near-optimal default for valence
calculations. For conduction calculations the default is to give all
remaining RAM to the SWOP hash table, because in conduction calculations
expansions are never re-used and the number of NGWF products is so
large, that it’s faster to give up on storing them entirely.

The three caches store, respectively:
\begin{itemize}
\item {} 
Spherical waves or potentials thereof (“SWOPs”). Generating SWOPs is
typically the main bottleneck of any HFx calculation, and increasing
the size of this cache will lead to significant improvements, with
returns diminishing after hit ratios exceed 90-95\%.

\item {} 
Spherical wave expansions (potentials of linear combinations of
spherical waves on a centre). These can help performance too, but
their size quickly becomes unwieldy.

\item {} 
NGWF products. Less useful than the above, but cheap to store, except
in conduction calculations.

\end{itemize}

In general, it is best to rely on the default division and to specify
only \sphinxcode{hfx\_memory\_limit}. However, if you feel you can do better, you
can manually set the maximum for any number of caches, using the
directives \sphinxcode{cache\_limit\_for\_swops}, \sphinxcode{cache\_limit\_for\_expansions},
\sphinxcode{cache\_limit\_for\_prods}. This might be useful if you specifically want
to disable one or more of the caches (by specifying 0). Remember that
\sphinxcode{hfx\_memory\_limit} is still in effect by default, even if you do not
specify it, and it will interact with the above. If you want to turn off
the automatic balancing of memory limits, specify
\sphinxcode{hfx\_memory\_limit -1}. Once you do this, the specified cache limits
will be used (with a default of 1024). Finally, if you keep the
automated balancing, \sphinxcode{hfx\_memory\_weights}, which accepts three real
numbers, can be used to set the desired weights, if you are not
satisfied with the default. The weights do not need to add to 1, they
will be automatically rescaled. They cannot all be zero, but some of
them can be zero (which then turns off the associated cache).

The utilisation of each cache is reported at some stage of the
calculation (assuming \sphinxcode{hfx\_output\_detail} is at \sphinxcode{NORMAL} or higher).
You will see banners like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{\textbar{}}    \PYG{n}{MPI} \PYG{o}{\textbar{}}                           \PYG{o}{\textbar{}}              \PYG{o}{\textbar{}}           \PYG{o}{\textbar{}}              \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}   \PYG{n}{rank} \PYG{o}{\textbar{}}       \PYG{n}{SWOP} \PYG{n}{cache} \PYG{n}{capacity} \PYG{o}{\textbar{}} \PYG{n}{SWOPs} \PYG{n}{needed} \PYG{o}{\textbar{}} \PYG{n}{Cacheable} \PYG{o}{\textbar{}}    \PYG{n}{Hit} \PYG{n}{ratio} \PYG{o}{\textbar{}}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{o}{\textbar{}}      \PYG{l+m+mi}{0} \PYG{o}{\textbar{}}       \PYG{l+m+mi}{3691} \PYG{n}{MiB} \PYG{p}{(}\PYG{l+m+mi}{24189} \PYG{n}{el}\PYG{p}{)} \PYG{o}{\textbar{}}    \PYG{l+m+mi}{109140} \PYG{n}{el} \PYG{o}{\textbar{}}    \PYG{l+m+mf}{22.16}\PYG{o}{\PYGZpc{}} \PYG{o}{\textbar{}}       \PYG{l+m+mf}{58.70}\PYG{o}{\PYGZpc{}} \PYG{o}{\textbar{}}
\PYG{o}{\textbar{}}      \PYG{l+m+mi}{1} \PYG{o}{\textbar{}}       \PYG{l+m+mi}{3691} \PYG{n}{MiB} \PYG{p}{(}\PYG{l+m+mi}{24189} \PYG{n}{el}\PYG{p}{)} \PYG{o}{\textbar{}}    \PYG{l+m+mi}{109140} \PYG{n}{el} \PYG{o}{\textbar{}}    \PYG{l+m+mf}{22.16}\PYG{o}{\PYGZpc{}} \PYG{o}{\textbar{}}       \PYG{l+m+mf}{58.85}\PYG{o}{\PYGZpc{}} \PYG{o}{\textbar{}}
\PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\end{sphinxVerbatim}

This is a breakdown over all MPI ranks (only two in this case),
informing you that you devoted about 3.7 GB per MPI rank to the SWOP
cache, which enables caching 24189 elements, whereas 109140 elements
could be stored, if you had more RAM. You were thus able to cache about
22\% of all elements, but because HFx stores the most reusable ones
first, the cache hit ratio will be about 59\% \textendash{} that is, in 59\% of cases
when HFx will be looking for a SWOP, it will find it in the cache.
Different SWOPs will be needed on different nodes, hence the hit ratios
are not exactly equal. Looking up SWOPs in the cache is at least an
order of magnitude faster than recaculating them, so you should aim for
a hit ratio of at least \(90\)\%.

Banners for the expansion and NGWF product caches will be printed after
the first LNV (or EDFT) iteration (for \sphinxcode{hfx\_output\_detail VERBOSE}) or
after every energy evaluation (for \sphinxcode{hfx\_output\_detail} at \sphinxcode{PROLIX}
or higher). They look like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{\textbar{}}    \PYG{n}{MPI} \PYG{o}{\textbar{}}                          \PYG{n}{Expansion} \PYG{n}{cache}                     \PYG{o}{\textbar{}}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{\textbar{}}   \PYG{n}{rank} \PYG{o}{\textbar{}}           \PYG{n}{hits} \PYG{o}{\textbar{}}         \PYG{n}{misses} \PYG{o}{\textbar{}}          \PYG{n}{total} \PYG{o}{\textbar{}} \PYG{n}{hit} \PYG{n}{ratio} \PYG{o}{\textbar{}}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{\textbar{}}      \PYG{l+m+mi}{0} \PYG{o}{\textbar{}}        \PYG{l+m+mi}{1982298} \PYG{o}{\textbar{}}       \PYG{l+m+mi}{13369145} \PYG{o}{\textbar{}}       \PYG{l+m+mi}{15351443} \PYG{o}{\textbar{}}   \PYG{l+m+mf}{12.91} \PYG{o}{\PYGZpc{}} \PYG{o}{\textbar{}}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{\textbar{}}      \PYG{l+m+mi}{1} \PYG{o}{\textbar{}}        \PYG{l+m+mi}{1947916} \PYG{o}{\textbar{}}       \PYG{l+m+mi}{13512601} \PYG{o}{\textbar{}}       \PYG{l+m+mi}{15460517} \PYG{o}{\textbar{}}   \PYG{l+m+mf}{12.60} \PYG{o}{\PYGZpc{}} \PYG{o}{\textbar{}}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{\textbar{}}    \PYG{n}{MPI} \PYG{o}{\textbar{}}                    \PYG{n}{AD} \PYG{n}{NGWF} \PYG{n}{product} \PYG{n}{cache}                     \PYG{o}{\textbar{}}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{\textbar{}}   \PYG{n}{rank} \PYG{o}{\textbar{}}           \PYG{n}{hits} \PYG{o}{\textbar{}}         \PYG{n}{misses} \PYG{o}{\textbar{}}          \PYG{n}{total} \PYG{o}{\textbar{}} \PYG{n}{hit} \PYG{n}{ratio} \PYG{o}{\textbar{}}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{\textbar{}}      \PYG{l+m+mi}{0} \PYG{o}{\textbar{}}        \PYG{l+m+mi}{1947809} \PYG{o}{\textbar{}}        \PYG{l+m+mi}{7499676} \PYG{o}{\textbar{}}        \PYG{l+m+mi}{9447485} \PYG{o}{\textbar{}}   \PYG{l+m+mf}{20.62} \PYG{o}{\PYGZpc{}} \PYG{o}{\textbar{}}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{\textbar{}}      \PYG{l+m+mi}{1} \PYG{o}{\textbar{}}        \PYG{l+m+mi}{1992291} \PYG{o}{\textbar{}}        \PYG{l+m+mi}{7737078} \PYG{o}{\textbar{}}        \PYG{l+m+mi}{9729369} \PYG{o}{\textbar{}}   \PYG{l+m+mf}{20.48} \PYG{o}{\PYGZpc{}} \PYG{o}{\textbar{}}
\PYG{n}{HFx}\PYG{p}{:} \PYG{o}{+}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{o}{+}
\end{sphinxVerbatim}

and show you a per-MPI-rank breakdown of how many hits and misses were
recorded in accessing the cache, and what the hit ratio was. You will be
able to achieve 100\% only for the smallest of systems,

Changing cache limits only affects the tradeoff between RAM and CPU
time, it has absolutely no effect on results, only on the time and
memory it will take to arrive at them. If you are very pressed for RAM,
you can set all the above cache sizes to 0. This will stop caching
altogether, conserving memory, but will vastly increase run time, by a
factor of several.

A simple, perhaps surprising, way of increasing performance (slightly)
is by using PPDs that are not flat. By default ONETEP initialises the
third dimension of a PPD to 1, making them flat. This makes sense in the
absence of HFx. With HFx the book-keeping of the caching machinery will
be faster when the PPDs are slightly larger. Preferably use
\sphinxcode{ppd\_npoints} to make the PPDs \(5\times{}5\times{}5\) or
\(7\times{}7\times{}7\). It might be necessary to explicitly set
\sphinxcode{psinc\_spacing} and carefully choose the box dimensions. An easy
solution is to choose \sphinxcode{psinc\_spacing 0.5 0.5 0.5} which corresponds to
a kinetic energy cutoff of 827 eV, and to make your box dimensions
divisible by \(2.5\,a_0\) (for \(5\times{}5\times{}5\) PPDs).

Finally, you can try omitting some terms in the expansion, if the
expansion coefficients are below a certain threshold. This will affect
the accuracy of your results, and so by default nothing is thrown away.
This can be done via the keyword \sphinxcode{swx\_c\_threshold} which takes a real
number as an argument. Whenever an NGWF-pair expansion coefficient is
below this value, potentials from this particular SW for this pair of
NGWFs will not even be generated. This can be used in conjunction with a
distance-based truncation. A value like 1E-5 will throw away maybe 2-3\%
of the terms. 1E-3 will throw away about 10-15\% (so, little gain), and
this will be enough to impair your NGWF convergence. I do not recommend
changing this setting.


\subsubsection{Other advanced options}
\label{\detokenize{hfx:other-advanced-options}}
\sphinxcode{swx\_output\_detail (string)} \textendash{} controls the verbosity of the spherical
wave expansion. Allowed options: \sphinxcode{BRIEF}, \sphinxcode{NORMAL}, \sphinxcode{VERBOSE}.
Defaults to \sphinxcode{NORMAL}. At \sphinxcode{VERBOSE} you might feel overwhelmed by the
output from all MPI ranks letting you know which atom they are working
on (lines looking like “\sphinxcode{+ A: 1}” or “\sphinxcode{- B: 1}”). This is useful for
big systems, where it takes a while to get from one LNV iteration to the
next one, with no output otherwise.

\sphinxcode{hfx\_output\_detail (string)} \textendash{} controls the verbosity of Hartree Fock
exchange. Allowed options: \sphinxcode{BRIEF}, \sphinxcode{NORMAL}, \sphinxcode{VERBOSE},
\sphinxcode{PROLIX}, \sphinxcode{MAXIMUM}. Defaults to the value of \sphinxcode{output\_detail}. At
\sphinxcode{VERBOSE} you might feel overwhelmed by the output from all MPI ranks
letting you know which atom they are working on (lines looking like
“\sphinxcode{- B: 1 {[}0{]} (1)}”). This is useful for big systems, where it takes a
while to get from one LNV iteration to the next one, with no output
otherwise. At \sphinxcode{PROLIX} there is even more feedback. At \sphinxcode{MAXIMUM}
even the \(X\) matrix is printed, which will make your output file
extremely big. This is recommended only when debugging. The recommended
setting is \sphinxcode{VERBOSE}.

\sphinxcode{hfx\_bessel\_rad\_nptsx (integer)} \textendash{} specifies how many points are used
in the radial interpolation of Bessel functions. The default is 100000
and should be sufficient. Increasing this value (perhaps to 250000 or
so) improves accuracy, particularly if your simulation cell is large,
but there is an associated linear memory cost (typically in tens of MB
per MPI rank).

\sphinxcode{use\_sph\_harm\_rot (logical)} \textendash{} Manually activate the
\sphinxcode{sph\_harm\_rotation} (spherical harmonic rotation) module (used to
evaluate the metric matrix in the 2Dn-1Da scheme). In normal operation
this is not necessary, since the module will be activated if it is
detected that spherical harmonic rotation is required. Setting this is
to false has no effect, since the option will be overridden if ONETEP
detects that the module is needed, anyway.

\sphinxcode{swx\_dbl\_grid} \textendash{} experimental functionality, please do not use.


\paragraph{devel\_code values}
\label{\detokenize{hfx:devel-code-values}}
\sphinxcode{SHROT:DEBUG={[}T/F{]}:SHROT} \textendash{} Activate debug mode for the
\sphinxcode{sph\_harm\_rotation} module

\sphinxcode{SHROT:UNIT\_TEST={[}T/F{]}:SHROT} \textendash{} Activate unit testing for the
\sphinxcode{sph\_harm\_rotation} module


\subsection{Frequently asked questions}
\label{\detokenize{hfx:frequently-asked-questions}}

\subsubsection{What hybrid functionals are available in ONETEP?}
\label{\detokenize{hfx:what-hybrid-functionals-are-available-in-onetep}}
\sphinxcode{B1LYP}, \sphinxcode{B1PW91}, \sphinxcode{B3LYP}, \sphinxcode{B3PW91}, \sphinxcode{PBE0}, \sphinxcode{X3LYP}. For a
pure Hartree-Fock calculation use \sphinxcode{HF}.


\subsubsection{How big can my system be when using HFx?}
\label{\detokenize{hfx:how-big-can-my-system-be-when-using-hfx}}
Up to 200 atoms should be a breeze on a desktop machine (64 GB RAM, 16
cores). About 500-600 atoms will be a limit for a desktop machine, but
it might take a week or two. Larger systems will be off-limits because
you will either run out of memory (if using \(>1\) MPI rank), or hit
\sphinxcode{sparse\_mod} integer overflows (if using 1 MPI rank).

On a HPC cluster (say, 640 cores) up to 1000 atoms should not be too
difficult (3-4 days). Current record is 4048 atoms (640 cores, 20 days,
June 2020). With significant resources (\(5000+\) cores) you should
be able to do 10000 atoms, but this has not been tried.


\subsubsection{How do I make HFx faster?}
\label{\detokenize{hfx:how-do-i-make-hfx-faster}}
Use as many OMP threads as possible, without crossing NUMA regions. On a
typical HPC system this will mean using only 2 MPI ranks per node, and
on a desktop machine \textendash{} only 1 MPI rank. This will minimise the number of
MPI ranks, allowing you to give much more memory to each of them.
Increase \sphinxcode{hfx\_memory\_limit} from the default value of 4096 to however
much you can spare. This is the maximum RAM consumption of HFx (on top
of the rest of ONETEP) per MPI rank. Here it is always the higher the
better, except you don’t want to run out of memory. Use  or for a slight
efficiency gain.


\subsubsection{I’m running out of memory}
\label{\detokenize{hfx:im-running-out-of-memory}}
Symptoms: you get error messages like “Killed”, or “Out of memory: Kill
process \sphinxstyleemphasis{nnn} (onetep.exe)” in \sphinxcode{dmesg} output, or your system starts
\sphinxstyleemphasis{thrashing} (swapping memory to HDD). What you can do:
\begin{itemize}
\item {} 
Reduce the number of MPI ranks per node. In the worst case scenario,
undersubscribe (leave some cores idle), even to the point of having
only 1 MPI rank per node.

\item {} 
Reduce \sphinxcode{hfx\_memory\_limit} from the default value of 4096 to
something smaller.

\item {} 
Reduce the quality of the SW expansion (\(l_{\textrm{max}}\),
\(q_{\textrm{max}}\)) (this will affect the quality of results).

\item {} 
If you’re running out of memory at the NGWF gradient stage, reduce
\sphinxcode{threads\_num\_fftboxes}. The default is equal to the number of OMP
threads. Reduce it to 1. This is a component of ONETEP that consumes
quite a bit of RAM irrespective of whether HFx is used or not.

\item {} 
Use high-memory nodes. Many HPC facilities provide these.

\item {} 
Increase the number of compute nodes used in the calculation. Some of
the necessary data will be distributed across nodes, reducing
per-node load. With a large number of OMP threads, you can easily use
much more CPUs than you have atoms in your system.

\end{itemize}


\subsubsection{The HFx engine does not use all the memory I asked it it to use. Why?}
\label{\detokenize{hfx:the-hfx-engine-does-not-use-all-the-memory-i-asked-it-it-to-use-why}}
If you devote too much memory to one of the caches, only as much will be
used as is needed to store all that is needed. Perhaps adjust
\sphinxcode{hfx\_memory\_weights} to give this memory to where it is needed more.


\subsubsection{My calculation aborts with \sphinxstyleliteralintitle{Error in sparse\_count\_ss: Integer overflow in sparse matrix index detected.} What now?}
\label{\detokenize{hfx:my-calculation-aborts-with-error-in-sparse-count-ss-integer-overflow-in-sparse-matrix-index-detected-what-now}}
Your sparse matrices are too large, overflowing integer indices in
ONETEP’s sparse matrix machinery. Essentially you are trying to run a
calculations with too many atoms on too few MPI ranks. Increase the
number of MPI ranks or decrease \sphinxcode{hfx\_cutoff}. The latter will impact
results.

My calculation crashes with a \sphinxcode{SIGSEGV} and the last line of output is
“\sphinxcode{KSKS matrix filling:}”. What now?
————————————————————————

Same as above, except the integer overflow has not been detected.


\subsubsection{My calculation aborts with \sphinxstyleliteralintitle{Exchange matrix not deemed accurate enough for a stable calculation}. What now?}
\label{\detokenize{hfx:my-calculation-aborts-with-exchange-matrix-not-deemed-accurate-enough-for-a-stable-calculation-what-now}}
One of the approximations broke down. You turned the “speed
vs. accuracy” knob too far towards “speed”.
\begin{itemize}
\item {} 
Is your SW expansion quality too low? The minimum reasonable quality
is about \(l_{\textrm{max}}=2\), \(q_{\textrm{max}}=8\), see
{[}Dziedzic2013{]} (Fig. 8). For some systems this might not be
enough, particularly in pure Hartree-Fock calculations
(\sphinxcode{xc\_functional HF}). Try \(l_{\textrm{max}}=3\),
\(q_{\textrm{max}}=10\).

\item {} 
Is your KE cutoff too low? In general, don’t go below 800 eV.

\item {} 
Is your Chebyshev interpolation quality too low?
\(N_{\textrm{i}}\) should be at least 10, preferably 12.
\(N_{\textrm{o}}\) should also be at least 10, preferably 12.

\item {} 
Is the number of points in the radial Bessel interpolation
(\sphinxcode{hfx\_bessel\_rad\_nptsx}) too low? Don’t go below 100000. For larger
simulation cells you might want to use a higher value (say, 250000).

\end{itemize}


\subsubsection{Can I do conduction calculations with HFx?}
\label{\detokenize{hfx:can-i-do-conduction-calculations-with-hfx}}
Yes!

Just make sure all NGWF radii are equal for all species and across
\sphinxcode{species} and \sphinxcode{species\_cond} blocks. You may reuse the metric
matrices between the valence and conduction calculation. Have a lot of
CPU power available. It shouldn’t be too difficult up to 500 atoms, then
difficulty ramps up. 1000+ atoms will require considerable resources
(\(\approx{}1000+\) cores) and patience (weeks). Current record is
1108 atoms (June 2020).


\subsubsection{Can I do LR-TDDFT calculations with HFx?}
\label{\detokenize{hfx:can-i-do-lr-tddft-calculations-with-hfx}}
Yes, but this is at an experimental stage at the moment.


\subsection{Further questions?}
\label{\detokenize{hfx:further-questions}}
General questions should be directed to Jacek Dziedzic,
\sphinxcode{J.Dziedzic{[}-at-{]}soton.ac.uk.}

Questions relating to the 2Dn-1Da metric matrix evaluation scheme or to
hybrid LR-TDDFT should be directed at James C. Womack,
\sphinxcode{J.C.Womack{[}-at-{]}bristol.ac.uk}.

{[}Hine2011{]} N. D. M. Hine, J. Dziedzic, P. D. Haynes, and C.-K. Skylaris, \sphinxstyleemphasis{J. Chem. Phys.} \sphinxstylestrong{135}, 204103 (2011)

{[}Dziedzic2013{]} J. Dziedzic, Q. Hill, and C.-K. Skylaris, \sphinxstyleemphasis{J. Chem. Phys.} \sphinxstylestrong{139}, 214103 (2013)

{[}Rein1973{]} R. Rein, \sphinxstyleemphasis{On Physical Properties and Interactions of Polyatomic Molecules: With Application to Molecular Recognition in Biology}, in Advances in Quantum Chemistry, ed. P. Lowdin, Academic Press (1973)

{[}Stone1981{]} A. J. Stone, \sphinxstyleemphasis{Chem. Phys. Lett.} \sphinxstylestrong{2}, 233 (1981)

{[}Stone1985{]} A. J. Stone and M. Alderton, \sphinxstyleemphasis{Mol. Phys.} \sphinxstylestrong{5}, 56 (1985)

{[}Stone1998{]} A. J. Stone, \sphinxstyleemphasis{GDMA: distributed multipoles from Gaussian98 wavefunctions} (technical report), University of Cambridge (1998)

{[}Stone2005{]} A. J. Stone, \sphinxstyleemphasis{J. Chem. Theory Comput.} \sphinxstylestrong{6}, 1128 (2005)

{[}Dziedzic2016{]} J. Dziedzic, Y. Mao, Y. Shao, J. Ponder, T. Head-Gordon, M. Head-Gordon, and C.-K. Skylaris, \sphinxstyleemphasis{J. Chem. Phys.} \sphinxstylestrong{145}, 124106 (2016)

{[}Vitale2015{]} V. Vitale, J. Dziedzic, S. M.-M. Dubois, H. Fangohr, and C.-K. Skylaris, \sphinxstyleemphasis{J. Chem. Theory Comput.} \sphinxstylestrong{11}, 3321 (2015)


\section{Cut-off Coulomb}
\label{\detokenize{cutoff_coulomb::doc}}\label{\detokenize{cutoff_coulomb:cut-off-coulomb}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Nick Hine, University of Warwick (implementation)

\item[{Author}] \leavevmode
Gabriel Bramley, University of Southampton (documentation)

\item[{Date}] \leavevmode
July 2019

\end{description}\end{quote}


\subsection{Theory}
\label{\detokenize{cutoff_coulomb:theory}}
The plane wave approach inherently involves the use of periodic boundary
conditions (PBC). In order to model isolated molecules, the supercell
technique was developed, which involves adding large quantities of
vacuum to the simualtion cell in order to separate their periodic
images. Although this method is adequate for neutral molecules, charged
systems and systems with significant multipoles require additional
considerations. The potential of the monopole and multipole moments
decay in accordance to the power law, where point charges decay with
\(\frac{1}{r^{1}}\), dipoles with \(\frac{1}{r^{2}}\) etc..
Using the supercell method for systems with a net charge or significant
dipoles require large volumes of vacuum to eliminate the electrostatic
interactions between the system of the unit cell and its periodic
images. However, as traditional plane wave codes extend across the
entire cell, adding large quantities of vacuum is computationally
costly. Various dipole corrections such as the cut-off Coulomb (CC)
{[}Jarvis1997{]}, Continuum Screening Method
{[}Otani2006{]} and Gaussian
Counter Charge model
{[}Dabo2008{]} have been
developed in order to isolate the electrostatic interactions of the unit
cell from its periodic images.

The cut-off Coulomb (or Coulomb cut-off) approach, as implemented in
ONETEP by Nick Hine {[}Hine2011{]}, achieves this by only
allowing Coulombic interactions within a specified region, thereby
emulating the electrostatics of an isolated system with a periodic
representation of the charge density {[}Jarvis1997{]}. By
selecting an appropriate region, one can eliminate spurious
electrostatic interactions between charges in the periodic replicas and
the home cell, while also retaining the correct description of the
potential between charges in the isolated system. One can choose to
maintain periodic Coulombic interactions along specified axes, thereby
representing electrostatics in systems with either 1D (wire), 2D (slab)
or 0D (sphere) periodicity.


\subsubsection{3D Periodic Coulomb Interaction}
\label{\detokenize{cutoff_coulomb:d-periodic-coulomb-interaction}}
In a standard periodic calculation, the electrostatic potential is
defined as through the Hartree potential:

\phantomsection\label{\detokenize{cutoff_coulomb:equation-hartree}}\begin{equation}\label{equation:cutoff_coulomb:hartree}
\begin{split}V_{H}(\mathbf{r}) = \int_{space} {\frac{n(\mathbf{r'})}{|\mathbf{r} -  \mathbf{r'}|}}  d\mathbf{r'}\end{split}
\end{equation}
Where \(n(\mathbf{r'})\) describes the charge density of the system.
This can be equivalently represented as:
\begin{equation*}
\begin{split}V_{H}(\mathbf{r}) = \int_{space} v(\mathbf{r},\mathbf{r'})n(\mathbf{r'}) d\mathbf{r'}\end{split}
\end{equation*}
Where \(v(\mathbf{r})\) represents the Coulomb interaction,
\(\frac{1}{|\mathbf{r} -  \mathbf{r'}|}\). This is more conveniently
calculated in reciprocal space, which is achieved through a Fourier
transformation of the \(V_{H}\) in accordance with convolution
theory:
\begin{equation*}
\begin{split}V_{H}(\mathbf{G}) = v(\mathbf{G})n(\mathbf{G})\end{split}
\end{equation*}
In the fully periodic case, the above expressions are taken over all
reciprocal space (\(\infty\) to \(-\infty\)), which yields a
Coulomb interaction of:
\begin{equation*}
\begin{split}v(\mathbf{G}) = \frac{4 \pi}{|\mathbf{G}|^2}\end{split}
\end{equation*}

\subsubsection{Coulomb Cut-off in 3D}
\label{\detokenize{cutoff_coulomb:coulomb-cut-off-in-3d}}
The standard periodic approach takes the integration of the Coulomb
interaction over all space, which allows interaction between the
periodic images and the original unit cell. In contrast, Coulomb cut-off
sets the Coulomb interaction between charges to zero beyond a specified
radius. In the simplest case, one can define this cut-off as a sphere,
which assumes a system without periodicity. By selecting an appropriate
cut-off radius, \(R_C\), one can retain the correct electrostatic
interactions of between charges in the unit cell, while eliminating
spurious interactions the periodic images:
\begin{equation*}
\begin{split}v^{3D}(\mathbf{r},\mathbf{r'}) =
     \begin{cases}
      \frac{1}{|\mathbf{r} -  \mathbf{r'}|} & \text{for $R_C < |\mathbf{r} -  \mathbf{r'}|$}\\
      0 & \text{for $R_C > |\mathbf{r} -  \mathbf{r'}|$}\\
     \end{cases}\end{split}
\end{equation*}
Performing an analytic Fourier Transformation of
\(v(\mathbf{r},\mathbf{r'})\) with modified boundaries yields the
following reciprocal space representation of the Coulomb interaction:
\begin{equation*}
\begin{split}v^{3D}(\mathbf{G}) =  \frac{4 \pi}{\mathbf{G}^2}(1 - \cos(\mathbf{G}R_C))\end{split}
\end{equation*}

\subsubsection{Coulomb Cut-off in 1D}
\label{\detokenize{cutoff_coulomb:coulomb-cut-off-in-1d}}
Although this approach is satisfactory for systems with no periodicity,
additional considerations must be made if periodicity is required in
either 1D (ie. a wire) or in 2D (ie. an infinitely extended plane). In
the 1D case, the Coulomb cut-off is defined as a cylinder, where
periodicity is retained in the z-axis and the Coulomb interaction is
applied in the xy-direction. In theory, this redefines the Coulomb
interaction as:

\phantomsection\label{\detokenize{cutoff_coulomb:equation-1dcc}}\begin{equation}\label{equation:cutoff_coulomb:1DCC}
\begin{split}\begin{aligned}
    v^{1D}(\mathbf{G_{\bot}, G}_x) =  \frac{4 \pi}{\mathbf{G}^2}  [1 + \mathbf{G}_{\bot}R_C J_1 (\mathbf{G}_{\bot}R_C) K_{0}(\mathbf{G}_x R_C)
    - \mathbf{G}_x R_C J_{0}(\mathbf{G}_{\bot}R_C) K_{1}(\mathbf{G}_x R_C) ]
    \end{aligned}\end{split}
\end{equation}
Where \(J\) and \(K\) are modified Bessel functions,
\(\mathbf{G}_x\), \(\mathbf{G}_y\) and \(\mathbf{G}_z\) the
reciprocal lattice vectors in \(x\), \(y\) and \(z\) and
\(\mathbf{G}_{\bot} = \sqrt{\mathbf{G}_x^2 + \mathbf{G}_z^2}\).

However, a divergence occurs at \(G_x = 0\), which is handled by
re-casting Equation \eqref{equation:cutoff_coulomb:1DCC} into an analytical expression solved through
:
\begin{equation*}
\begin{split}v^{1D}(\mathbf{G_{\bot}, G}_x = 0) =  - 4 \pi  \int_{0}^{R} r J_{0}(\mathbf{G}_{\bot})\ln{(\mathbf{r})} d \mathbf{r}\end{split}
\end{equation*}

\subsubsection{Coulomb Cut-off in 2D}
\label{\detokenize{cutoff_coulomb:coulomb-cut-off-in-2d}}
For systems where periodicity is maintained in 2D, the Coulomb cut-off
must only be applied in the out-of-plane direction, while retaining PBC
in the xy-plane. Originally, this was implemented in ONETEP from the
formulation of \sphinxstyleemphasis{Rozzi et al.}
{[}Rozzi2006{]}, where the Coulomb
interaction \(v^{3D}(\mathbf{G})\) is re-cast to the following
expression:
\begin{equation*}
\begin{split}v^{2D}(\mathbf{G_{\|}},\mathbf{G}_{z}) = \frac{4 \pi}{\mathbf{G}^2} \bigg \lbrack 1 + e^{-\mathbf{G}_{\|}R_C}\frac{\mathbf{G}_z}{\mathbf{G}_{\|}}\sin(\mathbf{G}_z R_C) - e^{-\mathbf{G}_{\|}R_C}\cos{|\mathbf{G}_z|R_C}) \bigg \rbrack\end{split}
\end{equation*}
Where \(\mathbf{G}_{\|} = \sqrt{\mathbf{G}_{x}^2+\mathbf{G}_{y}^2}\)
and \(\mathbf{G}_{z}\) represent the in-plane and out-of-plane
reciprocal space vectors respectively. However, as described by \sphinxstyleemphasis{Sohier
et al.} {[}Sohier2017{]}, if
\(R_C = \frac{L}{2}\), where L represents the length of the
simulation cell, this expression simplifies to:
\begin{equation*}
\begin{split}v^{2D}(\mathbf{\mathbf{G}_{\|}},\mathbf{G}_{z}) = \frac{4 \pi}{\mathbf{G}^2} \bigg \lbrack 1 - e^{-\mathbf{G}_{\|}R_C}\cos({|\mathbf{G}_z|R_C}) \bigg \rbrack\end{split}
\end{equation*}
Where \(G_z\) is a multiple of \(\frac{2 \pi}{L}\). As with the
Coulomb interaction under periodic boundary conditions, this term
diverges at \(\mathbf{G} = 0\), and is therefore treated separately
and \(v^{2D}(\mathbf{\mathbf{G}}=0) = 0\) as argued by \sphinxstyleemphasis{Sohier et
al.} {[}Sohier2017{]}.


\subsection{Performing a Calculation with Coulomb Cut-off}
\label{\detokenize{cutoff_coulomb:performing-a-calculation-with-coulomb-cut-off}}
To use Coulomb cut-off, the keyword \sphinxcode{COULOMB\_CUTOFF\_TYPE} must be
inserted, with the input specifying the periodicity of the system:
\begin{itemize}
\item {} 
1D - \sphinxcode{COULOMB\_CUTOFF\_TYPE: WIRE}

\item {} 
2D - \sphinxcode{COULOMB\_CUTOFF\_TYPE: SLAB}

\item {} 
3D - \sphinxcode{COULOMB\_CUTOFF\_TYPE: SPHERE}

\end{itemize}

In addition, the length/radius of the cut-off must be specified with
either \sphinxcode{COULOMB\_CUTOFF\_RADIUS} or \sphinxcode{COULOMB\_CUTOFF\_LENGTH}:
\begin{itemize}
\item {} 
1D \& 2D - \sphinxcode{COULOMB\_CUTOFF\_LENGTH}

\item {} 
3D - \sphinxcode{COULOMB\_CUTOFF\_RADIUS}

\end{itemize}

As part of the Coulomb cut-off in ONETEP, the electron density
\(n(\mathbf{r})\) in the original cell is placed into a larger,
padded cell in which \(n(\mathbf{r}) = 0\). This is determined in a
similar way as the original lattice block through a new block
\sphinxcode{\%BLOCK PADDED\_LATTICE\_CART}, which determines the size and dimensions
of the larger cell: \sphinxcode{\%BLOCK PADDED\_LATTICE\_CART} \sphinxcode{a11 a21 a31}
\sphinxcode{a21 a22 a23} \sphinxcode{a31 a32 a33} \sphinxcode{\%ENDBLOCK PADDED\_LATTICE\_CART}

This is automatically specified, so adjusting this block is not
recommended. The recommended set-ups for calculations of each
dimensionality are summarized in the table below:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstylethead{\sphinxstyletheadfamily 
Coulomb Cut-off Type
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Cut-off Length/Radius
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Cell Dimensions
\unskip}\relax \\
\hline&&
\(a_{11}^{pad} = 2a_{11}^{cell}\)
\\
\hline
Sphere*
&
\(R_C = \sqrt{3}a_{33}^{cell}\)
&
\(a_{22}^{pad} = 2a_{22}^{cell}\)
\\
\hline&&
\(a_{33}^{pad} = 2a_{33}^{cell}\)
\\
\hline&&
\(a_{11}^{pad} = 2a_{11}^{cell}\)
\\
\hline
Wire**
&
\(R_C = \sqrt{2}a_{33}^{cell}\)
&
\(a_{22}^{pad} = 2a_{22}^{cell}\)
\\
\hline&&
\(a_{33}^{pad} = a_{33}^{cell}\)
\\
\hline&&
\(a_{11}^{pad} = a_{11}^{cell}\)
\\
\hline
Slab***
&
\(R_C = a_{33}\)
&
\(a_{22}^{pad} = a_{22}^{cell}\)
\\
\hline&&
\(a_{33}^{pad} = 2 a_{33}^{cell}\)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Table: The recommended calculation parameters for each periodicity of
the Coulomb cut-off, where \(a_{ii}^{cell}\) and
\(a_{ii}^{pad}\) represent the diagonal components of the original
simulation cell specified in \sphinxcode{\% BLOCK\_LATTICE\_CART} and the padded
cell respectively. Assumed orthogonal cell in all cases.

\begin{DUlineblock}{0em}
\item[] * Assuming \(a_{11}^{cell} = a_{22}^{cell} = a_{33}^{cell}\).
\item[] ** Assuming \(a_{11}^{cell} = a_{22}^{cell}\). \(a_{33}\) being the periodic direction.
\item[] *** \(a_{33}\) defined as the non-periodic direction.
\end{DUlineblock}

These choices of both the padded cell dimension and the cut-off
length/radius ensure two conditions are satisfied:
\begin{enumerate}
\item {} 
Charges within the original unit cell correctly interact with one
another.

\item {} 
The interaction between charges of the periodic image and the
original simulation cell are set to zero.

\end{enumerate}

The first condition is satisfied by setting the cut-off distance equal
to or greater than the distance between any two non-zero charges within
the original unit cell. For the 3D case, this is typically satisfied by
\(R_C > \sqrt{3}L_{cell}\), while in 2D and 1D, this is satisfied by
\(R_C = \frac{L_{cell}}{2}\), where \(L_{cell}\) is the cell
dimension in the non-periodic axis. The second condition requires that
the distance between non-zero charges of the simulation cell and the
periodic image must be greater than or equal to the cut-off length. In
ONETEP, this is achieved by placing the unit cell inside a larger padded
cell, in which the charge density \(\rho(\mathbf{r})=0\). The second
condition is satisfied when the total cell length,
\(L_{total} = L_{cell} + L_{pad} \geq R_C + L_{cell}\).

{[}Jarvis1997{]} M. R. Jarvis, I. D. White, R. W. Godby, and M. C. Payne, \sphinxstyleemphasis{Supercell technique for total-energy calculations of finite charged and polar systems}, Phys. Rev. B, \sphinxstylestrong{56}, (1997).

{[}Otani2006{]} M. Otani, and O. Sugino, \sphinxstyleemphasis{First-principles calculations of charged surfaces and interfaces: A plane-wave nonrepeated slab approach}, Phys. Rev. B, \sphinxstylestrong{73}, (2006).

{[}Dabo2008{]} I. Dabo, B. Kozinsky, N. E. Singh-Miller, N. Marzari, \sphinxstyleemphasis{Electrostatics in periodic boundary conditions and real-space corrections}, Phys. Rev. B, \sphinxstylestrong{77}, (2008).

{[}Hine2011{]} N. D. M. Hine, J. Dziedzic, P. D. Haynes, and C.-K. Skylaris, \sphinxstyleemphasis{Electrostatic interactions in finite systems treated with periodic boundary conditions: Application to linear-scaling density functional theory}, J. Chem. Phys. \sphinxstylestrong{135} (2011).

{[}Rozzi2006{]} C. A. Rozzi, D. Varsano, A. Marini, E. K. U. Gross, and A. Rubio, \sphinxstyleemphasis{Exact Coulomb cutoff technique for supercell calculations}, Phys. Rev. B \sphinxstylestrong{73} (2006).

{[}Sohier2017{]} T. Sohier, M. Calandra, and F. Mauri, \sphinxstyleemphasis{Density functional perturbation theory for gated two-dimensional heterostructures: Theoretical developments and application to flexural phonons in graphene}, Phys. Rev. B \sphinxstylestrong{96} (2017).


\section{Species Dependent Scissor Shifts}
\label{\detokenize{scissor_operator::doc}}\label{\detokenize{scissor_operator:species-dependent-scissor-shifts}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Nelson Yeung, University of Warwick

\item[{Author}] \leavevmode
Nicholas Hine, University of Warwick

\end{description}\end{quote}


\subsection{Scissor Hamiltonian}
\label{\detokenize{scissor_operator:scissor-hamiltonian}}
The scissor hamiltonian allows one to apply species-dependent and
subspace-dependent energy-level shifts to the hamiltonian, which has the
effect of shifting eigenvalues associated with specific layers of the
material. One can separately shift the valence and conduction subspaces
associated with each layer. This also affects the total energy, so must
be applied with great care if you are using the total energy for any
purpose. The idea is that a band-alignment correction can be applied to
the individual layers of non-covalently-bonded layered materials, though
there may well be many other applications as well. It would seem
“unwise” at best to apply this approach to different regions of the same
molecule or solid which are strongly bonded: results would be
unpredictable and likely unphysical. One ideal use would be to correct
the alignment of the band-edges of a layered material heterobilayer so
that the appropriate heterostructure type was realised, for example
straddled-gap rather than broken-gap, using shifts chosen by reference
to beyond-DFT accuracy calculations of the individual materials, or from
experimental techniques such as ARPES.

In order to apply this shift, we define a scissor Hamiltonian operator
as follows:
\begin{equation*}
\begin{split}\hat{H}_\text{scissor} = \lvert\phi_\eta\rangle K_\text{shifted}^{\eta\delta}
    \langle\phi_\delta\rvert \, ,\end{split}
\end{equation*}
where \(K_\text{shifted}\) is the sum of the species-dependent
shifted valence and conduction density kernel, which is defined as
\begin{equation*}
\begin{split}K_\text{shifted} = \sum_L \left( \sigma_{v, L} K_L + \sigma_{c, L} (S^{-1}_L - K_L) \right)\,.\end{split}
\end{equation*}
The \(\sigma_v\) and \(\sigma_c\) are the shifts for valence
and conduction states, respectively, and the sum is over layer
\(L\). The scissor shifted eigenvalues are simply
\begin{equation*}
\begin{split}H_\text{shifted} = H + S K_\text{shifted} S \, .\end{split}
\end{equation*}
The gradient of the scissor energy with respect to the NGWFs can be
calculated using
\begin{equation*}
\begin{split}\begin{aligned}
    \begin{split}
        \frac{\partial E_\text{scissor}}{\partial\phi_\gamma^*(\mathbf{r})}
        &=
        K_n^{\beta\alpha} \frac{\partial}{\partial\phi_\gamma^*(\mathbf{r})}
        \langle \phi_\alpha\rvert\hat{H}_\text{scissor}\lvert\phi_\beta\rangle \\
        &=
        K_n^{\beta\alpha} \frac{\partial}{\partial\phi_\gamma^*(\mathbf{r})}
        \langle\phi_\alpha\rvert\phi_\eta\rangle K_\text{shifted}^{\eta\delta}
        \langle\phi_\delta\rvert\phi_\beta\rangle \\
        &=
        K_\text{shifted}^{\beta\delta} S_{\delta\eta} K_n^{\eta\alpha} \left(
            \phi_\beta + \sum_{ij} \tilde{p}^i(\mathbf{r}) O_{ij} {R^j}_\alpha
        \right) \, .
    \end{split}\end{aligned}\end{split}
\end{equation*}
The approach has been reasonably well tested in the context of LNV
calculations. As of April 2019 it has not been validated for EDFT,
conduction NGWF optimisation, TDDFT etc, but these would be reasonably
expected to work as well.


\subsection{Performing a Species Dependent Scissor Calculation}
\label{\detokenize{scissor_operator:performing-a-species-dependent-scissor-calculation}}
To activate the shift, the \sphinxcode{species\_scissor} block must be present.
The user must specify (on separate lines) groups of atom types, with
each line finishing with two numbers representing the valence and
conduction shifts to be applied to that group of species.

For example, for a \(\textrm{MoS}_2\) / \(\textrm{MoSe}_2\)
heterobilayer, we might use the following to correct the energies of the
individual layers:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}scissor}
\PYG{n}{Mo1} \PYG{n}{S}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.5} \PYG{l+m+mf}{0.5}
\PYG{n}{Mo2} \PYG{n}{Se} \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.1} \PYG{l+m+mf}{0.8}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}scissor}
\end{sphinxVerbatim}

This would have the effect of opening the gap of the
\(\textrm{MoS}_2\) layer by 1eV and opening the gap of the
\(\textrm{MoSe}_2\) layer by 0.9 eV, and shifting the alignment of
the valence bands by 0.4 eV.


\section{Embedded Mean-Field Theory}
\label{\detokenize{EMFT_in_ONETEP:embedded-mean-field-theory}}\label{\detokenize{EMFT_in_ONETEP::doc}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Robert J. Charlton, Imperial College London

\item[{Author}] \leavevmode
Joseph C.A. Prentice, Imperial College London

\item[{Date}] \leavevmode
January 2019

\item[{Date}] \leavevmode
Updated by J.C.A. Prentice October 2021

\end{description}\end{quote}


\subsection{Embedded Mean-Field Theory (EMFT)}
\label{\detokenize{EMFT_in_ONETEP:embedded-mean-field-theory-emft}}
Often in simulations of materials we wish to consider the impact of a
host environment on a system of interest, such as chromophores in
solvent or doped molecular crystals. While the interesting physics or
chemistry may be associated with the subsystem, the effects of the
environment can be significant and warrant description at the quantum
level of theory. However, the cost of applying accurate quantum methods
such as hybrid functionals to potentially large environments can be
restricted by the cost of such methods. Quantum embedding
{[}Huang2008{]}, {[}Gomes2012{]} methods are intended to combine
an accurate, high-level description of the subsystem of interest
(active) with a cheaper, low-level method for the host environment.

Embedded mean field theory (EMFT) {[}Fornace2015{]} is an
approach to quantum embedding based on the one-electron density matrix.
To begin, we partition the density matrix into subsystem components,

\phantomsection\label{\detokenize{EMFT_in_ONETEP:equation-emft-dm}}\begin{equation}\label{equation:EMFT_in_ONETEP:emft_dm}
\begin{split}\rho = \begin{pmatrix}
        \rho_\text{AA} & \rho_\text{AB}\\
        \rho_\text{BA} & \rho_\text{BB}
    \end{pmatrix},\end{split}
\end{equation}
where A is the active region and B is the inactive environment. The
total energy can be written as
\begin{equation*}
\begin{split}E{\left[\rho\right]}=\text{tr}{\left[\rho H_0\right]}+G{\left[\rho\right]},\end{split}
\end{equation*}
where \(H_0\) contains the one-electron terms of the Hamiltonian
and \(G{\left[\rho\right]}\) contains all two-electron terms (local,
Hartree and exchange-correlation effects). In embedded mean-field theory
(EMFT), the two-electron interaction for the active subsystem A is
constructed at a higher level of theory to the rest of the system,

\phantomsection\label{\detokenize{EMFT_in_ONETEP:equation-emft-en}}\begin{equation}\label{equation:EMFT_in_ONETEP:emft_en}
\begin{split}E^\text{EMFT}{\left[\rho\right]}=
        \text{tr}{\left[\rho H_0\right]}+G^\text{low}{\left[\rho\right]}+\left(G^\text{high}{\left[\rho_\text{AA}\right]}-G^\text{low}{\left[\rho_\text{AA}\right]}\right),\end{split}
\end{equation}
where \(G^\text{low}\) and \(G^\text{high}\) are the
two-electron interaction energies at the lower and higher levels of
theory, respectively. For example, the low level theory could be LDA
while the higher level uses a hybrid functional such as B3LYP. We assume
here that the core Hamiltonian \(H_0\) is the same at both levels of
theory, though this need not necessarily be the case. The ground state
of the embedded system can thus be obtained by minimising
\eqref{equation:EMFT_in_ONETEP:emft_en} with respect to the elements of the density
matrix.


\subsubsection{Block orthogonalisation}
\label{\detokenize{EMFT_in_ONETEP:block-orthogonalisation}}
Normalisation is maintained provided the trace of the density matrix
with the overlap matrix satisfies
\begin{equation*}
\begin{split}\text{Tr}\left[\rho\textbf{S}\right]=N.\end{split}
\end{equation*}
EMFT partitioning can result in unrealistic charge spillover from the
low-level to the high-level region, producing large negative results for
the off-diagonal terms
\(\text{Tr}\left[\rho_\text{AB}\textbf{S}_\text{BA}\right]\) and
\(\text{Tr}\left[\rho_\text{BA}\textbf{S}_\text{AB}\right]\). One
possible remedy is to impose a block-orthogonalisation (BO) between the
subsystem orbitals {[}Ding2017{]},
\begin{equation*}
\begin{split}\begin{aligned}
    {\lvert\tilde{\phi_i^\text{B}}\rangle}&
        =\left(1-\hat{P}^\text{A}\right){\lvert\phi_i^\text{B}\rangle}, \\
    \hat{P}^\text{A}&
        =\sum_{j,k\in\text{A}}{\lvert\phi_j^\text{A}\rangle}
        \left(\textbf{S}^\text{AA}\right)_{jk}^\text{-1}{\langle\phi_k^\text{A}\rvert}.\end{aligned}\end{split}
\end{equation*}
By construction
\(\text{Tr}\left[\rho_\text{AB}\textbf{S}_\text{BA}\right]\) and
\(\text{Tr}\left[\rho_\text{BA}\textbf{S}_\text{AB}\right]\) are
strictly zero and all electrons are associated with the diagonal blocks.


\subsection{Implementation in ONETEP}
\label{\detokenize{EMFT_in_ONETEP:implementation-in-onetep}}
Quantum embedding as implemented in ONETEP is based around
EMFT {[}Prentice2020{]}. Here we denote the active system
NGWFs as \({\lvert\chi_i^\text{A}\rangle}\) and the environment NGWFs as
\({\lvert\phi_j^\text{B}\rangle}\). The fundamental quantity of interest is
the Hamiltonian,
\begin{equation*}
\begin{split}\textbf{H}^\text{EMFT}=\begin{pmatrix}
        \textbf{H}^\text{high}_\text{AA} & \textbf{H}^\text{low}_\text{AB} \\
        \textbf{H}^\text{low}_\text{BA} & \textbf{H}^\text{low}_\text{BB}
    \end{pmatrix},
    \label{eq:emft_ham}\end{split}
\end{equation*}
where the high- and low-level Hamiltonian operators are given as
\begin{equation*}
\begin{split}\begin{aligned}
    \hat{H}^\text{high}=&\hat{T}+\hat{V}_\text{local}+\hat{V}_\text{Hartree}+\hat{V}_\text{XC}^\text{high},\\
    \hat{H}^\text{low}=&\hat{T}+\hat{V}_\text{local}+\hat{V}_\text{Hartree}+\hat{V}_\text{XC}^\text{low}.\end{aligned}\end{split}
\end{equation*}
The total energy can thus be found by minimising the quantity
\begin{equation*}
\begin{split}E^\text{EMFT}=
    \min_{\left\{K^{\alpha\beta}\right\},\left\{\chi_\alpha\right\}}
    \text{Tr}\left[\textbf{K}\textbf{H}^\text{EMFT}\right],
    \label{eq:emft_energy}\end{split}
\end{equation*}
with respect to the NGWFs and elements of the density kernel
\(\textbf{K}\), using the conventional methods available in ONETEP.
The Hamiltonian is constructed as follows,
\begin{enumerate}
\item {} 
The total electron density \(n{\left(\mathbf{r}\right)}\) is
constructed from the full system NGWFs and kernel, from which
\(V_\text{XC}^\text{low}{\left(\mathbf{r}\right)}\) is
calculated.

\item {} 
The active subsystem density
\(n^\text{AA}{\left(\mathbf{r}\right)}\) is constructed using the
subsystem terms and the subsystem XC potentials
\(V_\text{XC}^\text{low,A}{\left(\mathbf{r}\right)}\) and
\(V_\text{XC}^\text{high,A}{\left(\mathbf{r}\right)}\)
calculated.

\item {} 
Final EMFT potential can be written as
\begin{equation*}
\begin{split}V_\text{XC}^\text{high}{\left(\mathbf{r}\right)}
            =V_\text{XC}^\text{low}{\left(\mathbf{r}\right)}+\left(V_\text{XC}^\text{high,A}{\left(\mathbf{r}\right)}-V_\text{XC}^\text{low,A}{\left(\mathbf{r}\right)}\right).\end{split}
\end{equation*}
with which we can construct the high-level Hamiltonian.

\end{enumerate}

Although block orthogonalisation is found to work when just the density
kernel is being optimised, it does not do so generally for the
optimisation of the NGWFs. Because of this, there is an option to
optimise the NGWFs at the lower level of theory first (in all regions),
and then fix them for an optimisation of the kernel under EMFT.

If you would like to use hybrid functionals with embedding, there are
two things to bear in mind. Firstly, only hybrid-in-semi local DFT
calculations are currently supported \textendash{} hybrid-in-hybrid calculations are
not possible. Secondly, the species in the \sphinxcode{species\_swri-{[}swri name{]}}
block must match the species in the active region exactly. Anything else
will give incorrect results. Otherwise, the set-up of the hybrid
functional calculation is identical to a normal ONETEP calculation.

LR-TDDFT calculations can be performed with embedding
(TD-EMFT) {[}Ding2017-2{]}, and this is also implemented
within ONETEP {[}Prentice2022{]}. If you would like to
perform a TD-EMFT calculation, it may be advisable to restrict the
excitations to the active region, using the \sphinxcode{species\_tddft\_kernel}
block.

It is also possible to place the quantum embedding system within
implicit solvent, giving multi-level embedding
capability {[}Prentice2022{]}. This should work very
similarly to standard implicit solvent calculations, although there are
a couple of additional keywords (see below). The main difference is
whether the cavity is constructed using the density kernel optimised
solely at the low level of theory, or optimised using EMFT. This only
makes a difference if the active region is close to the edge of the
cavity.


\subsection{Keywords}
\label{\detokenize{EMFT_in_ONETEP:keywords}}\begin{itemize}
\item {} 
\sphinxcode{species\_ngwf\_regions} (block): This block defines which species
are in which region. Each line of the block corresponds to a distinct
region. The species within each region do not necessarily have to be
physically next to one another. If this block is not defined, it is
assumed that there is only one region, containing all the species in
the system.

\item {} 
\sphinxcode{do\_fandt} (logical): Controls whether a freeze-and-thaw (F+T)
optimisation of the NGWFs is performed or not. This is a cruder form
of embedding, where all regions are treated at the same level of
theory, but each region’s NGWFs are optimised in turn, with the
others frozen. Default \sphinxcode{F}.

\item {} 
\sphinxcode{freeze\_switch\_steps} (integer): How many NGWF CG optimisation
steps should be spent on each region before moving onto the next in a
F+T calculation. \sphinxcode{maxit\_ngwf\_cg} represents the total number of
NGWF optimisation steps across all regions. A value less than 0 means
that all NGWFs are optimised together i.e. no F+T takes place.
Default \sphinxcode{-1}.

\item {} 
\sphinxcode{use\_emft} (logical): Controls whether an EMFT calculation is
performed, as described above. Default \sphinxcode{F}.

\item {} 
\sphinxcode{active\_region} (integer): Defines which region is the active
region \textendash{} 1 means the species on the first line in the
\sphinxcode{species\_ngwf\_regions} block constitute the active region, 2 means
the second line, and so on. Default \sphinxcode{1}.

\item {} 
\sphinxcode{active\_xc\_functional} (string): Defines what functional is used as
the higher level of theory within EMFT. Default is the value of
\sphinxcode{xc\_functional} i.e. no difference between the regions.

\item {} 
\sphinxcode{freeze\_envir\_ngwfs} (logical): Controls whether the environment
NGWFs should ever be optimised or not. Default \sphinxcode{F}.

\item {} 
\sphinxcode{use\_emft\_follow} (logical): Controls whether the EMFT calculation
is only performed after a regular calculation, so the NGWFs are
optimised at the lower level of theory first, before applying EMFT.
Default \sphinxcode{F}.

\item {} 
\sphinxcode{use\_emft\_lnv\_only} (logical): Controls whether only the kernel is
optimised within EMFT, with the NGWFs optimised at the lower level of
theory and then fixed. Usually used in conjunction with
\sphinxcode{use\_emft\_follow}. Default \sphinxcode{F}.

\item {} 
\sphinxcode{emft\_lnv\_steps} (integer): Controls the number of LNV kernel
optimisation steps to be used in conjunction with
\sphinxcode{use\_emft\_lnv\_only}. Default \sphinxcode{10}.

\item {} 
\sphinxcode{block\_orthogonalise} (logical): Controls whether the environment
NGWFs are orthogonalised with respect to the active region NGWFs, as
described above. Default \sphinxcode{F}.

\item {} 
\sphinxcode{parallel\_scheme} (string): Defines the parallel scheme used for
the calculation. See Appendix for more information. Default \sphinxcode{NONE}.

\item {} 
\sphinxcode{read\_sub\_denskern} (logical): Controls whether only diagonal
blocks of the density kernel are read in when restarting. This is
useful for starting an embedding calculation from two separate
calculations on the individual regions, so you only have the diagonal
blocks of the density kernel. Default \sphinxcode{F}.

\item {} 
\sphinxcode{embed\_debug} (logical): Turns on verbose printing for debugging of
embedding functionalities. Default \sphinxcode{F}.

\item {} 
\sphinxcode{is\_restart\_vac\_from\_vac} (logical): Decides whether the vacuum
calculation in an autosolvation implicit solvent calculation should
be restarted from the vacuum\_ files or not. Useful for restarting
autosolvation calculations if they time-out or similar. Default
\sphinxcode{F}.

\item {} 
\sphinxcode{is\_emft\_cavity} (logical): Decides whether the cavity used in
implicit solvent calculations is determined using the low-level
density kernel (\sphinxcode{F}), or the EMFT-optimised density kernel (\sphinxcode{T}).
Default \sphinxcode{F}.

\end{itemize}

The most reliable way to run EMFT calculations is to have \sphinxcode{use\_emft},
\sphinxcode{use\_emft\_follow}, \sphinxcode{use\_emft\_lnv\_only} and \sphinxcode{block\_orthogonalise}
all set to \sphinxcode{T}. These can be set to \sphinxcode{F} (most sensibly in reverse
order i.e. \sphinxcode{block\_orthogonalise} first), but the calculation may
become more unstable, depending on the system, the regions chosen and
the functionals chosen.


\subsection{Example input file}
\label{\detokenize{EMFT_in_ONETEP:example-input-file}}
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
!====================================================!
! Input for calculation with the ONETEP program      !
!                                                    !
! O2 and H2 form the embedded system to be treated   !
! at the higher level of theory, O1 and H1 are the   !
! environment treated at the low\PYGZhy{}level.              !
!====================================================!

\PYGZpc{}block species\PYGZus{}ngwf\PYGZus{}regions
O2 H2
O1 H1
\PYGZpc{}endblock species\PYGZus{}ngwf\PYGZus{}regions

task: SINGLEPOINT
cutoff\PYGZus{}energy 1000 eV
write\PYGZus{}forces: T
xc\PYGZus{}functional: LDA
active\PYGZus{}xc\PYGZus{}functional: PBE

use\PYGZus{}emft: T
use\PYGZus{}emft\PYGZus{}follow: T
use\PYGZus{}emft\PYGZus{}lnv\PYGZus{}only: T
block\PYGZus{}orthogonalise : T
parallel\PYGZus{}scheme: HOUSE

\PYGZpc{}block species\PYGZus{}atomic\PYGZus{}set
H1 \PYGZdq{}SOLVE\PYGZdq{}
O1 \PYGZdq{}SOLVE\PYGZdq{}
H2 \PYGZdq{}SOLVE\PYGZdq{}
O2 \PYGZdq{}SOLVE\PYGZdq{}
\PYGZpc{}endblock species\PYGZus{}atomic\PYGZus{}set

\PYGZpc{}block species
H1 H 1 1 7.0
O1 O 8 4 7.0
H2 H 1 1 7.0
O2 O 8 4 7.0
\PYGZpc{}endblock species

\PYGZpc{}block species\PYGZus{}pot
H1 \PYGZdq{}pseudo/hydrogen.recpot\PYGZdq{}
O1 \PYGZdq{}pseudo/oxygen.recpot\PYGZdq{}
H2 \PYGZdq{}pseudo/hydrogen.recpot\PYGZdq{}
O2 \PYGZdq{}pseudo/oxygen.recpot\PYGZdq{}
\PYGZpc{}endblock species\PYGZus{}pot

\PYGZpc{}block lattice\PYGZus{}cart
     30.000000000       0.000000000       0.000000000
      0.000000000      30.000000000       0.000000000
      0.000000000       0.000000000      30.000000000
\PYGZpc{}endblock lattice\PYGZus{}cart

\PYGZpc{}block positions\PYGZus{}abs
O1       16.203224001     15.100000000     11.536063353
H1       15.100000000     15.100000000     10.100000000
H1       15.100000000     15.100000000     12.991451046
O2       12.600158789     15.100000000     17.306583960
H2       13.051873252     13.656398529     18.308114239
H2       13.051873252     16.543601471     18.308114239
\PYGZpc{}endblock positions\PYGZus{}abs
\end{sphinxVerbatim}


\subsection{Interaction with other functionalities}
\label{\detokenize{EMFT_in_ONETEP:interaction-with-other-functionalities}}

\subsubsection{Fully tested}
\label{\detokenize{EMFT_in_ONETEP:fully-tested}}\begin{itemize}
\item {} 
Energy and forces calculations

\item {} 
Hybrid-in-semi local DFT

\item {} 
Restarting calculations

\item {} 
LR-TDDFT

\item {} 
Implicit solvent

\end{itemize}


\subsubsection{Should work, not thoroughly tested}
\label{\detokenize{EMFT_in_ONETEP:should-work-not-thoroughly-tested}}\begin{itemize}
\item {} 
Geometry optimisation

\item {} 
Finite displacement phonons

\item {} 
Molecular dynamics

\item {} 
Conduction NGWF optimisation

\item {} 
Ensemble DFT

\item {} 
Kernel DIIS

\item {} 
QNTO

\item {} 
NAO

\item {} 
Cutoff Coulomb

\item {} 
Spin polarised calculations

\item {} 
Some properties calculations (eigenstates, Mulliken charges,
plotting, DoS)

\end{itemize}


\subsubsection{Not compatible with embedding}
\label{\detokenize{EMFT_in_ONETEP:not-compatible-with-embedding}}\begin{itemize}
\item {} 
Hubbard calculations

\item {} 
DMFT

\item {} 
PAW

\item {} 
cDFT

\item {} 
Bandstructure calculations

\item {} 
DMA

\item {} 
EDA

\item {} 
Electronic transport

\item {} 
Hybrid-in-hybrid DFT

\item {} 
NEB

\item {} 
EELS

\item {} 
Polarisable embedding

\item {} 
Transition state searching

\item {} 
DDEC

\end{itemize}

Any functionalities missed above are likely to not work with embedding.


\subsection{Appendix: Parallel strategies with embedding}
\label{\detokenize{EMFT_in_ONETEP:appendix-parallel-strategies-with-embedding}}
In a normal ONETEP calculation, atoms are distributed across the
available MPI processes according to a ‘parallel strategy’. This
determines how resources such as matrix elements will be spread across
the MPI environment in order to reduce the communication between nodes
and maximise the efficiency of the calculation. Details on maximising
parallel efficiency are available via the ONETEP documentation and
website.

As part of the embedding infrastructure, each subsystem is given its own
parallel strategy. This contains all information relating to the
distribution of resources across the MPI nodes available to the
calculation, which are determined by the parameter \sphinxcode{PARALLEL\_SCHEME}.
There are three settings for the distribution of resources during an
embedding calculation:
\begin{itemize}
\item {} 
\sphinxcode{NONE}: All subsystems are treated completely independently, with
atoms distributed across all available processors as though the other
subsystems do not exist. The number of MPI processes cannot be
greater than the number of atoms in the smallest subsystem. For
example, if there are 8 processors available then each will hold
atoms and data from all subsystems, though the calculation will fail
if any subsystem has less than 8 atoms (or possibly slightly more if
the space-filling curve is in use). This is the default setting for
testing but is not recommended for practical calculations due to the
constraint on the number of processors.

\item {} 
\sphinxcode{SENATE}: Nodes are partitioned evenly between all subsystems. For
example, if there are 8 processors and 2 subsystems, then each will
be allocated 4 processors, regardless of the number of atoms in each
subsystem. Unlike the \sphinxcode{NONE} setting, there is no upper bound on
the number of processors which may be used, so user discretion is
advised.

\item {} 
\sphinxcode{HOUSE}: Divides the processors proportionally between all
subsystems, with a minimum of 1 processor per subsystem. For example,
if we have two subsystems consisting of 15 and 5 atoms each, then
with 8 processors each subsystem will be allocated 6 and 2 nodes
respectively. At a minimum all subsystems are granted 1 processor —
if we had two subsystems with 1 and 100 atoms in our 8 processor
example, then they will receive 1 and 7 processor respectively. Like
\sphinxcode{SENATE}, there is no upper bound on the number of processors that
can be allocated and finding a sensible setting is left to the user.

\end{itemize}

\sphinxcode{HOUSE} is the recommended setting for running calculations, the
others are mainly of use for testing. Since they should all produce the
same results, any significant differences may be a sign of an underlying
problem, so comparing them is a useful consistency check.

{[}Ding2017-2{]} F. Ding, T. Tsuchiya, F. R. Manby and T. F. Miller, \sphinxstyleemphasis{J. Chem. Theory Comput.}, \sphinxstylestrong{13}, 4216\textendash{}4227, (2017).

{[}Prentice2020{]} J. C. A. Prentice, R. J. Charlton, A. A. Mostofi and P. D. Haynes, \sphinxstyleemphasis{J. Chem. Theory Comput.}, \sphinxstylestrong{16}, 354\textendash{}365, (2020).

{[}Prentice2022{]} J. C. A. Prentice, \sphinxstyleemphasis{J. Chem. Theory Comput.}, \sphinxstylestrong{18}, 1542-1554 (2022).

{[}Huang2008{]} P. Huang and E. M. Carter, \sphinxstyleemphasis{Annu. Rev. Phys. Chem.}, \sphinxstylestrong{59}, 261\textendash{}290, (2008).

{[}Gomes2012{]} A. S. P. Gomes and C. R. Jacob, \sphinxstyleemphasis{Annu. Rep. Prog. Chem., Sect. C: Phys. Chem.}, \sphinxstylestrong{108}, 222\textendash{}277, (2012).

{[}Fornace2015{]} M. E. Fornace, J. Lee, M. Kaito, F. R. Manby, T. F. Miller, \sphinxstyleemphasis{J. Chem. Theory Comput.}, \sphinxstylestrong{11}, 568\textendash{}580, (2015).

{[}Ding2017{]} F. Ding, F. R. Manby and T. F. Miller, \sphinxstyleemphasis{J. Chem. Theory Comput.}, \sphinxstylestrong{13}, 1605\textendash{}1615, (2017).


\chapter{Correlation and Constrained DFT}
\label{\detokenize{index_correlation_constrained::doc}}\label{\detokenize{index_correlation_constrained:correlation-and-constrained-dft}}

\section{DFT+\protect\(U\protect\)(+\protect\(J\protect\))}
\label{\detokenize{ONETEP_DFT+U_README:dft}}\label{\detokenize{ONETEP_DFT+U_README::doc}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
David D. O’Regan, Trinity College Dublin

\item[{Date}] \leavevmode
July 2015

\end{description}\end{quote}

DFT+\(U\) is fully and self-consistently implemented in ONETEP,
together with a number of advanced ancillary functionalities. The method
is linear-scaling with respect to system size, exhibiting no systematic
tendency to slow convergence to the ground-state. DFT+\(U\) in its
conventional fixed-projector form introduces only a small increase in
computational pre-factor with respect to the underlying
exchange-correlation functional {[}O-Regan2012{]}.

\sphinxstylestrong{PLEASE NOTE: Seven columns are now required in the Hubbard block in
order to allow for} \(+J\) \sphinxstylestrong{calculations. Older input files with six
columns will not yield incorrect results, but the code will exit.}


\subsection{A very short introduction to DFT+\protect\(U\protect\)}
\label{\detokenize{ONETEP_DFT+U_README:a-very-short-introduction-to-dft}}
DFT+\(U\) {[}Anisimov1991{]}, {[}Anisimov1997{]}, {[}Dudarev1998{]}, also
known as LDA+\(U\) or LSDA+\(U\), is a method used to
improve the description of so-called strongly correlated materials
offered by DFT within conventional approximations for
exchange-correlation (XC) such as the LSDA and \(\sigma\)-GGA,
quantitatively and even qualitatively. These functionals, based on the
locally-evaluated density and its gradients, can sometimes fail to
reproduce the physics associated with localised orbitals of \(3d\)
and \(4f\) character characteristic of conventionally-classed
strongly correlated materials, a category consisting of not only
first-row transition metals and their oxides, but also lanthanoid oxide
materials, and other materials such as certain magnetic semiconductors
and organometallic molecules.

Typically, the LDA and its extensions underestimate local magnetic
moments and the tendency to favour high-spin ground-states in such
materials, and the insulating gap in cases where it is related to
electron localisation. Underestimation of the gap due to the absence, in
the LDA, of the derivative discontinuity with respect to orbital
occupancy in the exact XC-funtional may be confounded by an
underestimation of the exchange splitting induced by local magnetic
moments.

The DFT+U correction term is usually thought of as an explicit
mean-field treatment of the exchange-correlation energy contributed by
the correlated sites (subspaces projected out with functions of
\(3d\) and or \(4f\) character) within the Hubbard model,
including a double-counting correction for that contribution already
included in the LDA term. The flavour implemented in ONETEP is the
basis-set independent, rotationally invariant quadratic penalty
functional of Ref {[}Cococcioni2005{]}, defined by the
additive energy correction
\begin{equation*}
\begin{split}E_{DFT+U} \left[ n^{(I) (\sigma)} \right] =  \sum_{I \sigma} \frac{U^{(I)}}{2} \rm{Tr}
\left[  n^{(I) (\sigma)} \left( 1 -  n^{(I) (\sigma)} \right)\right].\end{split}
\end{equation*}
Here, \(U\) is an estimate of the scalar screened density-density
Coulomb repulsion between localised orbitals. The occupancy matrix of
the correlated site \(I\), for spin channel \(\sigma\), is
defined, in the case of orthonormal projector functions \(\lbrace \lvert \varphi^{(I)}_m \rangle \rbrace\), and density-matrix
\(\hat{\rho}^{(\sigma)}\), by
\begin{equation*}
\begin{split}n^{(I)(\sigma)}_{m m'} = \langle \varphi_m^{(I)} \rvert \hat{\rho}^{(\sigma)}
\lvert \varphi_{m'}^{(\sigma)} \rangle.\end{split}
\end{equation*}
Put simply, if the system under study comprises open \(3d\) or
\(4f\) sub-shells, then there is a good chance that the LDA will
find a minimum energy by partly occupying and leaving degenerate the
Kohn-Sham orbitals strongly overlapping with these states, rather than
splitting them into occupied and virtual Hubbard bands. This leads to an
underestimation of the insulating gap and any associated magnetic order.
In this case, the DFT+\(U\) method can be used to penalise the
non-integer occupancy of these orbitals, tending to fill states with
occupancy greater than \(0.5\) and empty states with occupancy less
than \(0.5\), as can be seen from the expression for the
DFT+\(U\) potential
\begin{equation*}
\begin{split}\hat{V}^{(\sigma)}_{DFT+U} = \sum_{I}  U^{(I)}
 \lvert \varphi_m^{(I)} \rangle
\left( \frac{1}{2} \delta_{m m'} - n^{(I) (\sigma)}_{m m'} \right)  \langle
\varphi_{m'}^{(I)} \rvert .\end{split}
\end{equation*}
The DFT+\(U\) term may be considered as a correction which cancels
the contribution to the energy arising due to the spurious
self-interaction of a partially occupied
orbital {[}Cococcioni2005{]}. In this case, the \(U\)
parameter is the curvature of the total energy with respect to the
occupancy of the correlated manifold - which should be a piece-wise
linear curve were Janak’s theorem satisfied {[}Janak1978{]} \textendash{}
which can be computed using linear-response theory (among other methods
such as constrained DFT) according to the prescription given in
Refs. {[}Cococcioni2005{]}, {[}Kulik2006{]}.


\subsection{How to activate DFT+\protect\(U\protect\) in ONETEP}
\label{\detokenize{ONETEP_DFT+U_README:how-to-activate-dft-in-onetep}}
In order to activate the DFT+\(U\) functionality, the \sphinxstylestrong{hubbard}
block is added to the input file. For example, in the case of a system
containing iron and cerium atoms incorrectly described by the
exchange-correlation functional, which we suspect could benefit from the
DFT+\(U\) correction to improve the description of localisation,
we might use the \sphinxcode{hubbard} block:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}} \PYG{n}{block} \PYG{n}{hubbard}
  \PYG{n}{Fe1}   \PYG{l+m+mi}{2}   \PYG{l+m+mf}{4.0}   \PYG{l+m+mf}{0.0}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{10.0}   \PYG{l+m+mf}{0.00}   \PYG{l+m+mf}{1.0}
  \PYG{n}{Fe2}   \PYG{l+m+mi}{2}   \PYG{l+m+mf}{4.0}   \PYG{l+m+mf}{0.0}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{10.0}   \PYG{l+m+mf}{0.00}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.0}
  \PYG{n}{Ce1}   \PYG{l+m+mi}{3}   \PYG{l+m+mf}{6.0}   \PYG{l+m+mf}{0.0}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{10.0}   \PYG{l+m+mf}{0.50}   \PYG{l+m+mf}{0.0}
\PYG{o}{\PYGZpc{}} \PYG{n}{endblock} \PYG{n}{hubbard}
\end{sphinxVerbatim}

The columns of the \sphinxcode{hubbard} block are described as follows:
\begin{enumerate}
\item {} 
The species label, e.g. \(Fe1\) for iron atoms of a first type in
the cell, \(Fe2\) for iron atoms of a second kind, etc. Only the
species to which orbitals to be corrected by DFT+\(U\) are
assigned should be listed in this block.

\item {} 
The angular momentum channel of the projectors used to delineate the
strongly correlated sites on Hubbard atoms this type, e.g.
\(l=2\) for \(Fe1\). Conventionally, the radial quantum
number \(r=l+1\) is used to generate atom-centred atomic
projectors, so that \(l=2\) gives \(3d\) orbitals,
\(l=3\) gives \(4f\) orbitals etc. (please get in contact if
you need to use a \(r \ne l+1\) combination, or multiple
sub-shells per atom).

\item {} 
The value of the Hubbard \(U\) for this sub-shell, in
electron-volts. Most users will simply work with the value for
\(U\) that they find corrects the band-gap or bond-lengths in the
system they wish to study. Methods do, however, exist to estimate its
value, for example the linear-response technique
{[}Cococcioni2005{]}, {[}Kulik2006{]}, which is implemented in
ONETEP.

\item {} 
The value of the Hund’s exchange \(J\) for this sub-shell, in
electron-volts. The rotationally invariant exchange corrective term
described in detail in Ref. {[}Himmetoglu2011{]} is fully
implemented in ONETEP (including forces etc), and activated for any
\(J \ne 0\).

\item {} 
This number \(Z\) selects how the radial part of the projector
functions used to describe the \(1s\), \(2p\), \(3d\) or
\(4f\) atomic orbitals entering the DFT+\(U\) functional
are defined. In the case that \(\mathbf{ Z < 0}\), a subset of
the orbitals generated by solving the atomic problem subject to the
pseudopotential for the species in question are chosen (in which case
the projectors form a subset of the initial guesses for the ONETEP
NGWFs); here the magnitude of the negative Z makes no difference. In
the case that \(\mathbf{ Z > 0}\), for more advanced users, this
number is the effective charge divided by the ratio of effective
masses used to generate projectors in the form of solutions to the
hydrogenic Schrödinger equation. A good guess for this number might
be the Clementi-Raimondi effective charge, tabulated in
Refs. {[}Clementi1963{]}, {[}Clementi1967{]}, and the choice of
radial profile does matter {[}O-Regan2010{]}. In both
cases, the projectors are effectively renormalised within an
atom-centred sphere with the same radius as the NGWFs on that atom.

\item {} 
An additional potential acting on the subspace in question, the
prefactor \(\alpha\) is here entered in electron-volts. This is
needed, for example, in order to locally vary the potential in order
to determine the value of \(U\) which is consistent with the
screened response in the system with linear-response
theory {[}Cococcioni2005{]}, {[}Kulik2006{]}, or to break a
spatial symmetry, such as in a mixed-valence system. In the example
given, we are additionally penalising the occupancy on cerium
\(4f\) atomic orbitals.

\item {} 
The spin-splitting factor, in electron-volts, which is deducted from
the \(\alpha\) factor for the spin-up channel and added to
\(\alpha\) for the spin-down channel. In the example shown here
we’re promoting spin-up magnetisation for iron atoms \(Fe1\), and
spin-down for \(Fe2\). This can be very useful for appropriately
breaking magnetic symmetries in antiferromagnetic solids or
open-shell singlet molecules, or for estimating the magnetic
susceptibility or exchange coupling.

\sphinxstylestrong{N.B.} Users may find the DFT+\(U\) functionality useful in
cases of systems even when the DFT+\(U\) correction is not
needed (setting the all \(U\) parameters to zero does not disable
the functionality). The implementation offers a very inexpensive
method for carrying out carefully-defined atom-centred atomic
population analysis, or breaking symmetries in spin or charge ordered
systems.

\end{enumerate}


\subsection{Compatibility}
\label{\detokenize{ONETEP_DFT+U_README:compatibility}}
The DFT+\(U\) functionality is fully compatible with almost all
other parts of the ONETEP code, such as listed below, since it simply
involves an additional term in the Hamiltonian and ionic forces. Please
get in touch first if you would like to use a more exotic combination of
these functionalities:
\begin{enumerate}
\item {} 
Total-energy minimisation and ionic forces

\item {} 
Geometry optimisation, molecular dynamics and phonon calculations

\item {} 
All other functionals including hybrids and Van der Waals functionals

\item {} 
Implicit solvation

\item {} 
The PAW formalism and ultrasoft pseudopotentials

\item {} 
Constrained DFT

\item {} 
Local density of states (including a correlated subspace
decomposition)

\item {} 
Natural bond orbital calculations

\item {} 
Conduction-band optimisation and Fermi’s Golden Rule spectra

\item {} 
Calculations of changes in electric polarisation

\item {} 
Time-dependent DFT

\item {} 
Electronic transmission calculations

\end{enumerate}

The extension of the DFT+\(U\) implementation to cluster Dynamical
mean-field theory has also been implemented in ONETEP; for an example of
its capabilities see Ref. {[}Weber2012{]}.


\subsection{Using NGWFs and projector self-consistency}
\label{\detokenize{ONETEP_DFT+U_README:using-ngwfs-and-projector-self-consistency}}
Any reasonable set of localised atomic-like functions may, in principle,
be used for the projectors defining the correlated subspaces in
DFT+\(U\); the choice is somewhat arbitrary and the description
“atomic orbitals” does not uniquely define them. One possible approach
is to use Wannier functions for the Kohn-Sham orbitals, so that the
correlated subspaces are proper subspaces of the Kohn-Sham Hilbert
space. Indeed, there is numerical evidence to suggest that Maximally
Localised Wannier Functions (MLWFs) {[}Marzari1997{]}, {[}Souza2001{]},
in particular, provide a basis that maximises a particular measure of
the on-site Coulomb repulsion {[}Miyake2008{]}, and MLWFs are
in common use as a minimal basis with which to construct tight-binding
models from first-principles.

In ONETEP, a set of variationally-optimised nonorthogonal generalised
Wannier functions (NGWFs) are generated as a by-product of total-energy
minimisation. NGWFs exhibit some similar properties to MLWFs and other
flavours of localised Wannier functions, and, for example, can be used
to calculate finite-difference response properties in a similar
way {[}O-Regan2012-2{]}. As they are conveniently available in
ONETEP, we have made it possible to re-use the NGWFs from the end of a
ground-state calculation as a set of Hubbard projectors with which to
define the DFT+\(U\) correction. For this, it was necessary to
develop a tensorially-consistent formulation of DFT+\(U\) in order
to accommodate nonorthogonal projector
functions {[}O-Regan2011{]}; projector nonorthogonality
for a given subspace is automatically compensated for.

In order to ensure that NGWFs with appropriate symmetry are chosen as
Hubbard projectors for a given atom, those \(n\) NGWFs
\(\lvert \phi_\alpha \rangle\) that maximise \(\sum^n_{m,\alpha }\langle \varphi_m  \rvert  \phi^\alpha \rangle \langle \phi_\alpha \rvert \varphi_m \rangle\), for a given set of
\(n\) hydrogenic orbitals \(\lvert \varphi_m \rangle\), defined
in the \sphinxcode{hubbard} block, are selected for the task. The keyword
\sphinxcode{hubbard\_max\_iter}, (defaulting to \(0\)), sets the task to
\sphinxcode{HUBBARDSCF}, which performs a self-consistency cycle over the Hubbard
projectors, demonstrated in
Refs. {[}O-Regan2010{]}, {[}O-Regan2011{]}. The density from one
minimisation is re-used at the beginning of the next, and setting
\sphinxcode{hubbard\_max\_iter} to \(2\) one can carry out a DFT+\(U\)
calculation using the LDA NGWFs as projectors.

The keywords \sphinxcode{hubbard\_energy\_tol}, \sphinxcode{hubbard\_conv\_win}, and
\sphinxcode{hubbard\_proj\_mixing} are used to manage the Hubbard projector
self-consistency cycle. For convergence, the ground state energy must
deviate less than \sphinxcode{hubbard\_energy\_tol} (defaulting to
\(10^{-8}Ha\)) from one \sphinxcode{HUBBARDSCF} iteration to the next, over
\sphinxcode{hubbard\_conv\_win} (defaulting to \(2\)) iterations. A fraction
\sphinxcode{hubbard\_proj\_mixing} (defaulting to \(0.0\)) of the previous
Hubbard projectors may be mixed with the new ones in order to accelerate
the procedure, although this has never been found to be necessary.
Setting \sphinxcode{hubbard\_proj\_mixing} to a negative value causes the
projectors to be read in from a \sphinxcode{.tightbox\_hub\_projs} file, for
restarting a \sphinxcode{HUBBARDSCF} calculation or for a variety of
post-processing tasks.

{[}O-Regan2012{]} D. D. O’Regan, N. D. M. Hine, M. C. Payne and A. A. Mostofi, Phys. Rev. B \sphinxstylestrong{85}, 085107 (2012).

{[}Anisimov1991{]} J. Z. V. I. Anisimov and O. K. Andersen, Phys. Rev. B \sphinxstylestrong{44}, 943 (1991).

{[}Anisimov1997{]} V. I. Anisimov, F. Aryasetiawan, and A. I. Liechtenstein, J. Phys.: Condens. Matter \sphinxstylestrong{9}, 767 (1997).

{[}Dudarev1998{]} S. L. Dudarev, Phys. Rev. B \sphinxstylestrong{57}, 3 (1998).

{[}Cococcioni2005{]} M. Cococcioni and S. de Gironcoli, Phys. Rev. B \sphinxstylestrong{71}, 035105 (2005).

{[}Janak1978{]} J. F. Janak, Phys. Rev. B \sphinxstylestrong{18}, 12 (1978).

{[}Kulik2006{]} H. J. Kulik, M. Cococcioni, D. A. Scherlis and N. Marzari, Phys. Rev. Lett. \sphinxstylestrong{97}, 103001 (2006).

{[}Himmetoglu2011{]} B. Himmetoglu, R. M. Wentzcovitch, and M. Cococcioni, Phys. Rev. B,\sphinxstylestrong{84}, 115108 (2011).

{[}Clementi1963{]} E. Clementi and D.L. Raimondi, J. Chem. Phys. \sphinxstylestrong{38}, 2686 (1963).

{[}Clementi1967{]} E. Clementi, D.L. Raimondi, and W.P. Reinhardt, J. Chem. Phys. \sphinxstylestrong{47}, 1300 (1967).

{[}O-Regan2010{]} D. D. O’Regan, N. D. M. Hine, M. C. Payne and A. A. Mostofi, Phys. Rev. B \sphinxstylestrong{82}, 081102 (2010).

{[}Weber2012{]} C. Weber, D. D. O’Regan, N. D. M. Hine, M. C. Payne, G. Kotliar and P. B. Littlewood, Phys. Rev. Lett. \sphinxstylestrong{108}, 256402 (2012).

{[}Marzari1997{]} N. Marzari and D. Vanderbilt, Phys. Rev. B \sphinxstylestrong{56}, 12847 (1997).

{[}Souza2001{]} I. Souza, N. Marzari and D. Vanderbilt, Phys. Rev. B \sphinxstylestrong{65}, 035109 (2001).

{[}Miyake2008{]} T. Miyake and F. Aryasetiawan, Phys. Rev. B \sphinxstylestrong{77}, 085122 (2008).

{[}O-Regan2012-2{]} D. D. O’Regan, M. C. Payne, and A. A. Mostofi, Phys. Rev. B \sphinxstylestrong{85}, 193101 (2012).

{[}O-Regan2011{]} D. D. O’Regan, M. C. Payne and A. A. Mostofi, Phys. Rev. B \sphinxstylestrong{83}, 245124 (2011).


\section{Constrained Density Functional Theory (cDFT)}
\label{\detokenize{cDFT::doc}}\label{\detokenize{cDFT:constrained-density-functional-theory-cdft}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Gilberto Teobaldi, University of Liverpool (\sphinxhref{mailto:g.teobaldi@liv.ac.uk}{g.teobaldi@liv.ac.uk})

\item[{Date}] \leavevmode
November 2013

\end{description}\end{quote}


\subsection{cDFT input check-list}
\label{\detokenize{cDFT:cdft-input-check-list}}
This is a short check-list meant to help the setting up of a
constrained-DFT (cDFT) simulation. ONETEP implements some rather
extensive check of the input (as specified in .dat file). In spite of
this, users may be still capable of creating erroneous inputs which I
could not think of. If you experience disaster (commutators larger than
1.E-3, NWGFs- and cDFT-optimisation stuck at the same value of the
gradient for many iterations, or NaN (Not A Number) and ‘***’ outputs
from ONETEP), please do get in touch.


\subsubsection{Can I start by running a cDFT geometry-optimisation and/or Molecular Dynamics straightaway?}
\label{\detokenize{cDFT:can-i-start-by-running-a-cdft-geometry-optimisation-and-or-molecular-dynamics-straightaway}}
Currently, this is \sphinxstylestrong{not} possible. ONETEP will not allow you to run a
geometry-optimisation/molecular dynamics simulation unless a .cdft file
(containing the cDFT-potentials, Uq/s) is present. This is meant to
force you to first make sure that your cDFT-settings let you obtain a
good convergence in a single-point calculation for the system and
constrained solution you are interested in.


\subsubsection{What projectors am I telling ONETEP to use?}
\label{\detokenize{cDFT:what-projectors-am-i-telling-onetep-to-use}}
Is cdft\_read\_projector=F (this is the default) and cdft\_multi\_proj=F
(this is the default) in your input?

If so, you will be using as cDFT-projectors the orbitals, of angular
momentum \sphinxstyleemphasis{L-projectors}, of a hydrogenic atom of atomic number
\sphinxstyleemphasis{Z-projector}, provided \sphinxstyleemphasis{Z-projector} is positive in the \%block
constrained\_dft (Z\textgreater{}0). Conversely, if you have entered a negative
\sphinxstyleemphasis{Z-projector} value in the \%block constrained\_dft (Z\textless{}0), you will be
using the numerical orbital (of angular momentum \sphinxstyleemphasis{L-projectors}) for the
given cDFT-atom as cDFT-projectors.

Is cdft\_multi\_proj=T (this is NOT the default) in your input?

If so, you will be using as cDFT-projectors the numerical orbitals,
obtained from the pseudo-atom solver. You will be using as many
cDFT-projectors as NGWFs for the given cDFT-site. Thus, to know the
number and angular momentum of your cDFT-projectors, you need to refer
to the specific settings of the cDFT-site in the \%block
species\_atom\_set and the relevant output in the standard .out file.

Is cdft\_read\_projector=T in your input?

If so, you will use the projectors stored in the .tightbox\_hub\_projs
file (or experience a crash if this file is not present). Mind that the
file will contain different classes of projectors (hydrogenic orbitals,
numerical orbitals, self-consistent projectors) depending on the
settings you used for the cDFT-run which generated the
.tightbox\_hub\_projs file. This means that, unless one wants to
experience a crash, the projectors in the .tightbox\_hub\_projs file
should have been generated with the same entries for \sphinxstyleemphasis{Z-projector} \sphinxstyleemphasis{and
L-projector} in \%block constrained\_dft \sphinxstylestrong{OR} cdft\_multi\_proj and
\%block species\_atom\_set as in the current calculation.


\subsubsection{Is this the first single-point cDFT submission or do I want to restart a single-point calculation?}
\label{\detokenize{cDFT:is-this-the-first-single-point-cdft-submission-or-do-i-want-to-restart-a-single-point-calculation}}
For submission from scratch the user can chose between starting the
cDFT-run from previously obtained DFT-NGWFs and Density Kernel (DKN), by
setting (read\_denskern=T and read\_tightbox\_ngwfs=T), \sphinxstylestrong{or not}
(read\_denskern=F and read\_tightbox\_ngwfs=F).

\sphinxstylestrong{To restart a cDFT}-single point run (from the latest Uq/s-potentials)
or to run cDFT-geometry optimisations/Molecular Dynamics it is necessary
to activate cdft\_continuation=T. \sphinxstylestrong{Mind} that if, instead of
hydrogenic or numerical orbitals as cDFT-projectors (see above) one
wants to use/keep using pre-optimised projectors (stored in
.tightbox\_hub\_projs file) it is necessary to activate also
cdft\_read\_projector=T in a restart.


\subsubsection{Are the columns of the \%block constrained\_dft requesting the right targets for the given cDFT-flavour?}
\label{\detokenize{cDFT:are-the-columns-of-the-block-constrained-dft-requesting-the-right-targets-for-the-given-cdft-flavour}}
\sphinxstylestrong{MIND} that, as explained in the description of the keywords,
different columns of the \%block constrained\_dft are used depending on
the selected cDFT-modes (cdft\_atom\_charge, cdft\_atom\_spin,
cdft\_group\_charge/spin\_acceptor/donor,
cdft\_group\_charge/spin\_diff). Are you requesting the right targets in
terms of atomic-population, group-populations, atomic magnetic-moments
and group magnetic-moments?

Mind also that the cdft\_group\_charge/spin\_acceptor/donor,
cdft\_group\_charge/spin\_diff cDFT-modes require that targeted
population, magnetic-moment and differences are entered explicitly with
the corresponding \_TARGET keyword. If you have forgotten entering the
relevant \_TARGET keyword in your input, the simulation will stop and
ONETEP will tell you about it.


\subsubsection{Have I set CDFT\_GROUP\_CHARGE\_UP/DOWN\_ONLY=T?}
\label{\detokenize{cDFT:have-i-set-cdft-group-charge-up-down-only-t}}
Remember that, for CDFT\_GROUP\_CHARGE\_UP/DOWN\_ONLY=T, only the
corresponding spin-channel will be constrained in
cdft\_group\_charge\_acceptor/donor and cdft\_group\_charge\_diff runs.
Accordingly, you should target populations for one-spin channel only
(\sphinxstylestrong{not} for the UP+DOWN channels).


\subsubsection{Is the sign of U$_{\text{q/s}}$ correct for the group\_charge/spin\_acceptor/donor/diff run?}
\label{\detokenize{cDFT:is-the-sign-of-uq-s-correct-for-the-group-charge-spin-acceptor-donor-diff-run}}
Remember that atoms in acceptor- and donor-group are identified by mean
of the sign of the Uq/s in the \%block constrained\_dft. Thus,
\sphinxstylestrong{acceptor-group atoms} need to be assigned negative (e-attractive)
U$_{\text{q/s}}$ (\sphinxstylestrong{U:sub:{}`q/s{}`\textless{}0}), whereas \sphinxstylestrong{donor-group atoms}
need to be assigned positive (e-repulsive) U$_{\text{q/s}}$
(\sphinxstylestrong{U:sub:{}`q/s{}`\textgreater{}0}).


\subsubsection{Are my constraints compatible with the spin (=N$_{\text{UP}}$-N$_{\text{DOWN}}$) keyword in the input (.dat) file?}
\label{\detokenize{cDFT:are-my-constraints-compatible-with-the-spin-nup-ndown-keyword-in-the-input-dat-file}}
Remember that ONETEP optimises the Density Kernel keeping the number of
UP (N$_{\text{UP}}$) and DOWN (N$_{\text{DOWN}}$) electrons fixed. As a result,
the net magnetization of the system (N$_{\text{UP}}$-N$_{\text{DOWN}}$) is also
fixed. Have you introduced any incongruence between the spin=0,1,2,etc
keyword and the cDFT-ones in your input? If your targeted cDFT-solution
results in a high-value (i.e. \textgreater{} 0 \(\mu\)$_{\text{B}}$) magnetization of the
\sphinxstylestrong{total} system, the spin keyword should reflect it.


\subsubsection{What values of min/maxit\_lnv, maxit\_ngwf\_cg and maxit\_cdft\_u\_cg should I use?}
\label{\detokenize{cDFT:what-values-of-min-maxit-lnv-maxit-ngwf-cg-and-maxit-cdft-u-cg-should-i-use}}
Based on the tests run so far, and considering that the cDFT-potentials
(Uq/s) are iteratively optimised at each (1:sup:\sphinxtitleref{st}) step of the
NGWFs-optimisation line-search, the following choices seem to be
reasonable:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{maxit\PYGZus{}palser\PYGZus{}mano} \PYG{p}{:} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}
\PYG{n}{kerfix} \PYG{p}{:} \PYG{l+m+mi}{2}
\PYG{n}{maxit\PYGZus{}pen} \PYG{p}{:} \PYG{l+m+mi}{0}
\PYG{n}{minit\PYGZus{}lnv} \PYG{p}{:} \PYG{l+m+mi}{5}
\PYG{n}{maxit\PYGZus{}lnv} \PYG{p}{:} \PYG{l+m+mi}{10}
\PYG{n}{maxit\PYGZus{}ngwf\PYGZus{}cg} \PYG{p}{:} \PYG{l+m+mi}{60}
\PYG{n}{lnv\PYGZus{}check\PYGZus{}trial\PYGZus{}steps} \PYG{p}{:} \PYG{n}{T}
\PYG{n}{lnv\PYGZus{}threshold\PYGZus{}orig} \PYG{p}{:} \PYG{l+m+mf}{1.0e\PYGZhy{}10}
\PYG{n}{maxit\PYGZus{}cdft\PYGZus{}u\PYGZus{}cg} \PYG{p}{:} \PYG{l+m+mi}{5}
\end{sphinxVerbatim}

Increasing maxit\_cdft\_u\_cg above 5 is hardly going to accelerate the
convergence of the cDFT-run (the NGWFs will change at the following step
of NGWFs-optimisation), decreasing minit\_lnv below 5 might be risky.


\subsubsection{To what value should I initialise the cDFT-potentials (Uq/s)?}
\label{\detokenize{cDFT:to-what-value-should-i-initialise-the-cdft-potentials-uq-s}}
In the current implementation, unless cdft\_guru=T, in which case the
Uq/s entered in the \%block constrained\_dft will be used, the absolute
value of the Uq/s cDFT-potentials are internally initialised to 1 eV
(their original sign is, of course, maintained). For spin-excitation
\textbar{}Us\textbar{}=1eV may be too large, and initialising the \textbar{}Us\textbar{} with 0.1-0.3 eV
may accelerate convergence (this has been tested only on triplet
excitations in benzene dimers).


\subsubsection{What is the difference between a cdft\_atom\_charge run and a cdft\_group\_charge\_acceptor/donor one with one-atom group?}
\label{\detokenize{cDFT:what-is-the-difference-between-a-cdft-atom-charge-run-and-a-cdft-group-charge-acceptor-donor-one-with-one-atom-group}}
Whereas the cdft\_atom\_charge=T mode allows independent (i.e.
potentially different) constraining potentials to be applied to the UP
and DOWN spin-channels, for \sphinxstylestrong{one-atom}
cdft\_group\_charge\_acceptor/donor=T the same Uq will be applied to
both the UP and DOWN spin-channel. Activation of
cdft\_group\_charge\_up/down\_only=T in cdft\_group\_acceptor/donor
modes allows to optimise Uq for only a spin-channel, leaving the other
spin-channel unconstrained.


\subsubsection{Have I chosen a meaningful cdft\_cg\_max for the cDFT-mode I wish to use?}
\label{\detokenize{cDFT:have-i-chosen-a-meaningful-cdft-cg-max-for-the-cdft-mode-i-wish-to-use}}
For cDFT-runs with only one cDFT-group in the system
(cdft\_group\_charge/spin\_acceptor/donor modes) and
group\_charge/spin\_diff runs, \sphinxstylestrong{only one} cDFT-potential (Uq/s) will
be optimised in the cDFT-loop. Accordingly, for these cases it is
recommended to perform the cDFT-optimisation via a steepest descendent
algorithm (cdft\_cg\_max=1).


\subsubsection{How do I obtain the population of the cDFT-sites for a standard DFT-run?}
\label{\detokenize{cDFT:how-do-i-obtain-the-population-of-the-cdft-sites-for-a-standard-dft-run}}
Performing a single-point (task=singlepoint) fixed-Uq/s
(maxit\_cdft\_u\_cg=0) cDFT-run using very small (e.g. 1.E-60)
Uq/s-potentials in the \%block constrained\_dft and setting
output\_detail=VERBOSE will result in the cDFT-population of all the
cDFT-sites being printed in the standard output (.out) file. To obtain
atom-specific (instead of atomic\_species-specific) information on the
population of the cDFT-sites, it is necessary to set
CDFT\_PRINT\_ALL\_OCC=T.

\sphinxstylestrong{Mind.} The population of a given cDFT-site depends critically on the
projector used. Make sure you decide your cDFT-targets from the
DFT-populations obtained with the same set of projectors!


\subsubsection{How do I optimise self-consistently the projectors for a given geometry?}
\label{\detokenize{cDFT:how-do-i-optimise-self-consistently-the-projectors-for-a-given-geometry}}
In analogy with DFT+U simulations, self-consistent optimisation of the
cDFT-projectors (for a fixed geometry) is activated by setting
task=HUBBARDSCF in the .dat file. It is recommended to start the
task=HUBBARDSCF run from pre-optimised PAO-cDFT projectors (Z\textless{}0 in
\%block constrained\_dft), cDFT-potentials (Uq/s), NGWFs and DKN. This is
accomplished, regardless of the keywords specific to the chosen
cDFT-flavour, by making sure the input file (.dat) contains:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{task} \PYG{p}{:} \PYG{n}{HUBBARDSCF}
\PYG{n}{hubbard\PYGZus{}max\PYGZus{}iter} \PYG{p}{:} \PYG{l+m+mi}{40} \PYG{c+c1}{\PYGZsh{} perform 40 Hubbard\PYGZhy{}SCF iterations}
\PYG{n}{read\PYGZus{}denskern} \PYG{p}{:} \PYG{n}{T}
\PYG{n}{read\PYGZus{}tightbox\PYGZus{}ngwfs} \PYG{p}{:} \PYG{n}{T}
\PYG{n}{cdft\PYGZus{}read\PYGZus{}projectors} \PYG{p}{:} \PYG{n}{T}
\PYG{n}{cdft\PYGZus{}continuation} \PYG{p}{:} \PYG{n}{T}
\end{sphinxVerbatim}

The percentage of the latest-optimised cDFT-NGWFs to be used as new
cDFT-projectors is controlled by the hubbard\_proj\_mixing keyword {[}0 \textless{}
\textbar{}hubbard\_proj\_mixing\textbar{} \textless{} 1{]}, with hubbard\_proj\_mixing=1 meaning
that the latest optimised-NGWFs are used entirely as new
cDFT-projectors.

\sphinxstylestrong{Mind.} Provided cdft\_read\_projector=T, the cDFT-projectors in the
.tightbox\_hub\_projs file are used (entirely) as new projector during
the 1$^{\text{st}}$ HUBBARDSCF iteration.


\subsubsection{Is self-consistent optimisation of the cDFT-projectors at the DFT-geometry a good idea?}
\label{\detokenize{cDFT:is-self-consistent-optimisation-of-the-cdft-projectors-at-the-dft-geometry-a-good-idea}}
From the tests so far, this is \sphinxstylestrong{not a good idea}. For tightly
constrained systems (for instance an hypothetical
N$^{\text{(+)}}$=N$^{\text{(-)}}$ excitation) a cDFT task=HUBBARDSCF run at
the DFT-optimised geometry may result in very slow convergence. The
recommended procedure is to \sphinxstylestrong{first} optimise the cDFT-geometry using
numerical orbitals (PAO) as projectors (Z-projector \textless{}0 in \%block
constrained\_dft) and \sphinxstylestrong{then} optimise the cDFT-projectors at the
PAO-cDFT optimised geometry.


\subsection{cDFT Keywords}
\label{\detokenize{cDFT:cdft-keywords}}

\subsubsection{Intermediate Keywords}
\label{\detokenize{cDFT:intermediate-keywords}}
\sphinxstylestrong{CDFT\_ATOM\_CHARGE}

Syntax: CDFT\_ATOM\_CHARGE {[}Logical{]}

Description: Activate atom charge-constrained-DFT mode. This mode is
incompatible with any other cDFT-mode.

Default: False

Example: CDFT\_ATOM\_CHARGE T

\sphinxstylestrong{CDFT\_ATOM\_SPIN}

Syntax: CDFT\_ATOM\_SPIN {[}Logical{]}

Description: Activate atom magnetic-moment-constrained-DFT mode. This
mode is incompatible with any other cDFT-mode.

Default: False

Example: CDFT\_ATOM\_SPIN T

\sphinxstylestrong{CDFT\_CG\_MAX}

Syntax: CDFT\_CG\_MAX {[}Real{]}

Description: Specifies the maximum number of constraining potential
(Uq/s) conjugate gradient iterations between resets.

Default: Number of independent Uq/s for cdft\_guru=F

Example: CDFT\_CG\_MAX 1 \#Perform steepest descents optimisation

\sphinxstylestrong{CDFT\_CG\_MAX\_STEP}

Syntax: CDFT\_CG\_MAX\_STEP {[}Real{]}

Description: Maximum length of trial step for the constraining potential
(Uq/s) optimisation line search.

Default: 50.0

Example: CDFT\_CG\_MAX\_STEP 10.0

\sphinxstylestrong{CDFT\_CG\_THRESHOLD}

Syntax: CDFT\_CG\_THRESHOLD {[}Real{]}

Description: Specifies the convergence threshold for the RMS gradient of
the constraining potentials (Uq/s).

Default: 1.0E-3

Example: CDFT\_CG\_THRESHOLD 0.01

\sphinxstylestrong{CDFT\_CG\_TYPE}

Syntax: CDFT\_CG\_TYPE {[}Text{]}

Description: Specifies the variant of the conjugate gradients algorithm
used for the optimization of the constraining potentials (Uq/s),
currently either NGWF\_FLETCHER for Fletcher-Reeves or NGWF\_POLAK for
Polak-Ribiere.

Default: NGWF\_FLETCHER

Example: CDFT\_CG\_TYPE NGWF\_POLAK

\sphinxstylestrong{CDFT\_CHARGE\_ACCEPTOR\_TARGET}

Syntax: CDFT\_CHARGE\_ACCEPTOR\_TARGET {[}Real{]}

Description: Targeted acceptor-group electron population for
acceptor-group charge-constrained-DFT mode
{[}CDFT\_GROUP\_CHARGE\_ACCEPTOR=T{]}.

Default: 0.

Example: CDFT\_CHARGE\_ACCEPTOR\_TARGET 17 \#Constrain Nup+Ndown=17 e in
subspace

\sphinxstylestrong{CDFT\_CHARGE\_DONOR\_TARGET}

Syntax: CDFT\_CHARGE\_DONOR\_TARGET {[}Real{]}

Description: Targeted donor-group electron population for donor-group
charge-constrained-DFT mode {[}CDFT\_GROUP\_CHARGE\_DONOR=T{]}.

Default: 0.

Example: CDFT\_CHARGE\_DONOR\_TARGET 17 \#Constrain Nup+Ndown=17 e in
subspace

\sphinxstylestrong{CDFT\_CONTINUATION}

Syntax: CDFT\_CONTINUATION {[}Logical{]}

Description: Continue a constraining potential (Uq/s) optimisation from
a previous run using the .cdft file with the latest cDFT-potentials.
CDFT\_CONTINUATION=T allows also to perform single-point cDFT runs
(MAXIT\_CDFT\_U\_CG=0) reading atom-specific constraining potentials
from .cdft file (instead of species-specific ones from the
CONSTRAINED\_DFT block). For cdft\_continuation=T, the constraining
potentials (Uq/s) are read from the .cdft file no matter the setting of
cdft\_guru.

Default: False

Example: CDFT\_CONTINUATION T

\sphinxstylestrong{CDFT\_GROUP\_CHARGE\_ACCEPTOR}

Syntax: CDFT\_GROUP\_CHARGE\_ACCEPTOR {[}Logical{]}

Description: Activate acceptor-group charge-constrained-DFT mode. This
mode is compatible with CDFT\_GROUP\_CHARGE\_DONOR and
CDFT\_GROUP\_SPIN\_ACCEPTOR/DONOR cDFT-modes, and incompatible with
CDFT\_ATOM\_CHARGE/SPIN and CDFT\_GROUP\_CHARGE/SPIN\_DIFF cDFT modes.

Default: False

Example: CDFT\_GROUP\_CHARGE\_ACCEPTOR T

\sphinxstylestrong{CDFT\_GROUP\_CHARGE\_DIFF}

Syntax: CDFT\_GROUP\_CHARGE\_DIFF {[}Logical{]}

Description: Activate group charge-difference constrained-DFT mode. This
mode is compatible with CDFT\_GROUP\_SPIN\_DIFF cDFT mode only. Thus, it
is incompatible with any other CDFT\_ATOM\_CHARGE/SPIN and
CDFT\_GROUP\_CHARGE/SPIN\_ACCEPTOR/DONOR cDFT modes.

Default: False

Example: CDFT\_GROUP\_CHARGE\_DIFF T

\sphinxstylestrong{CDFT\_GROUP\_CHARGE\_DIFF\_TARGET}

Syntax: CDFT\_CHARGE\_DIFF\_TARGET {[}Real{]}

Description: Targeted electron population difference between acceptor
and donor group for -group charge-difference constrained-DFT mode
{[}CDFT\_GROUP\_CHARGE\_DIFF=T{]}.

Default: 0.

Example: CDFT\_CHARGE\_ACCEPTOR\_TARGET 2
\begin{quote}

\#Constrain {[}Nup+Ndown{]}\_ACC - {[}Nup+Ndown{]}\_DON to 2 e.
\end{quote}

\sphinxstylestrong{CDFT\_GROUP\_CHARGE\_DONOR}

Syntax: CDFT\_GROUP\_CHARGE\_DONOR {[}Logical{]}

Description: Activate donor-group charge-constrained-DFT mode. This mode
is compatible with CDFT\_GROUP\_CHARGE\_ACCEPTOR and
CDFT\_GROUP\_SPIN\_ACCEPTOR/DONOR cDFT-modes, and incompatible with
CDFT\_ATOM\_CHARGE/SPIN and CDFT\_GROUP\_CHARGE/SPIN\_DIFF cDFT modes.

Default: False

Example: CDFT\_GROUP\_CHARGE\_DONOR T

\sphinxstylestrong{CDFT\_GROUP\_CHARGE\_DOWN\_ONLY}

Syntax: CDFT\_GROUP\_CHARGE\_DOWN\_ONLY {[}Logical{]}

Description: Constrain only SPIN-DOWN channel in
CDFT\_GROUP\_CHARGE\_ACCEPTOR, CDFT\_GROUP\_CHARGE\_DONOR and
CDFT\_GROUP\_CHARGE\_DIFF modes. To avoid disaster, make sure the
specified CDFT\_CHARGE\_ACCEPTOR/DONOR\_TARGET or
CDFT\_CHARGE\_DIFF\_TARGET keywords are consistent with the fact only
one spin channel is being constrained. This functionality is NOT
compatible with CDFT\_GROUP\_CHARGE\_UP\_ONLY, CDFT\_ATOM\_CHARGE/SPIN,
and CDFT\_GROUP\_SPIN\_ACCEPTOR/DONOR and CDFT\_GROUP\_SPIN\_DIFF cDFT
modes.

Default: False

Example: CDFT\_GROUP\_CHARGE\_DOWN\_ONLY T

\sphinxstylestrong{CDFT\_GROUP\_CHARGE\_UP\_ONLY}

Syntax: CDFT\_GROUP\_CHARGE\_UP\_ONLY {[}Logical{]}

Description: Constrain only SPIN-UP channel in
CDFT\_GROUP\_CHARGE\_ACCEPTOR, CDFT\_GROUP\_CHARGE\_DONOR and
CDFT\_GROUP\_CHARGE\_DIFF modes. To avoid disaster, make sure the
specified CDFT\_CHARGE\_ACCEPTOR/DONOR\_TARGET or
CDFT\_CHARGE\_DIFF\_TARGET keywords are consistent with the fact only
one spin channel is being constrained. This functionality is NOT
compatible with CDFT\_GROUP\_CHARGE\_DOWN\_ONLY,
CDFT\_ATOM\_CHARGE/SPIN, and CDFT\_GROUP\_SPIN\_ACCEPTOR/DONOR and
CDFT\_GROUP\_SPIN\_DIFF cDFT modes.

Default: False

Example: CDFT\_GROUP\_CHARGE\_UP\_ONLY T

\sphinxstylestrong{CDFT\_GROUP\_SPIN\_ACCEPTOR}Syntax: CDFT\_GROUP\_SPIN\_ACCEPTOR
{[}Logical{]}

Description: Activate acceptor-group magnetic-moment constrained-DFT
mode. This mode is compatible with CDFT\_GROUP\_SPIN\_DONOR and
CDFT\_GROUP\_CHARGE\_ACCEPTOR/DONOR cDFT-modes, and incompatible with
CDFT\_ATOM\_CHARGE/SPIN and CDFT\_GROUP\_CHARGE/SPIN\_DIFF cDFT modes.

Default: False

Example: CDFT\_GROUP\_SPIN\_ACCEPTOR T

\sphinxstylestrong{CDFT\_GROUP\_SPIN\_DIFF}

Syntax: CDFT\_GROUP\_SPIN\_DIFF {[}Logical{]}

Description: Activate group magnetic-moment-difference constrained-DFT
mode. This mode is compatible with CDFT\_GROUP\_CHARGE\_DIFF cDFT mode
only. Thus, it is incompatible with any other CDFT\_ATOM\_CHARGE/SPIN
and CDFT\_GROUP\_CHARGE/SPIN\_ACCEPTOR/DONOR cDFT modes.

Default: False

Example: CDFT\_GROUP\_CHARGE\_DIFF T

\sphinxstylestrong{CDFT\_GROUP\_SPIN\_DIFF\_TARGET}

Syntax: CDFT\_SPIN\_DIFF\_TARGET {[}Real{]}

Description: Targeted magnetic-moment difference between acceptor and
donor group for group magnetic-moment-difference constrained-DFT mode
{[}CDFT\_GROUP\_SPIN\_DIFF=T{]}.

Default: 0.

Example: CDFT\_CHARGE\_ACCEPTOR\_TARGET 2
\begin{quote}

\#Constrain {[}Nup-Ndown{]}\_ACC - {[}Nup-Ndown{]}\_DON to 2 e.
\end{quote}

\sphinxstylestrong{CDFT\_GROUP\_SPIN\_DONOR}

Syntax: CDFT\_GROUP\_SPIN\_DONOR {[}Logical{]}

Description: Activate donor-group magnetic-moment constrained-DFT mode.
This mode is compatible with CDFT\_GROUP\_SPIN\_ACCEPTOR and
CDFT\_GROUP\_CHARGE\_ACCEPTOR/DONOR cDFT-modes, and incompatible with
CDFT\_ATOM\_CHARGE/SPIN and CDFT\_GROUP\_CHARGE/SPIN\_DIFF cDFT modes.

Default: False

Example: CDFT\_GROUP\_SPIN\_DONOR T

\sphinxstylestrong{CDFT\_GURU}

Syntax: CDFT\_GURU {[}Logical{]}

Description: Tell ONETEP you are a cDFT-expert and prevent it from
initialising the active \textbar{}Uq/s\textbar{} to failsafe value of 1 eV overwriting
the values entered in the \%block constrained\_dft (Uq/s).

Default: False

Example: CDFT\_GURU T

\sphinxstylestrong{CDFT\_HUBBARD}

Syntax: CDFT\_HUBBARD {[}Logical{]}

Description: Activate the constrained-DFT+U functionality. It requires
specifications of a positive value for the Hubbard correction (Uh) in
the CONSTRAINED\_DFT Block.

Default: False

Example: CDFT\_HUBBARD T

\sphinxstylestrong{CDFT\_MAX\_GRAD}

Syntax: CDFT\_MAX\_GRAD {[}Real{]}

Description: Specifies the convergence threshold for the maximum value
of the constraining-potential (Uq/s) gradient at any cDFT-site

Default: 1.0E-3

Example: CDFT\_MAX\_GRAD 0.01

\sphinxstylestrong{CDFT\_MULTI\_PROJ}

Syntax: CDFT\_MULTI\_PROJ {[}Logical{]}

Description: Activate the “as many cDFT-projectors as NGWFs” cDFT-mode.
In this mode, the number of cDFT-projectors for a given cDFT-atom equals
the number of NWGFs for that atom as specified in the \%block species.
Both the cDFT-projectors and the NGWFs are localised within spheres of
the same radius. When activated, this mode overwrites the L-projectors
and Z-projectors settings in \%block constrained\_dft, and the
cDFT-projectors are built according to the settings in \%block
species\_atomic\_set for that atom=cDFT-site.

Default: False

Example: CDFT\_MULTI\_PROJ T

\sphinxstylestrong{CDFT\_PRINT\_ALL\_OCC}

Syntax: CDFT\_PRINT\_ALL\_OCC {[}Logical{]}

Description: Print detailed information of occupancies for al the
cDFT-sites, for OUTPUT\_DETAIL = VERBOSE.

Default: False

Example: CDFT\_PRINT\_ALL\_OCC T

\sphinxstylestrong{CDFT\_READ\_PROJ}

Syntax: CDFT\_READ\_PROJ {[}Logical{]}

Description: Read cDFT-projectors from .tightbox\_hub\_proj file.
Activation of this keyword overwrites any Z-projector setting in \%block
constrained\_dft. It also makes not necessary to set
hubbard\_proj\_mixing\textless{}0 to have task=HUBBARDSCF runs with projectors
read in from file.

Default: False

Example: CDFT\_READ\_PROJ T

\sphinxstylestrong{CDFT\_SPIN\_ACCEPTOR\_TARGET}

Syntax: CDFT\_SPIN\_ACCEPTOR\_TARGET {[}Real{]}

Description: Targeted group magnetic-moment for acceptor-group
magnetic-moment constrained-DFT mode {[}CDFT\_GROUP\_SPIN\_ACCEPTOR=T{]}.

Default: 0.

Example: CDFT\_SPIN\_ACCEPTOR\_TARGET -2 \#Constrain Nup-Ndown=-2 in
subspace

\sphinxstylestrong{CDFT\_SPIN\_DONOR\_TARGET}

Syntax: CDFT\_SPIN\_DONOR\_TARGET {[}Real{]}

Description: Targeted group magnetic-moment for donor-group
magnetic-moment constrained-DFT mode {[}CDFT\_GROUP\_SPIN\_DONOR=T{]}.

Default: 0.

Example: CDFT\_SPIN\_DONOR\_TARGET -2 \#Constrain Nup-Ndown=-2 in
subspace

\sphinxstylestrong{CDFT\_TRIAL\_LENGTH}

Syntax: CDFT\_TRIAl\_LENGTH {[}Real{]}

Description: Specifies initial trial length for first step of
constraining-potential (Uq/s) conjugate gradients optimisation.

Default: 0.1

Example: CDFT\_TRIAL\_LENGTH 1.0

\sphinxstylestrong{CI\_CDFT}

Syntax: CI\_CDFT {[}Logical{]}

Description: Perform a Configuration Interaction calculation based on
constrained-DFT configurations.

Default: False

Example: CI\_CDFT T

\sphinxstylestrong{CI\_CDFT\_NUM\_CONF}

Syntax: CDFT\_MAX\_GRAD {[}Integer{]}

Description: Specifies the number of constrained-DFT configuration
available for a CI\_CDFT=T simulation

Default: 0

Example: CI\_CDFT\_NUM\_CONF 4

\sphinxstylestrong{CONSTRAINED\_DFT}

Syntax: CONSTRAINED\_DFT {[}Block{]}

Syntax: \%BLOCK CONSTRAINED\_DFT

S1 L1 Z1 Uh1 Uq1(UP) Uq1(DOWN) Us1 N1(UP) N1(DOWN) {[}N1(UP)-N1(DOWN){]} S2
L2 Z2 Uh2 Uq2(UP) Uq2(DOWN) Us2 N2(UP) N2(DOWN) {[}N2(UP)-N2(DOWN){]} …
. .

… . .

SM LM ZM UhM UqM(UP) UqM(DOWN) UsM NM(UP) NM(DOWN) {[}NM(UP)-NM(DOWN){]}

\%ENDBLOCK CONSTRAINED\_DFT

Description: Manages constrained-DFT simulations. Provided
cdft\_multi\_proj=F, for species S and subspace of angular momentum
channel L (with principal quantum number n=L+1) we apply charge
spin-specific {[}Uq(UP), Uq(DOWN){]} or magnetic-moment-specific (Us)
constraining potentials (eV). For cdft\_atom\_charge=T, N(UP) and
N(DOWN) indicate the targeted e-population for spin-channel UP and DOWN,
respectively. For cdft\_atom\_spin=T, {[}N1(UP)-N1(DOWN){]} indicates the
targeted e-population difference (i.e. local magnetic moment). Uh
indicates the optional Hubbard parameter (U, eV) to be applied for
cdft\_hubbard=T. An effective nuclear charge Z defines the hydrogenic
orbitals spanning the subspace unless a negative value is given, e.g.,
Z=-10, in which case the NGWFs initial guess orbitals (numerical atomic
orbitals) are used. Depending on the activated cDFT-mode, different
columns of the block are used. These are:
\begin{quote}

S, L, Z, (Uh), Uq(UP), Uq(DOWN), N(UP), N(DOWN) for
cdft\_atom\_charge=T

S, L, Z, (Uh), Us, {[}N(UP)-N(DOWN){]} for cdft\_atom\_spin=T

S, L, Z, (Uh), Uq(UP), Uq(DOWN) for cdft\_group\_charge\_acceptor=T,
cdft\_group\_charge\_donor=T, or cdft\_group\_charge\_diff=T. In
this case, Uq(UP) must be equal to Uq(DOWN). Acceptor and donor
atoms are differentiated by mean of negative {[}Uq(UP/DOWN)\textless{}0{]} and
positive {[}Uq(UP/DOWN)\textgreater{}0{]} constraining-potentials, respectively.
Setting Uq=0 in the \%block constrained\_dft will result in the given
cDFT-atom being excluded from the list of the atoms in a given
cdft\_group\_charge\_donor/acceptor/diff group.

S, L, Z, (Uh), and Us for cdft\_group\_spin\_acceptor=T,
cdft\_group\_spin\_donor=T, or cdft\_group\_spin\_diff=T. In this
case, Acceptor and donor atoms are differentiated by mean of
negative (Us\textless{}0) and positive (Us\textgreater{}0) constraining-potentials,
respectively. Setting Us=0 in the \%block constrained\_dft will
result in the given cDFT-atom being excluded from the list of the
atoms in a given cdft\_group\_spin\_donor/acceptor/diff group.

cdft\_group\_spin\_acceptor=T, cdft\_group\_spin\_donor=T,
cdft\_group\_charge\_acceptor=T and cdft\_group\_charge\_donor=T are
all compatible one with another. Charge- and magnetic-moment
acceptor- and donor-groups may or may not be the same group. Thus,
besides simultaneously constraining the charge and magnetic-moment
on a given group, it is also possible (by setting the appropriate
sign of Uq and Us in the \%block constrained\_dft) to create, within
the same input and system, a charge\_acceptor group-A, a
charge\_donor group-B, a spin\_acceptor group-C and a spin\_donor
group-C. Similar considerations apply also for simultaneous
activation of group\_charge\_diff and group\_spin\_diff cDFT-modes.
In sum,

Activation of cdft\_group\_charge\_up(down)\_only=T for
cdft\_group\_charge\_acceptor/donor or cdft\_group\_charge\_diff
modes leads to optimisation of the Uq potentials only for the
selected spin-channel i.e. Uq(UP) only for
cdft\_group\_charge\_up\_only=T, and Uq(DOWN) only for
cdft\_group\_charge\_down\_only=T, leaving the other spin channel
unconstrained.

For cdft\_multi\_proj=T the L-projector and Z-projector columns in
the \%block constrained\_dft are read but NOT used. The
cDFT-projectors are set on the basis of the \%block
species\_atomic\_set and taken as the NGWFs initial guess (numerical
atomic orbital). This leads to as many cDFT-projectors as NGWFs for
the cDFT-atom being used. In the current implementation, the same
Uq/s is applied to all the projectors of a given cDFT-atom
regardless of their principal quantum number and angular momentum.

For all the cDFT-modes, unless maxit\_cdft\_u\_cg=0, and depending
of the specific cDFT-mode, the constraining potentials (Uq,Us) will
be automatically optimised. Note that, unless cdft\_guru=T, the
constraining potentials (Uq/s) will be initialised to 1 eV. Thus, to
perform fixed-Uq/s cDFT-runs or to initialise Uq/s with values
different from 1 eV (useful for low-energy spin-excitation), it is
necessary to set cdft\_guru=T.

The CONSTRAINED\_DFT Block is incompatible with the HUBBARD Block.
To perform a constrained-DFT+U simulation with Hubbard (Uh)
correction applied to the subspace in addition to the constraining
potentials (Uq/s) it is necessary to set cdft\_hubbard=T. For
cdft\_hubbard=F (which is the default), the Hubbard correction will
NOT be applied to the subspace.
\end{quote}

Example: \%BLOCK CONSTRAINED\_DFT

\# L Z Uh Uq(UP) Uq(DOWN) Us N(UP) N1(DOWN) {[}N1(UP)-N1(DOWN){]}

N1 1 -5. 0.0 11.0 11.0 0.0 2.3 1.3 0.

N2 1 -5. 0.0 -26.0 -26.0 0.0 2.7 2.7 0.

\%ENDBLOCK CONSTRAINED\_DFT

\sphinxstylestrong{MAXIT\_CDFT\_U\_CG}

Syntax: MAXIT\_CDFT\_U\_CG {[}Integer{]}

Description: Specifies the maximum number of iterations for the
constraining potentials (Uq/s) conjugate gradients optimisation.

Default: 60

Example: MAXIT\_CDFT\_U\_CG 5

\sphinxstylestrong{HUBBARD\_TENSOR\_CORR}

Syntax: HUBBARD\_TENSOR\_CORR {[}Integer{]}

Description:
\begin{quote}
\begin{quote}

1: Correct tensorially for the slight nonorthogonality between DFT+U or constrained DFT (cDFT) projectors of numerical pseudoatomic orbital form, individually on each atom, which arise due to finite psinc sampling. See details see Phys. Rev. B 83, 245124 (2011).

2: Use the full simulation-cell overlap matrix of the initial numerical pseudoatomic orbitals (whether or not they are selected as projectors) to form the nonorthogonality correction, in the vein of Mulliken analysis. Experimental, non-Hermitian at present, and not recommended.

3: Do not correct for the slight nonorthogonality between DFT+U or constrained DFT (cDFT) projectors on a given atom. This is standard in many codes, and currently necessary to choose when using USP/PAW.

4: This is a reasonable, but not necessary choice, when using cDFT with constraints based on atom group populations. The non-negligible nonorthogonality between projectors on different atoms in the group is accounted for tensorially. This also activates multi-site Pulay force terms in constrained DFT (cDFT) that account for varying inter-atom nonorthogonality. For details see Phys. Rev. B 97, 205120 (2018).

5: This is also an arguably reasonable, but not necessary choice, when using cDFT with constraints based on, e.g. the difference of atom or atom group populations, that is source-drain cDFT. The non-negligible nonorthogonality between projectors on different atoms in a group is accounted for tensorially, and also the possible nonorthogonality between the source and drain atoms or atom-groups. For an application see Phys. Rev. B 93, 165102 (2016). This also activates (in principle) multi-site Pulay force terms in constrained DFT (cDFT) that account for varying inter-subspace nonorthogonality. This also activates multi-site Pulay force terms in constrained DFT (cDFT) that account for varying inter-atom nonorthogonality. This also activates multi-site Pulay force terms in constrained DFT (cDFT) that account for varying inter-atom nonorthogonality. For details see Phys. Rev. B 97, 205120 (2018).
\end{quote}

The HUBBARD\_TENSOR\_CORR functionality is not activated in the rare case that analytical hydrogenic projectors are instead of the default numerical pseudoatomic ones.
\end{quote}

Default: 1

Example: HUBBARD\_TENSOR\_CORR 4


\chapter{Dynamics}
\label{\detokenize{index_dynamics:dynamics}}\label{\detokenize{index_dynamics::doc}}

\section{Born-Oppenheimer Molecular Dynamics}
\label{\detokenize{BOMD::doc}}\label{\detokenize{BOMD:born-oppenheimer-molecular-dynamics}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Simon M.-M. Dubois, University of Cambridge

\item[{Author}] \leavevmode
Valerio Vitale, University of Southampton

\end{description}\end{quote}

This document is intended as a guide to the molecular dynamics (MD)
functionality in ONETEP (v4.4) {[}Skylaris2005{]}. Though
some theoretical concepts are reviewed, it is not meant to be a
stand-alone introduction to Born-Oppenheimer Molecular Dynamics (BOMD)
simulations. The reader is referred to the textbook of Frenkel and
Smit {[}Frenkel2001{]} for a review of the field.


\subsection{Integrating the equations of motion}
\label{\detokenize{BOMD:integrating-the-equations-of-motion}}
The MD functionality implemented in ONETEP is founded on the
Born-Oppenheimer approximation which states that the electrons are much
lighter than nuclei, the dynamics of electrons is much faster compared
to the dynamics of the nuclei. As a consequence, the former can be
considered to react instantaneously to the motion of the latter. The
forces acting on the nuclei are derived from the ground state electronic
configuration by means of the Hellmann-Feynamn theorem. The motion of
the nuclei is described by the laws of classical mechanics
\begin{equation*}
\begin{split}\frac{\partial H}{\partial \mathbf{r}} = -\dot{\mathbf{p}} \ \ \ \mbox{   and   } \ \ \ \frac{\partial H}{\partial \mathbf{p}} = \dot{\mathbf{r}}\end{split}
\end{equation*}
where \(H\) is the Hamiltonian (or the total energy) of the system
and \(\mathbf{r}\), \(\mathbf{p}\) are the nuclei positions and
conjugate momenta. At each MD steps, the forces on the particles are
computed, and the particles positions and momenta are updated according
to Newton’s equations of motion. Though this is an excellent
approximation for many materials, it is important to keep in mind that
classical dynamics does not account for quantum phenomena such as zero
point motion, tunneling, or quantum fluctuations which may play a
significant role in the dynamics of some systems.

In a BOMD simulation, the classical laws of motion are integrated using
a finite difference scheme (that usually preserves the symplectic
structure of phase space, e.g. the Velocity-Verlet
algorithm {[}Verlet1967{]}, {[}Swope1982{]}). For small enough time
steps, the particle trajectory becomes independent of the discretization
and the total energy of the system is conserved. At room temperature and
in situation close to equilibrium, a time step \(\Delta t\) of a
fraction of a femtosecond is usually adopted.

The Velocity-Verlet algorithm corresponds to the following set of four
operations:

\phantomsection\label{\detokenize{BOMD:equation-verlet1}}\begin{equation}\label{equation:BOMD:verlet1}
\begin{split}1: \mathbf{v}_{n+1/2} = \mathbf{v}_n + \frac{\Delta t}{2m}*\mathbf{F}_n\end{split}
\end{equation}\phantomsection\label{\detokenize{BOMD:equation-verlet2}}\begin{equation}\label{equation:BOMD:verlet2}
\begin{split}2: \mathbf{r}_{n+1} = \mathbf{r}_n + \Delta t * \mathbf{v}_{n+1/2}\end{split}
\end{equation}\phantomsection\label{\detokenize{BOMD:equation-verlet3}}\begin{equation}\label{equation:BOMD:verlet3}
\begin{split}3: \mbox{Compute ionic forces } \mathbf{F}_{n+1}\end{split}
\end{equation}\phantomsection\label{\detokenize{BOMD:equation-verlet4}}\begin{equation}\label{equation:BOMD:verlet4}
\begin{split}4: \mathbf{v}_{n+1} = \mathbf{v}_{n+1/2} + \frac{\Delta t}{2m}*\mathbf{F}_{n+1}\end{split}
\end{equation}
where subscripts are used to label the MD time steps. This approach
yields a reversible integrator that weights correctly the phase space
and conserves the phase space volume.

The velocities in eqs. \eqref{equation:BOMD:verlet1}-\eqref{equation:BOMD:verlet4}, are the internal (or
peculiar) velocities and not the atomic velocities. Internal velocities
are used to properly take into account the internal motion of the
system, for which the total linear momentum must vanish. When using open
boundary conditions, the use of internal velocities ensures that also
the total internal angular momentum vanishes. By setting the total
linear (angular) momentum to zero at the beginning of a simulation while
employing atomic velocities in eqs. \eqref{equation:BOMD:verlet1}-\eqref{equation:BOMD:verlet4}, does not
guarantee to keep the linear (angular) momentum conserved. This is due
to numerical errors that unavoidably modify the initial values. One of
the possible drawback is the well-known “flying ice cube effect”. The
interested reader is referred to Ref. {[}Hunenberger2005{]}
for a comprehensive description. However, before printing out the
trajectory info to the \sphinxcode{rootname.md} file, the internal velocities are
transformed back to the atomic velocities for visualization and
post-processing. In the limit of very long time, the ergodic hypothesis
is invoked which allows us to derive ensemble averages from the
molecular trajectories.


\subsection{Basic input parameters}
\label{\detokenize{BOMD:basic-input-parameters}}
The Molecular Dynamics functionality is activated by setting the input
parameter \sphinxcode{TASK} to \sphinxcode{MOLECULARDYNAMICS}. If a fresh calculation is
started, the initial nuclear positions are read from the
\sphinxcode{POSITIONS\_ABS} block while the nuclear velocities are obtained from
the \sphinxcode{VELOCITIES} block. If the latter is not specified, the velocities
are drawn from a maxwell-boltzmann distribution at a (user defined)
temperature set in the \sphinxcode{THERMOSTAT} block (see Thermostats section).
The values of \(\Delta t\) is determined by the parameter
\sphinxcode{MD\_DELTA\_T}. The number of integration steps is fixed by
\sphinxcode{MD\_NUM\_ITER}.

For example, the following set of input parameters instructs the code to
run a 4 ps long BOMD calculation with \(\Delta t = 0.8\) fs.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{TASK}          \PYG{p}{:}  \PYG{n}{MOLECULARDYNAMICS}
\PYG{n}{MD\PYGZus{}DELTA\PYGZus{}T}    \PYG{p}{:}  \PYG{l+m+mf}{0.8} \PYG{n}{fs}
\PYG{n}{MD\PYGZus{}NUM\PYGZus{}ITER}   \PYG{p}{:}  \PYG{l+m+mi}{5000}
\PYG{n}{MD\PYGZus{}PROPERTIES} \PYG{p}{:}  \PYG{n}{T}
\PYG{n}{MD\PYGZus{}RESTART}    \PYG{p}{:}  \PYG{n}{F}
\end{sphinxVerbatim}

The flag \sphinxcode{MD\_PROPERTIES} instructs the code to enter the properties
module at each MD steps. During the calculation a file \sphinxcode{rootname.md}
is generated that contains a summary of the trajectory, such as
temperature, energies, nuclear positions, velocities and forces at each
MD steps. Additionally, the latest phase space coordinates are stored in
the unformatted file \sphinxcode{rootname.md.restart}. The flag \sphinxcode{MD\_RESTART}
enables to restart an MD calculation from the phase space coordinates
stored in \sphinxcode{rootname.md.restart}. It is important to stress here that
\sphinxcode{MD\_NUM\_ITER} is an incremental counter. This means that the when
starting a fresh calculation the number of MD steps corresponds to
\sphinxcode{MD\_NUM\_ITER}, while for a restart calculation the actual number of MD
steps is calculated as the difference between \sphinxcode{MD\_NUM\_ITER} and the
total number of MD steps completed up to that point. Therefore, if we
want to continue the 4 ps long calculation of the previous example for
other 4 ps, we would have to set

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{TASK}          \PYG{p}{:}  \PYG{n}{MOLECULARDYNAMICS}
\PYG{n}{MD\PYGZus{}DELTA\PYGZus{}T}    \PYG{p}{:}  \PYG{l+m+mf}{0.8} \PYG{n}{fs}
\PYG{n}{MD\PYGZus{}NUM\PYGZus{}ITER}   \PYG{p}{:}  \PYG{l+m+mi}{10000}
\PYG{n}{MD\PYGZus{}PROPERTIES} \PYG{p}{:}  \PYG{n}{T}
\PYG{n}{MD\PYGZus{}RESTART}    \PYG{p}{:}  \PYG{n}{T}
\end{sphinxVerbatim}


\subsection{Thermostats}
\label{\detokenize{BOMD:thermostats}}
The \sphinxcode{THERMOSTAT} block must be defined for any MD calculation, even
when performing microcanonical runs. For equilibration purposes or to
extract thermodynamical averages, it is often desirable to sample the
canonical ensemble (constant-NVT) rather than the microcanonical one
(constant-NVE). In order to achieve this, there needs to be a mechanism
(i.e. a thermostat) by which the system can exchange energy with the
rest of the universe. Several thermostats, Andersen, Langevin,
Nose-Hoover chains, Berendsen and Bussi, are available in ONETEP.


\subsubsection{Andersen thermostat}
\label{\detokenize{BOMD:andersen-thermostat}}
One of the simplest constant temperature algorithm has been proposed by
Andersen {[}Andersen1980{]}. The system is thermally coupled
with a bath of fictitious particles at temperature \(T\).
Practically this coupling acts by replacing the momentum of a number of
atoms by a new momentum derived from the appropriate Boltzmann
distribution. The strength of the coupling can be adjusted by fixing the
characteristic time (\(\tau\)) at which the momentum rescaling
occurs and the amplitude (\(\gamma\)) of the rescaling. Eventually,
the probability that collision occurs during a time step
\(\Delta t\) is given by,

\phantomsection\label{\detokenize{BOMD:equation-ander1}}\begin{equation}\label{equation:BOMD:ander1}
\begin{split}q_{col} = 1 - e^{- \Delta t / \tau}\end{split}
\end{equation}
and the collision on atom \(i\) acts as,

\phantomsection\label{\detokenize{BOMD:equation-ander2}}\begin{equation}\label{equation:BOMD:ander2}
\begin{split}p^{new} = \sqrt{(1-\gamma^2)}\  p + \gamma \  p^{boltzmann},\end{split}
\end{equation}
where \(p^{new}\) is the momentum rescaled by Andersen thermostat,
and \(p^{boltzmann}\) is a random variable with appropriate
Boltzmann distribution.


\subsubsection{Langevin thermostat}
\label{\detokenize{BOMD:langevin-thermostat}}
The Langevin thermostat accounts for the motion of the atoms in the
presence of a fictitious viscous solvent {[}Grest1986{]}. As
they have to be pushed away, the solvent particles create a friction
force damping the momentum of the atoms. Besides random perturbations of
the ionic forces arise from the collisions between the atoms and the
solvent particles. Langevin dynamic corresponds to the modified equation
of motion,

\phantomsection\label{\detokenize{BOMD:equation-langevin1}}\begin{equation}\label{equation:BOMD:langevin1}
\begin{split}\dot{p_{\alpha}} = F_{\alpha} - \gamma \frac{p_{\alpha}}{m_{\alpha}} + f_{\alpha}\end{split}
\end{equation}
where greek superscripts label the nuclei, \(F_{\alpha}\) are the
conservative forces acting on the nuclei, \(\gamma\) is the damping
factor associated with the solvent viscosity and \(f_{\alpha}\) are
the random forces accounting for the collisions. In order to guarantee
NVT statistics, the random forces and the damping factor are chosen so
as to fulfill the fluctuation-dissipation theorem. Eventually, the
update of the nuclei momenta \(p_{\alpha}\) and forces
\(F_{\alpha}\) is given by,
\begin{equation*}
\begin{split}\begin{aligned}
p_{\alpha}^{new} &= p_{\alpha} \ * \ e^{-\gamma \Delta t} \\
F_{\alpha}^{new} &= F_{\alpha} \ * \ \frac{1}{\gamma}(1-e^{-\gamma \Delta t}) + f_{\alpha}\\
f_{\alpha} &= \sqrt{ \frac{m_{\alpha} k_B T (1-e^{-2 \gamma \Delta t})}{\Delta t^2}}*\xi_{\alpha}\end{aligned}\end{split}
\end{equation*}
where \(\{\xi_\alpha\}\) is a set of mutually uncorrelated random
Gaussian variables with a zero mean and unit variance.


\subsubsection{Nosé-Hoover thermostat and Nose-Hoover chains}
\label{\detokenize{BOMD:nose-hoover-thermostat-and-nose-hoover-chains}}
In the Andersen and Langevin approaches, the constant temperature is
achieved by stochastic collisions with fictitious particles. The
approach of Nosé is different and allows to perform deterministic MD at
constant temperature {[}Nose1984{]}, {[}Hoover1985{]}. To achieve
isothermal MD, an additional coordinate associated with an effective
mass is introduced in the Lagrangian ruling the dynamics of the nuclei.
For a derivation of the equations of motion, the reader is referred to
the textbook of Berend and Smith. Provided the center of mass of the
system remains fixed, the Nosé-Hoover thermostat leads to a canonical
distribution of positions and momenta. To alleviate this restriction on
the center of mass, the nuclei are coupled to a Nosé-Hoover thermostat
whose fluctuations are determined by another thermostat (i.e. the so
called Nosé-Hoover chains). In ONETEP, the effective masse of the
thermostats (\(Q_{th_i}\)) is chosen, following the prescription of
Martyna and Tuckerman {[}Martyna1996{]}, as

\phantomsection\label{\detokenize{BOMD:equation-nose1}}\begin{equation}\label{equation:BOMD:nose1}
\begin{split}Q_{th_1} &= 3N  \frac{k_B T}{\omega^2}\end{split}
\end{equation}\phantomsection\label{\detokenize{BOMD:equation-nose2}}\begin{equation}\label{equation:BOMD:nose2}
\begin{split}Q_{th_i} &= \frac{k_B T}{\omega^2},\end{split}
\end{equation}
where N is the number of nuclei and \(\omega= 2 \pi / \tau\) is the
characteristic frequency of the thermostats. That parameter \(\tau\)
has to be chosen so as to guarantee a good coupling with the atomic
system. E.g. when water is used as solvent in the system, a value of
\(9.4\) fs is appropriate as it corresponds to the first asymmetric
stretching mode of water molecules.


\subsubsection{Berendsen thermostat}
\label{\detokenize{BOMD:berendsen-thermostat}}
In the Berendsen thermostat, the ionic equation of motions are
supplemented by a first order equation for the kinetic energy,

\phantomsection\label{\detokenize{BOMD:equation-berendsen1}}\begin{equation}\label{equation:BOMD:berendsen1}
\begin{split}dK = \frac{K_{t}-K}{\tau} dt\, ,\end{split}
\end{equation}
where \(K_{t}\) stands for the target kinetic energy. The weak
coupling of the system with the heat bath is determined by the time
constant \(\tau\). This thermostat does not generate a canonical
ensemble but is vary efficient for thermalization of large systems.


\subsubsection{Canonical velocity scaling}
\label{\detokenize{BOMD:canonical-velocity-scaling}}
An extension of the Berendsen thermostat allows to recover the canonical
distribution of the kinetic energy. In this approach, the instantaneous
kinetic energy is propagated using an auxiliary stochastic dynamics. The
equation of motion for the kinetic energy is defined as,

\phantomsection\label{\detokenize{BOMD:equation-bussi1}}\begin{equation}\label{equation:BOMD:bussi1}
\begin{split}dK = \frac{K_{t}-K}{\tau}\, dt\, +2 \sqrt{\frac{KK_t}{3N \tau}}\, dW\, ,\end{split}
\end{equation}
where \(K_{t}\) stands for the target kinetic energy and
\(dW\) is a Wiener noise. For a complete derivation of the equations
of motion, the reader is referred to G. Bussi et
al. {[}Bussi2007{]}. In the same way as for the Berendsen
thermostat, the coupling of the system with the heat bath is determined
by the characteristic time \(\tau\).


\subsection{Thermostat definition}
\label{\detokenize{BOMD:thermostat-definition}}
The parameters related to constant-NVE or
constant-NVT sampling are determined by means of the \sphinxcode{THERMOSTAT}
block. For a constant-NVE calculation, the thermostat block is needed to
specify the initial temperature for the maxwell-boltzmann distribution,
from which initial velocities are drawn. For constant-NVT sampling,
different thermostats can be associated with different groups of atoms.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}block thermostat
  start\PYGZus{}iter \PYGZam{} end\PYGZus{}iter \PYGZam{} thermo\PYGZus{}name \PYGZam{} temp \PYGZam{} ! First thermostat definition
      option\PYGZus{}1 = value ! Optional parameter 1
      option\PYGZus{}2 = value ! Optional parameter 2
  start\PYGZus{}iter \PYGZam{} stop\PYGZus{}iter \PYGZam{} thermo\PYGZus{}name \PYGZam{} temp \PYGZam{} ! Second thermostat definition
      option\PYGZus{}1 = value ! Optional parameter 1
      option\PYGZus{}2 = value! Optional parameter 2
\PYGZpc{}endblock thermostat
\end{sphinxVerbatim}

A thermostat definition contains four mandatory parameters and several
optional parameters. The mandatory parameters are : the starting and
stopping MD steps (these must be set bearing in mind the global counter
logic), the type of thermostat (i.e. \sphinxcode{none}, \sphinxcode{andersen},
\sphinxcode{langevin}, \sphinxcode{nosehoover}, \sphinxcode{berendsen}, or \sphinxcode{bussi},) and the
temperature. The line containing the mandatory parameters may be
followed by one or more of optional parameter definition (one per line).

Let us set an NVT calculation at 300K with Langevin thermostat for the
equilibration (3000 steps) and Nosé-Hoover thermostat for the
thermodynamical sampling (10000 steps). The input parameters could look
like

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{thermostat}
\PYG{l+m+mi}{0}  \PYG{l+m+mi}{3000}  \PYG{n}{langevin}  \PYG{l+m+mf}{300.0} \PYG{n}{K}
   \PYG{n}{damp} \PYG{o}{=} \PYG{l+m+mf}{0.2}
\PYG{l+m+mi}{3001}  \PYG{l+m+mi}{13000}  \PYG{n}{nosehoover}  \PYG{l+m+mf}{300.0} \PYG{n}{K}
   \PYG{n}{nchain} \PYG{o}{=} \PYG{l+m+mi}{4}
   \PYG{n}{nsteps} \PYG{o}{=} \PYG{l+m+mi}{10}
   \PYG{n}{tau} \PYG{o}{=} \PYG{l+m+mi}{100}\PYG{n}{fs}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{thermostat}
\end{sphinxVerbatim}

If both \sphinxcode{MD\_RESTART} and \sphinxcode{MD\_RESTART\_THERMO} flags are set to true,
the thermostat internal parameters are initialized from the values found
in the unformatted file named\sphinxcode{rootname.thermo.restart}
(\sphinxcode{rootname.thermo.global.restart} if \sphinxcode{MD\_GLOBAL\_RESTART = .true.},
see section on MD history). This is particularly useful when using
Nosé-Hoover thermostat as it avoids any disruption in the trajectories
of the thermostat coordinates. A formatted report on the thermostat
trajectories is outputted in the file \sphinxcode{rootname.thermo}.


\subsubsection{Thermostat optional parameters}
\label{\detokenize{BOMD:thermostat-optional-parameters}}\begin{description}
\item[{tgrad}] \leavevmode
\begin{DUlineblock}{0em}
\item[] (Physical) (default = 0K)
\item[] Discrete variation of temperature T per MD step.
\end{DUlineblock}

\item[{group}] \leavevmode
\begin{DUlineblock}{0em}
\item[] (Integer) (default = 0)
\item[] Index of the group of atoms (as defined in \sphinxcode{positions\_abs}) to
wich the thermostat is coupled. If no group of atoms is specified
the thermostat is applied to the full system (i.e. group index 0).
\end{DUlineblock}

\item[{tau}] \leavevmode
\begin{DUlineblock}{0em}
\item[] (Physical) (default = 10*\sphinxcode{MD\_DELTA\_T})
\item[] Characteristic time scale of the thermostat. Depending on the type
of thermostat, it may relate either to the average collision
frequency (see Eq. \eqref{equation:BOMD:ander1}) or the thermostat fluctuation
frequency (see Eqs. \eqref{equation:BOMD:nose1} and \eqref{equation:BOMD:nose2}) or to the coupling with
the heat bath (see Eqs. \eqref{equation:BOMD:berendsen1} and \eqref{equation:BOMD:bussi1}).
\end{DUlineblock}

\item[{mix}] \leavevmode
\begin{DUlineblock}{0em}
\item[] (real) (default = 1.0)
\item[] Collision amplitude of the Andersen thermostat (see Eq. \eqref{equation:BOMD:ander2}).
\end{DUlineblock}

\item[{damp}] \leavevmode
\begin{DUlineblock}{0em}
\item[] (real) (default = 0.2)
\item[] Damping factor in the Langevin equation of motion (see Eq.
\eqref{equation:BOMD:langevin1}).
\end{DUlineblock}

\item[{nchain}] \leavevmode
\begin{DUlineblock}{0em}
\item[] (integer) (default = 0)
\item[] Number of thermostats in the Nosé Hoover chain.
\end{DUlineblock}

\item[{nsteps}] \leavevmode
\begin{DUlineblock}{0em}
\item[] (integer) (default = 20)
\item[] Number of substep used to integrate the equation of motion of the
Nosé-Hoover coordinates.
\end{DUlineblock}

\item[{update}] \leavevmode
\begin{DUlineblock}{0em}
\item[] (logical) (default = .false.)
\item[] Impose to update the effective masses of the Nosé-Hoover
coordinates when the temperature is modified.
\end{DUlineblock}

\end{description}


\subsection{Using MD history}
\label{\detokenize{BOMD:using-md-history}}
In order to predict sensible trajectories and ensemble averages, BOMD
requires to solve the self-consistent field (SCF) equations that
determines the ground-state electronic structure at each MD steps.
Solving the SCF equations therefore dominates the computational effort.
The number of SCF cycles required to reach a given level of
self-consistency can be substantially reduced by using a good initial
guess for the electronic degrees of freedom. Various schemes have been
proposed that enable to make a good use of the MD history in order to
build efficient initial guesses.


\subsubsection{Extrapolation of NGWFs and density kernel}
\label{\detokenize{BOMD:extrapolation-of-ngwfs-and-density-kernel}}
In ONETEP {[}Skylaris2005{]}, the Kohn-Sham SCF equations
are formulated in terms of the single-particle density matrix
\(\rho(\mathbf{x},\mathbf{x'})\),

\phantomsection\label{\detokenize{BOMD:equation-dkn}}\begin{equation}\label{equation:BOMD:dkn}
\begin{split}\rho(\mathbf{x},\mathbf{x'}) = \phi_{\alpha}(\mathbf{x}) \ K^{\alpha \beta} \ \phi^*_{\beta}(\mathbf{x'}) \ ,\end{split}
\end{equation}
where Einstein’s notation for repeated indices has been used.
\(\{\phi_{\alpha}(\mathbf{x})\}\) is a set of localised support
functions, hereafter named Non-orthogonal Generalized Wannier Functions
(NGWFs), and \(\mathbf{K}\) is the kernel representing the density
operator. At each MD step, the total energy is minimized with respect to
both the density kernel and the support functions. Here below, we
briefly review various algorithms that allows to initialise the density
kernel and NGWFs by extrapolation from previous time steps.

Hereafter, \(\chi{^{\mbox{\tiny{init}}}}_i\) and
\(\chi{^{\mbox{\tiny{scf}}}}_i\) are used to represent respectively
the initial guess and SCF solution for either the density kernel or a
given NGWF at time \(t=i\Delta t\).

One-dimensional linear extrapolation
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The simplest attempt at a trial configuration for the electronic
degrees of freedom is the linear extrapolation,
\end{DUlineblock}
\begin{quote}
\phantomsection\label{\detokenize{BOMD:equation-linxtpol1}}\begin{equation}\label{equation:BOMD:linxtpol1}
\begin{split}\chi{^{\mbox{\tiny{init}}}}_{(i+1)} = 2\chi{^{\mbox{\tiny{scf}}}}_{i}-\chi{^{\mbox{\tiny{scf}}}}_{(i-1)}.\end{split}
\end{equation}\end{quote}
\end{quote}

Multi-dimensional linear extrapolation
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The idea of multi-dimensional linear extrapolation was first
proposed by Arias, Payne and Joannopoulos for the generation of
trial wavefunctions {[}Arias92{]}. The
one-dimensional linear extrapolation scheme creates an acceptable
initial configuration for the ionic coordinates
\(\mathbf{r'}=2\mathbf{r}_i-\mathbf{r_{(i-1)}}\). However, the
actual coordinates \(\mathbf{r}_{i+1}\) are in general
different. In order to account for the non-linear propagation of
the coordinates, the extrapolation can be generalized as follow,
\end{DUlineblock}
\begin{quote}
\phantomsection\label{\detokenize{BOMD:equation-multixtpol1}}\begin{equation}\label{equation:BOMD:multixtpol1}
\begin{split}\chi{^{\mbox{\tiny{init}}}}_{(i+1)} = \chi{^{\mbox{\tiny{scf}}}}_{i} + \sum_{n=0}^{N} c_n \left(\chi{^{\mbox{\tiny{scf}}}}_{(i-n)}  - \chi{^{\mbox{\tiny{scf}}}}_{(i-(n+1))} \right)\end{split}
\end{equation}
where the \(N+1\) coefficients \(\{c_n\}\) are chosen by
minimizing the norm,

\phantomsection\label{\detokenize{BOMD:equation-multixtpol2}}\begin{equation}\label{equation:BOMD:multixtpol2}
\begin{split}\left\| \left(\mathbf{r}_{i} - \mathbf{r}_{i+1} \right) + \sum_{n=0}^{N} c_n \left(\mathbf{r}_{(i-n)}  - \mathbf{r}_{(i-(n+1))} \right) \right\|.\end{split}
\end{equation}
This insures that the extrapolated degrees of freedom are in
close correspondence to the BOMD trajectory.
\end{quote}
\end{quote}

Generalized multi-dimensional linear extrapolation
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The multi-dimensional extrapolation of NGWFs can be further
generalized in order to account for the local characteristics of
the ionic trajectories. By introducing a localization function
\(F(r-r_{cut})\) within Eq.{[}multixtpol2{]}, the coefficients
\(\{c_n\}\) can be further optimized with respect to the local
environment. In practice, a set of coefficients
\(\{c_{n}\}_{\alpha}\) is derived for each ion
(\(\alpha\)) by minimizing the modified norm,
\end{DUlineblock}
\begin{quote}
\phantomsection\label{\detokenize{BOMD:equation-genxtpol1}}\begin{equation}\label{equation:BOMD:genxtpol1}
\begin{split}\left\| \left(\mathbf{r'}(\alpha)_i - \mathbf{r'}(\alpha)_{(i+1)} \right) + \sum_{n=0}^{m} c(\alpha)_n \left(\mathbf{r'}(\alpha)_{(i-n)}  - \mathbf{r'}(\alpha)_{(i-(n+1))} \right) \right\|,\end{split}
\end{equation}
where \(\mathbf{r'}(\alpha)_i\) refers to a local projection
of the ionic coordinates at time \(t_i\),

\phantomsection\label{\detokenize{BOMD:equation-genxtpol2}}\begin{equation}\label{equation:BOMD:genxtpol2}
\begin{split}r'(\alpha)_{\beta,i} = F(r_{\alpha,i}-r_{\beta,i}  -r_{cut}) \ r_{\beta,i}\end{split}
\end{equation}
This way, the extrapolated NGWFs associated with a given ion are
in better correspondence to the BOMD trajectory of its local
environment.
\end{quote}
\end{quote}

One-dimensional polynomial extrapolation
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Another way to extrapolate the density kernel and NGWFs is to
assume that each element of the density kernel
(\(K^{\alpha\beta}\)) and component of the NGWFs on the grid
(\(\phi_{\alpha}(\mathbf{x})\)) can be represented as a
polynomial in the time \(t\). Applied to the density kernel,
this gives,
\end{DUlineblock}
\begin{quote}
\phantomsection\label{\detokenize{BOMD:equation-polyxtpol1}}\begin{equation}\label{equation:BOMD:polyxtpol1}
\begin{split}K^{\alpha\beta}(t) = \sum_{m=0}^N c^{\alpha \beta}_m \ t^{m}\end{split}
\end{equation}
where the \(N+1\) extrapolation coefficients
\(c^{\alpha \beta}_m\) are dertemined by fitting the
polynomial expression to the last \(N+1\) values of
\(K^{\alpha\beta}\).
\end{quote}
\end{quote}


\subsubsection{Density kernel transformations}
\label{\detokenize{BOMD:density-kernel-transformations}}
The extrapolation schemes, as described above, illustrates a point of
view in which the density kernel and the support functions are
considered on the same footing, either as a functional of the ionic
coordinates or as an oscillatory function in time. This is ignoring the
close link between the support functions and the density kernel (see
Eq.{[}dkn{]}). There is a broader point of view, where the density kernel
(\(K^{\alpha \beta}\)) is considered as the representation of the
density operator in the time-dependent basis formed by the NGWFs. If one
assume that the BOMD propagation of the electronic degrees of freedom is
more or less adiabatic, it is tempting to rely on the schemes described
above for the extrapolation of the support functions and to transform
the latest density kernel in order to account for the modification of
the basis set. In ONETEP, this can be done in two ways.

Projection of the density kernel
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The simplest attempt at transforming the density kernel in order
to adapt it to the new support functions is to project the density
kernel onto the extrapolated NGWFs. This transformation reads,
\end{DUlineblock}
\begin{quote}
\begin{equation*}
\begin{split}\mathbf{K}{^{\mbox{\tiny{init}}}}_{(i+1)} = \left(\mathbf{S}{^{\mbox{\tiny{init}}}}_{i+1}\right)^{-1} \mathbf{T}_{(i+1),i} \ \mathbf{K}{^{\mbox{\tiny{scf}}}}_{i} \ \mathbf{T}_{i,(i+1)} \left(\mathbf{S}{^{\mbox{\tiny{init}}}}_{i+1}\right)^{-1} \ ,\end{split}
\end{equation*}
where \(\mathbf{K}_i\) and \(\mathbf{S}_i\) stand for the
density kernel and overlap matrix at MD step \(i\); and
\(\mathbf{T}_{i,(i+1)}\) is the overlap between the NGWFs at
MD step \(i\) and the \sphinxstyleemphasis{extrapolated} NGWFs at step
\((i+1)\).
\end{quote}
\end{quote}

Christoffel correction to the density kernel
\begin{quote}

\begin{DUlineblock}{0em}
\item[] While projecting the density kernel onto the extrapolated support
functions is appealing because of its conceptual simplicity, it
does not fully account for the tensorial character of the density
operator. As the support functions are extrapolated, the metric of
the representation manifold changes giving rise to non-vanishing
Christoffel symbols. In order to preserve tensorial integrity and
idempotency to first order, contributions from the Christoffel
symbols should be accounted for in the transformation of the
density kernel. The correction to the density kernel then reads,
\end{DUlineblock}
\begin{quote}
\begin{equation*}
\begin{split}\Delta \mathbf{K}{^{\mbox{\tiny{init}}}}_{(i+1)} = -\left(\mathbf{S}{^{\mbox{\tiny{scf}}}}_{i} \right)^{-1}\  \mathbf{D}_{(i+1),i}\ \mathbf{K}_{i} \ - \mathbf{K}_{i}\ \mathbf{D}_{i,(i+1)}\ \left(\mathbf{S}{^{\mbox{\tiny{scf}}}}_{i} \right)^{-1}\end{split}
\end{equation*}
with
\begin{equation*}
\begin{split}\left(\mathbf{D}_{(i+1),i}\right)_{\alpha \beta} = \left \langle (\phi{^{\mbox{\tiny{init}}}}_{(i+1)})_{\alpha} - (\phi{^{\mbox{\tiny{scf}}}}_{i})_{\alpha} \ \bigg| \  (\phi{^{\mbox{\tiny{scf}}}}_{i})_{\beta} \right \rangle \ .\end{split}
\end{equation*}\end{quote}
\end{quote}


\subsubsection{Extended Lagrangian propagation of density kernel schemes}
\label{\detokenize{BOMD:extended-lagrangian-propagation-of-density-kernel-schemes}}
Extended Lagrangian naïve approach
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The number of SCF iterations needed to reach a given threshold at
each step of the BOMD calculation can be significantly reduced by
the extrapolation schemes presented in sections {[}xtpol{]} and {[}dkn{]}.
However, those methods come with a caveat that has to be kept in
mind. While, with a perfect SCF optimization, the SCF ground-state
electronic structure is independent from the initial guess, in
practice, self-consistence is only achieve up to a given
threshold. The consequence of this \sphinxstyleemphasis{incomplete} convergence is
that the extrapolation schemes introduce a \sphinxstyleemphasis{memory} effect in the
simulation and break the time-reversibility of the BOMD algorithm.
As a consequence, the resulting trajectories suffers from
systematic error and a significant energy drift may appear on time
scales of a few picoseconds. A simple way to restore energy
conservation is to impose tighter SCF convergence thresholds.
However, this may results in a considerable increase of the
computational cost. Another solution has been proposed by
Niklasson et al. (see Ref. {[}Niklasson2006{]}). This
scheme restores the time-reversibility of BOMD by extending the BO
Lagrangian with auxilliary degrees of freedom directly associated
with \(\chi^0\), the initial guess of the electronic degrees
of freedom. The user is referred to
Refs. {[}Niklasson2006{]}, {[}Niklasson2009{]} for a complete
introduction to this formalism.
\end{DUlineblock}
\end{quote}

Extended Lagrangian with dissipation, dEL/SCF
\begin{quote}

\begin{DUlineblock}{0em}
\item[] A more stable propagation scheme for the density kernel has also
been proposed by Niklasson {[}Niklasson2009{]}. In
this scheme, the numerical errors arising from an incomplete
convergence are averaged out via a dissipative term in the
extended BO Lagrangian. Following
Bowler {[}Arita2014{]}, we propagate the orthogonal
representation \sphinxstylestrong{P} of the auxiliary density kernel, i.e. \sphinxstylestrong{P}
has the sparsity pattern of \sphinxstylestrong{KS} rather than of \sphinxstylestrong{K}, to avoid
the extra intricacies of propagating tensors in a space with
non-unitary metric. The dissipative term is defined in terms of a
linear combination of previous density kernels, which using the
symplectic Verlet algorithm, yields the following equation of
motion
\end{DUlineblock}
\begin{quote}
\begin{equation*}
\begin{split}\begin{aligned}
\mathbf{P}_{i+1} &= 2\mathbf{P}_{i} - \mathbf{P}_{i - 1} + \kappa[(\mathbf{KS}{^{\mbox{\tiny{scf}}}})_i - \mathbf{P}_{i}] \nonumber \\
 &&+ \,\alpha\sum_{m=0}^M c_m \mathbf{P}_{i-m}. \end{aligned}\end{split}
\end{equation*}
where \(\kappa\), \(\alpha\) and \(c_m\)’s are
optimized coefficients obtained from
Ref. {[}Niklasson2009{]}. The initial guess for the
density kernel is given by
\begin{equation*}
\begin{split}\mathbf{K}{^{\mbox{\tiny{init}}}}_{i+1} = \mbox{sym}(\mathbf{PS}^{-1}_{i+1}) = \frac{1}{2}[(\mathbf{PS}^{-1})_{i+1} + (\mathbf{S}^{-1}\mathbf{P})_{i+1}]\end{split}
\end{equation*}
The problem with the above mentioned scheme lays in the use of a
dissipative term that unavoidably breaks the time-reversibility,
which in turn will generate, over long simulation time, a drift in
the energy. However, for simulation time accessible at the moment
in AIMD, this issue is of little concern.
\end{quote}
\end{quote}

Extended Lagrangian with thermostat, inertial iEL/SCF
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Recently, a similar scheme that overcomes the issue of the time
breaking symmetry has been proposed {[}Albaugh2015{]}.
The idea is to control the dynamics of the auxiliary degrees of
freedom through a thermostat. One of the simplest yet efficient
thermostats around is the Berendsen thermostat. Here, we also
propagate the orthogonal representation of the auxiliary density
kernel for the same reasons listed in the previous section. The
equation of motion for the auxiliary density kernel, using a
velocity-Verlet integrator, reads
\end{DUlineblock}
\begin{quote}
\begin{equation*}
\begin{split}\begin{aligned}
\mathbf{P}_{i + 1} &= \mathbf{P}_{i} + \dot{\mathbf{P}}_{i}\Delta t + \omega^2{\Delta t}^2[(\mathbf{KS}){^{\mbox{\tiny{scf}}}}_i - \mathbf{P}_{i}]  \\
\dot{\mathbf{P}}_{i + 1} &= \gamma_i\dot{\widetilde{\mathbf{P}}}_{i + 1} \nonumber \\
 &= \gamma_i \{ \dot{\mathbf{P}}_{i} + \omega^2{\Delta t}/2[((\mathbf{KS}){^{\mbox{\tiny{scf}}}}_{i+1} - \mathbf{P}_{i + 1}) +  \nonumber \\
 &  ((\mathbf{KS}){^{\mbox{\tiny{scf}}}}_i - \mathbf{P}_i)] \}
 \end{aligned}\end{split}
\end{equation*}
with \(\gamma_i\) given by
\begin{equation*}
\begin{split}\gamma_i = \sqrt{1+\frac{\tau}{\Delta t}\left(\frac{T{_{\mbox{\tiny{K}}}}}{ \langle\dot{\mathbf{P}_{i}}^2}\rangle - 1\right)}\end{split}
\end{equation*}
where \(T{_{\mbox{\tiny{K}}}}\) is the target temperature,
\(\tau\) is the characteristic time of the thermostat, and
\(\langle\dot{\mathbf{P}_{i}}^2\rangle\) is the instantaneous
temperature of the auxiliary degrees of freedom. The key parameter
is the target temperature and much care must be done in assigning
a value for it.
\end{quote}
\end{quote}


\subsection{Extrapolation and propagation of NGWFs}
\label{\detokenize{BOMD:extrapolation-and-propagation-of-ngwfs}}
The main input parameters that
determine the extrapolation and propagation of NGWFs are
\sphinxcode{mix\_ngwfs\_type} and \sphinxcode{mix\_ngwfs\_num}. The localization function
\(F(r-r_{cut})\) used in the generalized version of the
multi-dimensional linear extrapolation (see Eq. {[}genxtpol2{]}.) is
characterized by the input parameters \sphinxcode{mix\_local\_length} and
\sphinxcode{mix\_local\_smear}.

\sphinxcode{mix\_ngwfs\_type} (String) (default = \sphinxcode{none})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] \sphinxcode{none} : No use of MD history. Initial NGWFs are built according to \sphinxcode{species\_atomic\_set} block.
\item[] \sphinxcode{reuse} : No mixing of NGWFs. NGWFs at previous MD step are used as initial guess.
\item[] \sphinxcode{linear} : One dimensional linear extrapolation from NGWFs at two previous MD steps (see Eq. \eqref{equation:BOMD:linxtpol1}).
\item[] \sphinxcode{multid} : Multi-dimensional linear extrapolation from NGWFs at previous MD steps (see Eqs. \eqref{equation:BOMD:multixtpol1} and \eqref{equation:BOMD:multixtpol2}). The dimension of the extrapolation space is determined by input parameter \sphinxcode{mix\_ngwfs\_num}.
\item[] \sphinxcode{poly} : One-dimensional polynomial extrapolation from NGWFs at previous steps (see Eqs. \eqref{equation:BOMD:genxtpol1}). The degree of the extrapolation   polynom is determined by input parameter \sphinxcode{mix\_ngwfs\_num}.
\item[] \sphinxcode{local} : Generalized multi-dimensional linear extrapolation from NGWFs at previous steps (see Eqs. \eqref{equation:BOMD:genxtpol1}). The dimension of the extrapolation space is determined by input parameter \sphinxcode{mix\_ngwfs\_num}. The localization radius is determine by input parameter \sphinxcode{mix\_local\_length}. Optionnally, the localization radius can be smeared out by using non-zero values for \sphinxcode{mix\_local\_smear}
\item[] \sphinxcode{trprop} : Time-reversible propagation of auxiliary NGWFs. See section on extended Lagrangian and references therein.
\end{DUlineblock}
\end{quote}

\sphinxcode{mix\_ngwfs\_num} (Integer) (default depends on \sphinxcode{mix\_ngwfs\_type})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Number of previous MD steps required to build the initial guess for the density kernel
\end{DUlineblock}
\end{quote}

\sphinxcode{mix\_loc\_length} (Physical) (default = \sphinxcode{10.0 bohr})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Cutoff radius of the localization function \(F(r-r_{cut})\), see Eq. \eqref{equation:BOMD:genxtpol2}
\end{DUlineblock}
\end{quote}

\sphinxcode{mix\_loc\_smear} (Physical) (default = \sphinxcode{5.0 bohr})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] When \sphinxcode{mix\_loc\_smear} is non-vanishing, the localization function \(F(r-r_{cut})\) is assumed to be Fermi-Dirac like with a characteristic smearing of \sphinxcode{mix\_loc\_smear}.
\end{DUlineblock}
\end{quote}


\subsection{Extrapolation and transformation of density kernel}
\label{\detokenize{BOMD:extrapolation-and-transformation-of-density-kernel}}
The main input
parameters that determine the extrapolation, transformation and
propagation schemes for the density kernel and NGWFs are respectively
\sphinxcode{mix\_dkn\_type} and \sphinxcode{mix\_dkn\_num}.

\sphinxcode{mix\_dkn\_type} (String) (default = \sphinxcode{none})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] \sphinxcode{none} : No use of MD history. Initial density kernel is built according to \sphinxcode{coreham\_denskern\_guess} parameter.
\item[] \sphinxcode{reuse} : No kernel mixing. SCF density kernel at previous MD step is used as initial guess.
\item[] \sphinxcode{linear} : One dimensional linear extrapolation from density kernel at two previous MD steps (see Eq. \eqref{equation:BOMD:linxtpol1}).
\item[] \sphinxcode{multid} : Multi-dimensional linear extrapolation from density kernel at previous MD steps (see Eqs. \eqref{equation:BOMD:multixtpol1} and \eqref{equation:BOMD:multixtpol2}). The dimension of the extrapolation space is determined by \sphinxcode{mix\_dkn\_num}.
\item[] \sphinxcode{poly} : One-dimensional polynomial extrapolation from density kernel at previous steps (see Eqs. \eqref{equation:BOMD:genxtpol1}). The degree of the extrapolation polynom is determined by \sphinxcode{mix\_dkn\_num}.
\item[] \sphinxcode{proj} : Projection of the previous SCF density kernel onto the set of extrapolated NGWFs. This option requires \sphinxcode{mix\_ngwfs\_type} \(\neq\) none.
\item[] \sphinxcode{tensor} : Correction of the previous SCF density kernel in order to preserve tensorial integrity. This option requires \sphinxcode{mix\_ngwfs\_type} \(\neq\) none.
\item[] \sphinxcode{trprop} : Naïve time-reversible propagation of auxiliary density kernel. See section on extended Lagrangian and references therein.
\item[] \sphinxcode{dissip} : Dissipative propagation of auxiliary density kernel. See section on extended Lagrangian and references therein. The number of previous MD steps used for the derivation of the dissipative force is determined by \sphinxcode{mix\_dkn\_num}.
\item[] \sphinxcode{berendsen} : Thermostatted propagation of auxiliary density kernel with Berendsen thermostat. See section on extended Lagrangian and references therein. The target temperature for the thermostat is set by \sphinxcode{md\_aux\_dkn\_t} and the characteristic time constant \(\tau\) by \sphinxcode{md\_aux\_beren\_tc}.
\end{DUlineblock}
\end{quote}

\sphinxcode{mix\_dkn\_num} (Integer) (default depends on \sphinxcode{mix\_dkn\_type})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Number of previous MD steps required to build the initial guess for the density kernel.
\end{DUlineblock}
\end{quote}

\sphinxcode{mix\_aux\_dkn\_t} (Physical) (default = \sphinxcode{1e-8})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Target temperature of the auxiliary degrees of freedom to use in the Berendsen propagation of the density kernel.
\end{DUlineblock}
\end{quote}

\sphinxcode{mix\_aux\_beren\_tc} (Physical) (default = \sphinxcode{0.1 ps})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Characteristic time constant for the Berendsen thermostat to use in the Berensen propagation of the density kernel.
\end{DUlineblock}
\end{quote}


\subsection{Additional notes on extrapolation and propagation}
\label{\detokenize{BOMD:additional-notes-on-extrapolation-and-propagation}}
Most of the
extrapolation and propagation schemes suffer from restricted stability
under incomplete SCF convergence. Depending on the convergence
parameters, significant discrepancies between the MD trajectories and
the Born-Oppenheimer surface may arise during the first few MD
iterations. In this case, it is recommended not to use the extrapolation
and propagation schemes until a good level of SCF convergence is
reached. The input parameters \sphinxcode{mix\_ngwfs\_init\_type} and
\sphinxcode{mix\_ngwfs\_init\_num} allows to set up a smooth initialization phase.
It is also possible to have a different (usually tighter) thresholds
during this initialization phase. In fact, the usual
\sphinxcode{lnv\_threshold\_orig} and \sphinxcode{ngwf\_threshold\_orig} are used to set the
LNV and NGWFs gradient thresholds during the intialization phase, while
the two keywords \sphinxcode{md\_lnv\_threshold} and \sphinxcode{md\_ngwf\_threshold}
determine the LNV threshold and NGWFs gradient threshold for the
remaining MD calculation.

It is also possible to periodically reset the MD history using
\sphinxcode{mix\_ngwfs\_reset}, \sphinxcode{mix\_dkn\_reset} and \sphinxcode{md\_reset\_history},
although this is not recommended if one wants to avoid jumps into the
energy profile, i.e. avoid discontinuities in energy plots.

\sphinxcode{md\_reset\_history} (Integer) (default = \sphinxcode{100})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Every n MD steps, new initial guesses for the electronic degrees of freedom are built according to \sphinxcode{coreham\_denskern\_guess} and \sphinxcode{species\_atomic\_set}.
\end{DUlineblock}
\end{quote}

\sphinxcode{mix\_ngwfs\_reset} (Integer) (default = \sphinxcode{50})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Every n MD steps, the NGWFs mixing/extrapolation scheme is reset and a new initial guess for the NGWFs is built according to \sphinxcode{species\_atomic\_set}.
\end{DUlineblock}
\end{quote}

\sphinxcode{mix\_dkn\_reset} (Integer) (default = \sphinxcode{50})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Every n MD steps, the density kernel mixing/extrapolation scheme is reset and a new initial guess for the kernel is built according to \sphinxcode{coreham\_denskern\_guess}.
\end{DUlineblock}
\end{quote}

\sphinxcode{mix\_ngwfs\_init\_num} (Integer) (default = \sphinxcode{0})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Length of the initialization phase. Number of MD steps before the activation of the extrapolation/propagation scheme for building NGWF initial guesses.
\end{DUlineblock}
\end{quote}

\sphinxcode{mix\_ngwfs\_init\_type} (String) (default = \sphinxcode{none})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] \sphinxcode{none} : During the initialization phase, initial NGWFs are built according to \sphinxcode{species\_atomic\_set} block.
\item[] \sphinxcode{reuse} : During the initialization phase, NGWFs at last MD step is used as initial guess.
\end{DUlineblock}
\end{quote}

\sphinxcode{mix\_dkn\_init\_num} (Integer) (default = 0)
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Length of the initialization phase. Number of MD steps before the activation of the extrapolation/propagation scheme for building density kernel initial guesses.
\end{DUlineblock}
\end{quote}

\sphinxcode{mix\_dkn\_init\_type} (String) (default = \sphinxcode{none})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] \sphinxcode{none} : During the initialization phase, initial density kernels are built according to \sphinxcode{coreham\_denskern\_guess}.
\item[] \sphinxcode{reuse} : During the initialization phase, density kernel at last MD step is used as initial guess.
\end{DUlineblock}
\end{quote}

\sphinxcode{md\_lnv\_threshold} (Double) (default = \sphinxcode{lnv\_threshold\_orig})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] LNV threshold for the MD calculation. This can be set to be different from the initial LNV threshold \sphinxcode{lnv\_threshold\_orig} of the first n steps (set by \sphinxcode{mix\_ngwfs\_init\_num} / \sphinxcode{mix\_dkn\_init\_num}).
\end{DUlineblock}
\end{quote}

\sphinxcode{md\_ngwf\_threshold} (Double) (default = \sphinxcode{ngwf\_threshold\_orig})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] NGWF gradient threshold for the MD calculation. This can be set to be different from the initial NGWF gradient threshold \sphinxcode{ngwf\_threshold\_orig} of the first n steps (set by \sphinxcode{mix\_ngwfs\_init\_num} / \sphinxcode{mix\_dkn\_init\_num}).
\end{DUlineblock}
\end{quote}


\subsection{Additional notes on restart when using a propagation scheme}
\label{\detokenize{BOMD:additional-notes-on-restart-when-using-a-propagation-scheme}}
If a
“history” of NGWFs/density kernels is generated during a MD calculation
it can be periodically saved into external files through the keyword
\sphinxcode{md\_write\_history}. More precisely, when using
\sphinxcode{md\_write\_history = T} all the information about the dynamical state
(positions, velocities and accelerations), the thermostat state, and the
propagation scheme is saved to external files as well. To restart a MD
calculation by reading in the history from the last save the
\sphinxcode{md\_global\_restart} keyword must be set to true in the restart input
file. On a restart, one can either use the thermostat state stored in
\sphinxcode{rootname.thermo.global.restart} or start with a new thermostat block.
This is achieved by setting the \sphinxcode{md\_restart\_thermo} keyword.

\sphinxcode{md\_write\_history} (Integer) (default = \sphinxcode{-1})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Every n MD steps the history of auxiliary density kernels is written into external files \sphinxcode{rootname.history.dkn\#.scf/init/vel} (one of each kind for any element in the history). The info on the dynamical state, the thermostat, the propagation scheme and the composition method are saved into \sphinxcode{rootname.md.global.restart}, \sphinxcode{rootname.md.thermo.restart}, \sphinxcode{rootname.history.info} and \sphinxcode{rootname.history.var} respectively.
\end{DUlineblock}
\end{quote}

\sphinxcode{md\_global\_restart} (Logical) (default = \sphinxcode{F})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] MD global restart. This allows to restart a calculation by reading in a history of density kernels if present. \sphinxcode{md\_restart} is set to false.
\end{DUlineblock}
\end{quote}

\sphinxcode{md\_restart\_thermo} (Logical) (default = \sphinxcode{T})
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Read thermostat info from file. If set to false, the thermostat is set according to the thermostat block in the input file.
\end{DUlineblock}
\end{quote}

WARNING: Restarting a calculation with \sphinxcode{md\_global\_restart = T} comes
with a caveat: depending on the value of \sphinxcode{md\_write\_history} the last
batch of NGWFs/density kernels saved to files may not correspond to the
NGWFs/density kernels history of the last MD step completed. However,
the calculation restarts using the information stored in the
\sphinxcode{rootname.history.info} and \sphinxcode{rootname.history.var}. As a result,
there might be duplicated entries in the \sphinxcode{rootname.md} file which has
to be deleted manually by the user.

For example, let’s consider the following scenario

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{MD\PYGZus{}NUM\PYGZus{}ITER}      \PYG{p}{:} \PYG{l+m+mi}{124}
\PYG{n}{MD\PYGZus{}WRITE\PYGZus{}HISTORY} \PYG{p}{:} \PYG{l+m+mi}{10}
\end{sphinxVerbatim}

where we save a history of density kernels every 10 MD steps and the
simulation stops after 124 steps. The last batch of density kernels
(together with all the other MD info) is saved at step 120, but the
summary of the trajectory from step 121-124 is still appended to
\sphinxcode{rootname.md}. When restarting with \sphinxcode{md\_global\_restart = T}, the
code reads in the files \sphinxcode{rootname.history.info} and
\sphinxcode{rootname.history.var} containing the info corresponding to step 120
and starts to append the trajectory info to \sphinxcode{rootname.md}. As a
result, the summary of the trajectory from step 121-124 in the
\sphinxcode{rootname.md} is duplicated.

{[}Skylaris2005{]} C.-K. Skylaris et al., J. Chem. Phys. \sphinxstylestrong{122}, 084119 (2005).

{[}Frenkel2001{]} \sphinxstyleemphasis{Understanding Molecular Simulation}, 2nd Ed. D. Frenkel and B. Smit,Academic Press (2001)

{[}Verlet1967{]} L. Verlet, Phys. Rev. \sphinxstylestrong{159}, 98 (1967).

{[}Swope1982{]} W. C. Swope et al., J. Chem. Phys. \sphinxstylestrong{76}, 637 (1982).

{[}Andersen1980{]} H. C. Andersen, J. Chem. Phys. \sphinxstylestrong{72}, 2384 (1980).

{[}Grest1986{]} G. S. Grest and K. Kremer, Phys. Rev. A, \sphinxstylestrong{33} 3628 (1986).

{[}Nose1984{]} S. Nose, J. Chem. Phys., \sphinxstylestrong{81} 511 (1984).

{[}Hoover1985{]} W. G. Hoover, Phys. Rev. A, \sphinxstylestrong{31} 1695 (1985).

{[}Bussi2007{]} G. Bussi et al., J. Chem. Phys., \sphinxstylestrong{126} 014101 (2007).

{[}Martyna1996{]} G. J. Martyna, M.E. Tuckerman, et al., Molecular Physics \sphinxstylestrong{87}, 1117 (1996).

{[}Arias1992{]} T. A. Arias et al., Phys. Rev. B, \sphinxstylestrong{45}, 1538 (1992).

{[}Niklasson2006{]} A. M. N. Niklasson et al., Phys. Rev. Lett. \sphinxstylestrong{97}, 123001 (2006).

{[}Niklasson2009{]} A. M. N. Niklasson et al., J. Chem. Phys. \sphinxstylestrong{130}, 214109 (2009).

{[}Hunenberger2005{]} P. H. Hünenberger, Advanced Computer Simulation \sphinxstylestrong{173}, 105-109 (2005).

{[}Arita2014{]} M Arita et al., J. Chem. Theory Comput., \sphinxstylestrong{10}, 5419-5425 (2014)

{[}Albaugh2015{]} A. Albaugh et al, J. Chem. Phys., \sphinxstylestrong{143}, 174104 (2015)


\section{Phonon calculations}
\label{\detokenize{phonons::doc}}\label{\detokenize{phonons:phonon-calculations}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Fabiano Corsetti, Imperial College London

\item[{Date}] \leavevmode
September, 2013

\end{description}\end{quote}


\subsection{Theory}
\label{\detokenize{phonons:theory}}
We make use of the harmonic approximation, in which the total energy of
the system \(E^\mathrm{tot}\) is expanded to quadratic order in the
displacement of the ions about their equilibrium positions:
\begin{equation*}
\begin{split}E^\mathrm{tot} = E^\mathrm{eq} + \frac{1}{2} \sum_{a,\alpha,\kappa,a',\alpha',\kappa'} u_{a,\alpha,\kappa} \phi_{\kappa,\kappa'}^{\alpha,\alpha'} \left ( a,a' \right ) u_{a',\alpha',\kappa'},\end{split}
\end{equation*}
where \(E^\mathrm{eq}\) is the equilibrium energy and
\(u_{a,\alpha,\kappa}\) denotes a small displacement of ion
\(\alpha\) belonging to unit cell \(a\) in the Cartesian
coordinate direction \(\kappa\) from its equilibrium position;
\(\boldsymbol{\phi} \left ( a,a' \right )\) is known as the force
constants matrix, defined as
\begin{equation*}
\begin{split}\phi_{\kappa,\kappa'}^{\alpha,\alpha'} \left ( a,a' \right ) = \frac{\partial^2 E}{\partial u_{a,\alpha,\kappa} \partial u_{a',\alpha',\kappa'}}.\end{split}
\end{equation*}
It can be shown that the phonon frequencies
\(\omega_{\mathbf{q},n}\) at wavevector \(\mathbf{q}\) are the
eigenvalues of the dynamical matrix
\(\mathbf{D} \left ( \mathbf{q} \right )\), which can be calculated
from the Fourier transform of the force constants matrix:

\phantomsection\label{\detokenize{phonons:equation-dynamical-mat}}\begin{equation}\label{equation:phonons:dynamical_mat}
\begin{split}D_{\kappa,\kappa'}^{\alpha,\alpha'} \left ( \mathbf{q} \right ) = \frac{1}{\sqrt{M_\alpha M_{\alpha'}}} \sum_a \phi_{\kappa,\kappa'}^{\alpha,\alpha'} \left ( a,0 \right ) \mathrm{e}^{-\mathrm{i} \mathbf{q} \cdot \mathbf{R}_a},\end{split}
\end{equation}
where \(M_\alpha\) is the mass of ion \(\alpha\) and
\(\mathbf{R}_a\) is the lattice vector displacement for unit cell
\(a\). The vibrational free energy for the unit cell is then given
by

\phantomsection\label{\detokenize{phonons:equation-free-energy}}\begin{equation}\label{equation:phonons:free_energy}
\begin{split}F \left ( T \right ) = \frac{1}{2} \sum_{\mathbf{q},n} \omega_{\mathbf{q},n} + k_\mathrm{B} T \sum_{\mathbf{q},n} \ln{\left ( 1-\mathrm{e}^{-\omega_{\mathbf{q},n}/k_\mathrm{B} T} \right )},\end{split}
\end{equation}
where the first term is the zero-point energy of the system, and the
second term is the temperature-dependent part of the free energy. In the
limit of an infinite periodic system the sum over \(\mathbf{q}\)
should be replaced by an integral of the phonon dispersion curves over
the first Brillouin zone.

The \sphinxcode{phonon} module in onetep uses the \sphinxstyleemphasis{finite-displacement} method to
calculate the phonon frequencies of the system; for molecules (the
default), only the \(\Gamma\)-point frequencies
\(\omega_{\mathbf{0},n}\) are calculated, while for supercells of
bulk crystal, any arbitrary q point \(\omega_{\mathbf{q},n}\) can be
calculated. The elements of the force constants matrix are calculated by
a central-difference formula, using either 2 (the default) or 4
displacements:

\phantomsection\label{\detokenize{phonons:equation-fd}}\begin{equation}\label{equation:phonons:fd}
\begin{split}\begin{cases}
\phi_{\kappa,\kappa'}^{\alpha,\alpha'} \approx \frac{F_{\alpha,\kappa}^+ - F_{\alpha,\kappa}^-}{2d} & \text{\texttt{phonon\_sampling 1} (2 disps.)} \\
\phi_{\kappa,\kappa'}^{\alpha,\alpha'} \approx \frac{- F_{\alpha,\kappa}^{2+} + 8 F_{\alpha,\kappa}^+ - 8 F_{\alpha,\kappa}^- + F_{\alpha,\kappa}^{2-}}{12d} & \text{\texttt{phonon\_sampling 2} (4 disps.)}
\end{cases},\end{split}
\end{equation}
where \(F_{\alpha,\kappa}^\pm\) is the force on ion \(\alpha\)
in direction \(\kappa\) caused by a displacement \(\pm d\) of
ion \(\alpha'\) in direction \(\kappa'\), and
\(F_{\alpha,\kappa}^{2\pm}\) is the same for a displacement
\(\pm 2d\). Therefore, \(6N\)/\(12N\) calculations are
needed in total, where \(N\) is the number of atoms in the system.
However, each of these calculations is simply a small perturbation on
the equilibrium configuration. Therefore, the converged set of NGWFs
\(\left \{ \xi_\beta \left ( \mathbf{r} \right ) \right \}\) and
density kernel \(\mathbf{K}\) that are obtained from a preliminary
ground-state calculation on the equilibrium structure are used as the
starting guess for each of the displacement calculations.


\subsection{Overview of the \sphinxstyleliteralintitle{phonon} module}
\label{\detokenize{phonons:overview-of-the-phonon-module}}
A phonon calculation in onetep is divided into three stages:
\begin{enumerate}
\item {} 
A ground-state calculation is performed for the unperturbed
configuration, as specified in the input file. The forces on the ions
are then calculated, and the code checks that the magnitude of the
force on every ion is smaller than the value specified by
\sphinxcode{phonon\_fmax}, as the starting configuration must correspond to a
minimum in the energy landscape for the phonon calculation to be
meaningful. If this requirement is not met, the calculation is
interrupted.

\item {} 
Each ion is displaced in turn in the \(+\)ve and \(-\)ve
x-, y-, and z-directions by a distance \(d\) (and, optionally,
\(2d\)). For each displacement a separate ground-state
calculation is performed. The initial description of the electronic
structure is read in each time from the converged files
\sphinxcode{\textless{}seedname\textgreater{}.dkn} and \sphinxcode{\textless{}seedname\textgreater{}.tightbox\_ngwfs} for the
unperturbed structure that have been obtained from Stage 1; the
overwriting of these files is therefore disabled at the start of
Stage 2. After each set of \(+\)ve/\(-\)ve
displacements, one row of the force constants matrix is calculated
and written to the file \sphinxcode{\textless{}seedname\textgreater{}.force\_consts\_\textless{}i\textgreater{}}, where
\sphinxcode{\textless{}i\textgreater{}} is the number identifier of the row (going from 1 to
\(3N\) for an \(N\)-atom system). It is important to note
that \sphinxstyleemphasis{not all rows are necessarily computed}, if some vibrational
degrees of freedom are switched off (see section on selecting degrees of freedom below), and/or a
supercell calculation of bulk crystal is being performed
(see section on supercell calculations below); however, \sphinxcode{\textless{}i\textgreater{}} retains the same value as it
would have if all \(3N\) rows were to be used.

\item {} 
The rows of the force constants matrix are read back in from the
files \sphinxcode{\textless{}seedname\textgreater{}.force\_consts\_\textless{}i\textgreater{}}, and the full force constants
matrix is constructed. The dynamical matrix can then be calculated
for the desired q points and diagonalized to find the phonon
frequencies. First, the phonon frequencies are calculated on a
regular grid of q points (\(\Gamma\) only for a molecule); in
either case, the \(\Gamma\)-point frequencies only are printed to
standard output. Then, the following thermodynamic quantities are
calculated on the full grid and printed to standard output: the
zero-point energy, and the free energy, entropy, internal energy, and
specific heat within a user-specified temperature range. The phonon
DOS is also calculated on the full grid and written to the file
\sphinxcode{\textless{}seedname\textgreater{}.qdos}. Additionally, the user can specify a list of
arbitrary q points, for which the phonon frequencies (and,
optionally, the corresponding eigenvectors) are calculated and
written to the file \sphinxcode{\textless{}seedname\textgreater{}.phonon\_freqs}. Finally, a list of
\(\Gamma\)-point modes \sphinxcode{\textless{}j\textgreater{}} can be specified for which
animation files \sphinxcode{\textless{}seedname\textgreater{}.phonon\_\textless{}j\textgreater{}.xyz} are written.

\end{enumerate}

This division in stages is done so as to allow for a \sphinxstyleemphasis{task farming}
approach (see section on task farming for details).


\subsection{Selecting degrees of freedom}
\label{\detokenize{phonons:selecting-degrees-of-freedom}}

\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstylethead{\sphinxstyletheadfamily 
\sphinxcode{phonon\_vib\_free}
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
x
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
y
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
z
\unskip}\relax \\
\hline
\sphinxcode{0}
&
\sphinxcode{F}
&
\sphinxcode{F}
&
\sphinxcode{F}
\\
\hline
\sphinxcode{1}
&
\sphinxcode{T}
&
\sphinxcode{F}
&
\sphinxcode{F}
\\
\hline
\sphinxcode{2}
&
\sphinxcode{F}
&
\sphinxcode{T}
&
\sphinxcode{F}
\\
\hline
\sphinxcode{3}
&
\sphinxcode{T}
&
\sphinxcode{T}
&
\sphinxcode{F}
\\
\hline
\sphinxcode{4}
&
\sphinxcode{F}
&
\sphinxcode{F}
&
\sphinxcode{T}
\\
\hline
\sphinxcode{5}
&
\sphinxcode{T}
&
\sphinxcode{F}
&
\sphinxcode{T}
\\
\hline
\sphinxcode{6}
&
\sphinxcode{F}
&
\sphinxcode{T}
&
\sphinxcode{T}
\\
\hline
\sphinxcode{7}
&
\sphinxcode{T}
&
\sphinxcode{T}
&
\sphinxcode{T}
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Table: Allowed options for keyword \sphinxcode{phonon\_vib\_free}.

The input file allows the user to select only a subset of the complete
vibrational degrees of freedom of the entire system, as well as to
specify different finite-displacement options for each
\(\left ( \alpha, \kappa \right )\) pair. This is controlled through
two keywords: \sphinxcode{phonon\_vib\_free} and \sphinxcode{phonon\_exception\_list}.

\sphinxcode{phonon\_vib\_free} is an integer parameter controlling the global
default of which Cartesian directions are ‘switched on’ for all ions.
The options are listed in Table {[}table:free{]}. The default option is
\sphinxcode{7}, corresponding to all three Cartesian directions being switched on
(i.e., all vibrational degrees of freedom are allowed).

\sphinxcode{phonon\_exception\_list} is a block in which the user can list specific
\(\left ( \alpha, \kappa \right )\) pairs with options differing
from the global defaults defined by \sphinxcode{phonon\_vib\_free},
\sphinxcode{phonon\_sampling}, and \sphinxcode{phonon\_finite\_disp}. An example of doing so
is as follows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{phonon\PYGZus{}vib\PYGZus{}free} \PYG{l+m+mi}{3}
\PYG{n}{phonon\PYGZus{}sampling} \PYG{l+m+mi}{1}
\PYG{n}{phonon\PYGZus{}finite\PYGZus{}disp} \PYG{l+m+mf}{1.4e\PYGZhy{}1} \PYG{n}{bohr}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{phonon\PYGZus{}exception\PYGZus{}list}
\PYG{l+m+mi}{10} \PYG{l+m+mi}{3} \PYG{l+m+mi}{1} \PYG{l+m+mi}{2} \PYG{l+m+mf}{0.9}
\PYG{l+m+mi}{15} \PYG{l+m+mi}{1} \PYG{l+m+mi}{0} \PYG{l+m+mi}{1} \PYG{l+m+mf}{1.0}
\PYG{l+m+mi}{36} \PYG{l+m+mi}{2} \PYG{l+m+mi}{0} \PYG{l+m+mi}{1} \PYG{l+m+mf}{1.0}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{phonon\PYGZus{}exception\PYGZus{}list}
\end{sphinxVerbatim}

Here, we have first defined the global defaults; \sphinxcode{phonon\_vib\_free 3}
corresponds to only the x- and y-directions being selected for the
calculation, and the z-direction being switched off. Then, in the
\sphinxcode{phonon\_exception\_list} block, we list three exceptions:
\begin{itemize}
\item {} 
displacement of ion \sphinxcode{10} in the z-direction (\sphinxcode{3}) is switched on
(\sphinxcode{1}), with a value of \sphinxcode{phonon\_sampling} of \sphinxcode{2}, and a value of
\sphinxcode{phonon\_finite\_disp} of \sphinxcode{0.9} \(\times\) the global value
(i.e., \sphinxcode{1.26e-1 bohr});

\item {} 
displacement of ion \sphinxcode{15} in the x-direction (\sphinxcode{1}) is switched off
(\sphinxcode{0}), with the last two parameters not being read;

\item {} 
displacement of ion \sphinxcode{36} in the y-direction (\sphinxcode{2}) is switched off
(\sphinxcode{0}), with the last two parameters not being read.

\end{itemize}


\subsection{Bulk crystal supercell calculations}
\label{\detokenize{phonons:bulk-crystal-supercell-calculations}}
Phonon calculations for crystalline systems can be performed in onetep
using a supercell approach, with either a real-space truncation of the
force constants matrix, or a Slater-Koster style interpolation. The size
of the supercell is chosen by the user; obviously, larger supercells
will produce more accurate results at arbitrary q points.

It is the responsability of the user to provide the correct supercell
lattice vectors and atomic coordinates in the usual way. Additionally,
the \sphinxcode{supercell} block must be specified to inform the \sphinxcode{phonon}
module that the system is a supercell of bulk material; otherwise, it
will be assumed to be a molecule. An example of doing so is as follows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{lattice\PYGZus{}cart}
\PYG{n}{ang}
\PYG{l+m+mf}{5.3938105} \PYG{l+m+mf}{5.3938105} \PYG{l+m+mf}{0.0000000}
\PYG{l+m+mf}{5.3938105} \PYG{l+m+mf}{0.0000000} \PYG{l+m+mf}{5.3938105}
\PYG{l+m+mf}{0.0000000} \PYG{l+m+mf}{5.3938105} \PYG{l+m+mf}{5.3938105}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{lattice\PYGZus{}cart}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{positions\PYGZus{}abs}
\PYG{n}{ang}
\PYG{n}{Si} \PYG{l+m+mf}{0.000000000} \PYG{l+m+mf}{0.000000000} \PYG{l+m+mf}{0.000000000}
\PYG{n}{Si} \PYG{l+m+mf}{0.000000000} \PYG{l+m+mf}{2.696905250} \PYG{l+m+mf}{2.696905250}
\PYG{n}{Si} \PYG{l+m+mf}{2.696905250} \PYG{l+m+mf}{0.000000000} \PYG{l+m+mf}{2.696905250}
\PYG{n}{Si} \PYG{l+m+mf}{2.696905250} \PYG{l+m+mf}{2.696905250} \PYG{l+m+mf}{5.393810500}
\PYG{n}{Si} \PYG{l+m+mf}{2.696905250} \PYG{l+m+mf}{2.696905250} \PYG{l+m+mf}{0.000000000}
\PYG{n}{Si} \PYG{l+m+mf}{2.696905250} \PYG{l+m+mf}{5.393810500} \PYG{l+m+mf}{2.696905250}
\PYG{n}{Si} \PYG{l+m+mf}{5.393810500} \PYG{l+m+mf}{2.696905250} \PYG{l+m+mf}{2.696905250}
\PYG{n}{Si} \PYG{l+m+mf}{5.393810500} \PYG{l+m+mf}{5.393810500} \PYG{l+m+mf}{5.393810500}
\PYG{n}{Si} \PYG{l+m+mf}{1.348452625} \PYG{l+m+mf}{1.348452625} \PYG{l+m+mf}{1.348452625}
\PYG{n}{Si} \PYG{l+m+mf}{1.348452625} \PYG{l+m+mf}{4.045357875} \PYG{l+m+mf}{4.045357875}
\PYG{n}{Si} \PYG{l+m+mf}{4.045357875} \PYG{l+m+mf}{1.348452625} \PYG{l+m+mf}{4.045357875}
\PYG{n}{Si} \PYG{l+m+mf}{4.045357875} \PYG{l+m+mf}{4.045357875} \PYG{l+m+mf}{6.742263125}
\PYG{n}{Si} \PYG{l+m+mf}{4.045357875} \PYG{l+m+mf}{4.045357875} \PYG{l+m+mf}{1.348452625}
\PYG{n}{Si} \PYG{l+m+mf}{4.045357875} \PYG{l+m+mf}{6.742263125} \PYG{l+m+mf}{4.045357875}
\PYG{n}{Si} \PYG{l+m+mf}{6.742263125} \PYG{l+m+mf}{4.045357875} \PYG{l+m+mf}{4.045357875}
\PYG{n}{Si} \PYG{l+m+mf}{6.742263125} \PYG{l+m+mf}{6.742263125} \PYG{l+m+mf}{6.742263125}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{positions\PYGZus{}abs}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{supercell}
\PYG{l+m+mi}{2} \PYG{l+m+mi}{2} \PYG{l+m+mi}{2}
\PYG{l+m+mi}{1}
\PYG{l+m+mi}{9}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{supercell}
\end{sphinxVerbatim}

Within the \sphinxcode{supercell} block, the first line gives the shape of the
supercell (\sphinxcode{2}\(\times\)\sphinxcode{2}\(\times\)\sphinxcode{2}), and
subsequent lines list the ions in the \sphinxcode{positions\_abs} block that
belong to the ‘base’ unit cell (of course, this supercell is too small
to give sensible results for a phonon calculation, and is probably too
small to run in onetep anyway; a 1000-atom cubic supercell of Si gives
excellent results however!)

When a supercell calculations is specified, only the ions within the
unit cell are displaced, although the forces on all ions in the system
are used to calculate the elements of the dynamical matrix from
Eq. eq:\sphinxtitleref{dynamical\_mat}. It is also possible to specify
\sphinxcode{phonon\_vib\_free} and \sphinxcode{phonon\_exception\_list} in a supercell
calculation, although only the ions listed in the \sphinxcode{supercell} block
can be included in the \sphinxcode{phonon\_exception\_list} block.


\subsection{Task farming}
\label{\detokenize{phonons:task-farming}}
The most efficient way of performing a phonon calculation is by task
farming, as the full force constants matrix is built up from many
perturbed-structure calculations, each of which is completely
independent. This can be done with the following steps:
\begin{enumerate}
\item {} 
Run \sphinxcode{phonon\_farming\_task 1} as a single job; this is essentially a
standard single-point energy-and-force onetep calculation. Find the
line in the main output file which gives the
\sphinxcode{Number of force constants} needed for the phonon calculation you
have specified (this will be between 1 and \(3N\)).

\item {} 
Divide the total number of force constants that need to be calculated
between the desired number of jobs. Prepare the onetep input file for
each job specifying \sphinxcode{phonon\_farming\_task 2} and a subset of the
force constant calculations in the \sphinxcode{phonon\_disp\_list} block. Make
sure every job has access to the files \sphinxcode{\textless{}seedname\textgreater{}.dkn} and
\sphinxcode{\textless{}seedname\textgreater{}.tightbox\_ngwfs} obtained from the unperturbed
calculation in the previous step.

\item {} 
Collect all the \sphinxcode{\textless{}seedname\textgreater{}.force\_consts\_\textless{}i\textgreater{}} files and place them
in the same directory. Finally, run \sphinxcode{phonon\_farming\_task 3} as a
single job, to construct the full force constants matrix and perform
the post-processing calculations.

\end{enumerate}


\subsection{Keywords}
\label{\detokenize{phonons:keywords}}
The phonon calculation is selected by specifying \sphinxcode{task phonon}. All
other keywords related to the module are optional. They are:
\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_farming\_task} {[}Integer{]}
\item[] Select which stage to perform (as described in Sec. {[}sec:farm{]}).
Can be either \sphinxcode{1}, \sphinxcode{2}, \sphinxcode{3} for a single stage, or \sphinxcode{0} for
all stages. Default is \sphinxcode{0}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_sampling} {[}Integer{]}
\item[] Finite-difference formula to use (see Eq. eq:\sphinxtitleref{fd}). Default is
\sphinxcode{1}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_finite\_disp} {[}Physical{]}
\item[] Ionic displacement distance \(d\). Default is \sphinxcode{1.0e-1 bohr}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_fmax} {[}Physical{]}
\item[] Maximum ionic force allowed in the unperturbed system. Default is
\sphinxcode{5.0e-3 ha/bohr}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_energy\_check} {[}Logical{]}
\item[] Perform a sanity check that the total energy doesn’t decrease upon
ionic displacement. Default is \sphinxcode{F}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_vib\_free} {[}Integer{]}
\item[] Default allowed vibrational degrees of freedom for all ions (see
Sec. {[}sec:free{]} for details). Default is \sphinxcode{7}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_exception\_list} {[}Block{]}
\item[] List of exceptions to the global defaults defined by
\sphinxcode{phonon\_vib\_free}, \sphinxcode{phonon\_sampling}, and
\sphinxcode{phonon\_finite\_disp} (see Sec. {[}sec:free{]} for details). Default
is unspecified.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{supercell} {[}Block{]}
\item[] Definition of the supercell used for crystalline material (see
Sec. {[}sec:supercell{]} for details). Default is unspecified.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_disp\_list} {[}Block{]}
\item[] List of force constant calculations to perform for Stage 2. Note
that the total number of force constant calculations is given in
the main output file in the line \sphinxcode{Number of force constants};
this will be less than or equal to \(3N\). The numbers listed
in the \sphinxcode{phonon\_disp\_list} block should go from 1 to this number;
\sphinxstyleemphasis{they can only be equated to the label} \sphinxcode{\textless{}i\textgreater{}} \sphinxstyleemphasis{if all} \(3N\)
\sphinxstyleemphasis{force constants are calculated}. If unspecified, all displacements
are performed. Default is unspecified. Example:
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{phonon\PYGZus{}disp\PYGZus{}list}
\PYG{l+m+mi}{1}
\PYG{l+m+mi}{3}
\PYG{l+m+mi}{5}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{phonon\PYGZus{}disp\PYGZus{}list}
\end{sphinxVerbatim}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_grid} {[}Block{]}
\item[] Definition of the regular grid of q points used for the computation
of thermodynamic quantities and the phonon DOS. Default is
\sphinxcode{1 1 1} (i.e., \(\Gamma\) point only). Example:
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{phonon\PYGZus{}grid}
\PYG{l+m+mi}{10} \PYG{l+m+mi}{10} \PYG{l+m+mi}{10}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{phonon\PYGZus{}grid}
\end{sphinxVerbatim}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_SK} {[}Logical{]}
\item[] Use a Slater-Koster style interpolation for q points instead of a
real-space cutoff of the force constants matrix elements. Default
is \sphinxcode{F}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_tmin} {[}Physical{]}
\item[] Lower bound of the temperature range for the computation of
thermodynamic quantities, expressed as an energy
(\(k_\mathrm{B} T\)). Default is \sphinxcode{0.0 hartree}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_tmax} {[}Physical{]}
\item[] Upper bound of the temperature range for the computation of
thermodynamic quantities. Default is \sphinxcode{2.0e-3 hartree}
(\(\simeq 632\) K).
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_deltat} {[}Physical{]}
\item[] Temperature step for the computation of thermodynamic quantities.
Default is \sphinxcode{1.5e-5 hartree} (\(\simeq 5\) K).
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_min\_freq} {[}Physical{]}
\item[] Minimum phonon frequency for the computation of thermodynamic
quantities, expressed as an energy (\(\hbar \omega\));
frequencies lower than this are discarded. Default is
\sphinxcode{3.6e-6 hartree} (\(\simeq 5\) cm\(^{-1}\)).
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_DOS} {[}Logical{]}
\item[] Calculate the phonon DOS and write to file. Default is \sphinxcode{T}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_DOS\_min} {[}Real{]}
\item[] Lower bound of the phonon DOS range (in cm\(^{-1}\)). Default
is \sphinxcode{0.0}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_DOS\_max} {[}Real{]}
\item[] Upper bound of the phonon DOS range (in cm\(^{-1}\)). Default
is \sphinxcode{1000.0}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_DOS\_delta} {[}Real{]}
\item[] Frequency step for the phonon DOS calculation (in
cm\(^{-1}\)). Default is \sphinxcode{10.0}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_qpoints} {[}Block{]}
\item[] List of additional q points for which to calculate the phonon
frequencies, in fractional coordinates of the reciprocal unit cell
vectors. For non-supercell calculations only the \(\Gamma\)
point can be specified. Default is unspecified. Example:
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{phonon\PYGZus{}qpoints}
\PYG{l+m+mf}{0.0} \PYG{l+m+mf}{0.0} \PYG{l+m+mf}{0.0}
\PYG{l+m+mf}{0.0} \PYG{l+m+mf}{0.0} \PYG{l+m+mf}{0.1}
\PYG{l+m+mf}{0.0} \PYG{l+m+mf}{0.0} \PYG{l+m+mf}{0.2}
\PYG{l+m+mf}{0.0} \PYG{l+m+mf}{0.0} \PYG{l+m+mf}{0.3}
\PYG{l+m+mf}{0.0} \PYG{l+m+mf}{0.0} \PYG{l+m+mf}{0.4}
\PYG{l+m+mf}{0.0} \PYG{l+m+mf}{0.0} \PYG{l+m+mf}{0.5}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{phonon\PYGZus{}qpoints}
\end{sphinxVerbatim}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_write\_eigenvecs} {[}Logical{]}
\item[] Write the eigenvectors as well as the phonon frequencies to file
for the additional q points. Default is \sphinxcode{F}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_animate\_list} {[}Block{]}
\item[] List of \(\Gamma\)-point modes (where \sphinxcode{1} is the lowest) for
which to write xyz animation files. Default is unspecified.
Example:
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{phonon\PYGZus{}animate\PYGZus{}list}
\PYG{l+m+mi}{2}
\PYG{l+m+mi}{6}
\PYG{l+m+mi}{33}
\PYG{l+m+mi}{34}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{phonon\PYGZus{}animate\PYGZus{}list}
\end{sphinxVerbatim}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{phonon\_animate\_scale} {[}Real{]}
\item[] Relative scale of the amplitude of the vibration in the xyz
animation. Default is \sphinxcode{1.0}.
\end{DUlineblock}

\end{itemize}


\subsection{Additional notes}
\label{\detokenize{phonons:additional-notes}}
Phonon calculations are quite sensitive to the accuracy of the ionic
forces calculated for the perturbed structures. Therefore, it is
advisable to make sure that the forces are well-converged with respect
to the usual parameters: cut-off energy, number and radius of NGWFs, and
spatial cut-off of the density kernel.

Furthermore, it is also important to make sure that for a given set of
parameters the forces are properly converged at the end of the energy
minimization procedure, and that the numerical noise is reduced to a
minimum; the code will not check this automatically, and the forces
generally converge slower than the total energy. To ensure an accurate
result, therefore, the following values for the convergence threshold
parameters are suggested:
\begin{itemize}
\item {} 
\sphinxcode{ngwf\_threshold\_orig 1.0e-7}.

\item {} 
\sphinxcode{lnv\_threshold\_orig 1.0e-11}.

\end{itemize}


\chapter{Transition States and NEB}
\label{\detokenize{index_transition_states::doc}}\label{\detokenize{index_transition_states:transition-states-and-neb}}

\section{Nudged Elastic Band Transition State Searching and the Image-Parallel Running Mode}
\label{\detokenize{nudged-elastic-band::doc}}\label{\detokenize{nudged-elastic-band:nudged-elastic-band-transition-state-searching-and-the-image-parallel-running-mode}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Kevin Duff, University of Cambridge

\item[{Date}] \leavevmode
2018

\end{description}\end{quote}


\subsection{NEB Method}
\label{\detokenize{nudged-elastic-band:neb-method}}
The Nudged Elastic Band (NEB) method is a systematic approach to
transition state searching. A brief overview will be provided here; for
a more detailed description see {[}Jonsson1998{]}.


\subsubsection{Overview}
\label{\detokenize{nudged-elastic-band:overview}}
Tools such as geometry optimization make determining the properties and
relative energies of products and reactants relatively straightforward.
Of equal importance to understanding a reaction or diffusion problem is
the transition state (TS) - the highest-energy point on the minimum
energy path (MEP) connecting the reactant and product in configuration
space. Unfortunately determining the TS is not a simple local
minimization problem, but instead it requires a determination of the MEP
from the set of paths that connect the reactant and product. Several
approaches that attempt to approximate the TS given a set of assumptions
about the energy landscape exist, such as LST/QST. NEB attempts to offer
a systematic determination of the TS through a local optimization of the
MEP from an initial guess.


\subsubsection{Theory}
\label{\detokenize{nudged-elastic-band:theory}}
An elastic band method connects the reactant and product with a chain of
beads in configuration space connected to their immediate neighbors with
springs of natural length \(0\). This chain is then relaxed with the
reactant and product held fixed and each bead on the chain feeling the
forces from the potential energy surface as well as the springs.

Unfortunately, this approach runs into two immediate issues. The spring
force perpendicular to the path works to pull the chain away from the
correct MEP, leading to a poor approximation of the TS, and the force
from the potential energy surface tangent to the path pushes beads to
lower energy areas, whereas the goal is to sample the highest-energy
point on the path. Varying the spring constant can reduce one issue
while exacerbating the other and there is no systematic way to sample
the highest point of the correct MEP.

The nudged elastic band approach is to project out the problematic
components of the spring and PES force, ‘nudging’ the chain back onto
the MEP. That is, each bead feels only the component of the force due to
the potential energy surface perpendicular to the path tangent and that
of the spring force parallel to the path tangent. The former relaxes the
chain onto the MEP and the latter evenly distributes the images along
the path. Using this approach the beads will lie strictly on the MEP
regardless of bead count assuming an accurate approximation to the path
tangent at each point.

As with any local minimization, the final path depends on the initial
guess and is not guaranteed to be the global MEP. Care should be taken
in complicated reactions or diffusions - in particular a reaction
passing through several stable intermediates might be broken into a
number of separate NEB calculations. More control over the initial path
guess may be implemented in the future.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{NEB_example}.jpg}
\caption{Cartoon of a NEB path initialization by linear interpolation and final sampling of the MEP. Each image only feels the component of the spring force parallel to the path tangent and the real force perpendicular to the path tangent. Image source \& copyright {[}Cordier2018{]}.}\label{\detokenize{nudged-elastic-band:neb-example}}\label{\detokenize{nudged-elastic-band:id5}}\end{figure}


\subsubsection{Tangent Approximation}
\label{\detokenize{nudged-elastic-band:tangent-approximation}}
Because the MEP is approximated by a series of beads, the path tangent
must be approximated. A number of valid approximations exist - ONETEP
uses an improved-stability approximation described
in {[}Henkelman2000{]}. This approach reduces kinks
in the path that arise in some systems and is generally stable.
Equation \eqref{equation:nudged-elastic-band:improved_tangent_1} describes the tangent
\(\boldsymbol{\tau}_i\) approximated at bead \(i\) with energy
\(E_i\), where
\(\boldsymbol{\tau}_i^+=\mathbf{R}_{i+1}-\mathbf{R}_{i}\) and
\(\boldsymbol{\tau}_i^-=\mathbf{R}_{i}-\mathbf{R}_{i-1}\), in cases
where the neighboring beads’ energies make a strictly increasing or
decreasing series. If that’s not the case,
Equation \eqref{equation:nudged-elastic-band:improved_tangent_2} gives the tangent approximation,
where
\(\Delta V_i^\mathrm{max}=\max{\left(\left|V_{i+1}-V_i\right|,\left|V_{i}-V_{i-1}\right|\right)}\)
and
\(\Delta V_i^\mathrm{min}=\min{\left(\left|V_{i+1}-V_i\right|,\left|V_{i}-V_{i-1}\right|\right)}\).

\phantomsection\label{\detokenize{nudged-elastic-band:equation-improved-tangent-1}}\begin{equation}\label{equation:nudged-elastic-band:improved_tangent_1}
\begin{split}\boldsymbol{\tau}_i=
\begin{cases}
\boldsymbol{\tau}_i^+, & V_{i+1} > V_i > V_{i-1} \\
\boldsymbol{\tau}_i^-, & V_{i-1} > V_i > V_{i+1} \\
\end{cases}\end{split}
\end{equation}\phantomsection\label{\detokenize{nudged-elastic-band:equation-improved-tangent-2}}\begin{equation}\label{equation:nudged-elastic-band:improved_tangent_2}
\begin{split}\boldsymbol{\tau}_i=
\begin{cases}
\boldsymbol{\tau}_i^+ V_i^\mathrm{max} + \boldsymbol{\tau}_i^- V_i^\mathrm{min}, & V_{i+1} > V_{i-1} \\
\boldsymbol{\tau}_i^+ V_i^\mathrm{min} + \boldsymbol{\tau}_i^- V_i^\mathrm{max}, & V_{i-1} > V_{i+1}
\end{cases}\end{split}
\end{equation}

\subsubsection{Climbing-Image NEB}
\label{\detokenize{nudged-elastic-band:climbing-image-neb}}
NEB tries to ensure that the beads are equally spaced along the path.
This doesn’t guarantee good sampling of the transition state, which is
the most important part of the path. The TS energy can be interpolated
if there are enough beads on the path, but the climbing image addition
to NEB (CI-NEB) works to move a selected bead near the TS to exactly
sample the TS. Once enabled, the highest-energy bead doesn’t feel the
NEB spring force and moves in a modified potential energy surface, where
the components perpendicular to the path are essentially mirrored. This
transforms a saddle point region of the PES into a basin with a minimum
at the transition state. That bead is then minimized in this potential
and the rest of the chain in the normal way. This is generally useful
when the MEP is being sampled well, though it does make assumptions
about the shape of the PES near the saddle point. More details can be
found in {[}Henkelman2000-2{]}.


\subsection{Image-Parallel Implementation in ONETEP}
\label{\detokenize{nudged-elastic-band:image-parallel-implementation-in-onetep}}
Each NEB iteration each bead requires a local energy and force
calculation, as well as knowledge of the locations and relative energies
of its neighbors for spring force calculation and tangent approximation.
For this reason, and for other simulations that involve multiple
communicating but largely independent subsystems, an alternate running
mode was developed for Onetep that allows multiple simulations to exist
in the same MPI world. Each simulation, or image, can progress
independently but special communicators have been set up to allow
communication between them. In the case of NEB, each Onetep image
controls one bead in the chain.

Important to note is that when running in image-parallel mode the
default communicator for things like comms operations is changed from
\sphinxcode{mpi\_comm\_world} to \sphinxcode{comms} mod’s \sphinxcode{pub\_image\_comm}, a communicator
between all processes in one Onetep image. \sphinxcode{comms} mod’s
\sphinxcode{pub\_imroots\_comm} is a communicator between the root processes of
each image, allowing images to communicate and allowing tasks to give
each image something different to do. Additionally, each image opens its
own new file \sphinxcode{\{rootname\}\{image\_num\}.onetep} to write \sphinxcode{stdout} to,
with the original \sphinxcode{stdout} being available through \sphinxcode{image\_comms}
mod’s \sphinxcode{orig\_stdout}. Each image similarly maintains its own set of
restart files, properties files, etc, and nothing special has to be done
to restart image-parallel calculations.

Normally the number of MPI processes specified at runtime must be
divisible by the number of images requested. Advanced configuration
allows images to be different sizes, in case a task needs to be able to
perform calculations that aren’t necessarily comparable in cost.


\subsection{Commands}
\label{\detokenize{nudged-elastic-band:commands}}

\subsubsection{NEB Keywords}
\label{\detokenize{nudged-elastic-band:neb-keywords}}
NEB can be enabled by setting \sphinxcode{task : tssearch} and
\sphinxcode{tssearch\_method : neb} in the ONETEP input file. ONETEP must be
executed with enough MPI processes to support the number of images
requested. Several geometry optimization keywords will apply to NEB as
the chain optimization is threaded through the geometry optimizer.

The reactant is taken from the atomic positions specified in the input
file. A product section must also be provided through e.g.
\sphinxcode{\%block positions\_abs\_product}. A guess intermediate can also be
provided, in which case the NEB chain will place beads on the linear
interpolation from reactant to intermediate and intermediate to product.
This can be specified with e.g. \sphinxcode{\%block positions\_abs\_intermediate}.


\subsubsection{Basic Usage}
\label{\detokenize{nudged-elastic-band:basic-usage}}\begin{itemize}
\item {} 
\sphinxcode{num\_images: n} {[}Intermediate integer, default \sphinxcode{1}{]}. Defines the
number of Onetep instances that should run in the simulation and
enables image-parallel mode. In NEB, this is also the number of beads
in the chain.

\item {} 
\sphinxcode{\{reactant,product\}\_energy} {[}Intermediate real physical, default
\sphinxcode{N/A}{]} and \sphinxcode{\{reactant,product\}\_rootname} {[}Intermediate string,
default \sphinxcode{NONE}{]}. Both the reactant and product energies must be
known at the start of the calculation. The energy can be specified
either as a raw total energy or as a rootname from which Onetep can
read the tightbox NGWF and density kernel (and, in EDFT, Hamiltonian)
files from a previous calculation, or they can be calculated from
scratch if neither is specified. The reactant and product energies
needn’t be specified in the same way.

\end{itemize}


\subsubsection{Additional Controls}
\label{\detokenize{nudged-elastic-band:additional-controls}}\begin{itemize}
\item {} 
\sphinxcode{neb\_ci\_delay: n} {[}Intermediate integer, default \sphinxcode{-1}{]}. Defines
the number of BFGS steps the chain should take before enabling a
climbing image. Negative numbers disable the climbing image entirely.

\item {} 
\sphinxcode{neb\_print\_summary} {[}Intermediate boolean, default \sphinxcode{.true.}{]}. If
\sphinxcode{.true.}, Onetep will print NEB convergence information as well as
a summary of the reduced reaction coordinate and relative energy of
each bead after each NEB step to the original stdout.

\end{itemize}


\paragraph{Convergence}
\label{\detokenize{nudged-elastic-band:convergence}}
Currently the calculation is considered converged when each bead is
individually converged. These tolerances are used instead of the geomopt
ones.
\begin{itemize}
\item {} 
\sphinxcode{tssearch\_energy\_tol} {[}Expert real physical, default
\sphinxcode{1.0e-5 Ha}{]}. Convergence tolerance on change in bead energy in one
NEB step.

\item {} 
\sphinxcode{tssearch\_force\_tol} {[}Expert real physical, default
\sphinxcode{0.005 Ha/bohr}{]}. Convergence tolerance on max force on any atom.

\item {} 
\sphinxcode{tssearch\_disp\_tol} {[}Expert real physical, default
\sphinxcode{0.01 bohr}{]}. Convergence tolerance on displacement of any atom in
one NEB step.

\end{itemize}


\subsubsection{Other Image-Parallel Keywords}
\label{\detokenize{nudged-elastic-band:other-image-parallel-keywords}}\begin{itemize}
\item {} 
\sphinxcode{image\_sizes} {[}Expert string, default \sphinxcode{DEFAULT}{]}. If specified
in the input file, a string of the format \sphinxcode{i\textbar{}j\textbar{}k\textbar{}l\textbar{}m\textbar{}...} can be
used to individually size the images in an image-parallel run. The
number of sections specified should be equal the number of images in
the run and the sum of the image sizes should be equal the number of
MPI processes specified at runtime.

\end{itemize}

{[}Jonsson1998{]} H. Jónsson, G. Mills, and K. W. Jacobsen. \sphinxstyleemphasis{Chapter 16: Nudged elastic band method for finding minimum energy paths of transitions}, Classical and Quantum Dynamics in Condensed Phase Simulations Part II.

{[}Henkelman2000{]} G. Henkelman, and H. Jónsson. \sphinxstyleemphasis{Improved tangent estimate in the nudged elastic band method for finding minimum energy paths and saddle points}. J. Chem. Phys. \sphinxstylestrong{113}, 9978 (2000).

{[}Henkelman2000-2{]} G. Henkelman, B. P. Uberuaga, and H. Jónsson. \sphinxstyleemphasis{A climbing image nudged elastic band method for finding saddle points and minimum energy paths}. J. Chem. Phys. \sphinxstylestrong{113}, 9901 (2000).

{[}Cordier2018{]} Copyright P. Cordier \sphinxurl{http://umet.univ-lille.fr/Projets/RheoMan/en/to-learn-more-about/nudged-elastic-band.php} Accessed 21 April 2018.


\chapter{Spectroscopy and Transport}
\label{\detokenize{index_spectroscopy::doc}}\label{\detokenize{index_spectroscopy:spectroscopy-and-transport}}

\section{Calculating the Local/Partial Density of States and Angular Momentum Projected Density of States}
\label{\detokenize{ldos_calculations::doc}}\label{\detokenize{ldos_calculations:calculating-the-local-partial-density-of-states-and-angular-momentum-projected-density-of-states}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Nicholas D.M. Hine, University of Warwick (originally Imperial College London)

\item[{Author}] \leavevmode
Jolyon Aarons, University of Warwick

\item[{Date}] \leavevmode
June 2019 (Updated by Jolyon Aarons to add angular momentum PDOS information).

\item[{Date}] \leavevmode
Originally written by Nicholas D.M. Hine April 2012.

\end{description}\end{quote}


\subsection{What is being calculated?}
\label{\detokenize{ldos_calculations:what-is-being-calculated}}
The local density of states (LDOS) provides a description encompassing
both the spatial and energetic distribution of the single-particle
eigenstates simultaneously. The angular momentum projected density of
states (PDOS) decomposes the density of states energetic distribution
into angular momentum components. Both decompositions may be combined
into an LPDOS. The LDOS and PDOS can thus be two valuable sources of
information for understanding and interpreting electronic structure
calculations.

In the local-orbital framework of ONETEP
{[}Skylaris2005{]}, both decompositions are
achieved by first performing a diagonalisation of the Hamiltonian matrix
in the NGWF basis. This is a post-processing step performed at the end
of the calculation, once NGWF and density kernel convergence have been
achieved. While this comes with a \(O(N^{3})\) computational cost,
the prefactor is low because the NGWF basis is generally quite small.
Therefore, such a diagonalisation remains fast up to quite large system
sizes, particularly if a parallel eigensolver such as ScaLAPACK is used.

The generalised eigenproblem that needs to be solved to provide the
eigenvalues and eigenvectors is:

\phantomsection\label{\detokenize{ldos_calculations:equation-gen-eig-prob}}\begin{equation}\label{equation:ldos_calculations:gen_eig_prob}
\begin{split}\sum_{\beta}H_{\alpha\beta}M_{\phantom{\beta}n}^{\beta}=\epsilon_{n}\sum_{\beta}S_{\alpha\beta}M_{\phantom{\beta}n}^{\beta}\end{split}
\end{equation}
The matrix \(M_{\phantom{\beta}n}^{\beta}\) describes the
eigenvectors, which take the form
\(|\psi_{n}\rangle=\sum_{\beta}|\phi_{\beta}\rangle
M_{\phantom{\beta}n}^{\beta}\). In ONETEP, Eq. \eqref{equation:ldos_calculations:gen_eig_prob} can be
solved using either the LAPACK routine DSYGVX or (preferably) the
ScaLAPACK routine PDSYGVX, depending on whether -DSCALAPACK has been
specified at compile time, and ScaLAPACK libraries have been provided.

The result is the eigenvalues \(\{\epsilon_{n}\}\) and eigenvectors
\(M_{\phantom{\beta}n}^{\beta}\). From these, the total density of
states can be obtained as

\phantomsection\label{\detokenize{ldos_calculations:equation-dos}}\begin{equation}\label{equation:ldos_calculations:DOS}
\begin{split}D(\epsilon)=\sum_{n}\delta(\epsilon-\epsilon_{n})\;.\end{split}
\end{equation}
In practice the delta function is replaced with a Gaussian with
broadening \(\sigma\), typically of the order of
\(0.1\,\mathrm{eV}\):
\begin{equation*}
\begin{split}\delta(\epsilon-\epsilon_{n})\approx\sqrt{\frac{\log(2)}{\pi\sigma^2}}*\exp{\left(\frac{-\log(2)(\epsilon-\epsilon_n)^2}{\pi\sigma^2}\right)}.\end{split}
\end{equation*}

\subsubsection{Local Density of States}
\label{\detokenize{ldos_calculations:local-density-of-states}}
The local density of states in a given region \(I\) is calculated by
projecting each eigenstate onto the local orbitals of region \(I\),
as

\phantomsection\label{\detokenize{ldos_calculations:equation-ldos}}\begin{equation}\label{equation:ldos_calculations:LDOS}
\begin{split}D_{I}(\epsilon)=\sum_{n}\delta(\epsilon-\epsilon_{n})\;\langle\psi_{n}|\sum_{\alpha\in I}\left(|\phi^{\alpha}\rangle\langle\phi_{\alpha}|\right)|\psi_{n}\rangle.\end{split}
\end{equation}
Here, the non-orthogonality of the NGWFs when used as projectors means
that the ket must be contravariant. We are therefore implicitly using
the contravariant dual of the NGWF (as in DFT+U
{[}O-Regan2011{]}, {[}O-Regan2012{]}).
Fortunately, the functions \(|\phi^{\alpha}\rangle\) need not be
explicitly constructed in real space: the relationship
\(\langle\phi_{\alpha}|\phi^{\beta}\rangle=\delta_{\alpha\beta}\)
implies that we can re-write Eq. \eqref{equation:ldos_calculations:LDOS} as:

\phantomsection\label{\detokenize{ldos_calculations:equation-ldos2}}\begin{equation}\label{equation:ldos_calculations:LDOS2}
\begin{split}\begin{aligned}
D_{I}(\epsilon) & = & \sum_{n}\!\delta(\epsilon-\epsilon_{n})\!\!\!\!\!\!\sum_{\beta,\gamma,\alpha\in I}\!\!\!\!(M^{\dagger})_{n}^{\phantom{n}\gamma}\langle\phi_{\gamma}|\left(|\phi^{\alpha}\rangle\langle\phi_{\alpha}|\right)|\phi_{\beta}\rangle M_{\phantom{\beta}n}^{\beta}\nonumber \\
 & = & \sum_{n}\delta(\epsilon-\epsilon_{n})\sum_{\alpha\in I}(M^{\dagger})_{n}^{\phantom{n}\alpha}(\sum_{\beta}S_{\alpha\beta}M_{\phantom{\beta}n}^{\beta})\end{aligned}\end{split}
\end{equation}
What is therefore obtained is a series of functions
\(D_{I}(\epsilon)\) for each of the chosen regions \(I\), which
may be the NGWFs of a single atom, or those of a group of atom types.


\subsubsection{Angular Momentum Projected Density of States}
\label{\detokenize{ldos_calculations:angular-momentum-projected-density-of-states}}
To calculate the PDOS, we need to insert an additional resolution of the
identity into equation \eqref{equation:ldos_calculations:LDOS2} using a basis of angular momentum
resolved functions on which to project our NGWFS,
\(| \chi_{l,m}\rangle\):

\phantomsection\label{\detokenize{ldos_calculations:equation-dos-identity-operator}}\begin{equation}\label{equation:ldos_calculations:DOS_identity_operator}
\begin{split}D_{l,I}(\epsilon) \approx \sum_n  \delta(\epsilon-\epsilon_n) \sum_{\alpha,l\in I}(M^{\dagger})_n^{\,\,\,\,\alpha} \sum_{m \in l}\langle{\phi_\alpha
| \chi'_{\alpha l m}}\rangle \sum_{l'm'} \Lambda^{ l m, l'm'} \sum_\beta \left(\langle{ \chi'_{
l' m'} |\phi_\beta}\rangle M^\beta_{\ \, n}   \, \right),\end{split}
\end{equation}
where we need to include the overlap matrix of angular momentum
resolved functions, \(\Lambda\), since this basis is also
non-orthogonal.

We have considerable scope in which basis we choose for the angular
momentum resolved functions. Effectively, this is a set of spherical
harmonics multiplied by some radial term. In ONETEP, we currently have
two options implemented for the radial term: either spherical waves, or
pseudo-atomic functions, as used to initialise the NGWFs, before
optimisation in the NGWF SCF loop. More details about the theory behind
these options as well as tests and comparisons can be found in our paper
{[}Aarons2019{]}.


\subsection{Performing an LDOS Calculation}
\label{\detokenize{ldos_calculations:performing-an-ldos-calculation}}
An LDOS calculation is performed as part of the optional post-processing
activated using \sphinxcode{do\_properties: T} or using \sphinxcode{task: PROPERTIES}.
To activate LDOS we then need to specify the Gaussian broadening, such
as \sphinxcode{dos\_smear : 0.1 eV}. The default value of
\sphinxcode{dos\_smear : -0.1 eV} disables LDOS.

Then, we need to specify the groups of atom types. This is done via a
block, with each line listing a group of atoms. For example, in a
benzene ring, we might use the following to find the contributions of
the carbon and hydrogen atoms respectively:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}ldos\PYGZus{}groups}
  \PYG{n}{C}
  \PYG{n}{H}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}ldos\PYGZus{}groups}
\end{sphinxVerbatim}

A more complex example would be for a GaAs nanorod with hydrogen
termination on the faces. If we wished to see the LDOS varying over 5
layers, labelled 1-5, we could use:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}ldos\PYGZus{}groups}
  \PYG{n}{Ga1} \PYG{n}{As1} \PYG{n}{H1}
  \PYG{n}{Ga2} \PYG{n}{As2} \PYG{n}{H2}
  \PYG{n}{Ga3} \PYG{n}{As3} \PYG{n}{H3}
  \PYG{n}{Ga4} \PYG{n}{As4} \PYG{n}{H4}
  \PYG{n}{Ga5} \PYG{n}{As5} \PYG{n}{H5}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}ldos\PYGZus{}groups}
\end{sphinxVerbatim}

Examples of the use of LDOS analysis, including example plots, can be
found in several recent papers employing ONETEP
{[}Avraam2011{]}, {[}Avraam2012{]}, {[}Hine2012{]}.


\subsection{Performing a PDOS Calculation}
\label{\detokenize{ldos_calculations:performing-a-pdos-calculation}}
The default settings in ONETEP for PDOS calculations are to use the
pseudo-atomic states as the angular momentum resolved projection basis
with a Löwdin orthogonalisation. For most applications, the spilling
parameter associated with this basis will be sufficiently small.
PDOS calculations are enabled as part of the optional post-processing by
writing \sphinxcode{do\_properties : T} into the ONETEP input file, along with a
Gaussian smearing width, such as \sphinxcode{dos\_smear : 0.1 eV} and a maximum
angular momentum in the angular momentum resolved projection basis, such
as \sphinxcode{pdos\_max\_l : 2} to include up to d-states (when using the
default pseudo-atomic basis, this will also be limited by the maximum
angular momentum state in each species, as calculated by the
pseudo-atomic solver).


\subsubsection{Local PDOS (LPDOS) Calculations}
\label{\detokenize{ldos_calculations:local-pdos-lpdos-calculations}}
If you intend to calculate an angular momentum projected DOS on a subset
of atoms, this can be achieved by specifying a block in the input file,
in the same way as for LDOS. The block can be set up by using the
\sphinxcode{species\_pdos\_groups} keyword. For example, in a benzene ring
calculation, if you want to find the contributions to the PDOS coming
from solely carbon atoms and solely hydrogen atoms, you could write:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}pdos\PYGZus{}groups}
  \PYG{n}{C}
  \PYG{n}{H}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}pdos\PYGZus{}groups}
\end{sphinxVerbatim}

If you also want the combined contribution from carbon and hydrogen to
each angular momentum channel, you should add a line for this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}pdos\PYGZus{}groups}
  \PYG{n}{C}
  \PYG{n}{H}
  \PYG{n}{C} \PYG{n}{H}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}pdos\PYGZus{}groups}
\end{sphinxVerbatim}

This will calculate PDOS histogram data up to \sphinxcode{pdos\_max\_l} for each
line. As many or as few combinations of species as you require can be
calculated by adding extra lines.

If you instead want a specific subset of atoms of a particular species,
this can be achieved easily by labelling this subset differently to the
others in its species. For example, if you have the following species
specification:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species}
  \PYG{n}{Pt} \PYG{n}{Pt} \PYG{l+m+mi}{78} \PYG{l+m+mi}{9} \PYG{l+m+mf}{9.0}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}atomic\PYGZus{}set}
  \PYG{n}{Pt} \PYG{n}{SOLVE} \PYG{n}{conf}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{n}{d9} \PYG{l+m+mi}{6}\PYG{n}{s1} \PYG{l+m+mi}{6}\PYG{n}{p0}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}atomic\PYGZus{}set}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}pot}
  \PYG{n}{Pt} \PYG{n}{platinum}\PYG{o}{.}\PYG{n}{paw}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}pot}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}pdos\PYGZus{}groups}
  \PYG{n}{Pt}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}pdos\PYGZus{}groups}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{positions\PYGZus{}abs}
  \PYG{n}{Pt} \PYG{l+m+mf}{8.8292} \PYG{l+m+mf}{12.2847} \PYG{l+m+mf}{8.7330}
  \PYG{n}{Pt} \PYG{l+m+mf}{9.2819} \PYG{l+m+mf}{11.1839} \PYG{l+m+mf}{11.1325}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{positions\PYGZus{}abs}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] Then you may wish to duplicate the platinum species definitions to
label a subset of the atoms in the \sphinxcode{positions\_abs} block, as shown
here for example:
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species}
  \PYG{n}{Pt} \PYG{n}{Pt} \PYG{l+m+mi}{78} \PYG{l+m+mi}{9} \PYG{l+m+mf}{9.0}
  \PYG{n}{Pt1} \PYG{n}{Pt} \PYG{l+m+mi}{78} \PYG{l+m+mi}{9} \PYG{l+m+mf}{9.0}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}atomic\PYGZus{}set}
  \PYG{n}{Pt} \PYG{n}{SOLVE} \PYG{n}{conf}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{n}{d9} \PYG{l+m+mi}{6}\PYG{n}{s1} \PYG{l+m+mi}{6}\PYG{n}{p0}
  \PYG{n}{Pt1} \PYG{n}{SOLVE} \PYG{n}{conf}\PYG{o}{=}\PYG{l+m+mi}{5}\PYG{n}{d9} \PYG{l+m+mi}{6}\PYG{n}{s1} \PYG{l+m+mi}{6}\PYG{n}{p0}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}atomic\PYGZus{}set}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}pot}
  \PYG{n}{Pt} \PYG{n}{platinum}\PYG{o}{.}\PYG{n}{paw}
  \PYG{n}{Pt1} \PYG{n}{platinum}\PYG{o}{.}\PYG{n}{paw}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}pot}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}pdos\PYGZus{}groups}
  \PYG{n}{Pt}
  \PYG{n}{Pt1}
  \PYG{n}{Pt} \PYG{n}{Pt1}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}pdos\PYGZus{}groups}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{positions\PYGZus{}abs}
  \PYG{n}{Pt}  \PYG{l+m+mf}{8.8292} \PYG{l+m+mf}{12.2847} \PYG{l+m+mf}{8.7330}
  \PYG{n}{Pt1} \PYG{l+m+mf}{9.2819} \PYG{l+m+mf}{11.1839} \PYG{l+m+mf}{11.1325}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{positions\PYGZus{}abs}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] and hence calculate PDOS contributions for subsets of atoms of a
single species.
\end{DUlineblock}


\subsubsection{Expert PDOS Options}
\label{\detokenize{ldos_calculations:expert-pdos-options}}
Further options are available in the ONETEP PDOS functionality to
control the quality of the projection. These will be unneeded in most
cases, but if, for instance, you are observing larger spilling
parameters than your requirements permit, you may wish to enable some of
these options.

The most reliable way we have found to reduce the spilling parameter is
to use a spherical-wave basis rather than the pseudo-atomic basis as the
angular momentum resolved projection basis. To do this in ONETEP, add
\sphinxcode{pdos\_pseudoatomic : F} to your input file. By default, this will
create a set of contracted spherical waves by fitting spherical waves to
your converged NGWFs, via the contraction coefficients.

The spherical wave basis is contracted by default to reduce the memory
requirements of the code. You may, however, not see an improvement in
the spilling parameter by using this set. To be certain of reducing the
spilling parameter, you should also opt to use the full, non-contracted
spherical wave basis, by setting \sphinxcode{pdos\_reduce\_sws} : T in your input
file, along with an adequately large \sphinxcode{pdos\_max\_l}. For \sphinxcode{pdos\_max\_l}
you can start by running with 2 and increase to 3 if required. If you
choose to take this approach, beware of the memory requirements, which
can be \sphinxstyleemphasis{up to} 10 times greater.

If you choose to use a contracted set, then you almost certainly want to
use the default fitting coefficients (fitted to NGWFs). These can be
changed to unity by setting \sphinxcode{pdos\_construct\_basis : F}, however this
is not likely to improve your results, and is likely to be removed in a
future version of ONETEP due to it being mainly of use for debugging
purposes. To reduce the spilling parameter with the contracted set, we
recommend increasing the \sphinxcode{pdos\_max\_l} parameter.

In specialised cases, you may also wish to \sphinxstyleemphasis{not} sum over the magnetic
quantum number. This can be achieved by setting \sphinxcode{pdos\_sum\_mag : F}.
This will give histogram data for every magnetic quantum number of every
angular momentum channel of each atom group.


\subsubsection{Interpreting Outputs}
\label{\detokenize{ldos_calculations:interpreting-outputs}}
ONETEPs PDOS outputs are written to several files as well as to stdout,
which is itself usually redirected to the main log/output file. The
PDOS output to stdout will look something like the following (for an
input file with 3 \sphinxcode{pdos\_groups} and \sphinxcode{pdos\_max\_l=2}):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==} \PYG{n}{Projected} \PYG{n}{Density} \PYG{n}{of} \PYG{n}{States} \PYG{p}{(}\PYG{n}{pDOS}\PYG{p}{)} \PYG{n}{calculation} \PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}

\PYG{n}{Constructing} \PYG{n}{AM} \PYG{n}{resolved} \PYG{n}{functions}  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{n}{done}

\PYG{n}{Performing} \PYG{n}{overlap} \PYG{n}{integrals} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}  \PYG{n}{done}

\PYG{n}{Computing} \PYG{n}{pDOS} \PYG{n}{weights} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}  \PYG{n}{done}

\PYG{n}{All} \PYG{n}{bands} \PYG{n}{spilling} \PYG{n}{parameter} \PYG{o}{=}   \PYG{l+m+mf}{2.16} \PYG{o}{\PYGZpc{}}
\PYG{n}{Occupancy}\PYG{o}{\PYGZhy{}}\PYG{n}{weighted} \PYG{n}{spilling} \PYG{n}{parameter} \PYG{o}{=}   \PYG{l+m+mf}{0.30} \PYG{o}{\PYGZpc{}}

 \PYG{o}{=}\PYG{o}{\PYGZgt{}} \PYG{n}{Outputting} \PYG{n}{data} \PYG{k}{for} \PYG{n}{OptaDOS} \PYG{o}{\PYGZlt{}}\PYG{o}{=}

\PYG{n}{Writing} \PYG{n}{pDOS} \PYG{n}{weights} \PYG{n}{to} \PYG{n}{file} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Pt3O.val\PYGZus{}pdos\PYGZus{}bin}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{n}{done}

\PYG{n}{Writing} \PYG{n}{band} \PYG{n}{gradients} \PYG{n}{to} \PYG{n}{file} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Pt3O.val\PYGZus{}dome\PYGZus{}bin}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{n}{done}

\PYG{n}{Writing} \PYG{n}{Castep} \PYG{n}{output} \PYG{n}{cell} \PYG{n}{file} \PYG{n}{to} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Pt3O\PYGZhy{}out.cell}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{n}{done}

 \PYG{o}{=}\PYG{o}{\PYGZgt{}} \PYG{n}{Computing} \PYG{n}{Gaussian} \PYG{n}{smeared} \PYG{n}{pDOS} \PYG{o}{\PYGZlt{}}\PYG{o}{=}
\PYG{n}{Writing} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Pt3O\PYGZus{}PDOS.txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}  \PYG{n}{done}

 \PYG{o}{=}\PYG{o}{\PYGZgt{}} \PYG{n}{Computing} \PYG{n}{Occupancy}\PYG{o}{\PYGZhy{}}\PYG{n}{weighted} \PYG{n}{Gaussian} \PYG{n}{smeared} \PYG{n}{pDOS} \PYG{o}{\PYGZlt{}}\PYG{o}{=}
\PYG{n}{Writing} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Pt3O\PYGZus{}occ\PYGZus{}PDOS.txt}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}  \PYG{n}{done}
  \PYG{o}{=}\PYG{o}{\PYGZgt{}} \PYG{n}{Band} \PYG{n}{centres}\PYG{p}{:}
 \PYG{n}{S} \PYG{n}{band} \PYG{n}{centre} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{1}\PYG{p}{:}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{10.784858} \PYG{n}{eV}
 \PYG{n}{P} \PYG{n}{band} \PYG{n}{centre} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{1}\PYG{p}{:}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{6.380333} \PYG{n}{eV}
 \PYG{n}{D} \PYG{n}{band} \PYG{n}{centre} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{1}\PYG{p}{:}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.992269} \PYG{n}{eV}
 \PYG{n}{S} \PYG{n}{band} \PYG{n}{centre} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{2}\PYG{p}{:}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{3.492084} \PYG{n}{eV}
 \PYG{n}{P} \PYG{n}{band} \PYG{n}{centre} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{2}\PYG{p}{:}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{5.494629} \PYG{n}{eV}
 \PYG{n}{D} \PYG{n}{band} \PYG{n}{centre} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{2}\PYG{p}{:}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{1.992269} \PYG{n}{eV}
 \PYG{n}{S} \PYG{n}{band} \PYG{n}{centre} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{3}\PYG{p}{:}  \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{20.033217} \PYG{n}{eV}
 \PYG{n}{P} \PYG{n}{band} \PYG{n}{centre} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{3}\PYG{p}{:}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{6.607254} \PYG{n}{eV}
  \PYG{n}{Band} \PYG{n}{centres} \PYG{n}{done}\PYG{o}{.} \PYG{o}{\PYGZlt{}}\PYG{o}{=}
  \PYG{o}{=}\PYG{o}{\PYGZgt{}} \PYG{n}{Integrated} \PYG{n}{number} \PYG{n}{of} \PYG{n}{electrons} \PYG{o+ow}{in} \PYG{n}{each} \PYG{n}{AM} \PYG{n}{band}\PYG{p}{:}
 \PYG{n}{S} \PYG{n}{num} \PYG{n}{electrons} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{1}\PYG{p}{:}    \PYG{l+m+mf}{3.769061}
 \PYG{n}{P} \PYG{n}{num} \PYG{n}{electrons} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{1}\PYG{p}{:}    \PYG{l+m+mf}{5.624284}
 \PYG{n}{D} \PYG{n}{num} \PYG{n}{electrons} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{1}\PYG{p}{:}   \PYG{l+m+mf}{26.497454}
 \PYG{n}{S} \PYG{n}{num} \PYG{n}{electrons} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{2}\PYG{p}{:}    \PYG{l+m+mf}{2.107330}
 \PYG{n}{P} \PYG{n}{num} \PYG{n}{electrons} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{2}\PYG{p}{:}    \PYG{l+m+mf}{1.147080}
 \PYG{n}{D} \PYG{n}{num} \PYG{n}{electrons} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{2}\PYG{p}{:}   \PYG{l+m+mf}{26.497454}
 \PYG{n}{S} \PYG{n}{num} \PYG{n}{electrons} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{3}\PYG{p}{:}    \PYG{l+m+mf}{1.661731}
 \PYG{n}{P} \PYG{n}{num} \PYG{n}{electrons} \PYG{n}{of} \PYG{n}{group} \PYG{l+m+mi}{3}\PYG{p}{:}    \PYG{l+m+mf}{4.477204}
  \PYG{n}{Integrated} \PYG{n}{number} \PYG{n}{of} \PYG{n}{electrons} \PYG{n}{done}\PYG{o}{.} \PYG{o}{\PYGZlt{}}\PYG{o}{=}
\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}
\end{sphinxVerbatim}

First, we can see the spilling parameters \textendash{} effectively how well the
angular momentum resolved basis is able to represent the NGWFs. A lower
value is better; if you are running production calculations, you should
want a value lower than a few percent. If not, consider making some of
the changes suggested in the expert options section above. The all-bands
value includes un-occupied bands as well as valence states, which will
be the same as the occupancy-weighted version unless you are using
EDFT with a finite electronic temperature.

Following this are the files for use with \sphinxstylestrong{OptaDOS}. OptaDOS is a
freely available piece of software for plotting various DOS projections.
If you intend to use it, then please follow the CASTEP section of the
OptaDOS manual with these files, as they are compatible.

The histogram files are then written, “*\_PDOS.txt”. These also come in
all-bands and occupancy weighted flavours (the occupancy weighted
variant is more reliable for a usual ground state calculation with
ONETEP as the conduction states are not well described. Only if you are
doing LPDOS on the output of a ONETEP conduction calculation the
occupancy un-weighted LPDOS outputs will be meaningful). The order of
columns is firstly the energy column, followed by the angular momentum
component columns (i.e. s,p,d…) for each pdos group. This can be
plotted trivially with xmgrace, or any other plotting tool.

Finally ONETEP reports the energy and occupancy weighted averages of the
PDOS, so called-band centres, useful in catalysis (e.g. the value
“d-band centre” is a very useful decsriptor about the ability of a metal
surface to bind atomic oxygen and other types of adsorbates) and the
integrated number of electrons in each component.

{[}Skylaris2005{]} C.-K. Skylaris, P. D. Haynes, A. A. Mostofi, and M. C. Payne, J. Chem. Phys. \sphinxstylestrong{122}, 084119 (2005).

{[}O-Regan2011{]} D. D. O’Regan, M. C. Payne and A. A. Mostofi, Phys. Rev. B \sphinxstylestrong{83}, 245124 (2011).

{[}O-Regan2012{]} D. D. O’Regan, N. D. M. Hine, M. C. Payne and A. A. Mostofi, Phys. Rev. B \sphinxstylestrong{85}, 085107 (2012).

{[}Avraam2011{]} P. W. Avraam, N. D. M. Hine, P. Tangney, and P. D. Haynes, Phys. Rev. B \sphinxstylestrong{83}, 241402(R) (2011).

{[}Avraam2012{]} P. W. Avraam, N. D. M. Hine, P. Tangney, and P. D. Haynes, Phys. Rev. B \sphinxstylestrong{85}, 115404 (2012).

{[}Hine2012{]} N. D. M. Hine, P. W. Avraam, P. Tangney, and P. D. Haynes, J. Phys. Conf. Ser. (2012).

{[}Aarons2019{]} J. A. Aarons, L. G. Verga, N. D. M. Hine, and C.-K. Skylaris, Submitted (2019).


\section{Linear response time-dependent density-functional theory (LR-TDDFT)}
\label{\detokenize{lr_tddft::doc}}\label{\detokenize{lr_tddft:linear-response-time-dependent-density-functional-theory-lr-tddft}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Tim Zuehlsdorff, Imperial College London

\end{description}\end{quote}


\subsection{Linear Response TDDFT}
\label{\detokenize{lr_tddft:linear-response-tddft}}
The linear response TDDFT (LR-TDDFT) functionality in ONETEP allows the
calculation of the low energy excited states of a system in linear
scaling effort. In contrast to time-evolution TDDFT, where the density
matrix of the system is propagated explicitly in time, LR-TDDFT recasts
the problem of finding TDDFT excitation energies into an effective
non-hermitian eigenvalue equation of the form:

\phantomsection\label{\detokenize{lr_tddft:equation-full-tddft}}\begin{equation}\label{equation:lr_tddft:full_tddft}
\begin{split}\begin{pmatrix} \textbf{A} & \textbf{B} \\ \textbf{B} & \textbf{A}\end{pmatrix}\begin{pmatrix} \vec{\textbf{X}} \\ \vec{\textbf{Y}} \end{pmatrix} = \omega \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}\begin{pmatrix} \vec{\textbf{X}} \\ \vec{\textbf{Y}} \end{pmatrix}\end{split}
\end{equation}
where the elements of the block matrices \(\textbf{A}\) and
\(\textbf{B}\) can be expressed in canonical Kohn-Sham
representation as
\begin{equation*}
\begin{split}\begin{aligned}
A_{cv,c'v'}&=&\delta_{c,c'}\delta_{v,v'}(\epsilon^{\textrm{\scriptsize{KS}}}_{c}-\epsilon^{\textrm{\scriptsize{KS}}}_{v})+K_{cv,c'v'} \\
B_{cv,c'v'}&=&K_{cv, v'c'}\end{aligned}\end{split}
\end{equation*}
Here, \(c\) and \(v\) denote Kohn-Sham conduction and valence
states and \sphinxstylestrong{K} is the coupling matrix with elements given by
\begin{equation*}
\begin{split}\begin{aligned}
 \nonumber
K_{cv,c'v'}=2\int \mathrm{d} ^3 r \mathrm{d} ^3 r'\left[\frac{1}{|\textbf{r}-\textbf{r}'|}+\left. \frac{\delta^2 E_{\textrm{\scriptsize{xc}}}}{\delta\rho(\textbf{r})\delta\rho(\textbf{r}')}\right|_{\rho^{\{0\}}}\right]  \\
\times \psi^{\textrm{\scriptsize{KS}}*}_{c}(\textbf{r})\psi^{\textrm{\scriptsize{KS}}}_{v}(\textbf{r})\psi^{\textrm{\scriptsize{KS}}*}_{v'}(\textbf{r}')\psi^{\textrm{\scriptsize{KS}}}_{c'}(\textbf{r}').\end{aligned}\end{split}
\end{equation*}
with \(E_{\textrm{\scriptsize{xc}}}\) being the
exchange-correlation energy. Its second derivative, evaluated at the
ground-state density \(\rho^{\{0\}}\) of the system, is normally
referred to as the exchange-correlation kernel.

The above equation can be understood as an effective 2-particle
Hamiltonian consisting of a diagonal part of conduction-valence
eigenvalue differences and a coupling term \(K_{cv,c'v'}\)
connecting individual Kohn-Sham excitations.

In ONETEP, LR-TDDFT is implemented both in terms of the full TDDFT
eigenvalue equation (Eqn. {[}full\_tddft{]}) and in the Tamm-Dancoff
approximation, a commonly used simplification to the full non-hermitian
eigenvalue equation, where the off diagonal elements \(\textbf{B}\)
are set to zero. The problem of calculating the TDDFT excitation
energies thus becomes equivalent to solving the hermitian eigenvalue
equation
\begin{equation*}
\begin{split}\textbf{A}\vec{\textbf{X}}=\omega \vec{\textbf{X}}\end{split}
\end{equation*}
The Tamm-Dancoff approximation violates time-reversal symmetry and
oscillator strength sum rules and can blue-shift strong peaks in the
spectrum by up to 0.3 eV, however, dark states are typically left almost
unaltered from their corresponding states in the Tamm-Dancoff
approximation.

In the ONETEP code, the Tamm-Dancoff eigenvalue equation is re-expressed
in terms of two sets of NGWFs, one optimised for the valence space
(denoted as \(\{ \phi_\alpha\}\)) and one optimised for a low energy
subspace of the conduction manifold (denoted as \(\{\chi_\beta \}\),
see the documentation of the conduction NGWF optimiation functionality).
Furthermore, the eigenvalue equation is solved iteratively for the
lowest few eigenvalues using a conjugate gradient method. In order to do
so we define the action \(\textbf{q}\) of operator
\(\textbf{A}\) acting \(\vec{\textbf{X}}\) in conduction-valence
NGWF space as

\phantomsection\label{\detokenize{lr_tddft:equation-operator}}\begin{equation}\label{equation:lr_tddft:operator}
\begin{split}(q^{\chi\phi})^{\alpha\beta}=(P^{\{\mathrm{c}\}} H^{\chi}P^{\{1\}}-P^{\{1\}} H^{\phi}P^{\{\mathrm{v}\}})^{\alpha\beta}
+(P^{\{\mathrm{c}\}} V^{\{1\}\chi\phi}_{\textrm{\scriptsize{SCF}}}P^{\{\mathrm{v}\}})^{\alpha\beta}.\end{split}
\end{equation}
where \(\textbf{H}^{\chi}\) and \(\textbf{H}^\phi\) are the
Hamiltonians in conduction and valence NGWF representation respectively,
\(\textbf{P}^{\{c\}}\) and \(\textbf{P}^{\{v\}}\) denote the
conduction and valence density matrices and \(\textbf{P}^{\{1\}}\)
is the response density matrix, a representation of the trial vector
\(\vec{\textbf{X}}\) in conduction-valence NGWF space.
\(V^{\{1\}}_{\textrm{\scriptsize{SCF}}}\) is the first order
response of the system due to the density
\(\rho^{\{1\}}(\textbf{r})\) associated with
\(\textbf{P}^{\{1\}}\). Under this redefinition of the action
\(\textbf{A}\) in conduction-valence NGWF space, finding the lowest
\(N_\omega\) excitation energies is equivalent to minimising
\begin{equation*}
\begin{split}\Omega=\sum_i^{N_\omega}\omega_i=\sum_i^{N_{\omega}}\left[  \frac{\textrm{Tr}\left[\textbf{P}^{\{1\}\dagger}_i\textbf{S}^{\chi}\textbf{q}^{\chi\phi}_i\textbf{S}^\phi\right]}{\textrm{Tr}\left[\textbf{P}^{\{1\}^\dagger}_i\textbf{S}^{\chi}\textbf{P}^{\{1\}}_i\textbf{S}^\phi\right]}\right]\end{split}
\end{equation*}
with respect to \(\left\{ \textbf{P}^{\{1\}}_i\right\}\) under the
constraint

\phantomsection\label{\detokenize{lr_tddft:equation-ortho}}\begin{equation}\label{equation:lr_tddft:ortho}
\begin{split} \textrm{Tr}\left[\textbf{P}^{\{1\}\dagger}_i\textbf{S}^{\chi}\textbf{P}^{\{1\}}_j\textbf{S}^\phi\right]=\delta_{ij}.\end{split}
\end{equation}
If all density matrices involved in the above expressions, ie.
\(\textbf{P}^{\{1\}}\), \(\textbf{P}^{\{c\}}\) and
\(\textbf{P}^{\{v\}}\) are truncated and thus become sparse, the
algorithm scales as \(O(N)\) with system size for a fixed number of
excitation energies \(N_\omega\) and as \(O(N_\omega^2)\) with
the number of excitation energies required.

A similar algorithm can be derived for the full TDDFT eigenvalue
equation, where we make use of the change of variables
\(\textbf{p}=\vec{\textbf{X}}+\vec{\textbf{Y}}\) and
\(\textbf{q}=\vec{\textbf{X}}-\vec{\textbf{Y}}\). Each TDDFT
excitation then has two effective density matrices,
\(\textbf{P}^{\{p\}}\) and \(\textbf{P}^{\{q\}}\), associated
with it that have the same structure as \(\textbf{P}^{\{1\}}\) in
the Tamm-Dancoff approximation. The density matrices do obey an updated
orthonormality constraint of the form

\phantomsection\label{\detokenize{lr_tddft:equation-ortho2}}\begin{equation}\label{equation:lr_tddft:ortho2}
\begin{split} \frac{1}{2}\left(\textrm{Tr}\left[\textbf{P}^{\{p\}\dagger}_i\textbf{S}^{\chi}\textbf{P}^{\{q\}}_j\textbf{S}^\phi\right]+ \textrm{Tr}\left[\textbf{P}^{\{q\}\dagger}_i\textbf{S}^{\chi}\textbf{P}^{\{p\}}_j\textbf{S}^\phi\right]\right)=\delta_{ij}\end{split}
\end{equation}
and an analogous expression for the total energy \(\Omega\) in full
TDDFT can be derived.


\subsection{Performing a LR-TDDFT calculation}
\label{\detokenize{lr_tddft:performing-a-lr-tddft-calculation}}
The LR-TDDFT calculation in ONETEP is enabled by setting the task flag
to TASK=LR\_TDDFT. The LR-TDDFT calculation mode reads in the density
kernels and NGWFs of a converged ground state and conduction state
calculation, so the .dkn, .dkn\_cond, .tightbox\_ngwfs and
.tightbox\_ngwfs\_cond files all need to be present. The most important
keywords in a TDDFT calculation are:
\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_RPA}\): T/F.
\item[] Boolean, default \(\tt{lr\_tddft\_RPA}\)=F. If set to T, the
code performs a full TDDFT calculation without relying on the
simplified Tamm-Dancoff approximation.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_num\_states}\): n
\item[] Integer, default \(\tt{lr\_tddft\_num\_states}=1\).
\item[] The keyword specifies how many excitations we want to converge. If
set to a positive integer n, the TDDFT algorithm will converge the
n lowest excitations of the system.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_cg\_threshold}\): x
\item[] Real, default \(\tt{lr\_tddft\_cg\_threshold}=10^{-6}\).
\item[] The keyword specifies the convergence tolerance on the sum of the n
TDDFT excitation energies. If the sum of excitation energies
changes by less than x in two consecutive iterations, the
calculation is taken to be converged.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_maxit\_cg}\): n
\item[] Integer, default \(\tt{lr\_tddft\_maxit\_cg}=60\).
\item[] The maximum number of conjugate gradient iterations the algorithm
will perform.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_triplet}\): T/F
\item[] Boolean, default \(\tt{lr\_tddft\_triplet}=F\).
\item[] Flag that decides whether the \(\tt{lr\_tddft\_num\_states}=n\)
states to be converged are singlet or triplet states.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_write\_kernels}\): T/F
\item[] Boolean, default \(\tt{lr\_tddft\_write\_kernels}=T\).
\item[] If the flag is set to T, the TDDFT response density kernels are
printed out at every conjugate gradient iteration. These files are
necessary to restart a LR\_TDDFT calculation.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_restart}\): T/F
\item[] Boolean, default \(\tt{lr\_tddft\_trestart}=F\).
\item[] If the flag is set to T, the algorithm reads in
\(\tt{lr\_tddft\_num\_states}=n\) response density kernels in
.dkn format and uses them as initial trial vectors for a restarted
LR\_TDDFT calculation.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_restart\_from\_TDA}\): T/F
\item[] Boolean, default \(\tt{lr\_tddft\_trestart\_from\_TDA}=F\).
\item[] If the flag is set to T and \(\tt{lr\_tddft\_RPA}\): T, the
code will read in already converged density kernels
\(\left\{\textbf{P}^{\{1\}}_i\right\}\) and use them as a
starting guess for a full TDDFT calculation such that
\(\textbf{P}^{\{p\}}_i=\textbf{P}^{\{q\}}_i=\textbf{P}^{\{1\}}\).
In many cases, the full TDDFT results are similar to the
Tamm-Dancoff results and this strategy of starting the full TDDFT
calculation leads to a rapid convergence.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_init\_random}\) T/F
\item[] Boolean, default \(\tt{lr\_tddft\_init\_random}\) T.
\item[] By default, the initial TDDFT eigenvector guesses are initialised
to random matrices. This yields an unbiased convergence of the
TDDFT algorithm but can mean that one starts the optimisation
relatively far away from the minimum. If
\(\tt{lr\_tddft\_init\_random}\)=F, the code instead computes
the \(n\) minimum energy pure Kohn-Sham transitions in
linear-scaling effort and initialises the \(n\) TDDFT response
density matrices to the pure Kohn-Sham transition density matrices.
In many small to medium sized systems this leads to initial states
much closer to the TDDFT minimum and rapid convergence. In large
extended systems this can yield states that are spurious charge
transfer states that are not ideal, especially if a more advanced
density matrix truncation scheme is used. In this case it is
possible to set the keyword
\(\tt{lr\_tddft\_init\_max\_overlap}\) T, in which, rather than
choosing the lowest Kohn-Sham transitions, the code picks the
lowest few transitions that also have a maximum overlap of electron
and hole densities.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_kernel\_cutoff}\): x
\item[] Real, default \(\tt{lr\_tddft\_kernel\_cutoff}=1000 a_0\).
\item[] Keyword sets a truncation radius on all response density kernels in
order to achieve linear scaling computational effort with system
size.
\end{DUlineblock}

\end{itemize}

While the LR\_TDDFT calculation can be made to scale linearly for a
fixed number of excitations converged, it should be kept in mind that
the algorithm needs to perform orthonormalisation procedures and thus
scales as \(O(N^2)\) with \(\tt{lr\_tddft\_num\_states}\).


\subsection{Truncation of the Response density matrix}
\label{\detokenize{lr_tddft:truncation-of-the-response-density-matrix}}
To run a fully linear scaling TDDFT calculation the response density
matrix has to be truncated by setting
\(\tt{lr\_tddft\_kernel\_cutoff}\). This truncation introduces
numerical errors into the calculation, which mainly manifest themselves
in the form that the response density matrices do no longer exactly obey
a first order idempotency constraint that is placed on them. The
idempotency constraint can be written in form of an invariance equation:
\begin{equation*}
\begin{split}\textbf{P}^{\{1\}'}=\textbf{P}^{\{\mathrm{c}\}}\textbf{S}^{\chi}\textbf{P}^{\{1\}}\textbf{S}^{\phi}\textbf{P}^{\{\mathrm{v}\}}=\textbf{P}^{\{1\}}\end{split}
\end{equation*}
To measure the degree to which the invariance relation is violated we
make use of a penalty functional
\(Q\left[ \textbf{P}^{\{1\}}\right]\) given by:
\begin{equation*}
\begin{split}Q\left[\textbf{P}^{\{1\}}\right]=\textrm{Tr}\left[\left(\textbf{P}^{\{1\}\dagger}\textbf{S}^{\chi}\textbf{P}^{\{1\}}\textbf{S}^{\phi}-\textbf{P}^{\{1\}' \dagger}\textbf{S}^{\chi}\textbf{P}^{\{1\}'}\textbf{S}^{\phi} \right)^2\right].\end{split}
\end{equation*}
For truncated \(\textbf{P}^{\{1\}}\),
\(Q\left[\textbf{P}^{\{1\}}\right]\neq 0\) which can lead to
problems in the convergence of the conjugate gradient algorithm. In
order to avoid these issues, the TDDFT routines perform the minimisation
of the energy in an analogous form to the LNV method in ground-state
calculations: The auxiliary density kernel \(\textbf{P}^{\{1\}'}\)
is used instead of \(\textbf{P}^{\{1\}}\) for the minimisation of
\(\Omega\). While \(\textbf{P}^{\{1\}'}\) is much less sparse
than \(\textbf{P}^{\{1\}}\) it preserves idempotency to the same
degree as the conduction and valence density kernel, yielding a
stabilised convergence.

However, should \(Q\left[\textbf{P}^{\{1\}}\right]\) diverge
significantly from 0 during the calculation, there are routines in place
similar to the kernel purification schemes in ground state DFT that
force the kernel towards obeying its idempotency constraint. The keyword
controlling these routines are given below:
\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_penalty\_tol}\): x
\item[] Real, default \(\tt{lr\_tddft\_penalty\_tol}=10^{-8}\).
\item[] Keyword sets a tolerance for the penalty functional. If
\(Q\left[\textbf{P}^{\{1\}}\right]\) is larger than
\(\tt{lr\_tddft\_penalty\_tol}\) the algorithm will perform
purification iterations in order to decrease the penalty value and
force \(\textbf{P}^{\{1\}}\) towards the correct idempotency
behaviour.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_maxit\_pen}\): n
\item[] Integer, default \(\tt{lr\_tddft\_maxit\_pen}=20\).
\item[] The maximum number purification iterations performed per conjugate
gradient step.
\end{DUlineblock}

\end{itemize}


\subsection{More advanced TDDFT kernel truncation schemes}
\label{\detokenize{lr_tddft:more-advanced-tddft-kernel-truncation-schemes}}
\begin{DUlineblock}{0em}
\item[] There are many situations where physical intuition allows one to
specify a more sophisticated sparsity pattern than a uniform spherical
kernel cutoff on \(\textbf{P}^{\{1\}}\) (or
\(\textbf{P}^{\{p\}}\) and \(\textbf{P}^{\{q\}}\) for full
TDDFT). For example, in pigment-protein complexes the excitations of
interest retain a relative localisation on the pigment and one would
ideally converge these states directly, without obtaining any spurious
charge transfer states from the pigment to far away regions of the
protein, that can arise due to failures in semi-local exchange
correlation functionals. This can be achieved by introducing a new
block into the input file of the form
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}tddft\PYGZus{}kernel}
  \PYG{n}{label1} \PYG{n}{label} \PYG{l+m+mi}{2} \PYG{n}{label3} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
  \PYG{n}{label5} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
  \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}tddft\PYGZus{}kernel}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] where the labels refer to atom labels. As an example, consider a
 pigment protein complex, where the pigment atoms are labelled H1, C1
 etc. while the protein atoms are labelled H, C, etc. Then we can force
 the excitations of the system to be fully localised on the pigment by
including
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}tddft\PYGZus{}kernel}
  \PYG{n}{C1} \PYG{n}{H1} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}tddft\PYGZus{}kernel}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] This has the effect of setting all elements of
\(\textbf{P}^{\{1\}}\) to zero that correspond to conduction or
valence NGWFs centered on atoms of the environment. In this way the
electrostatic effects of the environment are treated fully quantum
mechanically, while no delocalisation into the protein is allowed. If
one would like to introduce a coupling to the environment but wants to
suppress any charge transfer coupling between the pigment and its
environment, it is possible to specify
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}tddft\PYGZus{}kernel}
  \PYG{n}{C1} \PYG{n}{H1} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
  \PYG{n}{C} \PYG{n}{H} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}tddft\PYGZus{}kernel}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] It is possible to specify an arbitrary number of subregions in the
system in this way. It is also possible to list the same species in
different lines, allowing for charge transfer interactions between
some atom types of two regions but not others.
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] Rather than having the off-diagonal charge-transfer blocks defined in
\sphinxcode{\%block species\_tddft\_kernel} set exactly to zero,
it is also possible to give these blocks a more realistic sparsity
pattern, for example that of the overlap matrix. While this process
still suppresses any significant amount of charge transfer between
TDDFT regions, it can be used to allow overlapping NGWFs from
different TDDFT regions to contribute to the TDDFT transition density.
In order to do so, set the block
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}tddft\PYGZus{}ct}
  \PYG{n}{C1} \PYG{n}{H1} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
  \PYG{n}{C2} \PYG{n}{H2} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}tddft\PYGZus{}ct}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] and set \sphinxcode{lr\_tddft\_ct\_length} to a chosen cutoff length
for the charge-transfer interaction between the specified blocks. For
example, if the off-diagonal blocks of the response density matrix
(corresponding to charge-transfer excitations between TDDFT regions)
should have the same sparsity pattern as the overlap matrix, set
\sphinxcode{lr\_tddft\_ct\_length} to twice the NGWF localisation
radius.
\end{DUlineblock}


\subsection{Preconditioning}
\label{\detokenize{lr_tddft:preconditioning}}
The TDDFT eigenvalue problem is generally ill-conditioned, which can
lead to a relatively slow convergence. For this reason, it is possible
to precondition the eigenvalue problem, which is achieved by solving a
linear system iteratively to a certain tolerance at each conjugate
gradient step. Solving the linear system only requires matrix-matrix
multiplications and is very cheap for small and medium sized systems,
however, it can get more costly for very large systems, especially when
no kernel truncation is used. In these cases, it can be necessary to
reduce the number of default iterations of the preconditioner. The main
keywords controlling the preconditioner are
\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_precond}\): T/F
\item[] Boolean, default \(\tt{lr\_tddft\_precond}=T\).
\item[] Flag that decides whether the preconditioner is switched on or off.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_precond\_iter}\): n
\item[] Integer, default \(\tt{lr\_tddft\_precond\_iter}=20\).
\item[] Maximum number of iterations in the linear system solver applying
the preconditioner.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_precond\_tol}\): x
\item[] Real, default \(\tt{lr\_tddft\_precond\_tol}=10^{-8}\).
\item[] The tolerance to which the linear system is solved in the
preconditioner. Choosing a large tolerance means that the
preconditioner is only applied approximately during each iteration.
\end{DUlineblock}

\end{itemize}


\subsection{Representation of the unoccupied subspace}
\label{\detokenize{lr_tddft:representation-of-the-unoccupied-subspace}}
In the LR\_TDDFT method as implemented in ONETEP, the user has two
options regarding the representation of the unoccupied subspace. The
first option is to define the active unoccupied subspace of the
calculation to only contain the Kohn-Sham states that were explicitly
optimised in the COND calculation. The other is to make use of a
projector onto the entire unoccupied subspace, where we redefine the
conduction density matrix as:
\begin{equation*}
\begin{split}\textbf{P}^{\{\textrm{c}\}}=\left(\left(\textbf{S}^{\chi}\right)^{-1} -\left(\textbf{S}^{\chi}\right)^{-1}\textbf{S}^{\chi\phi}\textbf{P}^{\{\textrm{v}\}}\left(\textbf{S}^{\chi\phi}\right)^\dagger \left(\textbf{S}^{\chi}\right)^{-1}\right) .\end{split}
\end{equation*}
The first option has the advantage that we only include states for
which the NGWFs are well optimised, but has the drawback that some
excitations converge very slowly with the size of the unoccupied
subspace and thus a good convergence with the number of conduction
states optimised is hard to reach. The second method implicitly includes
the entire unoccupied subspace (to the extent that it is representable
by a small, localised NGWF representation), but has the disadvantage
that now states are included in the calculation for which the NGWFs are
not optimised. Furthermore, the density matrix defined above is no
longer strictly idempotent, leading to violations of the idempotency
condition and thus a non-vanishing penalty functional
\(Q\left[\textbf{P}^{\{1\}}\right]\), requiring kernel purification
iterations as described in the previous section.

The problem of loss of idempotency can be avoided by using the joint
NGWF set to represent the conduction space when using the projector.
While this increases the computational cost of the LR\_TDDFT calculation
by a factor of 2, it preserves the idempotency of
\(\textbf{P}^{\{\textrm{c}\}}\) and is the recommended option when
using the projector onto the unoccupied subspace.

The keywords controlling the use of the projector are
\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_projector}\): T/F
\item[] Boolean, default \(\tt{lr\_tddft\_projector}=T\).
\item[] If the flag is set to T, the conduction density matrix
\(\textbf{P}^{\{\textrm{c}\}}\) is redefined to be a projector
onto the entire unoccupied subspace.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_joint\_set}\): T/F
\item[] Boolean, default \(\tt{lr\_tddft\_joint\_set}=T\).
\item[] If the flag is set to T, the joint NGWF set is used to represent
the conduction space in the LR\_TDDFT calculation.
\end{DUlineblock}

\end{itemize}


\subsection{Calculations in implicit solvent}
\label{\detokenize{lr_tddft:calculations-in-implicit-solvent}}
A TDDFT calculation in implicit solvent is performed in an analogous way
to the implicit solvent calculation in combination with a conduction
optimisation (see the documentation of the conduction optimisation for
further details). By default, the implicit solvent only acts on the
ground state of the system and thus influences the conduction and
valence Kohn-Sham states mixed into the TDDFT calculation. However, a
screening of the response density due to a dynamic dielectric constant
is not included in the calculation. In order to activate dynamic
screening effects in TDDFT, the user can set the keyword
\(\tt{lr\_optical\_permittivity}\) to the effective dynamic
dielectric constant \(\epsilon_\infty\) of the system in question.


\subsection{Outputs}
\label{\detokenize{lr_tddft:outputs}}
The LR\_TDDFT calculation will produce a number of outputs. At the end
of the calculation, the individual excitation energies and oscillator
strengths will be computed and printed in the main ONETEP output file.
Furthermore, the energies and oscillator strengths are used to generate
a excitation spectrum written to the textfile rootname.tddft\_spectrum.
The peaks in the spectrum are Gaussians of a width controlled by
\(\tt{lr\_tddft\_spectrum\_smear}\). Furthermore, by default,
density cube files of the response density, the electron and the hole
density for each excitation are printed out. The LR\_TDDFT code can also
perform an analysis of individual excitations, where the response
density matrix is decomposed into dominant Kohn-Sham transitions. Since
this analysis requires the Kohn-Sham eigenstates and thus a
diagonalisation of the Hamiltonian, it scales as \(O(N^3)\) and
should not be performed for very large system sizes.

The keywords controlling these outputs are:
\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_write\_densities}\): T/F
\item[] Boolean, default \(\tt{lr\_tddft\_write\_densities}=T\).
\item[] If the flag is set to T, the response density, electron density and
hole density for each excitation is computed and written into a
.cube file.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \(\tt{lr\_tddft\_analysis}\): T/F
\item[] Boolean, default \(\tt{lr\_tddft\_analysis}=F\).
\item[] If the flag is set to T, a full \(O(N^3)\) analysis of each
TDDFT excitation is performed in which the response density is
decomposed into dominant Kohn-Sham transitions.
\end{DUlineblock}

\end{itemize}


\subsection{Good practices and common problems}
\label{\detokenize{lr_tddft:good-practices-and-common-problems}}\begin{itemize}
\item {} 
The quality of the TDDFT excitation energies critically depends on
the representation of the conduction space manifold. Any excitation
that has a large contribution from an unoccupied state that is not
explicitly optimised in the COND calculation is not expected to be
represented correctly in the LR\_TDDFT calculation. In general it is
advisable to optimise as many conduction states as possible. However,
high energy conduction states are often very delocalised and only
representable if the conduction NGWF radius is increased
significantly, thus leading to poor computational efficiency. In
practice, there is a tradeoff between computational efficiency and
the representation of the conduction state manifold (see also the
documentation on conduction state optimisation on this issue).
Generally, TDDFT excitations should be converged with respect to both
the conduction NGWF radius and the number of conduction states
explicitly optimised.

\item {} 
Since the ground state and conduction density kernels are used as
projectors onto the occupied and unoccupied subspace in LR\_TDDFT,
one often finds that the inner loop of the SINGLEPOINT and COND
optimisation has to be converged to a higher degree of accuracy to
achieve well behaved TDDFT results. It is therefore recommended to
increase MAXIT\_LNV and MINIT\_LNV from their default value in the
SINGLEPOINT and COND calculation. If no density kernel cutoff is
used, the penalty functional value in the LR\_TDDFT calculation
should be vanishingly small. If the number increases significantly
during a calculation or if the code begins to perform penalty
optimisation steps, that is a clear sign that the initial conduction
and valence density kernels are not converged well enough.

\item {} 
In order to perform a LR\_TDDFT calculation that scales fully
linearly with system size, all density matrices involved have to be
sparse and thus a KERNEL\_CUTOFF has to be set for both the
SINGLEPOINT and COND calculation. Using a density matrix truncation
on the conduction states can sometimes be difficult depending on how
the subspace of optimised conduction states is chosen and care has to
be taken to prevent unphysical results.

\item {} 
When running calculations in full linear scaling mode, the ground
state and conduction density kernels are no longer strictly
idempotent, which means that the penalty functional in LR\_TDDFT will
no longer be strictly zero. The code might perform penalty functional
optimisation steps to keep the idempotency error small. However,
these idempotency corrections can cause the conjugate gradient
algorithm to stagnate and can even cause the energy to increase. If
this happens, it is an indication that the minimum energy and maximum
level of convergence for this truncation of the density kernel has
been reached.

\item {} 
When placing a truncation onto the the response density kernels it
should be kept in mind that this may cause the optimisation to miss
certain low energy excitations completely. Very long range
charge-transfer type excitations cannot be represented by a truncated
response density kernel and will thus be missing from the spectrum of
excitations converged. However, well localised excitations should be
unaffected. In a similar way, if the TDDFT kernel is limited to a
certain region, it should be checked whether increasing the region
leads to a smooth convergence of the energy of the localised state
within the region.

\end{itemize}


\subsection{Reference}
\label{\detokenize{lr_tddft:reference}}
For further background regarding the theory behind the LR\_TDDFT method
in ONETEP, as well as a number of benchmark tests, see
\begin{itemize}
\item {} 
Linear-scaling time-dependent density-functional theory in the linear
response formalism, T. J. Zuehlsdorff, N. D. M. Hine, J. S. Spencer,
N. M. Harrison, D. J. Riley, and P. D. Haynes, J. Chem. Phys.
\sphinxstylestrong{139}, 064104 (2013)

\end{itemize}


\section{Electron Energy Loss Calculations}
\label{\detokenize{eels_in_onetep:electron-energy-loss-calculations}}\label{\detokenize{eels_in_onetep::doc}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Edward Tait, University of Cambridge

\item[{Author}] \leavevmode
Nicholas Hine, University of Warwick

\item[{Date}] \leavevmode
September 2015

\item[{Date}] \leavevmode
Updated and Converted by NDMH September 2022

\end{description}\end{quote}


\subsection{Theory}
\label{\detokenize{eels_in_onetep:theory}}
Computation of Electron Energy Loss (EEL) spectra in the Kohn-Sham formal-
ism relies on the application of Fermi’s Golden Rule to compute the imaginary
part of the dielectric function,
\begin{equation*}
\begin{split}\epsilon_2(\omega) = \frac{1}{\Omega} \sum\limits_{c}\sum\limits_{i} |\langle  \psi_i| \exp(i\mathbf{r}\cdot\mathbf{q})
| \psi_c \rangle |^2 \delta (E_i - E_c - \omega)\,,\end{split}
\end{equation*}
Here \(\omega\) is the transition energy, \(\Omega\) the unit cell
volume, the \(\psi_i\) are (all electron) conduction band states,
the \(\psi_c\) are core states, with respective energies \(E_i\)
and \(E_c\). \(\mathbf{r}\) is the position operator
(defined as the displacement from the nucleus
whose core electrons are being excited). The \(\delta\)-function
conserves energy. \(\textsc{ONETEP}\) relies on the external tool
OptaDoS{[}1{]} for the computation of \(\epsilon_2\)
and only needs to supply matrix elements in a compatible form. The rest of
this section discusses the calculation of these elements.


\subsubsection{Projector Augmented Wave}
\label{\detokenize{eels_in_onetep:projector-augmented-wave}}
In common with many plane wave codes onetep uses pseudopotentials to increase
computational efficiency. A drawback of pseudopotentials is poor
representation of the all-electron Kohn-Sham wavefunction close to the nucleus,
this however is exactly the region in which the matrix elements used for EELS
simulation are computed.
To overcome this obstacle the projector augmented wave (PAW) formalism
of Blochl{[}2{]} is adopted, which permits reconstruction of all-electron
states \(\psi\)
(and thus matrix elements) from pseudo-wavefunctions \(\widetilde{\psi}\):

\phantomsection\label{\detokenize{eels_in_onetep:equation-paw-matel}}\begin{equation}\label{equation:eels_in_onetep:paw_matel}
\begin{split}\langle \phi_\alpha \vert \hat{O} \vert b \rangle =
\underbrace{ \langle \phi_\alpha \vert  \hat{O} \vert b\rangle }_\text{Cartesian Grid} +
\sum_{i}\langle \phi_\alpha \vert \widetilde{p}_\text{i}\rangle\underbrace{(\langle \varphi_\text{i} \vert  \hat{O}
\vert b \rangle -
\langle \widetilde{\varphi}_\text{i}
\vert  \hat{O} \vert b \rangle)}_\text{Radial Grids}\end{split}
\end{equation}
This process is accomplished by decomposing the pseudo-wavefunction in
the augmentation region into a sum of pseudo partial waves, \(\widetilde{\varphi}_i\), the weights in
this sum are determined using the projectors \(\widetilde{p}_i\).
These pseudo partial waves are
subtracted off and all electron partial waves, \(\varphi_i\), added in their place.
Simply put, within the augmentation regions (close to the nucleus) the pseudised part
of pseudo-wavefunction is subtracted off and the all electron part is added back
on.

Several PAW data sets are freely available (subject to the caveat that they
should be thoroughly tested for a specific use case). onetep accepts PAW
pseudopotentials in the abinit file format. Core wavefunctions, as produced
by the pseudopotential generator are also required, these are less frequently
available for download, but your PAW library should provide input files for a
pseudopotential generator which can be used to produce core wavefunction data
sets (again in the abinit format).


\subsubsection{Generation of Position-Core Kets}
\label{\detokenize{eels_in_onetep:generation-of-position-core-kets}}
To calculate the PAW matrix elements we must compute terms of the form:
\(\langle\widetilde{\psi}|\mathbf{r}|\psi_\mathrm{c}\rangle\)

As an intermediate we compute expressions of the form:
\(\langle\phi_\alpha|\mathbf{r}|\psi_\mathrm{c}\rangle\)

with \(\phi_\alpha\) an NGWF. The integral implied by this bra-ket must be computed
on the grid. The bra term, an NGWF, is readily available in this form but the
ket \(|\psi_\mathrm{c}\rangle\) must be constructed.

A Fourier space method is used, as it was found
to offer superior numerical performance and correctly treats periodic systems
without further modification. This method exploits the fact that differentiation
in Fourier space is equivalent to multiplication by the position vector in real
space:
\begin{equation*}
\begin{split}\begin{aligned}
\psi_{\rm c}(\mathbf{r}) &= \sum\limits_\mathbf{G}^{\mathbf{G}_{\rm max}} \exp(i\mathbf{G}\cdot\mathbf{r}) \\
\rightarrow \sum\limits_\mathbf{G}^{\mathbf{G}_{\rm max}}( \nabla_\mathbf{G}(\psi_{\rm c}(\mathbf{G}))\exp(i\mathbf{G}\cdot\mathbf{r}) &= \sum\limits_\mathbf{G}^{\mathbf{G}_{\rm max}}( \nabla_\mathbf{G}(\psi_{\rm c}(\mathbf{G})\exp(i\mathbf{G}\cdot\mathbf{r})) \\
&-\sum\limits_\mathbf{G}^{\mathbf{G}_{\rm max}} \psi_{\rm c}(\mathbf{G}) \nabla_\mathbf{G} \exp(i\mathbf{G}\cdot\mathbf{r}) \\
&=-\sum\limits_\mathbf{G}^{\mathbf{G}_{\rm max}} i \mathbf{r} \psi_{\rm c}(\mathbf{G}) \exp(i\mathbf{G}\cdot\mathbf{r})) \\
&=-i\mathbf{r}  \psi_{\rm c}(\mathbf{r})
\end{aligned}\end{split}
\end{equation*}

\subsubsection{Conduction Optimisation}
\label{\detokenize{eels_in_onetep:conduction-optimisation}}
Core loss calculations rely on an accurate description of conduction band states,
in onetep it is necessary to perform a conduction optimisation calculation in
order to obtain a second NGWF set and kernel which correctly represent the
conduction manifold. Detail of the process may be found in the document
“Conduction NGWF optimisation and optical absorption spectra in ONETEP”{[}3{]}
and is published{[}4{]}.

Two main parameters should be supplied: \sphinxcode{cond\_energy\_range} which sets the
energy window above the HOMO in which conduction states will be optimised.
The second parameter cond energy gap
specifies the energy gap between the highest optimised state and the lowest un-
optimised state, this parameter is used to prevent attempts to optimise only
part of a set of degenerate states


\subsection{Practical Example}
\label{\detokenize{eels_in_onetep:practical-example}}
In this section we will discuss the procedure for running an EELS calculation
on a toy system: silene (the silicon equivalent of ethene). You will need to
obtain PAW pseudopotentials for Silicon and Hydrogen and the associated core
wavefunction data for Silicon. The author used the JTH pseudopotentials{[}5{]},
though can’t offer any guarantee of their suitability for any particular use.
A boilerplate input file for a onetep EELS calculation is provided in Appendix B.

This input file can also be downloaded from the tutorials section of the
onetep site. There are a few differences between this input and the one for a
single point calculation:
\begin{itemize}
\item {} 
PAW is mandatory

\item {} 
We specify a second species for the atom whose core electrons we’re exciting

\item {} 
Because a conduction calculation is being performed we must provide a species cond block

\item {} 
We must provide a \sphinxcode{species\_core\_wf} block and every species must be listed there.

\end{itemize}

The input file can be run swiftly on a single node and should produce a
large number of output files. Most of these files are \sphinxcode{.cube}’s of wavefunctions
produced by default during the properties calculations. The files of interest
are the \sphinxcode{.elnes\_bin} files, which contain OptaDoS compatible matrix elements.

A little more setup is needed before we can run OptaDoS (using the silene
example):
\begin{itemize}
\item {} 
A dummy castep \sphinxcode{silene-out.cell} file must be produced, and it must contain a symmetry block

\item {} 
By default two \sphinxcode{.elnes bin} files are produced, one based on Kohn-Sham wavefunctions represented using only the valence NGWFs (\sphinxcode{silene\_val\_grad.elnes\_bin}) and a second which makes use of the joint basis of valence and conduction NGWFs (\sphinxcode{silene\_joint\_grad.elnes\_bin})

\item {} 
As per the discussion above, you should choose the latter and copy it to \sphinxcode{silene.elnes bin}.

\item {} 
A \sphinxcode{silene.bands} file must be produced, this is best done by copying \sphinxcode{silene.joint bands} to \sphinxcode{silene.bands}.

\item {} 
An OptaDoS input file, \sphinxcode{silene.odi} is needed.

\end{itemize}

To assist in these tasks a utility script, \sphinxcode{prep\_optados\_eels}, is provided in the
utils folder of the onetep distribution. Run it with the calculation seed name
as its argument and the steps listed above will be completed automatically.

The .odi file produced should be regarded as a basic template, consult the
OptaDoS documentation{[}6{]} if you wish to use more advanced features. Note
that at the moment only fixed broadening is supported by onetep.
When you are satisfied with your OptaDoS input file, execute OptaDoS
with your calculation seed name as the argument. All being well, you should
see a .dat file which you can plot with your favorite tool. Individual edges are
listed sequentially in the file, so a little post processing with awk or python is
needed to separate the edges for individual plotting


\subsection{OptaDoS}
\label{\detokenize{eels_in_onetep:optados}}
The OptaDoS code provides a single tool to compute densities of states and
optical spectra of various sorts. OptaDoS provides a number of smearing
schemes for evaluating integrals over the Brillouin Zone including fixed and
adaptive schemes. At present onetep only supports simple fixed broadening
schemes. The prep optados eels utility script provides a template .odi input
file:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{TASK} \PYG{p}{:} \PYG{n}{CORE}

\PYG{c+c1}{\PYGZsh{} Method OptaDoS should use to work out}
\PYG{c+c1}{\PYGZsh{} the Fermi energy in the material .}
\PYG{c+c1}{\PYGZsh{} the insulator method relies on electron}
\PYG{c+c1}{\PYGZsh{} counting and is best for the systems}
\PYG{c+c1}{\PYGZsh{} onetep is most commonly used to study .}
\PYG{n}{EFERMI} \PYG{p}{:} \PYG{n}{insulator}

\PYG{c+c1}{\PYGZsh{} Smearing scheme and width}
\PYG{n}{BROADENING} \PYG{p}{:} \PYG{n}{fixed}
\PYG{n}{DOS\PYGZus{}SPACING} \PYG{p}{:} \PYG{l+m+mf}{0.01}

\PYG{c+c1}{\PYGZsh{} Use an average of x , y and z components of}
\PYG{c+c1}{\PYGZsh{} the position vector matrix elements}
\PYG{n}{CORE\PYGZus{}GEOM} \PYG{p}{:} \PYG{n}{polycrystalline}

\PYG{c+c1}{\PYGZsh{} Parameters below control lifetime and}
\PYG{c+c1}{\PYGZsh{} instrument broadening}
\PYG{n}{CORE\PYGZus{}LAI\PYGZus{}BROADENING} \PYG{p}{:} \PYG{n}{true}
\PYG{n}{LAI\PYGZus{}GAUSSIAN\PYGZus{}WIDTH} \PYG{p}{:} \PYG{l+m+mf}{0.6}
\PYG{n}{LAI\PYGZus{}LORENTZIAN\PYGZus{}WIDTH} \PYG{p}{:} \PYG{l+m+mf}{0.2}
\PYG{n}{LAI\PYGZus{}LORENTZIAN\PYGZus{}SCALE} \PYG{p}{:} \PYG{l+m+mf}{0.1}
\end{sphinxVerbatim}


\subsection{References}
\label{\detokenize{eels_in_onetep:references}}
\begin{DUlineblock}{0em}
\item[] {[}1{]} RJ Nicholls, AJ Morris, CJ Pickard, and JR Yates. Optados-a new tool
for eels calculations. In Journal of Physics: Conference Series, volume 371,
page 012062. IOP Publishing, 2012.
\item[] {[}2{]} Peter E Blochl. Projector augmented-wave method. Physical Review B,
50(24):17953, 1994.
\item[] {[}3{]} Laura E. Ratcliff. Conduction NGWF optimisation and optical absorption
spectra in onetep. \sphinxurl{http://www2.tcm.phy.cam.ac.uk/onetep/pmwiki/}
uploads/Main/Documentation/conduction.pdf, 2011. {[}Online; accessed
22-Sept-2015{]}.
\item[] {[}4{]} Laura E Ratcliff, Nicholas DM Hine, and Peter D Haynes. Calculating op-
tical absorption spectra for large systems using linear-scaling density func-
tional theory. Physical Review B, 84(16):165131, 2011.
\item[] {[}5{]} Francois Jollet, Marc Torrent, and Natalie Holzwarth. Generation of projec-
tor augmented-wave atomic data: A 71 element validated table in the XML
format. Computer Physics Communications, 185(4):1246 \textendash{} 1254, 2014.
\item[] {[}6{]} Andrew J. Morris, Rebecca J. Nicholls, Chris J. Pickard, and Jonathan R.
Yates. OptaDoS user guide. \sphinxurl{http://www.cmmp.ucl.ac.uk/~ajm/}
optados/files/user\_guide\_1.0.pdf, 2014. {[}Online; accessed 22-Sept-
2015{]}
\end{DUlineblock}


\section{Electronic transport calculations}
\label{\detokenize{transport:electronic-transport-calculations}}\label{\detokenize{transport::doc}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Robert A. Bell, University of Cambridge (\sphinxcode{rab207@cam.ac.uk})

\end{description}\end{quote}


\subsection{Introduction}
\label{\detokenize{transport:introduction}}
This document describes the use of the electronic transport
functionality that is implemented in the ONETEP
code {[}Bell2014{]}. The implementation computes the
ballistic Landauer-Büttiker conductance at zero bias through a device
and associated properties using electronic structure derived from
density functional theory (DFT). The calculation proceeds as a
post-processing step after a ground-state single-point calculation.

This document focuses on the practical aspects of setting up
calculations; a detailed technical explanation of the method can be
found in {[}Bell2014{]}. For a detailed discussion
of the Landauer-Büttiker formalism and conductance derived from DFT see
{[}DiVentra2008{]}, {[}Datta1995{]}.

I first briefly outline what is being calculated, I then give an example
calculation and suitable input parameters, and then finally a full input
parameter listing is given.


\subsection{What is being calculated?}
\label{\detokenize{transport:what-is-being-calculated}}
The transport calculation determines the ballistic conductance through a
device. Current can flow between two leads via the connection made by
the central scattering region. We will refer to this geometry as the
\sphinxstyleemphasis{device} geometry.

Under the Landauer formalism, the contribution to the conductance
between two leads (indexed \(i\) and \(j\)) from electrons with
energy \(E\) is given by
\begin{equation*}
\begin{split}G_{ij}(E) = \frac{2e^2}{h} T_{ij}(E)\end{split}
\end{equation*}
where \(T_{ij}(E)\) is the transmission function. The transmission
function is the central quantity to the Landauer-Büttiker conductance
and is calculated using a Green’s function technique:

\phantomsection\label{\detokenize{transport:equation-caroli}}\begin{equation}\label{equation:transport:caroli}
\begin{split}   T_{ij}(E) = \mathrm{tr}\Big[\Gamma_i(E)\;G_{\rm d}(E)\;\Gamma_j(E)\;G_{\rm d}^{\dagger}(E)\Big],\end{split}
\end{equation}\phantomsection\label{\detokenize{transport:equation-greenf}}\begin{equation}\label{equation:transport:greenf}
\begin{split}   G_{\rm d}(E) = \big[ (E+i\eta)S_{\rm d} - H_{\rm d} - \Sigma(E)\big]^{-1},\end{split}
\end{equation}
where \(H_{\rm d}\), \(S_{\rm d}\) the
Hamiltonian and overlap matrices for the device, and \(\eta\) is an
infinitessimal positive energy that selects the retarded response of the
Green’s function \(G_{\rm d}\). The interaction with the
semi-infinite leads accounted for through the lead self-energies
\(\Sigma_j\), with
\(\Sigma = \sum_j \Sigma_j\). The coupling
matrices are defined as
\(\Gamma_j = i(\Sigma_j - \Sigma_j^{\dagger})\).

From the Green’s function, one may also calculate the density of states
within the device region as
\begin{equation*}
\begin{split}\mathcal{N}(E) = -\frac{1}{\pi}{\mathrm{Im}}\mathrm{tr}\big[G_{\rm d}(E) S_{\rm d}\big].\end{split}
\end{equation*}
Further post processing steps may be performed to determine the
eigenchannels. {[}Bell2014{]}, {[}Paulsson2007{]}


\subsection{Building the device}
\label{\detokenize{transport:building-the-device}}
The principal quantities required in Eqns. \eqref{equation:transport:caroli} and \eqref{equation:transport:greenf}
are the device Hamiltonian and overlap matrices, and the lead self
energies. The approach adopted in this implementation is to extract
these matrix elements from the ground-state electronic structure
obtained after a standard single-point calculation. This approach
corresponds to a non-self consistent calculation of the transmission
spectrum and device electronic structure. Note that this procedure
differs from self consistent approaches, such as e.g.
{[}Brandbyge2002{]}, where the open boundary conditions of
the leads are treated explicitly. At zero bias, however, both methods
produce equivalent results yet the non-self consistent approach is often
far less computationally expensive.

A detailed description of the matrix element extraction procedure, as
implemented in the ONETEP code, is given in {[}Bell2014{]}
which should be referred to in the first instance. Summarising briefly,
to calculate the transmission through any device geometry the user must
construct another \sphinxstyleemphasis{auxilliary simulation} structure that contains this
device. The \sphinxstyleemphasis{only} electronic structure that is calculated is that of
the auxilliary simulation geometry.

The structure of the auxilliary simulation geometry must take a specific
form, consisting of the central region that connects the leads and a
bulk-like region for each lead. Each lead region must have a local
electronic structure that is bulk-like, and be large enough that it
contains at least two principal layers of the bulk lead structure. %
\begin{footnote}[1]\sphinxAtStartFootnote
A lead principal layer is defined as the minimum number of primitive
unit cells for that lead such that Hamiltonian and overlap matrix
elements between atoms in non-adjacent principal layers are exactly
zero. This is guaranteed to be true if the periodic length of the
principal layer is larger than twice the maximum NGWF radius.
%
\end{footnote}
The device geometry is then defined as all the atoms contained within
the central region and the two lead principal layers for each lead.

For a device connecting two leads, the device Hamiltonian then looks
like
\begin{equation*}
\begin{split}H_{\rm d} =
   \begin{pmatrix}
      \mathbf{h}_{00,L}    & \mathbf{h}_{0,L}  & \cdot                & \cdot                  & \cdot              \\
      \mathbf{h}^\dagger_{01,L} & \mathbf{h}_{00,L}  & \mathbf{h}_{LC}    & \cdot                  & \cdot              \\
      \cdot                  & \mathbf{h}^\dagger_{LC} & \mathbf{h}_{C}     & \mathbf{h}_{CR}      & \cdot              \\
      \cdot                  & \cdot                & \mathbf{h}^\dagger_{CR} & \mathbf{h}_{00,R}    & \mathbf{h}_{01,R}\\
      \cdot                  & \cdot                & \cdot                & \mathbf{h}^\dagger_{01,R} & \mathbf{h}_{00,R}
   \end{pmatrix}\end{split}
\end{equation*}
where \(\mathbf{h}_{00,L}\) is the on-site Hamiltonian block for
the left lead principal layer, \(\mathbf{h}_{01,L}\) is the
coupling Hamiltonian between principal layers, \(\mathbf{h}_{LC}\)
is the coupling block between the left lead principal layer and the
central region, and \(\mathbf{h}_{C}\) is the on-site block for
the central region. As a result of the localisation of the NGWFs the
device Hamiltonian takes the block tri-diagonal form, with zero matrix
blocks denoted by a dot. An equivalent form is found for the device
overlap matrix.

The lead self energies are computed using the
\(\mathbf{h}_{00,L}, \mathbf{h}_{01,L}\) blocks via the method
of Ref. {[}Lopez-Sancho1985{]}. Note that these blocks are
contained within the device Hamiltonian \(H_{\rm d}\).

The device matrix elements are extracted from the electronic structure
of the auxilliary simulation geometry. This procedure is entirely
automated, however, and the user need only supply a list of atoms that
define the device, and the subsets of these atoms that form the two
principal layers for each lead. \sphinxstyleemphasis{i.e.} for an \(n\)-lead device, the
user must define \(2n+1\) sets of atoms.

A single limitation of the implementation is that the two principal
layers of any lead must be the exact same structure \sphinxstyleemphasis{with atoms in the
same relative ordering}. This ensures that the lead self energies are
computed correctly. The implementation will not do this automatically,
however a check is performed to ensure that it is true before the
calculation is started.

For a more detailed discussion of the procedure for extracting matrix
elements see {[}Bell2014{]}.


\subsection{Setting up a calculation}
\label{\detokenize{transport:setting-up-a-calculation}}
The best way to explain how to set up an input is through an example,
and here I give an explanation of the parameters required to calculation
the transmission between two semi-infinite organic wires. Specifically,
I will explain the setup for calculating the tunnelling current between
a polyacetylene wire and polyyne wire where each wire is semi-infinite
and terminated with a hydrogen atom. I will, however, assume that the
user knows how to successfully converge the standard ONETEP single-point
calculation.

A suitable auxiliary simulation geometry is shown in schematic form in Fig. \hyperref[\detokenize{transport:fig1}]{Fig.\@ \ref{\detokenize{transport:fig1}}},
consisting of molecular fragments of the polyacetylene and polyyne wires
located in vacuum. This entire geometry contains 52 atoms. I will assume
that these atoms are ordered in the input file by their position from
left to right.

Suppose that I wish to calculate the transmission spectrum in a
\(\pm 2eV\) window about the Fermi energy with a resolution
of \(0.01eV\). The transport specific input parameters are as
follows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
etrans\PYGZus{}lcr               : T
etrans\PYGZus{}bulk              : T
etrans\PYGZus{}emin              : \PYGZhy{}2.0 eV
etrans\PYGZus{}emax              :  2.0 eV
etrans\PYGZus{}enum              :  401
etrans\PYGZus{}calculate\PYGZus{}lead\PYGZus{}mu : T

\PYGZpc{}block etrans\PYGZus{}setup
  10  47
\PYGZpc{}endblock etrans\PYGZus{}setup

\PYGZpc{}block etrans\PYGZus{}leads
  10  17  18  25  unit\PYGZus{}cells=2
  44  47  40  43  unit\PYGZus{}cells=2
\PYGZpc{}endblock etrans\PYGZus{}leads

! rest of input file...
\end{sphinxVerbatim}

The first six lines indicate that we wish to calculate the transmission
between the two leads (the LCR transmision, see
{[}Bell2014{]}), and the maximum transmission that
could be injected by each lead (the bulk transmission), and the energy
range the calculation will be performed over. I am also indicating that
I want to calculate the lead band structures.

The first block after these six lines is the \sphinxcode{etrans\_setup} block which
states that all atoms between atom \(10\) and \(47\) (inclusive,
and in the order found in the input file) are defined as the device
geometry. This region is given by the long-dashed box in . Atoms outside
this set will not be included in the transmission calculation, but will
be used when calculating the ground-state electronic structure.

The final block is the \sphinxcode{etrans\_leads} block which gives the subset of
these device atoms that define the two principal layers for each lead.
Each lead is given on a separate line, with the first pair of indices
defining the principal layer furthest from the central region, and the
second pair the principal layer closest to the central region. Note that
this ordering of the two principal layers is important. Finally, I have
indicated that each principal layer is in fact two primitive unit cells
of the lead structure by using \sphinxcode{unit\_cells=2}. This tells ONETEP to symmetrise
the lead matrix elements to reflect this periodicity. The atoms
contained within each principal layer are indicated in by dotted boxes.

This choice of auxilliary simulation geometry tries to ensure that the
lead principal layers are sufficiently far from the ends of the
molecular fragments that the local electronic structure within the lead
is bulk-like. This has required the use of buffer atoms (atoms 1\textendash{}9 and
48\textendash{}52) that are not included in the transport calculation. Some buffer
has also been used between the principal layers and the central
tunnelling gap (atoms 26\textendash{}34 and 35\textendash{}39) for the same reason. In practice,
the size of this buffer is probably too small and the lead principal
layers will not be well converged to the bulk. This can be tested by
comparing the band structures of each lead to the corresponding bulk
band structure for that lead, which can be calculated separately. If the
lead band structure is not converged, the size of the buffer region
should be increased.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{transport_fig1}.png}
\caption{A possible auxilliary simulation geometry for calculating the tunnelling transmission between a polyacetylene wire and a polyyne wire. The atoms appear ordered in the input file by their position from left to right.}\label{\detokenize{transport:fig1}}\label{\detokenize{transport:id15}}\end{figure}


\subsection{Computational scaling}
\label{\detokenize{transport:computational-scaling}}
The dominant computationally-intensive task in the transport routines is
the computing of the device Green’s function. This calculation is
performed using an efficient block tri-diagonal Gaussian-elimination
algorithm {[}Petersen2008{]}. This algorithm results in memory
usage and operation counts that scale linearly in the number of atoms.
The pre-factor to this scaling depends on the precise geometry of the
device: the more one-dimensional a device (i.e. the fewer NGWFs that
overlap), the lower this pre-factor.


\subsection{Information on parallelisation}
\label{\detokenize{transport:information-on-parallelisation}}
The calculation of transmission coefficients is parallelised over the
energy points, with each MPI process performing the calculation in
serial. No internal communications are necessary making the routines
scale perfectly with the number of MPI processes. However, as all
matrices must be replicated on each MPI process, the memory requirements
can be large. On entering the transport routines but prior to starting
the calculation, an estimate of the additional memory required by the
transport routines is printed. Note that this estimate does not include
the memory required by the rest of the ONETEP routines.

Parallelisation using OpenMP threading is not currently available.
However, if the code is linked against Intel’s Math Kernel Library
(MKL), the linear algebra routines can make use of multi-threading
within this library. To do this, the flag \sphinxcode{-DMKLOMP} must be included
during compilation, and the number of threads can be set from the input
file using \sphinxcode{threads\_num\_mkl}.

The calculation of the eigenchannels can only be parallelised if linking
against the ScaLAPACK library to make use of parallel dense algebra. To
enable this, the flag \sphinxcode{-DSCALAPACK} must be included at compilation.


\subsection{Calculations using the joint NGWF basis}
\label{\detokenize{transport:calculations-using-the-joint-ngwf-basis}}
Transmission calculations using the joint (valence + conduction) NGWF
basis set have often been found to be numerically unstable and produce
qualitively incorrect results when compared to calculations using the
valence NGWF basis alone. This is a result of ill-conditioning of the
joint basis when the valence and conduction NGWFs are very similar in
character. This is a known issue, however there is currently no fix.

For some systems it has been found that the valence NGWFs alone are
capable of describing low-energy conduction states with good accuracy,
and therefore the joint basis is not needed. It is advised that the
valence basis is used in the first instance.

If you are certain that the joint basis is required, then proceed with
caution and always compare the results generated with the joint basis to
those generated using the valence basis. For energies below the Fermi
energy, the two calculations should coincide. If they do not, or if
errors (e.g. complaining about computing the transfer matrix/self
energy, or lead band structures) are found then it may not be possible
to use the joint basis.

If using the joint NGWF basis, all output files have \sphinxcode{.joint} prepended
to the extension.


\subsection{Warnings and fixing errors}
\label{\detokenize{transport:warnings-and-fixing-errors}}
A useful check is to ensure that the lead band structure is as expected,
and that the lead occupancy is correct. It is also useful to check the
lead/device \sphinxcode{.xyz} files to ensure that the leads have the expected
geometry.

The following are the main warning messages that may be encountered, and
how they may be tackled.
\begin{description}
\item[{\sphinxcode{Inversion of (eS-H)\_lcr failed}}] \leavevmode
\begin{DUlineblock}{0em}
\item[] 
\item[] \sphinxstylestrong{Cause}: Failed to calculate the Green’s function as it is
singular at this energy. This can happen if etrans\_ecmplx is too
small, or if localised states are present near this energy.
\item[] \sphinxstylestrong{Severity}: Low
\item[] \sphinxstylestrong{Fix}: It is safe to ignore this warning; the transmission
coefficients and associated values are not written to file. If it
occurs over a wide energy range, or in an energy range of
interest, try increasing \sphinxcode{etrans\_ecmplx}.
\end{DUlineblock}

\item[{\sphinxcode{Warning in compute\_transfer: Failed to compute transfer matrix.}}] \leavevmode
\begin{DUlineblock}{0em}
\item[] 
\item[] \sphinxstylestrong{Cause}: Failed to compute the lead self energy. This can happen
if \sphinxcode{etrans\_ecmplx} is too small, or if localised states are present
near this energy.
\item[] \sphinxstylestrong{Severity}: Low
\item[] \sphinxstylestrong{Fix}: It is safe to ignore this warning; the transmission
coefficients and associated values are not written to file. If it
occurs over a wide energy range, or in an energy range of
interest, try increasing \sphinxcode{etrans\_ecmplx}. If using the joint NGWF
basis, this may indicate that the basis is ill-conditioned and
that the calculation is numerically unstable.
\end{DUlineblock}

\item[{\sphinxcode{Lead electronic occupancy is significantly different ...}}] \leavevmode
\begin{DUlineblock}{0em}
\item[] 
\item[] \sphinxstylestrong{Cause}: Large discrepancy between the ionic and electronic
charge in the lead. Likely due to under-converged buffer region
between this lead and the scattering region.
\item[] \sphinxstylestrong{Severity}: high
\item[] \sphinxstylestrong{Fix}: Check that the lead band structure is what is expected.
Increase buffer region between the lead and the scattering region.
Check the ground state DFT calculation is converged and that the
density kernel occupancies are \(0\) or \(1\) (if using
the default LNV algorithm).
\end{DUlineblock}

\item[{\sphinxcode{Unable to determine lead potential for lead ...}}] \leavevmode
\begin{DUlineblock}{0em}
\item[] 
\item[] \sphinxstylestrong{Cause}: lead potential calculation for this lead failed: could
not determine the lead band structure. This may indicate that the
leads have been defined incorrectly. Check the lead structure.
\item[] \sphinxstylestrong{Severity}: possibly high
\item[] \sphinxstylestrong{Fix}: Check the lead structure. Check the matrix elements
contained in the lead .hsm output file are resonable, that the
main weight is along the matrix diagonal and that the values are
sensible. If using joint NGWF basis, try using the valence basis
only (\sphinxcode{task = properties} not \sphinxcode{properties\_cond}). The calculation
will attempt to continue, but check carefully the results are as
expected.
\end{DUlineblock}

\end{description}


\subsection{Full input parameter description}
\label{\detokenize{transport:full-input-parameter-description}}

\subsubsection{Main parameters}
\label{\detokenize{transport:main-parameters}}
\sphinxcode{etrans\_lcr: T/F} {[}Logical, default \sphinxcode{etrans\_lcr: F} {]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Calculate the transmission spectrum between all pairs of leads in the
system.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_bulk: T/F} {[}Logical, default \sphinxcode{etrans\_bulk: F} {]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Calculate the bulk transmission spectrum for the leads.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_setup: {[}block{]}}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] \sphinxcode{\%block etrans\_setup}
\item[]
\begin{DUlineblock}{\DUlineblockindent}
\item[] \sphinxcode{start end}
\end{DUlineblock}
\item[] \sphinxcode{\%endblock etrans\_setup}
\item[] The block defining the atoms to be used in the transport calculation. \sphinxcode{start/end} are integers giving the indices (from the input file) of the first/last atoms to be included as part of the system. All atoms between \sphinxcode{start} and \sphinxcode{end} are used in the calculation; atoms outside this range are buffer regions and ignored. The atoms consituting the leads must be contained within this region.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_leads: {[}block{]}}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] \sphinxcode{\%block etrans\_leads}
\item[]
\begin{DUlineblock}{\DUlineblockindent}
\item[] \sphinxcode{start0 end0 start1 end1}
\item[] \sphinxcode{start0 end0 start1 end1 unit\_cells=\textless{}n\textgreater{} file=\textless{}lead2.hsm\textgreater{}}
\item[] \sphinxcode{...}
\end{DUlineblock}
\item[] \sphinxcode{\%endblock etrans\_leads}
\item[] The block defining the atoms to be used as the leads. Each line defines a new lead. \sphinxcode{start0/end0} are integers giving the indices (from the input file) of the first/last atoms of the lead principal layer farthest from the central region; \sphinxcode{start1/end1} are integers giving the indices of the first/last atom of the principal later closest to the central region.
\item[] The first principal layer geometry must be a periodic repeat of the lead geometry (i.e. same number of atoms, in the same relative ordering in the input file).
\item[] For each lead, two optional tags can be defined. The option \sphinxcode{unit\_cells=\textless{}n\textgreater{}} forces the translational symmetry of the principal layer matrix elements, where \sphinxcode{n} is the number of primitive unit cells in the principal layer. The option \sphinxcode{file=\textless{}lead1.hsm\textgreater{}} allows for the lead matrix elements to be read in from a \sphinxcode{.hsm} file. Reading in matrix elements is generally unnecessary, however it may be used effectively by taking the \sphinxcode{.hsm} of a separate pristine/bulk transport calculation to ensure that the matrix elements are exactly at their bulk values. The positions and ordering of atoms in the lead principal layers in both calculations must be identical: this is not checked in the calculation.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_enum: n} {[}Integer, default \sphinxcode{etrans\_enum: 50}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Number of transmission energy points calculated for. Energies are
distributed uniformly.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_emax :} \(E_{\mathrm{max}}\) {[}Physical, default \sphinxcode{etrans\_emax: -0.2 Hartree}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The maximum energy above the reference energy transmission is
calculated for.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_emin :} \(E_{\mathrm{min}}\) {[}Physical, default \sphinxcode{etrans\_emin: 0.2 Hartree}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The minimum energy below the reference energy transmission is
calculated for.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_eref\_method: LEADS\textbar{}REFERENCE\textbar{}DIAG} {[}String, default \sphinxcode{etrans\_eref\_method: LEADS}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The method used to determine the reference energy
\(E_{\mathrm{ref}}\) for the transmission calculation.
\item[] If \sphinxcode{etrans\_eref\_method: LEADS}, the reference energy is set as the average lead chemical potential.
\item[] If \sphinxcode{etrans\_eref\_method: DIAG}, the reference energy is set as the Fermi energy of the original DFT system.
\item[] If \sphinxcode{etrans\_eref\_method: REFERENCE}, the reference energy is set with \sphinxcode{etrans\_eref}.
\item[] If unset, this will be determined by calculating the average chemical
potential of the leads, or if that calculation fails, the Fermi energy
of the original DFT system will be used.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_eref :} \(E_{\mathrm{ref}}\) {[}Physical, default \sphinxcode{etrans\_eref: Determined automatically}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Reference energy around which the transmission will be calculated. Energies are distributed uniformly in range \(E_{\mathrm{ref}}+E_{\mathrm{min}} \leq E \leq E_{\mathrm{ref}}+E_{\mathrm{max}}\).
\item[] This value is only used if \sphinxcode{etrans\_eref\_method : REFERENCE}, otherwise it is determined automatically by the method given by \sphinxcode{etrans\_eref\_method}.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_num\_eigchan :} \(n_{\mathrm{chan}}\) {[}Integer, default \sphinxcode{etrans\_num\_eigchan: 0}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The number of eigenchannel transmissions calculated. The default does
not decompose into eigenchannel transmissions.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_plot\_eigchan : T/F} {[}Logical, default \sphinxcode{etrans\_plot\_eigchan: F}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Whether to plot the transmission eigenchannels of the LCR system.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_plot\_eigchan\_energies : {[}block{]}}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] \sphinxcode{\%block etrans\_plot\_eigchan\_energies}
\item[]
\begin{DUlineblock}{\DUlineblockindent}
\item[] \sphinxcode{\{Ha\textbar{}eV\} ! optional energy unit}
\item[] \(E_1\)
\item[] \(E_2\)
\item[] \sphinxcode{...}
\end{DUlineblock}
\item[] \sphinxcode{\%endblock etrans\_plot\_eigchan\_energies}
\item[] The energies at which the eigenchannels are calculated and plotted. The first line may, optionally, define the energy unit; if undefined, the energy unit is Hartree.
\item[] Plotting the eigenchannels uses an algorithm that scales with the cube of the number of atoms in the LCR system. Compiling with the ScaLAPACK library is strongly recommended to reduce memory requirements.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_write\_xyz : T/F} {[}Logical, default \sphinxcode{etrans\_write\_xyz : T}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Whether to write, separately, the lead and LCR geometries to file in
the .xyz file format. This is useful for ensuring that the correct
atoms have been chosen for the leads/LCR region.
\end{DUlineblock}
\end{quote}


\subsubsection{Tweaking/optional parameters}
\label{\detokenize{transport:tweaking-optional-parameters}}
\sphinxcode{etrans\_ecmplx :} \(\eta\) {[}Physical, default \sphinxcode{etrans\_ecmplx: 1e-6 Hartree}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The small complex energy added to calculate the retarded Green’s
function.
\item[] Ideally this should be infinitesimally small, however too small values
create numerical instabilities. Large values improve numerical
stability, but creates artificial scattering, reducing transmission.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_calculate\_lead\_mu : T/F} {[}Logical, default \sphinxcode{etrans\_calculate\_lead\_mu: T}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Determine the chemical potential of the leads using a tight-binding
approach. If \sphinxcode{etrans\_eref} is unset, the average lead chemical
potential will be used as the reference energy. The band structure for
each lead is saved to file \sphinxcode{basename\_lead\textless{}nn\textgreater{}.bands}.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_num\_lead\_kpoints :} \(n_k\) {[}Integer, default \sphinxcode{etrans\_num\_lead\_kpoints: 32}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The number of lead band structure \(k\)-points sampled to
determine the lead chemical potential. The \(k\)-points are
distributed uniformly between \(\Gamma\) and \(X\).
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_same\_leads : T/F} {[}Logical, default \sphinxcode{etrans\_same\_leads: F}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Reuse the self energy from one lead for all leads. If all leads are
identical, this may lead to a small computational saving. The saving
is typically negligible however.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_write\_hs : T/F} {[}Logical, default \sphinxcode{etrans\_write\_hs: F}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Write the lead Hamiltonian and overlap matrices to disk.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_lead\_disp\_tol :} \(\Delta r\) {[}Physical, default \sphinxcode{etrans\_lead\_disp\_tol : 1.0 bohr}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The geometries of each lead and corresponding first principal layer
should be identical; this parameter determines how strictly this is
enforced. This should only be done if you are clear of the consequences.
\item[] This may be useful in the case that the lead unit cell is much larger
than the NGWF radius. If the distance between the lead and the first
principal layer furthest from the lead is much larger than 2 NGWF radii,
these atoms do not directly influence the non-zero matrix elements
between the principal layer and the lead, and the coupling matrix
\(h_L\) is (approximately) independent of the structure of these
atoms. Therefore, it may be possible to use a much smaller buffer region
between the lead and the first principal layer by including part of the
first principal layer in that buffer. The first principal layer and lead
geometry need not be identical, however both regions must contain the
same number of atoms and orbitals.
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] For each lead, the translation vector between the \(i^{th}\) atoms
of the lead and first principal layer is calculated:
\(\mathbf{R}_{i} = \mathbf{r}_{i\mathrm{,lead}} - \mathbf{r}_{i\mathrm{,PL}}\).
If the geometries of the lead and first principal layer are identical,
all of these translation vectors are identical. The maximum allowed
difference between these displacement vectors is
\(\Delta r > |\mathbf{R}_{i} - \mathbf{R}_{j}|\).
\item[] If the lead crosses the supercell boundary, this check will fail. This
can be overridden by increasing \(\Delta r\) to some very large
value.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_lead\_size\_check : T/F} {[}Logical, default \sphinxcode{etrans\_lead\_size\_check: T}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] If true, a check is performed to ensure that each lead forms complete
principal layer. The run will abort if the periodic length of the lead
unit cells, as defined in the input file, are smaller than twice the
maximum NGWF radius of the species in that lead.
\item[] Turning off this check is not advised as the lead band structure and
self energies can be inaccurate. This can also be a problem in
situations where the left
lead can interact with the principal layer of the right lead, allowing
current to flow between the leads in the wrong direction, bypassing
the central scattering region.
\end{DUlineblock}
\end{quote}

\sphinxcode{etrans\_seed\_lead} {[}Integer, default \sphinxcode{etrans\_seed\_lead: 1}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The lead used to seed the block tri-diagonal partitioning. This should
only be relevant for devices with more than two leads where one lead
is much larger than the other leads.
\end{DUlineblock}
\end{quote}

\sphinxcode{threads\_num\_mkl} {[}Integer, default \sphinxcode{threads\_num\_mkl: 1}{]}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] If the code is linked against Intel’s Math Kernel Library (MKL), this
defines the number of threads used in the linear algebra routines. The
flag \sphinxcode{-DMKLOMP} must be set during compilation to enable this parameter,
otherwise it is ignored.
\end{DUlineblock}
\end{quote}


\subsection{Output file description}
\label{\detokenize{transport:output-file-description}}
Output files contain self-explanatory headers for each column. For spin
polarised calculations, a separate file is outputted for each spin
channel.

\sphinxcode{basename\_LCR.TRC}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The LCR transmission coefficients between different pairs of leads
of the system.
\end{DUlineblock}
\end{quote}

\sphinxcode{basename\_LCR\_channels\_lead\textless{}nn\textgreater{}.TRC}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The LCR transmission coefficients decomposed into eigenchannels.
The lead number defines which lead acts as the source.
\end{DUlineblock}
\end{quote}

\sphinxcode{basename\_LCR\_E\textless{}nn\textgreater{}\_lead\textless{}mm\textgreater{}\_chan\textless{}ll\textgreater{}\_\{real\textbackslash{}\textbar{}imag\}.cube}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The plotted LCR eigenchannel. \(nn\) is the the energy index
from \sphinxcode{\%block etrans\_plot\_eigchan\_energies}; \(mm\) is the lead
that acts as the source; \(ll\) is the eigenchannel number.
The real and imaginary part are printed separately.
\end{DUlineblock}
\end{quote}

\sphinxcode{basename\_BULK.TRC}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The bulk transmission coefficients for each lead of the system.
\end{DUlineblock}
\end{quote}

\sphinxcode{basename\_LCR.DOS}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The density of states for the LCR system.
\end{DUlineblock}
\end{quote}

\sphinxcode{basename\_BULK.DOS}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The density of states for each lead of the system.
\end{DUlineblock}
\end{quote}

\sphinxcode{basename\_lead\textless{}nn\textgreater{}.bands}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Bandstructure of the lead in the  .bands format. The number of
\(k\)-points is set with etrans\_num\_lead\_kpoints.
\end{DUlineblock}
\end{quote}

\sphinxcode{basename\_device.xyz}   \sphinxcode{basename\_lead\textless{}nn\textgreater{}.xyz}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The geometries of the device and leads in .xyz file format.
\end{DUlineblock}
\end{quote}

\sphinxcode{basename\_lead\textless{}nn\textgreater{}.hsm}
\begin{quote}

\begin{DUlineblock}{0em}
\item[] The lead matrix elements in Fortran (unformatted) binary format.
Note that all energies are in Hartree. It is planned, but
currently not possible, to be able to access the device matrix
elements. Please contact the developers if you are interested in
using this functionality. The format of this file is
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
character(len=*) :: block\PYGZus{}type  ! always lead
character(len=*) :: ham\PYGZus{}type    ! valence or joint
integer          :: nspin       ! number of spin channels
integer          :: orbs(4)     ! NGWF indices corresponding
                                ! to the atoms defined
                                ! in block\PYGZus{}etrans\PYGZus{}leads
integer          :: norb        ! matrix sizes
real(kind=8)     :: eref        ! the lead chemical potential

real(kind=8)   :: h00(norb,norb,nspin)
real(kind=8)   :: h01(norb,norb,nspin)
real(kind=8)   :: s00(norb,norb)
real(kind=8)   :: s01(norb,norb)
\end{sphinxVerbatim}
\end{quote}

{[}Bell2014{]} R.A. Bell, S.M.-M. Dubois, M.C. Payne, A. A. Mostofi, \sphinxstyleemphasis{in preparation} (2014)

{[}DiVentra2008{]} M. Di Ventra, \sphinxstyleemphasis{Electrical Transport in Nanoscale Systems}, (Cambridge University Press, Cambridge 2008)

{[}Datta1995{]} S. Datta, \sphinxstyleemphasis{Electronic Transport in Mesoscopic System}, 2nd ed. (Cambridge University Press, Cambridge 1995)

{[}Paulsson2007{]} M. Paulsson, M. Brandbyge, Phys. Rev. B. \sphinxstylestrong{76} 115117 (2007)

{[}Lopez-Sancho1985{]} M.P. Lopez-Sancho, J.M. Lopez-Sancho, J. Rubio, \sphinxstyleemphasis{J. Phys. F: Met. Phys.} \sphinxstylestrong{15}, 851 (1985)

{[}Petersen2008{]} D.E. Petersen \sphinxstyleemphasis{et al.}, \sphinxstyleemphasis{J. Comp. Phys} \sphinxstylestrong{227}, 3174 (2008)


\section{Bandstructure (spectral-function) unfolding}
\label{\detokenize{spectral_function_unfolding::doc}}\label{\detokenize{spectral_function_unfolding:bandstructure-spectral-function-unfolding}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Gabriel Constantinescu, University of Cambridge

\end{description}\end{quote}

\begin{DUlineblock}{0em}
\item[] As described in the Supplementary Information in the work of
Constantinescu and Hine {[}Constantinescu2015{]},
spectral function unfolding is the means through which one can study
the bandstructure of the primitive cell from simulations involving
(often complicated) supercells. For details theoretical descriptions,
one should visit the aforementioned article
{[}Constantinescu2015{]}.
\item[] In this documentation, I will give a short explanation of the
procedures required to unfold the bandstructure in a ONETEP
“Properties” calculation. We strongly suggest that one reads the
entire document carefully before attempting any calculations, as there
are some stringent requirements along the way. For further details,
please contact Gabriel Constantinescu, the code author. Essentially,
all one will need is the following group of keywords and blocks:
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{BSUNFLD\PYGZus{}CALCULATE} \PYG{p}{:} \PYG{n}{T}
\PYG{n}{BSUNFLD\PYGZus{}TRANSFORMATION} \PYG{p}{:} \PYG{n}{t11} \PYG{n}{t12} \PYG{n}{t13} \PYG{n}{t21} \PYG{n}{t22} \PYG{n}{t23} \PYG{n}{t31} \PYG{n}{t32} \PYG{n}{t33}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{SPECIES\PYGZus{}BSUNFLD\PYGZus{}GROUPS}
\PYG{n}{Species\PYGZus{}name}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1} \PYG{n}{Species\PYGZus{}name}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{2} \PYG{o}{.}\PYG{o}{.}\PYG{o}{.} \PYG{n}{Species\PYGZus{}name}\PYG{o}{\PYGZhy{}}\PYG{n}{N}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{SPECIES\PYGZus{}BSUNFLD\PYGZus{}GROUPS}

\PYG{n}{BS\PYGZus{}PERTURBATIVE\PYGZus{}SOC} \PYG{p}{:} \PYG{n}{F}
\PYG{n}{BSUNFLD\PYGZus{}NUM\PYGZus{}ATOMS\PYGZus{}PRIM} \PYG{p}{:} \PYG{n}{nat\PYGZus{}prim}
\PYG{n}{BSUNFLD\PYGZus{}RESTART} \PYG{p}{:} \PYG{n}{F}
\PYG{n}{BSUNFLD\PYGZus{}NUM\PYGZus{}EIGENVALUES} \PYG{p}{:} \PYG{n}{num\PYGZus{}eigvl}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{BSUNFLD\PYGZus{}KPOINT\PYGZus{}PATH}
 \PYG{n}{fraction\PYGZus{}G1\PYGZus{}kpt}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1} \PYG{n}{fraction\PYGZus{}G2\PYGZus{}kpt}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1} \PYG{n}{fraction\PYGZus{}G3\PYGZus{}kpt}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}
 \PYG{n}{fraction\PYGZus{}G1\PYGZus{}kpt}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{2} \PYG{n}{fraction\PYGZus{}G2\PYGZus{}kpt}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{2} \PYG{n}{fraction\PYGZus{}G3\PYGZus{}kpt}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{2}
 \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
 \PYG{n}{fraction\PYGZus{}G1\PYGZus{}kpt}\PYG{o}{\PYGZhy{}}\PYG{n}{N} \PYG{n}{fraction\PYGZus{}G2\PYGZus{}kpt}\PYG{o}{\PYGZhy{}}\PYG{n}{N} \PYG{n}{fraction\PYGZus{}G3\PYGZus{}kpt}\PYG{o}{\PYGZhy{}}\PYG{n}{N}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{BSUNFLD\PYGZus{}KPOINT\PYGZus{}PATH}

\PYG{n}{BSUNFLD\PYGZus{}NUM\PYGZus{}KPTS\PYGZus{}PATH} \PYG{p}{:} \PYG{n}{num\PYGZus{}kpts\PYGZus{}path}
\end{sphinxVerbatim}

For each in turn:
\begin{itemize}
\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{BSUNFLD\_CALCULATE} setting this to True will enable the calculation of the unfolded
spectral function. Default: False
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{BSUNFLD\_TRANSFORMATION} is a list of 9 integers representing the flattened transformation
\end{DUlineblock}

matrix from the primitive cell to the supercell: \(\textbf{T}= \begin{bmatrix} t11 & t12 & t13 \\ t21 & t22 & t23 \\ t31 & t32 & t33 \end{bmatrix}\), where \(\textbf{T} \begin{bmatrix} \mathbf{a_1} \\ \mathbf{a_2} \\ \mathbf{a_3} \end{bmatrix} = \begin{bmatrix} \mathbf{A_1} \\ \mathbf{A_2} \\ \mathbf{A_3} \end{bmatrix}\), with \(\mathbf{a_i}\) (\(\mathbf{A_i}\)) being the
lattice vectors of the primitive cell (supercell). For instance, \sphinxcode{BSUNFLD\_TRANSFORMATION} :
4 0 0 0 4 0 0 0 1 would correspond to an implicit 4x4x1 supercell.
Default: 1 0 0 0 1 0 0 0 1, corresponding to a 1x1x1 supercell.

\item {} 
\begin{DUlineblock}{0em}
\item[] The block \sphinxcode{SPECIES\_BSUNFLD\_GROUPS} contains the atoms on which we are projecting; one needs to
specify the of the atoms species (can be different from the chemical
symbol) on which the spectral function is projected. Currently, only
one group at a time is allowed. Example:
\end{DUlineblock}
\begin{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{SPECIES\PYGZus{}BSUNFLD\PYGZus{}GROUPS}
\PYG{n}{Mo} \PYG{n}{Se1}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{SPECIES\PYGZus{}BSUNFLD\PYGZus{}GROUPS}
\end{sphinxVerbatim}

this projects onto the MoSe\(_2\) monolayer in a
MoSe\(_2\)/WSe\(_2\) heterostructure, where the Se atoms
belonging to the MoSe\(_2\) monolayer have been denoted as
\sphinxstyleemphasis{Se1}.
\end{quote}

\item {} 
\begin{DUlineblock}{0em}
\item[] The logical keyword \sphinxcode{BS\_PERTURBATIVE\_SOC} controls the inclusion (True) or exclusion
(False) of perturbative spin-orbit coupling in our calculation.
Note that if set to True, the eigenvalues are no longer
spin-degenerate and one will have twice the number of states. Since
this option essentially quadruples the size of the Hamiltonian and
overlap matrix, the calculation will be significantly slower.
Default: False.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] The integer keyword \sphinxcode{BSUNFLD\_NUM\_ATOMS\_PRIM} indicates the number of atoms in the primitive
cell onto which you are unfolding. This brings us to a major
requirement of the code: while the projected atoms can be split
across the list of all input atoms, \sphinxstylestrong{the former must be grouped by primitive cells, always maintaining the same order of the atoms in the primitive cells!} Example: if atoms \sphinxstylestrong{At1} and \sphinxstylestrong{At2} form a
primitive cell, the input ordering “At3 \sphinxstylestrong{At1 At2} At4 \sphinxstylestrong{At1 At2} A3” is correct, while
“At3 \sphinxstylestrong{At1 At2} At4 \sphinxstylestrong{At2} At3 \sphinxstylestrong{At1}” or “At3 \sphinxstylestrong{At1 At2} At4 \sphinxstylestrong{At2 At1} At3” are incorrect.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] The logical keyword \sphinxcode{BSUNFLD\_RESTART} controls whether one wishes to reuse previously
calculated values for the spectral function. The restart procedure
works as follows: the code writes a restart file
(“unfolded\(\_\)specfunc\(\_\)red.dat”) where it
stores the calculated values for the unfolded spectral function at
unique k-points of the monolayer - the values that have not been
calculated yet are filled with zeros. If this file is present and the
restart keyword is set to true, the code will read in the previously
calculated values and skip them in the current computations. The
final output file (“unfolded\(\_\)specfunc.dat”) will only be
written once all the k-points have been dealt with.
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] Each line in final output file or the restart file contains 8
numbers: the eigenvalue (in eV), the real part of the unfolded
spectral function (at that k-point and eigenvalue), the imaginary
part of the unfolded spectral function, the eigenvalue count (from 1
to \(2\cdot\) BSUNFLD\(\_\)NUM\(\_\)EIGENVALUES,
the x, y, and z component of the current primitive-cell k-point
(\(\AA^{-1}\)), and the index of the k-point (from 1 to the total
number of considered k-points).
\end{DUlineblock}

\begin{DUlineblock}{0em}
\item[] After the final output file has been obtained, one can use a
discretisation script (should be found on the ONETEP webside, in the
utilities section), in order to obtain a file that is ready to plot
with gnuplot.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] The integer keyword \sphinxcode{BSUNFLD\_NUM\_EIGENVALUES} controls the number of eigenvalues (above and
below the Fermi level) for which the spectral function is calculated.
If set to negative values,
\sphinxcode{BSUNFLD\_NUM\_EIGENVALUES} will internally be
set to the number of nondegenerate occupied eigenstates. Thus, in
total, for each k-point, the spectral function will be calculated at
\(2\cdot\) \sphinxcode{BSUNFLD\_NUM\_EIGENVALUES}.
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] The block \sphinxcode{BSUNFLD\_KPOINT\_PATH} indicates the fractional coordinates of the different
k-points that mark endpoints of desired paths through the \sphinxstylestrong{primitive-cell Brillouin zone. The fractional coordinates are with respect to the implied reciprocal lattice vectors of the primitive cell, not the simulation cell (supercell).}
\end{DUlineblock}

\item {} 
\begin{DUlineblock}{0em}
\item[] \sphinxcode{BSUNFLD\_NUM\_KPTS\_PATH} represents the number of k-points calculated along each path from
the \sphinxcode{BSUNFLD\_KPOINT\_PATH} block. This number includes the endpoints of each path. Default:
2 (the endpoints only)
\end{DUlineblock}

\end{itemize}

{[}Constantinescu2015{]} Constantinescu, G. C.; Hine, N. D. M. \sphinxstyleemphasis{Phys. Rev. B} \sphinxstylestrong{2015}, \sphinxstyleemphasis{91}, 195416


\section{Configuration Interaction (CI)}
\label{\detokenize{ci::doc}}\label{\detokenize{ci:configuration-interaction-ci}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
David Turban, University of Cambridge

\end{description}\end{quote}


\subsection{Introduction}
\label{\detokenize{ci:introduction}}
The aim of the CI functionality is to evaluate the electronic
Hamiltonian with respect to a set of reference configurations obtained
from constrained DFT (cDFT) and LR-TDDFT. This makes it possible to
obtain transition rates between different electronic states using
Fermi’s Golden Rule (e.g. rate of charge transfer at
donor/acceptor-interface in an organic solar cell). Also, CI can help to
construct eigenstates of a system in situations where the basic ground-
and excited state methods fail due to deficiencies of the approximate
exchange-correlation functional.

A classic example for such a case is the binding curve of
\(\text{H}_{2}^{+}\). The LDA functional gives an incorrect
dissociation limit with a binding energy that is significantly too
small. The reason is that there is a spurious self-interaction of the
single electron with itself, such that a delocalisation of the electron
over both atoms will always yield a lower energy, even at infinite
separation. Even more advanced hybrid functionals (like B3LYP) do not
solve this problem since they only include part of the exact
Hartree-Fock exchange which would cancel the self-interaction. In this
scenario CI offers a way forward. By choosing the two states with the
electron fully localised on either atom as references one ensures the
correct long-range limit. Finally, CI is used to evaluate the
Hamiltonian in the reference basis and obtain approximate eigenstates.
This gives a very good match with LDA at short range and also retains
the physical dissociation limit.


\subsection{Theory}
\label{\detokenize{ci:theory}}
As a first step we assume that one intends to find the Hamiltonian
matrix element \(\langle\Psi_{B}|\hat{H}|\Psi_{A}\rangle\) between
two cDFT states. In cDFT the constrained solutions are obtained as
ground states of the electronic Hamiltonian augmented with a
constraining potential that pushes charge (and/or spin) around the
system:
\begin{equation*}
\begin{split}(\hat{H}+\hat{V}_{c})|\Psi_{c}\rangle=(\hat{H}+V_{c}\hat{w}_{c})|\Psi_{c}\rangle=F|\Psi_{c}\rangle.\end{split}
\end{equation*}
Here the potential is written as the product of its magnitude
\(V_{c}\) and a weighting operator \(\hat{w}_{c}\) which
specifically acts on the donor and acceptor regions of the system with
appropriate signs. In ONETEP the weighting operator is built from local
orbitals (like PAOs or NGWFs) that define the donor and acceptor
regions. The eigenvalue \(F\) is the energy \(E\) of the
constrained solution plus a correction due to the (unphysical)
constraining potential:
\begin{equation*}
\begin{split}F=\langle\Psi_{c}|\hat{H}+V_{c}\hat{w}_{c}|\Psi_{c}\rangle=E[\rho_{c}]+V_{c}\int d\mathbf{r}w_{c}(\mathbf{r})\rho_{c}(\mathbf{r})=E+V_{c}N_{c}.\end{split}
\end{equation*}
The magnitude of the potential \(V_{c}\) takes the role of a
Lagrange multiplier that is chosen such that the amount of displaced
charge/spin matches the population target \(N_{c}\). It should be
noted that cDFT states are generally not eigenstates of the electronic
Hamiltonian \(\hat{H}\).

Using the cDFT potentials we now obtain
\begin{equation*}
\begin{split}\begin{aligned}
\langle\Psi_{B}|\hat{H}|\Psi_{A}\rangle & = & \langle\Psi_{B}|\hat{H}+\hat{V}_{A}-\hat{V}_{A}|\Psi_{A}\rangle\nonumber \\
 & = & F_{A}\langle\Psi_{B}|\Psi_{A}\rangle-\langle\Psi_{B}|\hat{V}_{A}|\Psi_{A}\rangle,\end{aligned}\end{split}
\end{equation*}
which reduces the problem to calculating overlaps of states and matrix
elements of the cDFT potentials. At this point the expression still
contain the full many-body wave functions \(\Psi\). To obtain a
practical computational scheme we replace them with Kohn-Sham (KS)
determinants \(\Phi\) and approximate
\begin{equation*}
\begin{split}\langle\Psi_{B}|\Psi_{A}\rangle\approx\langle\Phi_{B}|\Phi_{A}\rangle,\;\;\langle\Psi_{B}|\hat{V}|\Psi_{A}\rangle\approx\langle\Phi_{B}|\hat{V}|\Phi_{A}\rangle.\end{split}
\end{equation*}
We will assume that all orbitals are chosen to be real functions, and
not worry about complex conjugation in inner products. The standard
result for the overlap of two Slater determinants is given by
\begin{equation*}
\begin{split}\begin{aligned}
\langle\Phi_{B}|\Phi_{A}\rangle & = & \int d\mathbf{r}_{1}\ldots d\mathbf{r}_{N}\frac{1}{\sqrt{N!}}\left|\begin{array}{ccc}
\psi_{1}^{B}(\mathbf{r}_{1}) & \cdots & \psi_{1}^{B}(\mathbf{r}_{N})\\
\vdots &  & \vdots\\
\psi_{N}^{B}(\mathbf{r}_{1}) & \cdots & \psi_{N}^{B}(\mathbf{r}_{N})
\end{array}\right|\times\frac{1}{\sqrt{N!}}\left|\begin{array}{ccc}
\psi_{1}^{A}(\mathbf{r}_{1}) & \cdots & \psi_{1}^{A}(\mathbf{r}_{N})\\
\vdots &  & \vdots\\
\psi_{N}^{A}(\mathbf{r}_{1}) & \cdots & \psi_{N}^{A}(\mathbf{r}_{N})
\end{array}\right|\nonumber \\
 & = & \int d\mathbf{r}_{1}\ldots d\mathbf{r}_{N}\psi_{1}^{B}(\mathbf{r}_{1})\ldots\psi_{N}^{B}(\mathbf{r}_{N})\left|\begin{array}{ccc}
\psi_{1}^{A}(\mathbf{r}_{1}) & \cdots & \psi_{1}^{A}(\mathbf{r}_{N})\\
\vdots &  & \vdots\\
\psi_{N}^{A}(\mathbf{r}_{1}) & \cdots & \psi_{N}^{A}(\mathbf{r}_{N})
\end{array}\right|\nonumber \\
 & = & \left|\begin{array}{ccc}
\langle\psi_{1}^{A}|\psi_{1}^{B}\rangle & \cdots & \langle\psi_{1}^{A}|\psi_{N}^{B}\rangle\\
\vdots &  & \vdots\\
\langle\psi_{N}^{A}|\psi_{1}^{B}\rangle & \cdots & \langle\psi_{N}^{A}|\psi_{N}^{B}\rangle
\end{array}\right|\;\;\;=\;\;\;\det\left(S_{AB}\right),\end{aligned}\end{split}
\end{equation*}
where the functions \(\psi\) denote KS orbitals. The result is
simply the determinant of the matrix \(S_{AB}\) of overlaps between
KS orbitals of states A and B. In a similar fashion we can evaluate
matrix elements of a potential operator:
\begin{equation*}
\begin{split}\begin{aligned}
\langle\Phi_{B}|\hat{V}|\Phi_{A}\rangle & = & \int d\mathbf{r}_{1}\ldots d\mathbf{r}_{N}\psi_{1}^{B}(\mathbf{r}_{1})\ldots\psi_{N}^{B}(\mathbf{r}_{N})\left[\sum_{i}V(\mathbf{r}_{i})\right]\times\left|\begin{array}{ccc}
\psi_{1}^{A}(\mathbf{r}_{1}) & \cdots & \psi_{1}^{A}(\mathbf{r}_{N})\\
\vdots &  & \vdots\\
\psi_{N}^{A}(\mathbf{r}_{1}) & \cdots & \psi_{N}^{A}(\mathbf{r}_{N})
\end{array}\right|\nonumber \\
 & = & \sum_{i}\left|\begin{array}{ccccc}
\langle\psi_{1}^{A}|\psi_{1}^{B}\rangle & \cdots & \langle\psi_{1}^{A}|\hat{V}|\psi_{i}^{B}\rangle & \cdots & \langle\psi_{1}^{A}|\psi_{N}^{B}\rangle\\
\vdots &  & \vdots &  & \vdots\\
\langle\psi_{N}^{A}|\psi_{1}^{B}\rangle & \cdots & \langle\psi_{N}^{A}|\hat{V}|\psi_{i}^{B}\rangle & \cdots & \langle\psi_{N}^{A}|\psi_{N}^{B}\rangle
\end{array}\right|\nonumber \\
 & = & \sum_{ij}\langle\psi_{j}^{A}|\hat{V}|\psi_{i}^{B}\rangle\cdot C_{j,i}\nonumber \\
 & = & \det\left(S_{AB}\right)\times\text{tr}\left(V_{AB}\cdot S_{AB}^{-1}\right).\end{aligned}\end{split}
\end{equation*}
In the third line the determinant is expanded along the \(i\)-th
column. \(C_{j,i}\) denotes cofactors of \(S_{AB}\) which are
sign-adapted determinants of the submatrices formed by deleting the
\(j\)-th row and \(i\)-th column of \(S_{AB}\). A well-known
theorem in linear algebra states that the matrix of cofactors of an
invertible matrix is equal to the transpose of the inverse of the matrix
times its determinant.

Next, we discuss how a constrained reference state can be coupled to an
excited state from LR-TDDFT. In LR-TDDFT the excited states are
represented as superpositions of single-particle excitations from an
occupied to an unoccupied orbital. This information is contained in the
response density matrix \(R_{jb}\). A particular non-zero entry
indicates that a transition from valence orbital \(\psi_{j}\) to
conduction orbital \(\psi_{b}\) contributes to the excited state. In
the following indices \(i,j,k,\ldots\) will denote valence orbitals
and indices \(b,c,d,\ldots\) conduction orbitals. A natural choice
for a DFT wave function of such an excitation that retains the response
density by construction is
\begin{equation*}
\begin{split}|\Phi\rangle=\sum_{jb}R_{jb}|\Phi_{j}^{b}\rangle.\end{split}
\end{equation*}
\(|\Phi_{j}^{b}\rangle\) denotes a Slater determinant constructed
from the valence orbitals, except for the single valence orbital
\(j\) replaced with conduction orbital \(b\). For the following
we assume that state B was obtained as a LR-TDDFT excitation, and A is a
(constrained) ground state as before. For the overlap we calculate
\begin{equation*}
\begin{split}\begin{aligned}
\langle\Phi_{B}|\Phi_{A}\rangle & = & \int d\mathbf{r}_{1}\ldots d\mathbf{r}_{N}\sum_{jb}R_{jb}\psi_{1}^{B}(\mathbf{r}_{1})\ldots\psi_{b}^{B}(\mathbf{r}_{j})\ldots\psi_{N}^{B}(\mathbf{r}_{N})\times\left|\begin{array}{ccc}
\psi_{1}^{A}(\mathbf{r}_{1}) & \cdots & \psi_{1}^{A}(\mathbf{r}_{N})\\
\vdots &  & \vdots\\
\psi_{N}^{A}(\mathbf{r}_{1}) & \cdots & \psi_{N}^{A}(\mathbf{r}_{N})
\end{array}\right|\nonumber \\
 & = & \sum_{jb}R_{jb}\underset{\uparrow j}{\left|\begin{array}{ccccc}
\langle\psi_{1}^{A}|\psi_{1}^{B}\rangle & \cdots & \langle\psi_{1}^{A}|\psi_{b}^{B}\rangle & \cdots & \langle\psi_{1}^{A}|\psi_{N}^{B}\rangle\\
\vdots &  & \vdots &  & \vdots\\
\langle\psi_{N}^{A}|\psi_{1}^{B}\rangle & \cdots & \langle\psi_{N}^{A}|\psi_{b}^{B}\rangle & \cdots & \langle\psi_{N}^{A}|\psi_{N}^{B}\rangle
\end{array}\right|}\nonumber \\
 & = & \sum_{ijb}R_{jb}\langle\psi_{i}^{A}|\psi_{b}^{B}\rangle\cdot C_{i,j}\nonumber \\
 & = & \det\left(S_{AB}\right)\times\text{tr}\left(T_{AB}^{vc}\cdot R^{\top}\cdot S_{AB}^{-1}\right).\end{aligned}\end{split}
\end{equation*}
The matrix \(T_{AB}^{vc}\) represents the overlap of the valence
orbitals of state A with the conduction orbitals of state B. The
derivation of the overlap with a potential operator is a bit more
involved but proceeds along similar lines:
\begin{equation*}
\begin{split}\begin{aligned}
\langle\Phi_{B}|\hat{V}|\Phi_{A}\rangle & = & \int d\mathbf{r}_{1}\ldots d\mathbf{r}_{N}\sum_{jb}R_{jb}\psi_{1}^{B}(\mathbf{r}_{1})\ldots\psi_{b}^{B}(\mathbf{r}_{j})\ldots\psi_{N}^{B}(\mathbf{r}_{N})\left[\sum_{i}V(\mathbf{r}_{i})\right]\left|\begin{array}{ccc}
\psi_{1}^{A}(\mathbf{r}_{1}) & \cdots & \psi_{1}^{A}(\mathbf{r}_{N})\\
\vdots &  & \vdots\\
\psi_{N}^{A}(\mathbf{r}_{1}) & \cdots & \psi_{N}^{A}(\mathbf{r}_{N})
\end{array}\right|\nonumber \\
\nonumber \\
 & = & \sum_{i\ne j}\sum_{b}R_{jb}\left|\begin{array}{ccccccc}
\langle\psi_{1}^{A}|\psi_{1}^{B}\rangle & \cdots & \langle\psi_{1}^{A}|\hat{V}|\psi_{i}^{B}\rangle & \cdots & \langle\psi_{1}^{A}|\psi_{b}^{B}\rangle & \cdots & \langle\psi_{1}^{A}|\psi_{N}^{B}\rangle\\
\vdots &  & \vdots &  & \vdots &  & \vdots\\
\langle\psi_{N}^{A}|\psi_{1}^{B}\rangle & \cdots & \langle\psi_{N}^{A}|\hat{V}|\psi_{i}^{B}\rangle & \cdots & \langle\psi_{N}^{A}|\psi_{b}^{B}\rangle & \cdots & \langle\psi_{N}^{A}|\psi_{N}^{B}\rangle
\end{array}\right|\nonumber \\
 &  & +\sum_{jb}R_{jb}\left|\begin{array}{ccccc}
\langle\psi_{1}^{A}|\psi_{1}^{B}\rangle & \cdots & \langle\psi_{1}^{A}|\hat{V}|\psi_{b}^{B}\rangle & \cdots & \langle\psi_{1}^{A}|\psi_{N}^{B}\rangle\\
\vdots &  & \vdots &  & \vdots\\
\langle\psi_{N}^{A}|\psi_{1}^{B}\rangle & \cdots & \langle\psi_{N}^{A}|\hat{V}|\psi_{b}^{B}\rangle & \cdots & \langle\psi_{N}^{A}|\psi_{N}^{B}\rangle
\end{array}\right|\nonumber \\
\nonumber \\
 & = & \sum_{ijb}R_{jb}\sum_{kl}\langle\psi_{k}^{A}|\hat{V}|\psi_{i}^{B}\rangle\langle\psi_{l}^{A}|\psi_{b}^{B}\rangle\cdot\epsilon_{kl}\epsilon_{ij}C_{kl,ij}\;\;+\;\;\sum_{ijb}R_{jb}\langle\psi_{i}^{A}|\hat{V}|\psi_{b}^{B}\rangle\cdot C_{i,j}.\end{aligned}\end{split}
\end{equation*}
In the first determinant two columns are distinct from the overlap
\(S_{AB}\), we therefore expand along both. This leads to an
expression including the second cofactors \(C_{kl,ij}\). It follows
from Jacobi’s theorem that
\begin{equation*}
\begin{split}\begin{aligned}
\epsilon_{kl}\epsilon_{ij}C_{kl,ij} & = & \det\left(S_{AB}\right)\times\left[\left(S_{AB}^{-1}\right)_{ik}\left(S_{AB}^{-1}\right)_{jl}-\left(S_{AB}^{-1}\right)_{il}\left(S_{AB}^{-1}\right)_{jk}\right].\end{aligned}\end{split}
\end{equation*}
Putting everything together we finally obtain
\begin{equation*}
\begin{split}\begin{aligned}
\langle\Phi_{B}|\hat{V}|\Phi_{A}\rangle & = & \det\left(S_{AB}\right)\times\left[\text{tr}\left(V_{AB}\cdot S_{AB}^{-1}\right)\text{tr}\left(T_{AB}^{vc}\cdot R^{\top}\cdot S_{AB}^{-1}\right)-\text{tr}\left(V_{AB}\cdot S_{AB}^{-1}\cdot T_{AB}^{vc}\cdot R^{\top}\cdot S_{AB}^{-1}\right)\right]\nonumber \\
 &  & +\det\left(S_{AB}\right)\times\text{tr}\left(W_{AB}^{vc}\cdot R^{\top}\cdot S_{AB}^{-1}\right),\end{aligned}\end{split}
\end{equation*}
where \(W_{AB}^{vc}\) refers to matrix elements of \(\hat{V}\)
between valence orbitals of state A and conduction orbitals of state B.

We note that in general the Hamiltonian matrix obtained in the way shown
is not symmetric due to the approximations inherent in the DFT
formalism. Hence, the Hamiltonian must be symmetrised before eigenstates
can be obtained.


\subsection{Implementation}
\label{\detokenize{ci:implementation}}
The CI functionality is implemented in \sphinxcode{couplings\_mod}. For each
reference state the density kernel and NGWFs are read from the
corresponding files. Additionally, the cDFT-potentials are read from
file for a cDFT reference state. For an excited state from LR-TDDFT,
conduction kernel, conduction NGWFs and the response kernel are read. A
set of orthonormal orbitals representing the valence space is obtained
from the NGWF representation by solving the eigenvalue problem
\begin{equation*}
\begin{split}\sum_{\beta\gamma}K^{\alpha\beta}S_{\beta\gamma}x^{\gamma}=n\cdot x^{\alpha},\end{split}
\end{equation*}
and restricting to the occupied subspace. Here \(K^{\alpha\beta}\)
is the valence density kernel and \(S_{\beta\gamma}\) the overlap
matrix of valence NGWFs. Orthonormal conduction orbitals are obtained in
an equivalent manner. The actual CI calculations then proceeds in this
basis as outlined in the theory section. It should be noted that the
orbitals obtained in this way generally do not correspond to the KS
orbitals (they do not result from a diagonalisation of the Hamiltonian).
However, both are related through an orthogonal transformation. Hence,
the determinants are identical, therefore all results are unaffected by
this choice of basis.

The transformation to a orthonormal basis comes with an inherent
\(N^{3}\) scaling of the method. The computational effort is
expected to be comparable with a properties calculation (which involves
a diagonalisation of the Hamiltonian).


\subsection{Performing a calculation}
\label{\detokenize{ci:performing-a-calculation}}
This section explains how to set up a CI calculation, and points out a
couple of important things to look out for.
\begin{itemize}
\item {} 
First perform calculations for desired reference states. For each
state the density kernel and NGWFs have to be written to files
(\sphinxcode{.dkn} and \sphinxcode{.tightbox\_ngwfs}). For cDFT reference states the
potentials and projectors are required (\sphinxcode{.cdft} and
\sphinxcode{.tightbox\_hub\_projs}). For LR-TDDFT states conduction kernel and
NGWFs are required (\sphinxcode{.dkn\_cond} and \sphinxcode{.tightbox\_ngwfs\_cond}), as
well as the response density matrix.

\item {} 
It is currently required that all reference states use the same unit
cell, grid, geometry and identical atomic species with the same
number of NGWFs and the same pseudopotentials. \sphinxstylestrong{NOTE:} The current
implementation is not compatible with PAW!

\item {} 
Now set up a new input file for the CI calculation. It is recommended
to copy the input file of one of the cDFT reference calculations.
This ensures that the setup of the CI run is consistent with the
reference calculations (in particular with the correct projectors).
If a LR-TDDFT reference state is used, also copy the conduction
species block into the file. Set \sphinxcode{TASK} to \sphinxcode{COUPLINGS}.

\item {} 
Add the block \sphinxcode{couplings\_states}. This tells the CI calculation
which reference states to use. Here is an example:Each line
corresponds to one reference state. The first column is short
identifier for the state (currently unused). The second column
indicates whether it is a cDFT or LR-TDDFT state, the third column
contains the root name (i.e. name of original input file without
extension). For a LR-TDDFT state, the fourth column determines the
index of the excitation to be used (set to 0 for cDFT states).
Finally, the fifth column is the energy in Hartree. It should be made
sure that all energies are referenced to the same zero point.

\item {} 
The output is written to matrix files (using \sphinxcode{dense\_write}). The
names of these files consist of the root name of the CI run with
extensions \sphinxcode{\_ci\_ham} and \sphinxcode{\_ci\_ham\_sym} for the CI Hamiltonian and
its symmetrised version, respectively. Eigenvalues and -states of the
(symmetrised) CI Hamiltonian are written to files with extensions
\sphinxcode{\_ci\_eigvals} and \sphinxcode{\_ci\_eigstates} (column-wise). If
\sphinxcode{output\_detail : VERBOSE} is chosen, the results are also written
to standard output.

\end{itemize}


\subsection{References}
\label{\detokenize{ci:references}}\begin{itemize}
\item {} 
Extracting electron transfer coupling elements from constrained
density functional theory, Q. Wu and T. Van Voorhis, J. Chem. Phys.
\sphinxstylestrong{125}, 164105 (2006)

\item {} 
Exciton/Charge-Transfer Electronic Couplings in Organic
Semiconductors, S. Difley and T. Van Voorhis, JCTC \sphinxstylestrong{7}, 594 (2011)

\item {} 
Determinants and matrices, A.C. Aitken, University mathematical texts
vol. 20, Oliver and Boyd (1958)

\end{itemize}


\chapter{Population Analysis}
\label{\detokenize{index_population::doc}}\label{\detokenize{index_population:population-analysis}}

\section{ONETEP to GENNBO \sphinxstyleliteralintitle{FILE.47} Input Parameters}
\label{\detokenize{nbo_onetep::doc}}\label{\detokenize{nbo_onetep:onetep-to-gennbo-file-47-input-parameters}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Louis Lee, University of Cambridge (\sphinxcode{lpl24@cam.ac.uk})

\end{description}\end{quote}


\subsection{Standalone nbo 5 Program gennbo}
\label{\detokenize{nbo_onetep:standalone-nbo-5-program-gennbo}}
The standalone version of the NBO program
(GENNBO) {[}Glendening{]} accepts parameters from an input
ASCII free-format \sphinxcode{FILE.47} containing atomic coordinates and matrix
information, as printed by ONETEP if the Natural Population
Analysis {[}Reed1985{]} subroutine is called during a
\sphinxcode{PROPERTIES} calculation, by specifying the keyword \sphinxcode{write\_nbo: T}.
The NBO formalism allows one transform a converged 1-particle
wavefunction in an atom-centred bases into a set of highly-local
‘Natural Bond Orbitals’, which are one and two (or three)-centred ‘lone’
and ‘bond’ pairs recognizable as chemical bonds from a classical Lewis
structure standpoint {[}Reed1988{]}.
Details of the NBO formalism are discussed
elsewhere {[}Reed1985{]}, {[}Reed1988{]}, {[}MacKerell1998{]}.


\subsubsection{Compiling GENNBO}
\label{\detokenize{nbo_onetep:compiling-gennbo}}
Compilation of the standalone GENNBO does not involve ONETEP in any way.
As of writing, the latest nbo release is version
5.9 {[}Glendening{]}. Compilation instructions are listed here
for convenience, based on some trial-and-error when the arcane \sphinxcode{g77}
compiler listed in the nbo manual is unavailable.

To compile GENNBO, first, compile the activator, \sphinxcode{enable.f}:
\begin{quote}

\sphinxcode{gfortran -o enable enable.f}
\end{quote}

then run the \sphinxcode{enable} program. Complete the selections to generate the
standalone GENNBO source \sphinxcode{gennbo.f}.

By default, GENNBO limits the number of atoms and basis in the
\sphinxcode{FILE.47} input to 200 and 2000 respectively. This can be increased by
replacing all instances of \sphinxcode{MAXATM = 200} and \sphinxcode{MAXBAS = 2000} to a
user-specified value, up to a limit of 999 and 9999 respectively (higher
values are possible, albeit accompanied by illegible output due to
format overflow. In principle one could modify the code even further to
remedy this issue.).

The following command should compile GENNBO correctly on x64
architectures, when no modification is made to the \sphinxcode{gennbo.f} source:
\begin{quote}

\begin{DUlineblock}{0em}
\item[] \sphinxcode{gfortran -fdefault-integer-8 -fno-sign-zero -m64 -o gennbo gennbo.f}
\item[] \sphinxcode{ifort -i8 -m64 -f77rtl -o gennbo gennbo.f}
\end{DUlineblock}
\end{quote}

For the 32-bit version, integer length should be set to 4 bytes instead
(e.g. \sphinxcode{-i4} in \sphinxcode{ifort}). If \sphinxcode{MAXATM} and \sphinxcode{MAXBAS} have been
increased then the memory model should also be set to allow data
\(> 2\) GB, by adding a \sphinxcode{-mcmodel=medium} flag. For \sphinxcode{ifort}, an
additional \sphinxcode{-shared-intel} flag is most likely necessary.

Then, to run:
\begin{quote}

\sphinxcode{gennbo \textless{} FILE.47 \textgreater{} output.out}
\end{quote}


\subsection{ONETEP NPA Generation Routine}
\label{\detokenize{nbo_onetep:onetep-npa-generation-routine}}
The Natural Population Analysis {[}Reed1985{]} method of
computing atomic charges is implemented in ONETEP. The routine
transforms the set of non-orthogonal, optimized NGWFs into a set of
orthogonal atom-centred ‘Natural Atomic Orbitals’ (NAOs) via an
‘occupancy-weighted symmetric orthogonalization’ procedure, which serves
to maximise the resemblance of the final orthogonal orbitals to their
initial non-orthogonal parents (a la Löwdin orthogonalization), weighted
according to the parent orbital occupancies. Therefore, vacant,
highly-diffuse orbitals are free to distort to achieve orthogonality
with their more highly-preserved occupied counterpart. This ensures that
the final NAO population (the ‘Natural Population’) remains stable with
respect to basis set size.

Once in the NAO basis, further transformations such as pair-block
density matrix diagonalization produce the final set of NBOs \textendash{} these
procedures are performed by nbo 5 from the \sphinxcode{FILE.47} output of ONETEP,
which contains relevant matrices in the NAO basis. The NAO routine is
performed internally in ONETEP as nbo 5 requires pseudo-atomic orbitals
(such as Gaussian-type orbitals) with free-atom symmetries and
orthogonality within each atom, a property not rigorously satisfied by
the optimized NGWFs.

The NPA module in ONETEP performs at its best for large systems when
compiles with the ScaLapack linear algebra package, as it takes
advantage of the distributed memory storage of dense global matrices,
such as the inverse square root of the overlap matrix that needs to be
computed for the ‘occupancy-weighted symmetric orthogonalization’ step.
This has the unfortunate side effect of rendering the NAO transformation
a cubic-scaling method. However, this step occurs only once during the
routine, and should be comparable to the time needed to generate
canonical molecular orbitals.


\subsection{List of Available Parameters}
\label{\detokenize{nbo_onetep:list-of-available-parameters}}

\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{NAO Generation (Default)}\label{\detokenize{nbo_onetep:id12}}
\sphinxaftercaption
\begin{tabular}[t]{|\X{30}{100}|\X{8}{100}|\X{14}{100}|\X{8}{100}|\X{40}{100}|}
\hline
\sphinxstylethead{\sphinxstyletheadfamily 
Keyword
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Type
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Default
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Level
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Description
\unskip}\relax \\
\hline
\sphinxcode{write\_nbo}
&
L
&
F
&
B
&
Enables Natural Population Analysis (NPA) and writing of GENNBO input file \sphinxcode{\textless{}seedname\textgreater{}\_nao\_nbo.47}
\\
\hline
\sphinxcode{nbo\_init\_lclowdin}
&
L
&
T
&
E
&
Performs atom-local Löwdin
orthogonalisation on NGWFs as the first step before constructing NAOs
\\
\hline
\sphinxcode{nbo\_write\_lclowdin}
&
L
&
F
&
E
&
Writes full matrices (all atoms)
in the atom-local Löwdin-orthogonalized basis to \sphinxcode{FILE.47} (For
reference/testing/comparison purposes). Output will be
\sphinxcode{\textless{}seedname\textgreater{}\_lclowdin\_nbo.47}
\\
\hline
\sphinxcode{nbo\_write\_npacomp}
&
L
&
F
&
B
&
Writes NAO charges for all
orbitals to standard output
\\
\hline
\sphinxcode{nbo\_write\_dipole}
&
L
&
F
&
B
&
Computes and writes dipole matix to
\sphinxcode{FILE.47}
\\
\hline
\sphinxcode{nbo\_scale\_dm}
&
L
&
T
&
E
&
Scales partial density matrix output to
\sphinxcode{\textless{}seedname\textgreater{}\_nao\_nbo.47} in order to achieve charge integrality
\\
\hline
\sphinxcode{nbo\_scale\_spin}
&
L
&
T
&
E
&
Scales \(\alpha\) and
\(\beta\) spins independently to integral chrage when partial
matrices are printed and \sphinxcode{nbo\_scale\_dm = T}. Inevitably means spin
density values from GENNBO are invalid and one should calculate them
manually from the \(\alpha\) and \(\beta\) NPA populations.
\\
\hline
\sphinxcode{nbo\_write\_species}
&
B
&
N/A
&
B
&
Block of lists of species to be
included in the partial matrix output of \sphinxcode{\textless{}seedname\textgreater{}\_nao\_nbo.47}. If
not present all atoms will be included. E.g. specified will default to
AUTO. E.g.:

\begin{DUlineblock}{0em}
\item[] \sphinxcode{\%block nbo\_write\_species}
\item[] \sphinxcode{C1}
\item[] \sphinxcode{H1}
\item[] \sphinxcode{\%endblock nbo\_write\_species}
\end{DUlineblock}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{NAO Generation (Default) continued}\label{\detokenize{nbo_onetep:id13}}
\sphinxaftercaption
\begin{tabular}[t]{|\X{30}{100}|\X{8}{100}|\X{14}{100}|\X{8}{100}|\X{40}{100}|}
\hline

\sphinxcode{nbo\_species\_ngwflabel}
&
B
&
AUTO
&
I
&
Optional user-defined
(false) \sphinxstyleemphasis{lm}-label for NGWFs according to GENNBO convention. Species
not specified will default to AUTO. E.g.:

\begin{DUlineblock}{0em}
\item[] \sphinxcode{\%block nbo\_species\_ngwflabel}
\item[] \sphinxcode{C1 "1N 151N 152N 153N"}
\item[] \sphinxcode{H1 AUTO}
\item[] \sphinxcode{\%endblock nbo\_species\_ngwflabel}
\item[] -N suffix denotes NMB orbital. If
’SOLVE’ orbitals are used, this block should be present as ’AUTO’
initialisation assumes orbitals were also initialised as ’AUTO’.
\end{DUlineblock}
\\
\hline
\sphinxcode{nbo\_aopnao\_scheme}
&
T
&
ORIGINAL
&
E
&
The AO to PNAO scheme to
use. Affects the ’\sphinxstyleemphasis{lm}-averaging’ and diagonalisation steps in the
initial AO to PNAO, NRB \sphinxstyleemphasis{lm}-averaging, and rediagonaliation
transformations (the ’\sphinxstylestrong{N}’ transformations in
{[}Reed1985{]}). For testing purposes only - so far none
of the other schemes apart from \sphinxcode{ORIGINAL} works. Possbile values
are: \sphinxcode{ORIGINAL} - default, as in {[}Reed1985{]} with
\sphinxstyleemphasis{lm}-averaging \sphinxcode{DIAGONALIZATION} - Diagonalises entire atom-centred
sub-block w/o \sphinxstyleemphasis{lm}-averaging or splitting between different angular
channels. \sphinxcode{NONE} - Skips all ’\sphinxstylestrong{N}’ transformations.
\\
\hline
\sphinxcode{nbo\_pnao\_analysis}
&
L
&
F
&
E
&
Perform s/p/d/f analysis on the
PNAOs (analogous to \sphinxcode{ngwf\_analysis})
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Orbital Plotting}\label{\detokenize{nbo_onetep:id14}}
\sphinxaftercaption
\begin{tabular}[t]{|\X{30}{100}|\X{8}{100}|\X{14}{100}|\X{8}{100}|\X{40}{100}|}
\hline
\sphinxstylethead{\sphinxstyletheadfamily 
Keyword
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Type
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Default
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Level
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Description
\unskip}\relax \\
\hline
\sphinxcode{plot\_nbo}
&
L
&
F
&
B
&
Instructs ONETEP to read the relevant
orbital transformation output from GENNBO, determined by the flag
\sphinxcode{nbo\_plot\_orbtype} and plots the orbitals specified in
\sphinxcode{\%block nbo\_list\_plotnbo}. \sphinxcode{write\_nbo} and \sphinxcode{plot\_nbo} are
mutually exclusive. Scalar field plotting must be enabled (e.g.
\sphinxcode{cube\_format = T}).
\\
\hline
\sphinxcode{nbo\_plot\_orbtype}
&
T
&
N/A
&
B
&
The type of GENNBO-generated
orbitals to read and plot. Possible values and their associated GENNBO
transformation files must be present, as follows:

\begin{DUlineblock}{0em}
\item[] \sphinxcode{NAO} - \sphinxcode{\textless{}seedname\textgreater{}\_nao.33}
\item[] \sphinxcode{NHO} - \sphinxcode{\textless{}seedname\textgreater{}\_nao.35}
\item[] \sphinxcode{NBO} - \sphinxcode{\textless{}seedname\textgreater{}\_nao.37}
\item[] \sphinxcode{NLMO} - \sphinxcode{\textless{}seedname\textgreater{}\_nao.39}
\item[] NLMO is only
defined for the full system i.e. partitioned \sphinxcode{FILE.47} will give
meaningless NLMOs. Except for NLMO, adding a ’P’ prefix e.g. ’PNAO’ to
the value of \sphinxcode{nbo\_plot\_orbtype} causes the non-orthogonalised PNAOs
to be used in plotting instead of NAOs. PNAOs are of the normal type,
i.e. when \sphinxcode{RPNAO = F} in GENNBO (default).
\end{DUlineblock}
\\
\hline
\sphinxcode{nbo\_list\_plotnbo}
&
B
&
N/A
&
B
&
The list of \sphinxcode{nbo\_plot\_orbtype}
orbitals to be plotted, identified by their indices as in the GENNBO
output. Specify each index on a new line.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxcaption{Output files}\label{\detokenize{nbo_onetep:id15}}
\sphinxaftercaption
\begin{tabular}[t]{|\X{40}{100}|\X{60}{100}|}
\hline
\sphinxstylethead{\sphinxstyletheadfamily 
\sphinxcode{\textless{}seedname\textgreater{}\_nao\_nbo.47}
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Always written. Contains partial matrices according to \sphinxcode{\%block nbo\_write\_species}.
\unskip}\relax \\
\hline
\sphinxcode{\textless{}seedname\textgreater{}\_lclowdin\_nbo.47}
&
Written if \sphinxcode{nbo\_write\_lclowdin = T}. Always contains all atoms in the atom-local Löwdin-orthogonalized basis. If \sphinxcode{nbo\_init\_lclowdin = T} and all atoms are included \sphinxcode{\textless{}seedname\textgreater{}\_lclowdin\_nbo.47} = \sphinxcode{\textless{}seedname\textgreater{}\_nao\_nbo.47} except for ordering of atomic centers (will be fixed in newer releases).
\\
\hline
\sphinxcode{\textless{}seedname\textgreater{}\_nao\_atomindex.dat}
&
Contains mapping of atomic indices of the potentially subset of the full system in \sphinxcode{\textless{}seedname\textgreater{}\_nao\_nbo.47} to the real atomic index of the full system (since labels have to be consecutive). Real atomic index refers to original input order in ONETEP.
\\
\hline
\sphinxcode{\textless{}seedname\textgreater{}\_inittr\_nao\_nbo.dat}
&
Raw NGWF to NAO transformation read for plotting (i.e. when \sphinxcode{plot\_nbo = T})
\\
\hline
\sphinxcode{\textless{}seedname\textgreater{}\_inittr\_pnao\_nbo.dat}
&
Raw NGWF to PNAO transformation read for plotting (i.e. when \sphinxcode{plot\_nbo = T}). PNAOs are of the ’normal’ type, i.e when \sphinxcode{RPNAO = F} in GENNBO.
\\
\hline
\sphinxcode{\textless{}seedname\textgreater{}\_nbo\_DEBUG.dat}
&
Contains various debugging info. Only written if compiled in debug mode.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\subsection{Notes}
\label{\detokenize{nbo_onetep:notes}}

\subsubsection{Orbital labelling with pseudoatomic solver}
\label{\detokenize{nbo_onetep:orbital-labelling-with-pseudoatomic-solver}}\begin{itemize}
\item {} 
GENNBO labels in \sphinxcode{\%block nbo\_species\_ngwflabel} should always be
explicitly given when \sphinxcode{SOLVE} is used to initialise the NGWFs. The
label string is however limited to 80 characters in ONETEP, which
should be fine up to \(1s2sp3spd4sp\). This will be fixed later
unless it is urgently required.

\item {} 
Make sure the orbitals selected for plotting are valid. The NPA
routine assumes that the appropriate transformation file from GENNBO
in the same directory is correct, and only complains if it encounters
an EOF, but not if the wrong transformation file is given (e.g. from
a different system with a larger basis).

\item {} 
Do not rename the GENNBO-generated transformation files. ONETEP
expects them to have the name \sphinxcode{\textless{}seedname\textgreater{}\_nao.xx}.

\end{itemize}


\subsubsection{Orbital plotting}
\label{\detokenize{nbo_onetep:orbital-plotting}}\begin{itemize}
\item {} 
In order to plot the various orbitals, first run the output
\sphinxcode{FILE.47} through GENNBO to obtain the relevant orbital vectors.
Refer to the nbo 5 manual for details on how to print these (e.g. to
print NBOs in the input \sphinxcode{FILE.47} basis, set \sphinxcode{AONBO=W} in the
\sphinxcode{\$NBO} block).

\item {} 
For some reason, the \sphinxcode{PLOT} keyword itself in GENNBO doesn’t work.
This might have something to do with the ’\sphinxcode{ORTHO} bug’.

\end{itemize}


\subsubsection{’\sphinxstyleliteralintitle{ORTHO} bug’}
\label{\detokenize{nbo_onetep:ortho-bug}}
The nbo 5 program up till circa April/May 2011 had a bug whereby
specifying the \sphinxcode{ORTHO} flag causes the program to crash. The nbo 5
developers seem to have fixed most of this and given me the an updated
version, but residual bug could remain (have they made the fix a general
release yet?). This is of course fixable by running the
\sphinxcode{\textless{}seedname\textgreater{}\_lclowdin\_nbo.47} file through GENNBO instead, albeit this
would mean one can’t do DM partitioning.


\subsection{Example Usage}
\label{\detokenize{nbo_onetep:example-usage}}

\subsubsection{Obtaining \protect\(2^{\mathrm{nd}}\protect\)-order Perturbation Estimates of the \protect\(n\rightarrow\sigma^*\protect\) Secondary Hyperconjugation in Water Dimer (Hydrogen Bond)}
\label{\detokenize{nbo_onetep:obtaining-order-perturbation-estimates-of-the-secondary-hyperconjugation-in-water-dimer-hydrogen-bond}}
The hydrogen bond stabilization in water dimer can be attributed to the
non-classical ’charge transfer’ interaction between two water molecules
due to delocalization of the electronic charge from the oxygen lone pair
\(n\) of the donor monomer to the \(\sigma^*\) O\textendash{}H antibond of
the acceptor {[}Reed1988{]}. The expansion
of the variational space to included non-Lewis, formally vacant antibond
NBOs leads to an energetic lowering compared to the ideal Lewis
configuration (all Lewis NBO occupancy = 2 \sphinxstyleemphasis{e}), which can be estimated
via \(2^{\mathrm{nd}}\)-order perturbation theory as the ’charge
transfer’ energetic component of the dimer interaction.

From a converged SCF calculation in ONETEP using the reference
coordinates below (given in Angstroms):
\begin{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block}  \PYG{n}{positions\PYGZus{}abs}
\PYG{n}{ang}
 \PYG{n}{O}  \PYG{l+m+mf}{10.6080354926368} \PYG{l+m+mf}{12.5000150953008} \PYG{l+m+mf}{12.5705695516353}
 \PYG{n}{H}  \PYG{l+m+mf}{10.4341376488693} \PYG{l+m+mf}{12.5000119731552} \PYG{l+m+mf}{13.5119746410112}
 \PYG{n}{H1} \PYG{l+m+mf}{11.5729802892758} \PYG{l+m+mf}{12.5000098564464} \PYG{l+m+mf}{12.5000098564464}
 \PYG{n}{H}  \PYG{l+m+mf}{13.9638274701977} \PYG{l+m+mf}{13.2691512541917} \PYG{l+m+mf}{12.2000071259853}
 \PYG{n}{O1} \PYG{l+m+mf}{13.4760438789916} \PYG{l+m+mf}{12.5000098564464} \PYG{l+m+mf}{12.5000098564464}
 \PYG{n}{H}  \PYG{l+m+mf}{13.9638258826660} \PYG{l+m+mf}{11.7308667653340} \PYG{l+m+mf}{12.2000083960106}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock}  \PYG{n}{positions\PYGZus{}abs}
\end{sphinxVerbatim}
\end{quote}

with the pseudoatomic solver employing a minimal NGWF basis (1 NGWF on
H, 4 on O) with a 10.0 a\(_0\) NGWF radius cutoff, PBE
exchange-correlation functional, norm-conserving pseudopotential with
pseudized \(1s\) core for O, and a 1200 eV psinc cutoff in a 25.0
a\(_0\) cubic simulation cell, one should run a \sphinxcode{PROPERTIES}
calculation with the additional keywords as such:
\begin{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{write\PYGZus{}nbo}\PYG{p}{:} \PYG{n}{T}
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}ngwflabel}
 \PYG{n}{H}  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{1N}\PYG{l+s+s2}{\PYGZdq{}}
 \PYG{n}{O}  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{1N 152N 153N 151N}\PYG{l+s+s2}{\PYGZdq{}}
 \PYG{n}{H1} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{1N}\PYG{l+s+s2}{\PYGZdq{}}
 \PYG{n}{O1} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{1N 152N 153N 151N}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}ngwflabel}
\end{sphinxVerbatim}
\end{quote}

where the \sphinxcode{species\_ngwflabel} block tells the NPA routine in ONETEP
how to label each NGWF. The order of \(m\) for each \(l\) in the
\(Y(l,m)\) isn’t straightforward, and follows the pattern of e.g.
“152 153 151” i.e. \(m=\{-1,0,1\}\) for \(l=1\), and “251 253
255 252 254” for \(l=2\). I’ve yet to look at how others are
arranged, though this is not very important unless one is interested in
’NHO Directionality and Bond Bending’ analysis, as in the NBO scheme,
all \(m\) of the same \(l\) are treated equally. The order of
each \(Y(l,m)\) should follow that of the pseudoatomic solver, which
does them in principal quantum number (\(n\)) increments (with
multiple-\(\zeta\) basis, the split-valence set of \(Y(l,m)\)
probably comes first i.e. \(Y^{\zeta1}(l,m)\) then
\(Y^{\zeta2}(l,m)\) before the next \(n\). The “N” suffix
denotes valence orbital in the ground state, which in the case of H,
“1N” is the \(1s\) orbital. Make sure the correct orbitals are
marked as valence as they would appear in the ground state (even if the
pseudoatomic solver basis was initialized in an excited configuration).
In this example, the pseudoatomic solver block would have explicitly
been:
\begin{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}atomic\PYGZus{}set}
 \PYG{n}{H}  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{SOLVE conf=1s1}\PYG{l+s+s2}{\PYGZdq{}}
 \PYG{n}{O}  \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{SOLVE conf=1sX 2s2 2p4}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}atomic\PYGZus{}set}
\end{sphinxVerbatim}
\end{quote}

ONETEP should run and produce an NPA output listing the NPA charges on
each atom, and print a \sphinxcode{\textless{}seedname\textgreater{}\_nao\_nbo.47} file. This \sphinxcode{.47} file
serves as the input for GENNBO.

If we wanted to generate NBOs and visualize them, insert the keyword
\sphinxcode{AONBO=W} in the \sphinxcode{\$NBO} block of the \sphinxcode{.47} file before running it
through GENNBO. GENNBO will output a report containing NBO information,
including the \(2^{\mathrm{nd}}\)-order perturbation estimates, and
a \sphinxcode{.37} file containing the NBO vectors in terms of the \sphinxcode{.37} input
basis (don’t change any of the \sphinxcode{.47}, \sphinxcode{.37} etc. filenames).

First, we can see that the \(2^{\mathrm{nd}}\)-order perturbation
report shows one prominenet interaction, namely one between the occupied
lone pair of oxygen from one H\(_2\)O unit (\sphinxcode{LP ( 2) O 5}) to
the O\textendash{}H antibond of the other (\sphinxcode{BD*( 2) O 1- H 3}) with an estimate of
15.32 kcal/mol, corresponding to the hydrogen bond in water dimer:
\begin{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{SECOND} \PYG{n}{ORDER} \PYG{n}{PERTURBATION} \PYG{n}{THEORY} \PYG{n}{ANALYSIS} \PYG{n}{OF} \PYG{n}{FOCK} \PYG{n}{MATRIX} \PYG{n}{IN} \PYG{n}{NBO} \PYG{n}{BASIS}

    \PYG{n}{Threshold} \PYG{k}{for} \PYG{n}{printing}\PYG{p}{:}   \PYG{l+m+mf}{0.50} \PYG{n}{kcal}\PYG{o}{/}\PYG{n}{mol}
   \PYG{p}{(}\PYG{n}{Intermolecular} \PYG{n}{threshold}\PYG{p}{:} \PYG{l+m+mf}{0.05} \PYG{n}{kcal}\PYG{o}{/}\PYG{n}{mol}\PYG{p}{)}
                                                         \PYG{n}{E}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}  \PYG{n}{E}\PYG{p}{(}\PYG{n}{j}\PYG{p}{)}\PYG{o}{\PYGZhy{}}\PYG{n}{E}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)} \PYG{n}{F}\PYG{p}{(}\PYG{n}{i}\PYG{p}{,}\PYG{n}{j}\PYG{p}{)}
     \PYG{n}{Donor} \PYG{n}{NBO} \PYG{p}{(}\PYG{n}{i}\PYG{p}{)}              \PYG{n}{Acceptor} \PYG{n}{NBO} \PYG{p}{(}\PYG{n}{j}\PYG{p}{)}       \PYG{n}{kcal}\PYG{o}{/}\PYG{n}{mol}   \PYG{n}{a}\PYG{o}{.}\PYG{n}{u}\PYG{o}{.}    \PYG{n}{a}\PYG{o}{.}\PYG{n}{u}\PYG{o}{.}
\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{==}\PYG{o}{=}

\PYG{n}{within} \PYG{n}{unit}  \PYG{l+m+mi}{1}
      \PYG{k+kc}{None} \PYG{n}{above} \PYG{n}{threshold}

\PYG{k+kn}{from} \PYG{n+nn}{unit}  \PYG{l+m+mi}{1} \PYG{n}{to} \PYG{n}{unit}  \PYG{l+m+mi}{2}
  \PYG{l+m+mf}{2.} \PYG{n}{BD} \PYG{p}{(} \PYG{l+m+mi}{1}\PYG{p}{)} \PYG{n}{O} \PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}} \PYG{n}{H} \PYG{l+m+mi}{3}       \PYG{l+m+mf}{11.} \PYG{n}{BD}\PYG{o}{*}\PYG{p}{(} \PYG{l+m+mi}{1}\PYG{p}{)} \PYG{n}{H} \PYG{l+m+mi}{4}\PYG{o}{\PYGZhy{}} \PYG{n}{O} \PYG{l+m+mi}{5}         \PYG{l+m+mf}{0.08}    \PYG{l+m+mf}{0.67}    \PYG{l+m+mf}{0.007}
  \PYG{l+m+mf}{2.} \PYG{n}{BD} \PYG{p}{(} \PYG{l+m+mi}{1}\PYG{p}{)} \PYG{n}{O} \PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}} \PYG{n}{H} \PYG{l+m+mi}{3}       \PYG{l+m+mf}{12.} \PYG{n}{BD}\PYG{o}{*}\PYG{p}{(} \PYG{l+m+mi}{1}\PYG{p}{)} \PYG{n}{O} \PYG{l+m+mi}{5}\PYG{o}{\PYGZhy{}} \PYG{n}{H} \PYG{l+m+mi}{6}         \PYG{l+m+mf}{0.08}    \PYG{l+m+mf}{0.67}    \PYG{l+m+mf}{0.007}

\PYG{k+kn}{from} \PYG{n+nn}{unit}  \PYG{l+m+mi}{2} \PYG{n}{to} \PYG{n}{unit}  \PYG{l+m+mi}{1}
  \PYG{l+m+mf}{3.} \PYG{n}{BD} \PYG{p}{(} \PYG{l+m+mi}{1}\PYG{p}{)} \PYG{n}{H} \PYG{l+m+mi}{4}\PYG{o}{\PYGZhy{}} \PYG{n}{O} \PYG{l+m+mi}{5}       \PYG{l+m+mf}{10.} \PYG{n}{BD}\PYG{o}{*}\PYG{p}{(} \PYG{l+m+mi}{1}\PYG{p}{)} \PYG{n}{O} \PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}} \PYG{n}{H} \PYG{l+m+mi}{3}         \PYG{l+m+mf}{0.10}    \PYG{l+m+mf}{0.83}    \PYG{l+m+mf}{0.008}
  \PYG{l+m+mf}{4.} \PYG{n}{BD} \PYG{p}{(} \PYG{l+m+mi}{1}\PYG{p}{)} \PYG{n}{O} \PYG{l+m+mi}{5}\PYG{o}{\PYGZhy{}} \PYG{n}{H} \PYG{l+m+mi}{6}       \PYG{l+m+mf}{10.} \PYG{n}{BD}\PYG{o}{*}\PYG{p}{(} \PYG{l+m+mi}{1}\PYG{p}{)} \PYG{n}{O} \PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}} \PYG{n}{H} \PYG{l+m+mi}{3}         \PYG{l+m+mf}{0.10}    \PYG{l+m+mf}{0.83}    \PYG{l+m+mf}{0.008}
  \PYG{l+m+mf}{7.} \PYG{n}{LP} \PYG{p}{(} \PYG{l+m+mi}{1}\PYG{p}{)} \PYG{n}{O} \PYG{l+m+mi}{5}            \PYG{l+m+mf}{10.} \PYG{n}{BD}\PYG{o}{*}\PYG{p}{(} \PYG{l+m+mi}{1}\PYG{p}{)} \PYG{n}{O} \PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}} \PYG{n}{H} \PYG{l+m+mi}{3}         \PYG{l+m+mf}{0.18}    \PYG{l+m+mf}{0.49}    \PYG{l+m+mf}{0.008}
  \PYG{l+m+mf}{8.} \PYG{n}{LP} \PYG{p}{(} \PYG{l+m+mi}{2}\PYG{p}{)} \PYG{n}{O} \PYG{l+m+mi}{5}            \PYG{l+m+mf}{10.} \PYG{n}{BD}\PYG{o}{*}\PYG{p}{(} \PYG{l+m+mi}{1}\PYG{p}{)} \PYG{n}{O} \PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}} \PYG{n}{H} \PYG{l+m+mi}{3}        \PYG{l+m+mf}{15.32}    \PYG{l+m+mf}{0.60}    \PYG{l+m+mf}{0.085}

\PYG{n}{within} \PYG{n}{unit}  \PYG{l+m+mi}{2}
      \PYG{k+kc}{None} \PYG{n}{above} \PYG{n}{threshold}
\end{sphinxVerbatim}
\end{quote}

Noting down the orbital numbers, we can then proceed to plot them by
running another properties calculation in ONETEP with the following
block:
\begin{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{write\PYGZus{}nbo}   \PYG{p}{:} \PYG{n}{F}
\PYG{n}{plot\PYGZus{}nbo}    \PYG{p}{:} \PYG{n}{T}
\PYG{n}{cube\PYGZus{}format} \PYG{p}{:} \PYG{n}{T}
\PYG{n}{nbo\PYGZus{}plot\PYGZus{}orbtype} \PYG{p}{:} \PYG{n}{NBO}
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{nbo\PYGZus{}list\PYGZus{}plotnbo}
  \PYG{l+m+mi}{8}
 \PYG{l+m+mi}{10}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{nbo\PYGZus{}list\PYGZus{}plotnbo}
\end{sphinxVerbatim}
\end{quote}

where \sphinxcode{write\_nbo} needs to be set to \sphinxcode{F}. ONETEP will then read the
\sphinxcode{\textless{}seedname\textgreater{}\_inittr\_nao\_nbo.dat} file printed during the first run and
the \sphinxcode{.37} file to plot the orbitals specified in the
\sphinxcode{nbo\_list\_plotnbo} block into Gaussian cube files.

An example result is displayed in a figure available in the published
paper.


\subsubsection{Notes on Selectively Passing sub-region sub-matrices into GENNBO}
\label{\detokenize{nbo_onetep:notes-on-selectively-passing-sub-region-sub-matrices-into-gennbo}}
To circumvent the limitations on system size in GENNBO, and for
convenience, we could output only matrix elements corresponding to atoms
within a selected sub-region of a large system. To do so, during an NPA
analysis run (not plotting) within a properties run in ONETEP, the
following should be specified:
\begin{quote}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{nbo\PYGZus{}write\PYGZus{}species}
 \PYG{n}{O1}
 \PYG{n}{H1}
 \PYG{n}{C1}
 \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{nbo\PYGZus{}write\PYGZus{}species}
\end{sphinxVerbatim}
\end{quote}

ONETEP would then print only matrix elements belongning to species
specified by the labels in the \sphinxcode{\%block nbo\_write\_species} block to
\sphinxcode{\textless{}seedname\textgreater{}\_nao\_nbo.47}. Due to GENNBO insisting on integral charges,
the density matrix in the \sphinxcode{.47} file is re-scaled downwards to the
nearest lowest integral number, to avoid the possibility of orbitals
having occupancies \(> 2\) \sphinxstyleemphasis{e}, which also annoys GENNBO. To
minimize the impact of this technical re-scaling to the NBO results, a
sufficiently-sized partition should be chosen in
\sphinxcode{\%block nbo\_write\_species} so that \(1/N_e << 1\), where
\(N_e\) is the number of electrons in the partition.

The final results fron NBO analysis that depend on the density matrix
will then need to be de-scaled to arrive at the correct value (e.g. NPA
charges, NBO occupancies, \(2^{\mathrm{nd}}\)-order perturbation
estimates, while orbital energies don’t require de-scaling).

Note that the region included in \sphinxcode{\%block nbo\_write\_species} should
have buffer atoms, which minimally should include the next-nearest
neighbour atom bonded to the last atom in the selection \textendash{} that way, the
severing of a bond would only affect NBOs centred on the buffer atom,
and not anywhere else.

As a final note, there is a possibility that during an NBO search,
slightly different NBO pictures are obtained when passing only part of
the matrix as compared to analyzing the full system \textendash{} this can be caused
by the fact that during an NBO search, the nbo 5 program iterates
through different occupancy thresholds (\(n_{min}\)) for deciding
upon whether an orbital is a lone pair/NBO. If one is pedantic about
this, then \(n_{min}\) can be fixed by specifying the
\sphinxcode{THRESH =}\(n_{min}\) keyword manually in the \sphinxcode{\$NBO} block in
the \sphinxcode{.47} file, where \(n_{min}\) is defined by the user.

{[}Glendening{]} E. D. Glendening, J. K. Badenhoop, A. E. Reed, J. E. Carpenter, J. A. Bohmann, C. M. Morales, F. Weinhold; NBO 5.9 (\sphinxurl{http://www.chem.wisc.edu/~nbo5}) \& the NBO 5.9 Manual, Theoretical Chemistry Institute, University of Wisconsin, Madison, WI.

{[}Reed1985{]} A. E. Reed, R. B. Weinstock, F. Weinhold \sphinxstyleemphasis{J. Chem. Phys.} \sphinxstylestrong{1985,} \sphinxstyleemphasis{83,} 735-746.

{[}Reed1988{]} A. E. Reed, L. A. Curtiss, F. Weinhold \sphinxstyleemphasis{Chem. Rev.} \sphinxstylestrong{1988,} \sphinxstyleemphasis{88,} 899-926.

{[}MacKerell1998{]} A. D. MacKerell, Jr., B. Brooks, C. L. Brooks III, L. Nilsson, B. Roux, Y. Won, M. Karplus, in Encyclopedia of Computational Chemistry; R. Schleyer et al. Eds.; John Wiley \& Sons, Chichester, \sphinxstylestrong{1998}; Vol. 3, Chapter ‘Natural Bond Orbital Methods’, pp 1792-1811.


\section{Density derived electrostatic and chemical (DDEC) electron density partitioning}
\label{\detokenize{ddec::doc}}\label{\detokenize{ddec:density-derived-electrostatic-and-chemical-ddec-electron-density-partitioning}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Louis P. Lee, University of Cambridge

\item[{Author}] \leavevmode
Daniel J. Cole, University of Cambridge

\end{description}\end{quote}

Atoms-in-molecule electron density partitioning is a useful
post-processing analysis tool for computing atomic charges (as well as
higher order atomic multipoles) from the total electron density. ONETEP
uses the DDEC3 method {[}1,3{]} for this purpose, as the computed charges
are both chemically meaningful and reproduce the electrostatic potential
of the underlying QM calculation. Options are also available for
computing \sphinxstyleemphasis{Hirshfeld} and \sphinxstyleemphasis{iterated stockholder atoms} (ISA) charges
{[}3,4{]}.

A DDEC3 calculation to partition the electron density and output atomic
charges, multipoles and volumes is performed by specifying:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ddec\PYGZus{}calculate} \PYG{p}{:} \PYG{n}{T}
\PYG{n}{ddec\PYGZus{}multipole} \PYG{p}{:} \PYG{n}{T}
\PYG{n}{ddec\PYGZus{}moment} \PYG{p}{:} \PYG{l+m+mi}{3}
\end{sphinxVerbatim}

along with the ddec\_rcomp block for your system (see below). Iterated
stockholder atoms (ISA) partitioning may be performed instead by
additionally specifying:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ddec\PYGZus{}IH\PYGZus{}fraction} \PYG{p}{:} \PYG{l+m+mf}{0.00}
\end{sphinxVerbatim}

Classical Hirshfeld partitioning may be performed instead by
additionally specifying:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ddec\PYGZus{}classical\PYGZus{}hirshfeld} \PYG{p}{:} \PYG{n}{T}
\PYG{n}{ddec\PYGZus{}IH\PYGZus{}fraction} \PYG{p}{:} \PYG{l+m+mf}{1.00}
\PYG{n}{ddec\PYGZus{}maxit} \PYG{p}{:} \PYG{l+m+mi}{1}
\end{sphinxVerbatim}

\begin{DUlineblock}{0em}
\item[] The reference ion densities for use with DDEC3 are read in from an
external library kindly provided by Thomas A. Manz and Nidia Gabaldon
Limas (please cite Refs. {[}1,2{]}), and are available for download from
the ONETEP website:
\item[] \sphinxurl{http://www.onetep.org/pmwiki/uploads/Main/Utilities/ddec\_atomic\_densities.tar.gz}
\item[] The paths to the reference densities are specified in the block
\sphinxcode{ddec\_rcomp}. Specify one core and one total density file for each
species in your system (except for hydrogen and helium which do not
require a core density file). The example below is for methanol:
\end{DUlineblock}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}block ddec\PYGZus{}rcomp
  H ALL “H\PYGZus{}c2.refconf”
  O ALL “O\PYGZus{}c2.refconf”
  O CORE “O\PYGZus{}c2.coreconf”
  C ALL “C\PYGZus{}c2.refconf”
  C CORE “C\PYGZus{}c2.coreconf”
\PYGZpc{}endblock ddec\PYGZus{}rcomp
\end{sphinxVerbatim}


\subsection{References}
\label{\detokenize{ddec:references}}
\begin{DUlineblock}{0em}
\item[] For the development of the DDEC method:
\item[] \([1]\) T.A. Manz and D.S. Sholl, “Improved Atoms-in-Molecule
Charge Partitioning Functional for Simultaneously Reproducing the
Electrostatic Potential and Chemical States in Periodic and
Non-Periodic Materials,” J. Chem. Theory Comput. 8 (2012) 2844-2867.
\item[] \([2]\) T. A. Manz and D. S. Sholl, “Chemically Meaningful Atomic
Charges that Reproduce the Electrostatic Potential in Periodic and
Nonperiodic Materials”, J. Chem. Theory Comput. 6 (2010) 2455-2468.
\item[] And its implementation in ONETEP:
\item[] \([3]\) L. P. Lee, N. Gabaldon Limas, D. J. Cole, M. C. Payne,
C.-K. Skylaris, T. A. Manz, “Expanding the Scope of Density Derived
Electrostatic and Chemical Charge Partitioning to Thousands of Atoms”,
J. Chem. Theory Comput., 10 (2014) 5377.
\item[] \([4]\) L. P. Lee, D. J. Cole, C.-K. Skylaris, W. L. Jorgensen, M.
C. Payne, “Polarized Protein-Specific Charges from Atoms-in-Molecule
Electron Density Partitioning”, J. Chem. Theory Comput., 9 (2013),
2981.
\end{DUlineblock}


\chapter{GPU Accelerated Code}
\label{\detokenize{index_gpu::doc}}\label{\detokenize{index_gpu:gpu-accelerated-code}}

\section{GPU Accelerated Implementation}
\label{\detokenize{ONETEP_OpenACC::doc}}\label{\detokenize{ONETEP_OpenACC:gpu-accelerated-implementation}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Karl A. Wilkinson, University of Cape Town %
\begin{footnote}[1]\sphinxAtStartFootnote
\sphinxhref{mailto:karl.wilkinson@uct.ac.za}{karl.wilkinson@uct.ac.za}
%
\end{footnote}

\end{description}\end{quote}


\subsection{Introduction}
\label{\detokenize{ONETEP_OpenACC:introduction}}
An OpenACC implementation of ONETEP is available to allow execution on
machines containing graphic processing units based accelerators (GPUs).
GPUs are highly parallel and are well suited to algorithms such as the
fast fourier transforms (FFTs) within ONETEP during the calculation of
properties such as the local potential integrals and the charge density.

However, the connection of the accelerators to the host machine through
the peripheral component interconnect express (PCIe) bus introduces a
bottleneck when large amounts of data are transferred. Currently, this
is an issue when moving the fine grid FFT boxes from the accelerator to
the host machine but future generations of hardware, and developments
within ONETEP are expected to reduce this issue and improve performance
significantly.

This work has been published in the Journal of Computational Chemistry.
More detailed information is available in this publication:
\sphinxurl{http://onlinelibrary.wiley.com/doi/10.1002/jcc.23410/abstract} It should
be noted that this feature of the ONETEP package is under development
and that significant performance improvements have achieved since the
publication of this article.


\subsection{Compilation}
\label{\detokenize{ONETEP_OpenACC:compilation}}
Compilation of the OpenACC implementation of ONETEP is only currently
supported by the compilers from the Portland Group International (PGI).
Relatively few changes are required in order to perform the compilation:
The flag:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{n}{DGPU\PYGZus{}PGI}
\end{sphinxVerbatim}

should be used and additional variable describing the flags and
libraries need to be defined:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ACCFLAGS} \PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{n}{ta}\PYG{o}{=}\PYG{n}{nvidia} \PYG{o}{\PYGZhy{}}\PYG{n}{Mcuda}\PYG{o}{=}\PYG{l+m+mf}{6.5}
\PYG{n}{ACCLIBS} \PYG{o}{=} \PYG{o}{\PYGZhy{}}\PYG{n}{lcufft} \PYG{o}{\PYGZhy{}}\PYG{n}{lcudart}
\end{sphinxVerbatim}

Here, we are utilising the CUDA 6.5 runtime libraries as they are the
most up to date version available on the TITAN supercomputer at the Oak
Ridge National laboratories, your local machine may have a more up to
data version available.

Further examples of complete config files for the desktops at the
University of Southampton and the Wilkes cluster at the University of
Cambridge follow:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}  Southampton desktop \PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}
F90 = pgf90
MPIROOT=/local/scratch/kaw2e11/software/openmpi\PYGZus{}1.6.4/pgi/
FFTWROOT=/local/scratch/kaw2e11/software/fftw/pgi/
FFLAGS = \PYGZhy{}DGPU\PYGZus{}PGI \PYGZhy{}DFFTW3 \PYGZhy{}DMPI \PYGZhy{}I\PYGZdl{}(MPIROOT)include \PYGZhy{}I\PYGZdl{}(FFTWROOT)include \PYGZhy{}I\PYGZdl{}(MPIROOT)lib/
OPTFLAGS = \PYGZhy{}O3 \PYGZhy{}fast
DEBUGFLAGS = \PYGZhy{}g \PYGZhy{}C
MPILIBS= \PYGZhy{}L\PYGZdl{}(MPIROOT)lib/ \PYGZhy{}lmpi\PYGZus{}f90 \PYGZhy{}lmpi\PYGZus{}f77 \PYGZhy{}lmpi \PYGZhy{}lopen\PYGZhy{}rte \PYGZhy{}lopen\PYGZhy{}pal \PYGZhy{}ldl \PYGZhy{}Wl,
\PYGZhy{}\PYGZhy{}export\PYGZhy{}dynamic \PYGZhy{}lnsl \PYGZhy{}lutil \PYGZhy{}ldl
ACCFLAGS = \PYGZhy{}ta=nvidia \PYGZhy{}Mcuda=6.5
ACCLIBS = \PYGZhy{}L/usr/lib64/nvidia \PYGZhy{}L\PYGZdl{}(CUDAROOT)/lib64/ \PYGZhy{}lcufft \PYGZhy{}lcudart
LIBS = \PYGZdl{}(MPILIBS) \PYGZhy{}llapack \PYGZhy{}lblas \PYGZhy{}L\PYGZdl{}(FFTWROOT)lib/ \PYGZhy{}lfftw3\PYGZus{}omp \PYGZhy{}lfftw3 \PYGZhy{}lm
\end{sphinxVerbatim}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{} WILKES \PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}
FC := mpif90
F90 := \PYGZdl{}(FC)
FFLAGS = \PYGZhy{}DGPU\PYGZus{}PGI \PYGZhy{}DFFTW3\PYGZus{}NO\PYGZus{}OMP \PYGZhy{}DMPI \PYGZhy{}DNOMPIIO \PYGZhy{}Mdalign
MKLPATH=\PYGZdl{}\PYGZob{}MKLROOT\PYGZcb{}/lib/intel64
LIBS=  \PYGZhy{}L\PYGZdl{}(MKLROOT)/lib/intel64 \PYGZhy{}lmkl\PYGZus{}intel\PYGZus{}lp64 \PYGZhy{}lmkl\PYGZus{}core \PYGZhy{}lmkl\PYGZus{}sequential \PYGZhy{}lpthread \PYGZhy{}lm
OPTFLAGS = \PYGZhy{}O3 \PYGZhy{}m64
WARNINGFLAGS = \PYGZhy{}Wall \PYGZhy{}Wextra
DEBUGFLAGS =
COMPILER = PORTLAND\PYGZhy{}pgf90\PYGZhy{}on\PYGZhy{}LINUX
ACCFLAGS = \PYGZhy{}acc \PYGZhy{}ta=nvidia:cc35 \PYGZhy{}Mcuda=6.5
ACCLIBS = \PYGZhy{}lcufft \PYGZhy{}lcudart
\end{sphinxVerbatim}

\sphinxstylestrong{Unfortunately, attention should be paid to to the version of the
compilers and libraries used as, due to the speed at which the OpenACC
approach is evolving, it is a common for functionality to break. As
such, this document will be regularly updated with details of
combinations of compiler and library versions that are known to be
stable.}


\subsubsection{Known Working Configurations}
\label{\detokenize{ONETEP_OpenACC:known-working-configurations}}
The following combinations of machine, PGI compiler and CUDA libraries
have been tested successfully.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline

\sphinxstylestrong{Machine}
&
\sphinxstylestrong{Compiler}
&
\sphinxstylestrong{CUDA library}
\\
\hline
Wilkes
&
PGI 15.3
&
6.5
\\
\hline
Wilkes
&
PGI 15.9
&
7.5
\\
\hline
Titan
&
Cray
&
6.5
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsection{Execution}
\label{\detokenize{ONETEP_OpenACC:execution}}
Use of the OpenACC implementation of ONETEP does not require any changes
to the ONETEP input files. However, job submission does change
significantly in some platforms.


\subsubsection{CUDA Multi Process Service}
\label{\detokenize{ONETEP_OpenACC:cuda-multi-process-service}}
The CUDA Multi Process Service (MPS) daemon controls the way MPI
processes see GPUs and allows multiple MPI processes to use a single GPU
wherein the hyperqueue scheduler is used to utilise the hardware much
more efficiently than when a single process is used per GPU. As, in the
case of a single MPI process does not provide sufficient computation to
fully utilize a GPU, it is critical to use this technology to achieve
optimal performance.

However, attention must be paid to ensure that GPU memory is not
exhausted. Currently, the usage is reported but these safety checks need
to be extended to allow a graceful exit should the total memory be
exhausted.

Below are examples for the usage of MPS during job submission on Wilkes
and TITAN:


\paragraph{Wilkes}
\label{\detokenize{ONETEP_OpenACC:wilkes}}
On Wilkes, job submission is performed using: sbatch slurm\_submit.tesla

where: slurm\_submit.tesla is:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{}!/bin/bash
\PYGZsh{}SBATCH \PYGZhy{}J MPS\PYGZus{}test
\PYGZsh{}SBATCH \PYGZhy{}A SKYLARIS\PYGZhy{}GPU
\PYGZsh{}SBATCH \PYGZhy{}\PYGZhy{}nodes=1
\PYGZsh{}SBATCH \PYGZhy{}\PYGZhy{}ntasks=4
\PYGZsh{}SBATCH \PYGZhy{}\PYGZhy{}time=00:30:00
\PYGZsh{}SBATCH \PYGZhy{}\PYGZhy{}no\PYGZhy{}requeue
\PYGZsh{}SBATCH \PYGZhy{}p tesla

. /etc/profile.d/modules.sh
module purge
module load default\PYGZhy{}wilkes
module unload intel/impi intel/cce intel/fce cuda
module load pgi/14.7
module load mvapich2/2.0/pgi\PYGZhy{}14
ulimit \PYGZhy{}s unlimited

numnodes=\PYGZdl{}SLURM\PYGZus{}JOB\PYGZus{}NUM\PYGZus{}NODES
numtasks=\PYGZdl{}SLURM\PYGZus{}NTASKS
mpi\PYGZus{}tasks\PYGZus{}per\PYGZus{}node=\PYGZdl{}(echo \PYGZdq{}\PYGZdl{}SLURM\PYGZus{}TASKS\PYGZus{}PER\PYGZus{}NODE\PYGZdq{} \textbar{} sed \PYGZhy{}e  \PYGZsq{}s/\PYGZca{}\PYGZbs{}([0\PYGZhy{}9][0\PYGZhy{}9]*\PYGZbs{}).*\PYGZdl{}/\PYGZbs{}1/\PYGZsq{})
JOBID=\PYGZdl{}SLURM\PYGZus{}JOB\PYGZus{}ID

cd \PYGZdl{}SLURM\PYGZus{}SUBMIT\PYGZus{}DIR

application=\PYGZdq{}onetep.wilkes.gpu.cuda55\PYGZdq{}

echo \PYGZdq{}JobID: \PYGZdl{}JOBID\PYGZdq{}
echo \PYGZdq{}Time: {}`date{}`\PYGZdq{}
echo \PYGZdq{}Running on master node: {}`hostname{}`\PYGZdq{}
echo \PYGZdq{}Current directory: {}`pwd{}`\PYGZdq{}

if [ \PYGZdq{}\PYGZdl{}SLURM\PYGZus{}JOB\PYGZus{}NODELIST\PYGZdq{} ]; then
       \PYGZsh{}! Create a machine file:
       export NODEFILE={}`generate\PYGZus{}pbs\PYGZus{}nodefile{}`
       cat \PYGZdl{}NODEFILE \textbar{} uniq \PYGZgt{} machine.file.\PYGZdl{}JOBID
       echo \PYGZhy{}e \PYGZdq{}\PYGZbs{}nNodes allocated:\PYGZbs{}n================\PYGZdq{}
       echo {}`cat machine.file.\PYGZdl{}JOBID \textbar{} sed \PYGZhy{}e \PYGZsq{}s/\PYGZbs{}..*\PYGZdl{}//g\PYGZsq{}{}`
fi

echo \PYGZhy{}e \PYGZdq{}\PYGZbs{}nnumtasks=\PYGZdl{}numtasks, numnodes=\PYGZdl{}numnodes, \PYGZbs{}
mpi\PYGZus{}tasks\PYGZus{}per\PYGZus{}node=\PYGZdl{}mpi\PYGZus{}tasks\PYGZus{}per\PYGZus{}node (OMP\PYGZus{}NUM\PYGZus{}THREADS=\PYGZdl{}OMP\PYGZus{}NUM\PYGZus{}THREADS)\PYGZbs{}n\PYGZdq{}

\PYGZsh{} Start MPS deamons...
srun \PYGZhy{}N\PYGZdl{}SLURM\PYGZus{}JOB\PYGZus{}NUM\PYGZus{}NODES \PYGZhy{}n\PYGZdl{}SLURM\PYGZus{}JOB\PYGZus{}NUM\PYGZus{}NODES ./run\PYGZus{}MPS.sh

echo \PYGZhy{}e \PYGZdq{}\PYGZbs{}nExecuting program:\PYGZbs{}n==================\PYGZbs{}n\PYGZbs{}n\PYGZdq{}

mpirun \PYGZhy{}np \PYGZdl{}\PYGZob{}SLURM\PYGZus{}NTASKS\PYGZcb{} \PYGZhy{}ppn \PYGZdl{}\PYGZob{}mpi\PYGZus{}tasks\PYGZus{}per\PYGZus{}node\PYGZcb{} \PYGZhy{}\PYGZhy{}genvall \PYGZbs{}
\PYGZhy{}genv MV2\PYGZus{}RAIL\PYGZus{}SHARING\PYGZus{}LARGE\PYGZus{}MSG\PYGZus{}THRESHOLD 1G \PYGZhy{}genv MV2\PYGZus{}ENABLE\PYGZus{}AFFINITY 1 \PYGZbs{}
\PYGZhy{}genv MV2\PYGZus{}CPU\PYGZus{}BINDING\PYGZus{}LEVEL SOCKET \PYGZhy{}genv MV2\PYGZus{}CPU\PYGZus{}BINDING\PYGZus{}POLICY SCATTER \PYGZbs{}
\PYGZhy{}genv MV2\PYGZus{}SHOW\PYGZus{}CPU\PYGZus{}BINDING 1 ./run\PYGZus{}app.sh ../\PYGZdl{}\PYGZob{}application\PYGZcb{} onetep.dat 2\PYGZgt{}\PYGZam{}1 \PYGZbs{}
\textbar{} tee onetep.out


echo \PYGZhy{}e \PYGZdq{}\PYGZbs{}n\PYGZbs{}n\PYGZgt{}\PYGZgt{}\PYGZgt{} Program terminated! \PYGZlt{}\PYGZlt{}\PYGZlt{}\PYGZbs{}n\PYGZdq{}
echo \PYGZhy{}e \PYGZdq{}Time: {}`date{}` \PYGZbs{}n\PYGZbs{}n\PYGZdq{}

\PYGZsh{} Kill MPS deamons
srun \PYGZhy{}N\PYGZdl{}SLURM\PYGZus{}JOB\PYGZus{}NUM\PYGZus{}NODES \PYGZhy{}n\PYGZdl{}SLURM\PYGZus{}JOB\PYGZus{}NUM\PYGZus{}NODES ./kill\PYGZus{}MPS.sh
\end{sphinxVerbatim}

This file, and the following files, were obtained from the Wilkes
systems administrators. It is advisable to contact system administrators
if you have any questions regarding the submission process.

Here, the files: run\_MPS.sh and kill\_MPS.sh manage the initialisation
and termination of the MPS deamon and the run\_app.sh controls the
allocation of MPI processes to the correct GPUs. For reference, the
contents of those files are as follows, again, it is advisable to speak
with your systems administrator about equivalent scripts for other
machines (For example, run\_app.sh assumes the use of MVAPICH2).

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}run\PYGZus{}MPS.sh
\PYGZsh{}!/bin/bash

\PYGZsh{} Number of gpus with compute\PYGZus{}capability 3.5  per server
NGPUS=2

\PYGZsh{} Start the MPS server for each GPU
for ((i=0; i\PYGZlt{} \PYGZdl{}NGPUS; i++))
do
 echo \PYGZdq{}[CUDA\PYGZhy{}PROXY] Setting MPS on {}`hostname{}` for GPU \PYGZdl{}i...\PYGZdq{}
 mkdir /tmp/mps\PYGZus{}\PYGZdl{}i
 mkdir /tmp/mps\PYGZus{}log\PYGZus{}\PYGZdl{}i
 export CUDA\PYGZus{}VISIBLE\PYGZus{}DEVICES=\PYGZdl{}i
 export CUDA\PYGZus{}MPS\PYGZus{}PIPE\PYGZus{}DIRECTORY=/tmp/mps\PYGZus{}\PYGZdl{}i
 export CUDA\PYGZus{}MPS\PYGZus{}LOG\PYGZus{}DIRECTORY=/tmp/mps\PYGZus{}log\PYGZus{}\PYGZdl{}i
 nvidia\PYGZhy{}cuda\PYGZhy{}mps\PYGZhy{}control \PYGZhy{}d
done

exit 0
\end{sphinxVerbatim}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{}\PYGZsh{}\PYGZsh{}/run\PYGZus{}app.sh
\PYGZsh{}!/bin/bash

\PYGZsh{} Important note: it works properly when MV2\PYGZus{}CPU\PYGZus{}BINDING\PYGZus{}LEVEL=SOCKET \PYGZam{}\PYGZam{}
\PYGZsh{} MV2\PYGZus{}CPU\PYGZus{}BINDING\PYGZus{}POLICY=SCATTER

lrank=\PYGZdl{}MV2\PYGZus{}COMM\PYGZus{}WORLD\PYGZus{}LOCAL\PYGZus{}RANK
grank=\PYGZdl{}MV2\PYGZus{}COMM\PYGZus{}WORLD\PYGZus{}RANK

case \PYGZdl{}\PYGZob{}lrank\PYGZcb{} in
0\textbar{}2\textbar{}4\textbar{}6\textbar{}8\textbar{}10)
  export CUDA\PYGZus{}MPS\PYGZus{}PIPE\PYGZus{}DIRECTORY=/tmp/mps\PYGZus{}0
  export MV2\PYGZus{}NUM\PYGZus{}HCAS=1
  export MV2\PYGZus{}NUM\PYGZus{}PORTS=1
  export MV2\PYGZus{}IBA\PYGZus{}HCA=mlx5\PYGZus{}0
  echo \PYGZdq{}[CUDA\PYGZhy{}PROXY] I am globally rank \PYGZdl{}grank (locally \PYGZdl{}lrank ) on \PYGZbs{}
  {}`hostname{}` and I am using GPU 0\PYGZdq{}
  \PYGZdq{}\PYGZdl{}@\PYGZdq{}
  ;;
1\textbar{}3\textbar{}5\textbar{}7\textbar{}9\textbar{}11)
  export CUDA\PYGZus{}MPS\PYGZus{}PIPE\PYGZus{}DIRECTORY=/tmp/mps\PYGZus{}1
  export MV2\PYGZus{}NUM\PYGZus{}HCAS=1
  export MV2\PYGZus{}NUM\PYGZus{}PORTS=1
  export MV2\PYGZus{}IBA\PYGZus{}HCA=mlx5\PYGZus{}1
  echo \PYGZdq{}[CUDA\PYGZhy{}PROXY] I am globally rank \PYGZdl{}grank (locally \PYGZdl{}lrank ) on \PYGZbs{}
  {}`hostname{}` and I am using GPU 1\PYGZdq{}
  \PYGZdq{}\PYGZdl{}@\PYGZdq{}
  ;;
esac
\end{sphinxVerbatim}

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{}\PYGZsh{}kill\PYGZus{}MPS.sh}
\PYG{c+c1}{\PYGZsh{}!/bin/bash}

\PYG{n}{echo} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{[CUDA\PYGZhy{}PROXY] Kill nvidia\PYGZhy{}cuda\PYGZhy{}mps\PYGZhy{}control on {}`hostname{}`...}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{killall} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{9} \PYG{n}{nvidia}\PYG{o}{\PYGZhy{}}\PYG{n}{cuda}\PYG{o}{\PYGZhy{}}\PYG{n}{mps}\PYG{o}{\PYGZhy{}}\PYG{n}{control}

\PYG{c+c1}{\PYGZsh{} this waiting time is to let killall have effect...}
\PYG{n}{sleep} \PYG{l+m+mi}{3}

\PYG{n}{echo} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{[CUDA\PYGZhy{}PROXY] Clean /tmp on {}`hostname{}`...}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{rm} \PYG{o}{\PYGZhy{}}\PYG{n}{rf} \PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{n}{mps\PYGZus{}}\PYG{o}{*}
\PYG{n}{rm} \PYG{o}{\PYGZhy{}}\PYG{n}{rf} \PYG{o}{/}\PYG{n}{tmp}\PYG{o}{/}\PYG{n}{mps\PYGZus{}log\PYGZus{}}\PYG{o}{*}

\PYG{n}{exit} \PYG{l+m+mi}{0}
\end{sphinxVerbatim}


\paragraph{TITAN}
\label{\detokenize{ONETEP_OpenACC:titan}}
Job submission on TITAN is somewhat more straightforward and the
following script may be used directly. The important line is:
\sphinxcode{export CRAY\_CUDA\_PROXY=1} which enables the use of MPS.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZsh{}!/bin/bash
\PYGZsh{}PBS \PYGZhy{}A CODENAME
\PYGZsh{}PBS \PYGZhy{}N MgMOF74\PYGZus{}111\PYGZus{}SP
\PYGZsh{}PBS \PYGZhy{}j oe
\PYGZsh{}PBS \PYGZhy{}l walltime=1:30:00,nodes=XNUMNODES
\PYGZsh{}PBS \PYGZhy{}l gres=atlas1\PYGZpc{}atlas2

PROJECT=chm113

source \PYGZdl{}MODULESHOME/init/bash
module load cudatoolkit
\PYGZsh{}module swap PrgEnv\PYGZhy{}pgi/5.2.40 PrgEnv\PYGZhy{}intel/5.2.40

export CRAY\PYGZus{}CUDA\PYGZus{}PROXY=1

EXEDIR=/lustre/atlas/scratch/kaw2e11/chm113/binaries
\PYGZsh{}EXE=onetep.4313.titan.cpu.intel
EXE=onetep.4313.titan.gpu.pgi

\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}
SOURCEDIR=/ccs/home/kaw2e11/BENCHMARKS/PGI\PYGZus{}GPU/benchmark\PYGZhy{}XTOTALMPI\PYGZhy{}\PYGZbs{}
XNUMNODES\PYGZhy{}XMPIPERNUMANODE
INPUT=G\PYGZus{}222\PYGZus{}80\PYGZus{}D2.dat
INFO=PGI\PYGZus{}GPU\PYGZhy{}XTOTALMPI\PYGZhy{}XNUMNODES\PYGZhy{}XMPIPERNUMANODE
\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}\PYGZsh{}

BASENAME={}`basename \PYGZdl{}INPUT{}`\PYGZhy{}\PYGZdl{}INFO
OUTPUT=\PYGZdl{}BASENAME.out

cd \PYGZdl{}MEMBERWORK/\PYGZdl{}PROJECT/
mkdir dir\PYGZhy{}\PYGZdl{}BASENAME
cd dir\PYGZhy{}\PYGZdl{}BASENAME

cp \PYGZdl{}SOURCEDIR/* \PYGZdl{}MEMBERWORK/\PYGZdl{}PROJECT/dir\PYGZhy{}\PYGZdl{}BASENAME

aprun \PYGZhy{}n XTOTALMPI \PYGZhy{}S XMPIPERNUMANODE \PYGZhy{}j 2 \PYGZdl{}EXEDIR/\PYGZdl{}EXE \PYGZdl{}INPUT \PYGZam{}\PYGZgt{} \PYGZdl{}OUTPUT

cd ..
\end{sphinxVerbatim}


\chapter{QM/MM (TINKTEP) and Polarisable Embedding}
\label{\detokenize{index_qmmm::doc}}\label{\detokenize{index_qmmm:qm-mm-tinktep-and-polarisable-embedding}}

\section{TINKTEP and polarisable embedding: linear-scaling QM/polarisable-MM}
\label{\detokenize{tinktep::doc}}\label{\detokenize{tinktep:tinktep-and-polarisable-embedding-linear-scaling-qm-polarisable-mm}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Jacek Dziedzic, University of Southampton

\item[{Date}] \leavevmode
May 2018

\end{description}\end{quote}

This manual pertains to ONETEP versions v4.5.18.8 and later, and TINKTEP
versions v1.19 and later.


\subsection{Executive summary}
\label{\detokenize{tinktep:executive-summary}}
TINKTEP {[}Dziedzic2016{]}, {[}Dziedzic2018{]} is an interface between
ONETEP and TINKER (an implementation of the AMOEBA force-field). It
enables QM/MM calculations, where ONETEP is used as the QM engine, and
TINKER is used as the MM engine. The two main distinguishing features of
TINKTEP are the linear scaling of the QM part (subject to usual ONETEP
linear scaling caveats), and the fact that the MM side uses a
polarisable force field (AMOEBA). There is full mutual self-consistency
between the QM and MM subsystem \textendash{} the QM subsystem polarises the MM
subsystem and vice versa. Van der Waals interactions between QM and MM
are also taken care of. TINKTEP is work in progress, both on the front
of theory (improving the model) and implementation (adding desired
features, simplifying use). It is currently not distributed to end users
and not fully supported at the level we support mainstream ONETEP
features.


\subsection{Main limitations}
\label{\detokenize{tinktep:main-limitations}}
Some of these might be deal-breakers for you, so make sure you read this
carefully.
\begin{itemize}
\item {} 
You must obtain and install TINKER separately, and then patch it
using the provided patches.

\item {} 
The filesystem on the node from which you submit parallel jobs must
be visible on the compute nodes. This can make set-up tricky on
systems like ARCHER, where there is an intermediate layer of MOM
nodes between the login node and the compute nodes. Currently it’s
easiest to run TINKTEP on single-node desktop machines, where you can
leverage MPI and OMP parallelism without the hassle of a batch
system.

\item {} 
Only open boundary conditions (OBCs) are supported so far. The QM
calculation is performed in OBCs, with the QM subsystem embedded in
MM point charges, dipoles, quadrupoles and polarisable dipoles. The
MM calculation is performed in OBCs. You will not be able to simulate
e.g. a QM subsystem in a periodic box of water, for instance, but
using a large sphere of MM water molecules is a decent workaround. We
plan to support PBCs in the future.

\item {} 
QM/MM forces, molecular dynamics, geometry optimisation and
transition state search are all not available currently.

\item {} 
Covalent bonds spanning the QM/MM interface are not supported.

\item {} 
All QM species must have identical NGWF radii. Without this
simplification the numerical methods used in SWRI (refer to
“Spherical-wave resolution of identity, distributed multipole
analysis (DMA) and Hartree-Fock exchange” manual for more details)
would get ugly. Typically this is a non-issue, just increase the NGWF
radii to the largest value. This might admittedly be an issue if you
have a single species that requires a large NGWF radius. This is
checked against and ONETEP will not let you do SWRI unless all NGWF
radii are identical.

\item {} 
TINKTEP is currently incompatible with complex NGWFs and ONETEP will
refuse to use both.

\item {} 
The TINKTEP1 model uses a classical model for QM/MM van der Waals
interactions. The TINKTEP2 model uses a quantum-classical model for
QM/MM van der Waals interactions, which requires suitable vdW
parameters for all MM species that you use. We only provide these
parameters for water, K\(^{+}\) and Cl\(^{-}\), so
applications of TINKTEP2 are restricted to embedding a QM subsystem
in water or KCl solutions, unless you wish to determine suitable MM
vdW parameters yourself. These are \sphinxstylestrong{not} the familiar LJ parameters
\(\sigma\) and \(\epsilon\) .

\end{itemize}


\subsection{Basics}
\label{\detokenize{tinktep:basics}}
Consult {[}Dziedzic2016{]} for a detailed exposure of the
theory behind the model. Consult {[}Dziedzic2018{]} for a
description of TINKTEP2 and how it differs from TINKTEP1. This manual
takes a hands-on approach, but assumes you are familiar with the theory.
This manual should be suitable for both TINKTEP1 and TINKTEP2, but the
former will likely be discontinued in the future.

TINKTEP uses Distributed Multipole Analysis
(DMA) {[}Stone1998{]}, {[}Stone2005{]}, {[}Vitale2015{]} to build an auxiliary
representation (termed QM\(^*\)) of the QM subsystem as a set of
multipoles. Make sure you are famliar with DMA and SWRI (“Spherical-wave
resolution of identity, distributed multipole analysis (DMA) and
Hartree-Fock exchange”) beforehand.


\subsection{Setting up your computational environment}
\label{\detokenize{tinktep:setting-up-your-computational-environment}}\begin{enumerate}
\item {} 
Obtain a copy of TINKER v7.1.3. This should be available at no cost
from Jay Ponder’s website. It is imperative that you use v7.1.3 or
else the patches supplied with ONETEP will not work.

\item {} 
Patch your copy of TINKER using the set of patches located in
\sphinxcode{utils/tinktep/tinktep\_patches}. Make sure they all applied
correctly.

\item {} 
Compile and install your patched copy of TINKER.

\item {} 
Ensure that at least the following executables from the TINKER suite
can be found in your \sphinxcode{PATH}: \sphinxcode{analyze}, \sphinxcode{dynamic}, \sphinxcode{poledit}.

\item {} 
Compile ONETEP v4.5.18.8 or later.

\item {} 
Ensure all scripts supplied in \sphinxcode{utils/tinktep} can be found in your
\sphinxcode{PATH}.

\end{enumerate}


\subsection{Setting up a QM/MM calculation}
\label{\detokenize{tinktep:setting-up-a-qm-mm-calculation}}

\subsubsection{Input \sphinxstyleliteralintitle{.xyz} file}
\label{\detokenize{tinktep:input-xyz-file}}
First, prepare your complete QM+MM system in the form of a TINKER
\sphinxcode{.xyz} file. This format differs from the four-column (species,
\(x\), \(y\), \(z\)) \sphinxcode{.xyz} file you might be familiar
with. Consult the TINKER manual for the details of the format. In
further text “\sphinxcode{.xyz} format” will implicitly mean the TINKER \sphinxcode{.xyz}
format. If your \sphinxcode{.xyz} file came from a TINKER MD simulation, no
adjustments are necessary. If you are creating the \sphinxcode{.xyz} file on your
own, make sure you get the atom types and classes right, and the
connectivity too \textendash{} as prescribed by your MM \sphinxcode{.prm} file
(e.g. \sphinxcode{amoeba09.prm}). If you do not know what atom types to choose
for what will be your QM atoms, do not worry particularly, just make
sure they roughly match their classical equivalents in the \sphinxcode{.prm} file
in terms of chemical species, hybridisation (sp2, sp3, etc.) and
connectivity. What will only matter will be their polarisabilities (for
correct Thole damping of induced QM/MM interactions) and classical vdW
parameters (for QM/MM vdW energies (both the repulsive and dispersive
term in TINKTEP1, dispersive term only in TINKTEP2).

An example \sphinxcode{.xyz} file for a water dimer (one water molecule in QM,
one water molecule in MM) could look like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m+mi}{6}
\PYG{l+m+mi}{1}  \PYG{n}{O}      \PYG{l+m+mf}{0.583801}    \PYG{l+m+mf}{0.000000}    \PYG{l+m+mf}{0.759932}    \PYG{l+m+mi}{36}     \PYG{l+m+mi}{2}     \PYG{l+m+mi}{3}
\PYG{l+m+mi}{2}  \PYG{n}{H}      \PYG{l+m+mf}{0.000000}    \PYG{l+m+mf}{0.000000}    \PYG{l+m+mf}{0.000000}    \PYG{l+m+mi}{37}     \PYG{l+m+mi}{1}
\PYG{l+m+mi}{3}  \PYG{n}{H}      \PYG{l+m+mf}{0.000000}    \PYG{l+m+mf}{0.000000}    \PYG{l+m+mf}{1.530090}    \PYG{l+m+mi}{37}     \PYG{l+m+mi}{1}
\PYG{l+m+mi}{4}  \PYG{n}{O}     \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.687305}    \PYG{l+m+mf}{0.000000}    \PYG{l+m+mf}{2.795684}    \PYG{l+m+mi}{36}     \PYG{l+m+mi}{5}     \PYG{l+m+mi}{6}
\PYG{l+m+mi}{5}  \PYG{n}{H}     \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.448269}   \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.763921}    \PYG{l+m+mf}{3.325671}    \PYG{l+m+mi}{37}     \PYG{l+m+mi}{4}
\PYG{l+m+mi}{6}  \PYG{n}{H}     \PYG{o}{\PYGZhy{}}\PYG{l+m+mf}{0.448269}    \PYG{l+m+mf}{0.763921}    \PYG{l+m+mf}{3.325671}    \PYG{l+m+mi}{37}     \PYG{l+m+mi}{4}
\end{sphinxVerbatim}

In the above 36 and 37 are atom types as defined in \sphinxcode{amoeba09.prm},
and the last two colums define connectivity. Do not worry about the
absolute positioning of the molecule (if it crosses zero in any of the
directions) \textendash{} TINKER will work in OBC mode and will not attempt to wrap
your atoms back to the simulation cell, because there is none. ONETEP
will work with a suitably translated version of the molecule anyway.


\subsubsection{Input \sphinxstyleliteralintitle{.tag} file}
\label{\detokenize{tinktep:input-tag-file}}
Now we need to designate each atom as part of the QM subsystem or the MM
subsystem. This is done via a \sphinxcode{.tag} file. This file should contain
two or three lines. The first line specifies the indices of atoms
belonging to the QM subsystem. The second line specifies the indices of
atoms belonging to the MM subsystem, like this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m+mi}{1} \PYG{l+m+mi}{2} \PYG{l+m+mi}{3}
\PYG{l+m+mi}{4} \PYG{l+m+mi}{5} \PYG{l+m+mi}{6}
\end{sphinxVerbatim}

The above assigns the first water molecule to the QM subsystem, and the
second water molecule to the MM subsystem. In the \sphinxcode{.tag} file, all
atoms must be accounted for. If you want TINKTEP to ignore some atoms
(say, you have \sphinxcode{.xyz} file of a large system and want to discard some
of it), put their indices in the third line. Normally you would simply
omit the third line. It is not permitted for covalent bonds to span the
QM/MM interface, and TINKTEP will refuse to proceed if it detects this.
For instance this:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+m+mi}{1} \PYG{l+m+mi}{2}
\PYG{l+m+mi}{3} \PYG{l+m+mi}{4} \PYG{l+m+mi}{5} \PYG{l+m+mi}{6}
\end{sphinxVerbatim}

would not be a valid \sphinxcode{.tag} file.

If you want \sphinxstyleemphasis{no} atoms in the QM subsystem (for a purely MM calculation)
or the MM subsystem (for a purely QM calculation), put \sphinxcode{-1} in the
corresponding line, rather than leaving it blank.

Do not put any comments or additional information in the \sphinxcode{.tag} file,
that would make it misformatted.

Rename your \sphinxcode{.tag} file to use the same base name as the \sphinxcode{.xyz} file
(say, \sphinxcode{my\_molecule.tag} and \sphinxcode{my\_molecule.xyz}).


\subsubsection{Input \sphinxstyleliteralintitle{.key} file}
\label{\detokenize{tinktep:input-key-file}}
Create a \sphinxcode{.key} file with the same base name as the \sphinxcode{.xyz} and
\sphinxcode{.tag} files, and with the following contents:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{digits} \PYG{l+m+mi}{9}
\PYG{n}{parameters} \PYG{n}{amoeba09}
\end{sphinxVerbatim}

The line with \sphinxcode{digits 9} is necessary to force TINKER to use extra
precision in its outputs. The second line specifies the MM parameter
file for TINKER. Adjust it if you want to use a file different from
\sphinxcode{amoeba09.prm}.


\subsubsection{Input \sphinxstyleliteralintitle{.dat.template} file}
\label{\detokenize{tinktep:input-dat-template-file}}
Create a \sphinxcode{.dat.template} file with the same base name as the \sphinxcode{.xyz},
\sphinxcode{.tag} and \sphinxcode{.key} files. Populate this file with the keywords you
want to be passed to ONETEP. Essentially, this file will be slightly
modified by TINKTEP (specifically by \sphinxcode{qm\_xyz\_to\_dat}) and will become
the \sphinxcode{.dat} that ONETEP will read. The modifications undertaken by
TINKTEP are:
\begin{itemize}
\item {} 
\sphinxcode{pol\_emb\_pot\_filename} will be added %
\begin{footnote}[1]\sphinxAtStartFootnote
Except for purely QM calculations.
%
\end{footnote} to instruct ONETEP to
perform a QM/MM calculation and inform it about the name of the file
used for communicating between ONETEP and TINKER.

\item {} 
\sphinxcode{pol\_emb\_polscal} will be set accordingly if \sphinxcode{qm\_mm\_polscal} was
set in \sphinxcode{tinktep.config}.

\item {} 
\sphinxcode{pol\_emb\_thole\_a} will be set accordingly if \sphinxcode{qm\_mm\_thole\_a} was
set in \sphinxcode{tinktep.config}.

\item {} 
\sphinxcode{pol\_emb\_fixed\_charge T} will be added if the MM force field is
\sphinxstyleemphasis{not} polarisable (e.g. GAFF), to inform ONETEP about this fact.

\item {} 
A \sphinxcode{\%block positions\_abs} will be added, containing the species and
positions of QM atoms inferred from the \sphinxcode{.xyz} and \sphinxcode{.tag} files,
suitably translated.

\item {} 
If \sphinxcode{tinktep.config} specified \sphinxcode{qm\_thole\_polarisability}, a
\sphinxcode{\%block thole\_polarisabilities} will be added, containing the Thole
polarisabilities of QM atoms inferred from the \sphinxcode{.prm} and \sphinxcode{.tag}
files.

\item {} 
If the scenario of a purely QM calculation with classical atoms
(“sparkles”) has been selected by specifying \sphinxcode{classical\_atoms} in
\sphinxcode{tinktep.config}, a \sphinxcode{\%block classical\_info} will be added,
containing the species and positions of MM atoms inferred from the
\sphinxcode{.xyz} and \sphinxcode{.tag} files, suitably translated.

\item {} 
If the \sphinxcode{.xyz} file contained a bounding box (for PBC calculations),
a suitable \sphinxcode{\%block lattice\_cart} will be added to match the MM box
size. PBCs are not supported yet, do not rely on this functionality.

\end{itemize}

Basically, what you put in the \sphinxcode{.dat.template} file should look like a
normal ONETEP \sphinxcode{.dat} file, \sphinxstyleemphasis{except for} the positions of atoms. Do not
attempt to create a \sphinxcode{.dat} file on your own, leave it to TINKTEP to
create it automatically when it is run. For instance, for our water
dimer example you could use this bare-bones \sphinxcode{.dat.template} file:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
! \PYGZhy{}\PYGZhy{}\PYGZhy{} usual ONETEP keywords \PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYGZpc{}block species\PYGZus{}atomic\PYGZus{}set
H  \PYGZdq{}SOLVE\PYGZdq{}
O  \PYGZdq{}SOLVE\PYGZdq{}
\PYGZpc{}endblock species\PYGZus{}atomic\PYGZus{}set

\PYGZpc{}block species
H  H 1 1 7.0
O  O 8 4 7.0
\PYGZpc{}endblock species

\PYGZpc{}block species\PYGZus{}pot
H  \PYGZsq{}H\PYGZus{}04.recpot\PYGZsq{}
O  \PYGZsq{}O\PYGZus{}02.recpot\PYGZsq{}
\PYGZpc{}endblock species\PYGZus{}pot

\PYGZpc{}block lattice\PYGZus{}cart
30.0  0.0  0.0
 0.0 30.0  0.0
 0.0  0.0 30.0
\PYGZpc{}endblock lattice\PYGZus{}cart

cutoff\PYGZus{}energy 1000 eV
charge 0
xc\PYGZus{}functional PBE
dispersion 1

! \PYGZhy{}\PYGZhy{}\PYGZhy{} cutoff Coulomb to enforce OBCs in ONETEP \PYGZhy{}\PYGZhy{}\PYGZhy{}
coulomb\PYGZus{}cutoff\PYGZus{}type SPHERE
coulomb\PYGZus{}cutoff\PYGZus{}radius 40.0 bohr
coulomb\PYGZus{}cutoff\PYGZus{}write\PYGZus{}int F

! \PYGZhy{}\PYGZhy{}\PYGZhy{} DMA setup, needed for QM/MM. Consult DMA manual for details \PYGZhy{}\PYGZhy{}\PYGZhy{}
\PYGZpc{}block swri
  for\PYGZus{}dma 1 12 V 12 12 W
\PYGZpc{}endblock swri

\PYGZpc{}block species\PYGZus{}swri\PYGZhy{}for\PYGZus{}dma
H
O
\PYGZpc{}endblock species\PYGZus{}swri\PYGZhy{}for\PYGZus{}dma

dma\PYGZus{}calculate T
dma\PYGZus{}use\PYGZus{}ri for\PYGZus{}dma
dma\PYGZus{}max\PYGZus{}l 1
dma\PYGZus{}max\PYGZus{}q 12
dma\PYGZus{}metric ELECTROSTATIC
dma\PYGZus{}bessel\PYGZus{}averaging T
dma\PYGZus{}scale\PYGZus{}charge F

! \PYGZhy{}\PYGZhy{}\PYGZhy{} Polarisable embedding, needed for QM/MM. See further text. \PYGZhy{}\PYGZhy{}\PYGZhy{}
pol\PYGZus{}emb\PYGZus{}dma\PYGZus{}min\PYGZus{}l 0
pol\PYGZus{}emb\PYGZus{}dma\PYGZus{}max\PYGZus{}l 1
pol\PYGZus{}emb\PYGZus{}mpole\PYGZus{}exclusion\PYGZus{}radius 1.00 bohr
pol\PYGZus{}emb\PYGZus{}repulsive\PYGZus{}mm\PYGZus{}pot\PYGZus{}cutoff 10.0 bohr

\PYGZpc{}block mm\PYGZus{}rep\PYGZus{}params
H   35 2.400 ! follows TINKTEP\PYGZhy{}2 paper
O  550 1.580 ! follows TINKTEP\PYGZhy{}2 paper
\PYGZpc{}endblock mm\PYGZus{}rep\PYGZus{}params
\end{sphinxVerbatim}


\subsubsection{TINKER’s \sphinxstyleliteralintitle{.prm} file}
\label{\detokenize{tinktep:tinkers-prm-file}}
Copy the \sphinxcode{.prm} file of your choice (typically \sphinxcode{amoeba09.prm}) to
the same directory where you put the \sphinxcode{.xyz}, \sphinxcode{.tag}, \sphinxcode{.key} and
\sphinxcode{.dat.template} files. Do not rename it. Ensure its basename is
reflected in the \sphinxcode{parameters} keyword in the \sphinxcode{.key file}.


\subsubsection{\sphinxstyleliteralintitle{tinktep.config} file}
\label{\detokenize{tinktep:tinktep-config-file}}
This is the main file for controlling the QM/MM calculation. Its name is
fixed, do not change it. Here’s an example suitable for our water dimer,
using the TINKTEP2 model:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{jobname} \PYG{n}{water\PYGZus{}dimer}

\PYG{c+c1}{\PYGZsh{} *** Computational environment set\PYGZhy{}up ***}
\PYG{n}{tinker\PYGZus{}nthreads} \PYG{l+m+mi}{8}
\PYG{n}{onetep\PYGZus{}nranks} \PYG{l+m+mi}{2}
\PYG{n}{onetep\PYGZus{}nthreads} \PYG{l+m+mi}{8}
\PYG{n}{onetep\PYGZus{}executable} \PYG{o}{.}\PYG{o}{/}\PYG{n}{onetep}\PYG{o}{.}\PYG{n}{RH7}
\PYG{n}{mpirun\PYGZus{}executable} \PYG{n}{mpirun}

\PYG{c+c1}{\PYGZsh{} *** Nuts and bolts of the QM/MM interface ***}
\PYG{n}{qm\PYGZus{}mm\PYGZus{}polscal} \PYG{l+m+mf}{6.0}
\PYG{n}{qm\PYGZus{}polarisability}
\PYG{n}{qm\PYGZus{}thole\PYGZus{}polarisability}
\PYG{n}{renumber\PYGZus{}offset} \PYG{l+m+mi}{500}

\PYG{c+c1}{\PYGZsh{} *** Physics ***}

\PYG{c+c1}{\PYGZsh{} Undamped fixed, permanent multipoles using the full density representation,}
\PYG{c+c1}{\PYGZsh{} and Thole\PYGZhy{}damped induced dipoles using the QM* representation. MM repulsive potential.}
\PYG{n}{onetep\PYGZus{}perm\PYGZus{}mpoles}     \PYG{n}{perm\PYGZus{}fix\PYGZus{}rep} \PYG{n}{potential\PYGZus{}coulombic\PYGZus{}smeared} \PYG{n}{energy\PYGZus{}from\PYGZus{}potential}
\PYG{n}{onetep\PYGZus{}induced\PYGZus{}dipoles} \PYG{n}{ind\PYGZus{}qmstar}   \PYG{n}{potential\PYGZus{}thole\PYGZus{}damped}      \PYG{n}{energy\PYGZus{}from\PYGZus{}potential}

\PYG{c+c1}{\PYGZsh{} TINKER handles all bonded (valence) terms between MM atoms.}
\PYG{n}{tinker\PYGZus{}bond\PYGZus{}energy} \PYG{l+m+mi}{1}
\PYG{n}{tinker\PYGZus{}angle\PYGZus{}energy} \PYG{l+m+mi}{1}
\PYG{n}{tinker\PYGZus{}ureybrad\PYGZus{}energy} \PYG{l+m+mi}{1}

\PYG{c+c1}{\PYGZsh{} TINKER handles MM electrostatics.}
\PYG{n}{tinker\PYGZus{}mm\PYGZus{}perm\PYGZus{}energy} \PYG{l+m+mi}{1}
\PYG{n}{tinker\PYGZus{}mm\PYGZus{}pol\PYGZus{}energy} \PYG{l+m+mi}{1}

\PYG{c+c1}{\PYGZsh{} ONETEP handles QM/MM electrostatics.}
\PYG{n}{tinker\PYGZus{}qm\PYGZus{}mm\PYGZus{}perm\PYGZus{}energy} \PYG{l+m+mi}{0}
\PYG{n}{tinker\PYGZus{}qm\PYGZus{}mm\PYGZus{}pol\PYGZus{}energy} \PYG{l+m+mi}{0}

\PYG{c+c1}{\PYGZsh{} TINKER handles van der Waals for MM, and only the dispersive term for QM/MM.}
\PYG{n}{tinker\PYGZus{}mm\PYGZus{}vdw\PYGZus{}energy} \PYG{l+m+mi}{1}
\PYG{n}{tinker\PYGZus{}qm\PYGZus{}mm\PYGZus{}vdw\PYGZus{}energy} \PYG{l+m+mi}{2}
\end{sphinxVerbatim}

All \sphinxcode{tinktep.config} keywords will be described later.


\subsection{Running a QM/MM calculation}
\label{\detokenize{tinktep:running-a-qm-mm-calculation}}
Once you have all input files in place, simply type \sphinxcode{tinktep} to run
the QM/MM calculation. Expect the following to happen:
\begin{enumerate}
\item {} 
\sphinxcode{xyz\_split} will be run to split your \sphinxcode{.xyz} file into a
\sphinxcode{qm.xyz} and a \sphinxcode{mm.xyz} file, based on the contents of the
\sphinxcode{.tag} file.

\item {} 
\sphinxcode{qm\_xyz\_to\_dat} will be run to build a ONETEP \sphinxcode{.dat} file from
the \sphinxcode{.dat.template} file and the \sphinxcode{qm.xyz} file, using information
from the \sphinxcode{.prm} file.

\item {} 
A pair of FIFOs (\sphinxcode{\$QM2MM.lock} and \sphinxcode{\$MM2QM.lock}) will be
created. These will be used for interprocess communication (ONETEP to
TINKTEP and TINKTEP to ONETEP).

\item {} 
ONETEP will be started in the background (via \sphinxcode{mpirun} or
equivalent).

\item {} 
A watchdog process will be started in the background. It will keep an
eye on the \sphinxcode{mpirun} process that launched ONETEP and on ONETEP’s
\sphinxcode{.err} and \sphinxcode{.error\_message} files. It will attempt to clean up
gracefully if it decides that ONETEP crashed or was killed.

\item {} 
{[}scf{]}TINKTEP will block until it ONETEP reaches a point where total
energy needs to be evaluated. Then it will resume.

\item {} 
TINKTEP will read the \sphinxcode{.gdma\_like.txt} file produced by ONETEP.
This file contains the multipole representation of the QM subsystem.
It will run TINKER’s \sphinxcode{poledit} to process these multipoles.

\item {} 
\sphinxcode{xyz\_process} will be run to process the \sphinxcode{qm.xyz} and \sphinxcode{mm.xyz}
files to a form digestible by TINKER (\sphinxcode{qm\_mm.xyz} file). This is
mostly about renumbering the atom types in the QM subsystem so that
they do not clash with the types in the \sphinxcode{.prm} file.

\item {} 
\sphinxcode{key\_process} will be run to prepare a suitable \sphinxcode{.key} file for
TINKER (\sphinxcode{qm\_mm.key}). This takes the contents of the original
\sphinxcode{.key} file, and modifies it accordingly so that it is digestible
by TINKER. For instance dummy bond and angle parameters will be
supplied for the QM atoms, QM sites and multipoles will be
renumbered, polarisabilities of QM atoms will be defined, the QM
subsystem will be made inactive and “only formally polarisable”,
etc..

\item {} 
TINKER (specifically \sphinxcode{analyze} and \sphinxcode{dynamic}) will be run to
obtain the polarisation response of the MM subsystem, all of MM
electrostatics, QM/MM electrostatics, QM/MM van der Waals energies,
MM van der Waals and MM bonded interactions. Not all of these terms
will necessarily be used in the final energy expression.

\item {} 
\sphinxcode{mpoles\_process} will be run to process TINKER’s multipoles and
energy terms into a format understandable by ONETEP
(\sphinxcode{.mpoles\_for\_onetep} file).

\item {} 
ONETEP will resume, after having been pinged via \sphinxcode{\$MM2QM.lock}.

\item {} 
If SCF convergence has been reached, TINKTEP will terminate with a
short summary. If not, control will transfer to step {[}scf{]}.

\end{enumerate}

All in all, the TINKTEP script drives both ONETEP and TINKER. ONETEP is
executed once, in the background, and is resumed when necessary. TINKER
is started each time ONETEP performs an energy evaluation. TINKER, which
does not support MPI parallelism, is run on the local node (possibly
using OMP threads). ONETEP is started via \sphinxcode{mpirun} or equivalent, and
it’s the user’s responsibility to set the parallel environment in such a
way, that ONETEP gets started on the appropriate nodes (e.g. via a
hostfile).

All ONETEP output goes to a \sphinxcode{qm\_mm.out} file with the same base name
as the input. All ONETEP error messages go to a \sphinxcode{qm\_mm.err} file with
the same base name as the input. TINKTEP’s output goes to \sphinxcode{stdout}
and \sphinxcode{stderr}. TINKTEP attempts to detect a large variety of error
conditions and should at least provide an informative error message if
something goes wrong. When diagnosing errors, examine \sphinxcode{stderr},
ONETEP’s \sphinxcode{qm\_mm.err} file, ONETEP’s \sphinxcode{qm\_mm.error\_message} file
(if any), and see if there’s a file called \sphinxcode{error\_message} (with no
base name) \textendash{} it is created when more exotic error conditions occur.

All intermediate files are automatically moved to a subdirectory called
\sphinxcode{intermediate} (at each SCF iteration), they are tagged with an SCF
iteration (energy evaluation) number. It is safe to delete this
directory after the calculation has run, it’s mostly useful when
diagnosing problems.


\subsection{Output from a QM/MM calculation}
\label{\detokenize{tinktep:output-from-a-qm-mm-calculation}}
Your \sphinxcode{qm\_mm.out} file will contain usual ONETEP output, interspersed
with a lot of informative messages from DMA and polarisable embedding.
Every time the energy is evaluated, you will get a detailed breakdown of
energies associated with the QM/MM interface. Here’s what it looks like:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZbs{}
\textbar{} Polarisable embedding potential from water\PYGZus{}dimer\PYGZus{}mm.mpoles\PYGZus{}for\PYGZus{}onetep        \textbar{}
\textbar{} Multipole set \PYGZdq{}perm\PYGZus{}fix\PYGZus{}rep\PYGZdq{}: 6 sites.                                       \textbar{}
\textbar{} Multipole set \PYGZdq{}ind\PYGZus{}qmstar\PYGZdq{}: 6 sites.                                         \textbar{}
\textbar{} All in all 12 sites, and 11 external energy terms (out of which 3 \PYGZsh{}ignored). \textbar{}
\textbar{} Energy term                              Energy      Source   Included?      \textbar{}
\textbar{} \PYGZhy{} MMv bond stretch                   0.000013814 Ha  TINKER      YES         \textbar{}
\textbar{} \PYGZhy{} MMv angle bend                     0.000229041 Ha  TINKER      YES         \textbar{}
\textbar{} \PYGZhy{} MMv Urey\PYGZhy{}Bradley                  \PYGZhy{}0.000000274 Ha  TINKER      YES         \textbar{}
\textbar{} \PYGZhy{} \PYGZsh{}QM/MM perm mpole                 \PYGZhy{}0.032818501 Ha  TINKER       NO         \textbar{}
\textbar{} \PYGZhy{} \PYGZsh{}QM/MM polarisation               \PYGZhy{}0.000794393 Ha  TINKER       NO         \textbar{}
\textbar{} \PYGZhy{} MM perm mpole                      0.000000000 Ha  TINKER      YES         \textbar{}
\textbar{} \PYGZhy{} MM+ polarisation                   0.000000000 Ha  TINKER      YES         \textbar{}
\textbar{} \PYGZhy{} \PYGZsh{}QM/MM vdW\PYGZhy{}rep                     0.050008920 Ha  TINKER       NO         \textbar{}
\textbar{} \PYGZhy{} QM/MM vdW\PYGZhy{}disp                    \PYGZhy{}0.013332666 Ha  TINKER      YES         \textbar{}
\textbar{} \PYGZhy{} MM vdW\PYGZhy{}rep                         0.000000000 Ha  TINKER      YES         \textbar{}
\textbar{} \PYGZhy{} MM vdW\PYGZhy{}disp                        0.000000000 Ha  TINKER      YES         \textbar{}
\textbar{} \PYGZhy{} QM elec \PYGZlt{}\PYGZhy{}\PYGZgt{} rep MM perm\PYGZus{}fix        0.033334141 Ha  ONETEP   REPULS  P Fr   \textbar{}
\textbar{} \PYGZhy{} QM elec \PYGZlt{}\PYGZhy{}\PYGZgt{} MM perm\PYGZus{}fix\PYGZus{}rep        0.229940160 Ha  ONETEP   COUL\PYGZhy{}S  P Fr   \textbar{}
\textbar{} \PYGZhy{} QM core \PYGZlt{}\PYGZhy{}\PYGZgt{} MM perm\PYGZus{}fix\PYGZus{}rep       \PYGZhy{}0.263586238 Ha  ONETEP   COUL\PYGZhy{}S  P FR   \textbar{}
\textbar{} \PYGZhy{} QM* elec \PYGZlt{}\PYGZhy{}\PYGZgt{} MM ind\PYGZus{}qmstar         0.014117659 Ha  ONETEP    THOLE  I*     \textbar{}
\textbar{} \PYGZhy{} QM core \PYGZlt{}\PYGZhy{}\PYGZgt{} MM ind\PYGZus{}qmstar         \PYGZhy{}0.014912052 Ha  ONETEP    THOLE  I*     \textbar{}
\textbar{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\textbar{}
\textbar{}                      External \textbar{}           Internal \textbar{}         Difference      \textbar{}
\textbar{} Permanent:       \PYGZhy{}0.032818501 \textbar{}       \PYGZhy{}0.033646079 \textbar{}     0.000827577479 (Ha) \textbar{}
\textbar{} Induced:         \PYGZhy{}0.000794393 \textbar{}       \PYGZhy{}0.000794393 \textbar{}    \PYGZhy{}0.000000000001 (Ha) \textbar{}
\textbar{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\textbar{}
\textbar{} Perm embed. potential  min: \PYGZhy{}0.3743E+01  max:  0.6338E+01  norm:  0.1776E\PYGZhy{}01 \textbar{}
\PYGZbs{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}\PYGZti{}/
\end{sphinxVerbatim}

From the above example you can infer the following:
\begin{enumerate}
\item {} 
The file from which ONETEP reads the details of the MM embedding is
\sphinxcode{water\_dimer\_mm.mpoles\_for\_onetep}.

\item {} 
There are two sets of multipoles, with 6 sites each. The first set
entails permanent (\sphinxcode{perm}) (as in not induced), fixed (\sphinxcode{fix}) (as
in not variable in time) multipoles that generate a repulsive
(\sphinxcode{rep}) potential. The second set entails induced (\sphinxcode{ind})
multipoles, which interact not with ONETEP’s full electronic
density, but with the QM\(^*\) description (\sphinxcode{qmstar}). You
probably expected 3, not 6 sites, but the \sphinxcode{.mpoles\_for\_onetep} file
also includes QM sites in addition to MM sites. The QM sites are
tagged with “\#” and subsequently ignored.

\item {} 
There are 11 energy terms coming from TINKER, but 3 of these will be
ignored by ONETEP in accordance with the user’s wishes. The ignored
terms are prefixed by “\#” and have a “NO” in the “Included?” column.
The ignored terms in this case are:
\begin{itemize}
\item {} 
QM interaction with permanent MM multipoles as calculated by
TINKER. This is because we instead use the full density QM
representation (as calculated by ONETEP) for this term, excluding
TINKER’s approximate idea on purpose (compare
\sphinxcode{tinker\_qm\_mm\_perm\_energy 0} earlier).

\item {} 
QM interaction with induced MM multipoles as calculated by TINKER.
This is because we instead use the value calculated by ONETEP for
this term, even though the two should be (and are) identical,
excluding TINKER’s value on purpose (compare
\sphinxcode{tinker\_qm\_mm\_pol\_energy 0} earlier).

\item {} 
Repulsive part of QM/MM van der Waals interaction as calculated by
TINKER. This is because we instead use the repulsive potential
model introduced in TINKTEP2, calculated by ONETEP for this term,
excluding TINKER’s classical value on purpose (compare
\sphinxcode{tinker\_qm\_mm\_vdw\_energy 2} earlier).

\end{itemize}

The other terms coming from TINKER are included. These are: MM
valence terms (\sphinxcode{MMv}): bond, angle and Urey-Bradley, MM-MM
permanent multipole interactions (zero in this case, as there is only
one molecule in MM, and AMOEBA masked the MM permanent interactions
within the water molecule), MM polarisation (“+” serves as a reminder
that this polarisation is not strictly only due to MM, because of
non-additivity) (again zero in this case, because of masking),
dispersive part of QM/MM van der Waals interactions, and MM/MM vdW
terms (repulsion and dispersion) (also zero, since there is only one
molecule in MM).

\item {} 
There are 5 energy terms coming from ONETEP (denoted by “ONETEP” in
the “Source” column). These are
\begin{itemize}
\item {} 
The interaction of QM electrons with the MM repulsive potential
attached to one of the multipole sets (\sphinxcode{REPULS}).

\item {} 
The interaction of QM electrons with the permanent MM multipoles,
treated Coulombically with smearing (\sphinxcode{COUL-S}).

\item {} 
The interaction of QM ionic cores with the permanent MM
multipoles, treated Coulombically with smearing (\sphinxcode{COUL-S}).

\item {} 
The interaction of QM\(^*\) electrons (i.e. electronic
multipoles) with the induced MM multipoles, treated using Thole
damping (\sphinxcode{THOLE}).

\item {} 
The interaction of QM ionic cores (i.e. ionic charges) with the
induced MM multipoles, treated using Thole damping (\sphinxcode{THOLE}).

\end{itemize}

\item {} 
The symbols to the right of the table inform us about the assumptions
ONETEP makes about some energy terms:
\begin{itemize}
\item {} 
Column 1: \sphinxcode{P} \textendash{} MM multipole set is permanent, or \sphinxcode{I} \textendash{} MM
multipole set is induced. This affects energy expressions \textendash{}
induced multipoles require work to assemble,
cf. Ref. {[}Dziedzic2016{]}.

\item {} 
Column 2: \sphinxcode{*} \textendash{} calculation uses the QM\(^*\)
representation of the density, or (blank) \textendash{} calculation uses the
full density.

\item {} 
Column 3: \sphinxcode{F} \textendash{} MM multipole set is fixed (its value is
time-independent), so its electrostatic potential can be stored
and reused, or (blank) \textendash{} MM multipole set is not fixed (then its
electrostatic potential has to be recalculated every time).

\item {} 
Column 4: \sphinxcode{1} \textendash{} Energy term has been calculated for the first
time, and will either be reused later (e.g. for QM cores
interacting with permanent MM multipoles) or at least the MM
potential will be reused (e.g. for QM electrons interacting with
permanent MM multipoles), or \sphinxcode{R} \textendash{} energy term has just been
reused, or \sphinxcode{r} \textendash{} the MM potential has been reused, but the
energy has been recalculated, or (blank) \textendash{} neither of the above.

\item {} 
Column 5: \sphinxcode{S} \textendash{} \sphinxcode{dma\_multipole\_scaling} affected this energy
term, or \sphinxcode{s} \textendash{} \sphinxcode{pol\_emb\_perm\_scaling} affected this energy
term. These are expert directives, do not worry about them.

\end{itemize}

\item {} 
This is followed by a summary of QM/MM permanent and QM/MM induced
electrostatics. “External” is TINKER’s idea of these energy terms,
“Internal” is ONETEP’s idea, “Difference” is the difference between
the two. Unless you do something very exotic, like ignoring
polarisation, the row with “Induced” should always match extremely
well, because both ONETEP and TINKER use the same model (QM:math:\sphinxtitleref{\textasciicircum{}*}
interacting with MM dipoles), and their calculations should match (if
not, this indicates a bug or a set-up problem, and ONETEP will
abort). Unless you do something exotic, like using the QM\(^*\)
for permanent interactions, the row with “Permanent” will not match,
because TINKER uses the QM\(^{*}\) model and thus suffers from
charge penetration, while ONETEP uses the full density for permanent
interactions, arriving at the “right” result. Here, “Difference” is a
good estimate of QM/MM charge penetration error.

\item {} 
The last row gives some statistics about the permanent MM multipole
potential in which QM electrons are embedded.

\end{enumerate}


\subsection{\sphinxstyleliteralintitle{tinktep.config} directives}
\label{\detokenize{tinktep:tinktep-config-directives}}
Here is a list of directives understood by TINKTEP that you can put in
the \sphinxcode{tinktep.config} file. Make sure you spell these right, unlike
ONETEP, TINKTEP \sphinxstylestrong{silently ignores} directives it does not recognise.
You can use “\#” to denote comment lines. These will be ignored.


\subsubsection{Environment set-up}
\label{\detokenize{tinktep:environment-set-up}}
\sphinxcode{jobname (string)} \sphinxstylestrong{{[}mandatory, basic{]}} \textendash{} specifies the base name
for input (\sphinxcode{.xyz}, \sphinxcode{.tag}, \sphinxcode{.key}, \sphinxcode{.dat.template}), files.
Example: \sphinxcode{jobname qm\_tryptophan\_in\_40\_mm\_waters}.

\sphinxcode{onetep\_executable (string)} \sphinxstylestrong{{[}mandatory, basic{]}} \textendash{} specifies the
name of the ONETEP executable that TINKTEP will pass to \sphinxcode{mpirun} (or
equivalent). This file must be user-executable.

\sphinxcode{onetep\_nranks (integer)} \sphinxstylestrong{{[}mandatory, basic{]}} \textendash{} specifies the
number of MPI ranks that TINKTEP will tell \sphinxcode{mpirun} (or equivalent) to
start ONETEP on.

\sphinxcode{onetep\_nthreads (integer)} \sphinxstylestrong{{[}mandatory, basic{]}} \textendash{} specifies the
number of OMP threads that TINKTEP will tell ONETEP to use (by setting
\sphinxcode{OMP\_NUM\_THREADS}. You can always override this with specific ONETEP
thread keywords in the \sphinxcode{.dat.template} file.

\sphinxcode{onetep\_args (string)} \sphinxstylestrong{{[}optional, expert{]}} \textendash{} specifies additional
arguments that you might want to pass to ONETEP. These will go between
the ONETEP executable and the ONETEP input file. This only makes sense
if your \sphinxcode{onetep\_executable} actually points to a wrapper script that
will know what to do with these arguments.

\sphinxcode{tinker\_nthreads (integer)} \sphinxstylestrong{{[}optional, intermediate{]}} \textendash{} specifies
the number of OMP threads that TINKTEP will tell TINKER to use (by
adding a keyword to \sphinxcode{qm\_mm.key}. If left unspecified, this will be
left at TINKER’s discretion. Caveat: TINKER sometimes carelessly
outputs to \sphinxcode{stdout} from OMP regions, which can cause a mess. If
TINKTEP complains that it cannot parse TINKER’s output, try setting
this to 1 to disable OMP in TINKER.

\sphinxcode{mpirun\_executable (string)} \sphinxstylestrong{{[}mandatory, basic{]}} \textendash{} specifies the
name of the \sphinxcode{mpirun} executable that TINKTEP will use to launch
ONETEP. Set this to \sphinxcode{mpirun}, unless your environment uses something
fancier like \sphinxcode{aprun}, or you want to specify a full path to select a
specific \sphinxcode{mpirun} executable.

\sphinxcode{mpirun\_args (string)} \sphinxstylestrong{{[}optional, intermediate{]}} \textendash{} specifies
additional arguments that you might want to pass to \sphinxcode{mpirun}. These
will go between the \sphinxcode{mpirun} executable and \sphinxcode{-np \textless{}onetep\_nranks\textgreater{}}.
Can be useful for passing a hostfile name.

\sphinxcode{watchdog\_unfazed\_by\_stderr (no args)} \sphinxstylestrong{{[}optional, intermediate{]}} \textendash{}
tells TINKTEP’s watchdog not to keep an eye on ONETEP’s \sphinxcode{.err}
file. Normally any output to this file is an indication that something
went wrong, and the watchdog then initiates cleanup. In some
environments you can get innocuous messages written to a job’s \sphinxcode{.err}
file, e.g. warnings from MPI or the transport layer. Use this directive
to immunize the watchdog against these.


\subsubsection{QM/MM set-up: basic}
\label{\detokenize{tinktep:qm-mm-set-up-basic}}
\sphinxcode{onetep\_perm\_mpoles (set\_name) (potential\_mode) (energy\_mode)}
\sphinxstylestrong{{[}mandatory, basic{]}} \textendash{} specifies the treatment of permanent MM
multipoles inside ONETEP. All three arguments are strings and are
mandatory. These are extremely important and have to be discussed in
detail.
\begin{itemize}
\item {} 
\sphinxcode{set\_name} \textendash{} a short, descriptive name that will identify the
permanent MM multipole set in ONETEP. Crucially, this name will also
be parsed by ONETEP to infer the properties of this set. Thus,
certain tokens (substrings) carry very specific meaning in the
context of the name. These are:
\begin{itemize}
\item {} 
\sphinxcode{perm} \textendash{} the set is permanent (as in “not induced”). This
affects energy expressions \textendash{} induced multipoles require work to
assemble, permanent sets do not,
cf. Ref. {[}Dziedzic2016{]}.

\item {} 
\sphinxcode{ind} \textendash{} the set is induced (as in “not permanent”). This affects
energy expressions \textendash{} induced multipoles require work to assemble,
permanent sets do not, cf. Ref. {[}Dziedzic2016{]}.

\item {} 
\sphinxcode{fix} \textendash{} the set is fixed (as in “not changing in time”). This
does not mean “not moving through space” (currently \sphinxstyleemphasis{all} MM
multipoles are presumed not to be moving through space).
Calculations on fixed sets will be optimised to re-use
electrostatic potentials or entire energy terms.

\item {} 
\sphinxcode{qmstar} \textendash{} the set uses the QM\(^*\) representation and
not the full QM density when interacting with the QM subsystem. If
absent, the full QM density is used by default.

\item {} 
\sphinxcode{rep} \textendash{} the set generates an MM repulsive potential (for the
TINKTEP2 model). If absent, no MM repulsive potential will be
generated by the set. Note: If \sphinxcode{rep} is present for more than
one set, only the last set set will generate the MM repulsive
potential.

\end{itemize}

\item {} 
\sphinxcode{potential\_mode} \textendash{} describes how ONETEP generates the electrostatic
potential coming from this multipole set. Four options are possible:
\begin{itemize}
\item {} 
\sphinxcode{potential\_zero} \textendash{} the set does not generate any potential (and
so is essentially ignored).

\item {} 
\sphinxcode{potential\_coulombic\_smeared} \textendash{} the set generates a Coulombic
potential, with a small degree of smearing only very close to the
location of each point multipole \textendash{} this is done to avoid
singularities (cf. \sphinxcode{pol\_emb\_mpole\_exclusion\_radius},
\sphinxcode{polemb\_smearing\_a}).

\item {} 
\sphinxcode{potential\_coulombic\_masked} \textendash{} the set generates a Coulombic
potential, which is, however, masked (zeroed) very close to the
location of each point multipole \textendash{} this is done to avoid
singularities (cf. \sphinxcode{pol\_emb\_mpole\_exclusion\_radius}). This is
not recommended, except for tests, use
\sphinxcode{potential\_coulombic\_smeared} instead.

\item {} 
\sphinxcode{potential\_thole\_damped} \textendash{} the set generates a Thole-damped
potential, mimicking AMOEBA polarisation interactions. Thole
damping is a classical scheme and is designed to be applied to
interactions between two point multipoles. Thus it is best suited
to the QM\(^*\) representation (cf. \sphinxcode{qmstar} above), and
not to interactions between MM point multipoles and the full,
distributed QM density, although this is, in principle, possible.
The magnitude of the damping depends on the polarisabilities of
the two interacting sites. For MM sites the polarisabilities are
determined by the force field (\sphinxcode{.prm} file). For QM\(^*\)
sites the polarisabilities either have to be specified in the
\sphinxcode{.dat.template} file (\sphinxcode{\%block thole\_polarisabilities}), or can
be inferred automatically from the \sphinxcode{.prm} file. The latter
option is preferred, it can be activated via the directive
\sphinxcode{qm\_thole\_polarisability} in \sphinxcode{tinktep.config}. This instructs
TINKTEP (and \sphinxcode{qm\_xyz\_to\_dat} in particular) to add a suitable
\sphinxcode{\%block thole\_polarisabilities} automatically. When an attempt
is made to use Thole damping with a multipole set that does not
specify \sphinxcode{qmstar}, a Thole-damped potential coming from the set
will need to be integrated with the full QM density, and there is
no corresponding polarisability that can be used in the Thole
damping expression. In this unlikely scenario, the value of
\sphinxcode{pol\_emb\_pairwise\_polarisability}, with a unit of bohr, is used
for the Thole variable \(A\) (which is otherwise equal to
\(\sqrt{\alpha_1 \alpha_2}\)). The default value of this
parameter corresponds to the average polarisability of all atom
types in AMOEBA09.

\end{itemize}

\item {} 
\sphinxcode{energy\_mode} \textendash{} describes how ONETEP calculates the electrostatic
energy of this multipole set interacting with the QM subsystem. Two
options are possible:
\begin{itemize}
\item {} 
\sphinxcode{energy\_zero} \textendash{} the set does not contribute to energy (and so is
essentially ignored).

\item {} 
\sphinxcode{energy\_from\_potential} \textendash{} the set’s contribution to energy will
be made consistent with the setting for the potential (see above).

\end{itemize}

Not all combinations of \sphinxcode{potential\_mode} and \sphinxcode{energy\_mode} make
sense. For instance trying to combine \sphinxcode{potential\_coulombic\_smeared}
with \sphinxcode{energy\_zero} will lead to an inconsistency between the
Hamiltonian and the energy expression, breaking LNV and NGWF
convergence. Using \sphinxcode{energy\_from\_potential} is generally the safest
option, as it guarantees consistency.

\end{itemize}

\sphinxcode{onetep\_induced\_dipoles (set\_name) (potential\_mode) (energy\_mode)}
\sphinxstylestrong{{[}mandatory, basic{]}} \textendash{} specifies the treatment of induced MM dipoles
inside ONETEP. The meaning of the arguments is the same as for
\sphinxcode{onetep\_perm\_mpoles} above.

Some typical settings for the above two keywords:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Usual TINKTEP2 set\PYGZhy{}up: Permanent multipoles interact Coulombically with full QM density,}
\PYG{c+c1}{\PYGZsh{}                        induced dipoles interact with QM* via Thole damping,}
\PYG{c+c1}{\PYGZsh{}                        repulsive MM potential in effect (attached to perm. multipoles)}
\PYG{n}{onetep\PYGZus{}perm\PYGZus{}mpoles}      \PYG{n}{perm\PYGZus{}fix\PYGZus{}rep}  \PYG{n}{potential\PYGZus{}coulombic\PYGZus{}smeared}  \PYG{n}{energy\PYGZus{}from\PYGZus{}potential}
\PYG{n}{onetep\PYGZus{}induced\PYGZus{}dipoles}  \PYG{n}{ind\PYGZus{}qmstar}    \PYG{n}{potential\PYGZus{}thole\PYGZus{}damped}       \PYG{n}{energy\PYGZus{}from\PYGZus{}potential}

\PYG{c+c1}{\PYGZsh{} Usual TINKTEP1 set\PYGZhy{}up: Permanent multipoles interact Coulombically with full QM density,}
\PYG{c+c1}{\PYGZsh{}                        induced dipoles interact with QM* via Thole damping,}
\PYG{c+c1}{\PYGZsh{}                        no repulsive MM potential in effect.}
\PYG{n}{onetep\PYGZus{}perm\PYGZus{}mpoles}      \PYG{n}{perm\PYGZus{}fix}      \PYG{n}{potential\PYGZus{}coulombic\PYGZus{}smeared}  \PYG{n}{energy\PYGZus{}from\PYGZus{}potential}
\PYG{n}{onetep\PYGZus{}induced\PYGZus{}dipoles}  \PYG{n}{ind\PYGZus{}qmstar}    \PYG{n}{potential\PYGZus{}thole\PYGZus{}damped}       \PYG{n}{energy\PYGZus{}from\PYGZus{}potential}

\PYG{c+c1}{\PYGZsh{} TINKTEP2 set\PYGZhy{}up for a non\PYGZhy{}polarisable force\PYGZhy{}field (eg. GAFF).}
\PYG{n}{onetep\PYGZus{}perm\PYGZus{}mpoles}      \PYG{n}{perm\PYGZus{}fix\PYGZus{}rep}  \PYG{n}{potential\PYGZus{}coulombic\PYGZus{}smeared}  \PYG{n}{energy\PYGZus{}from\PYGZus{}potential}
\PYG{n}{onetep\PYGZus{}induced\PYGZus{}dipoles}  \PYG{n}{ind\PYGZus{}qmstar}    \PYG{n}{potential\PYGZus{}zero}               \PYG{n}{energy\PYGZus{}from\PYGZus{}potential}

\PYG{c+c1}{\PYGZsh{} TINKTEP2 set\PYGZhy{}up, where both permanent and induced interactions use QM* and Thole damping}
\PYG{n}{onetep\PYGZus{}perm\PYGZus{}mpoles}      \PYG{n}{perm\PYGZus{}fix\PYGZus{}rep\PYGZus{}qmstar}  \PYG{n}{potential\PYGZus{}thole\PYGZus{}damped}  \PYG{n}{energy\PYGZus{}from\PYGZus{}potential}
\PYG{n}{onetep\PYGZus{}induced\PYGZus{}dipoles}  \PYG{n}{ind\PYGZus{}qmstar}           \PYG{n}{potential\PYGZus{}thole\PYGZus{}damped}  \PYG{n}{energy\PYGZus{}from\PYGZus{}potential}
\end{sphinxVerbatim}

\sphinxcode{qm\_thole\_polarisability (no args)} \sphinxstylestrong{{[}optional, basic{]}} \textendash{} asks
TINKTEP to automatically infer the Thole polarisabilities of QM sites
from the \sphinxcode{.prm} file and to automatically add a suitable
\sphinxcode{\%block thole\_polarisabilities} to the \sphinxcode{.dat} file. Strongly
recommended.

\sphinxcode{qm\_polarisability (no args)} \sphinxstylestrong{{[}optional, basic{]}} \textendash{} forces TINKER to
treat QM sites as “formally polarisable”, that is, to take their
polarisabilities into account in Thole damping expressions, but not to
put induced dipoles on them. Treat this directive as mandatory, the
alternative scheme is no longer supported.


\subsubsection{QM/MM set-up: treatment of energy terms}
\label{\detokenize{tinktep:qm-mm-set-up-treatment-of-energy-terms}}
The following directives control how different energy terms generated by
TINKER are taken into account in the QM/MM calculation.

\sphinxcode{tinker\_bond\_energy (0 or 1)} \sphinxstylestrong{{[}optional, intermediate{]}} \textendash{} when
enabled (\sphinxcode{1}), the valence MM term due to bond stretches is included
in the QM/MM energy expression. When omitted, defaults to \sphinxcode{0}. In
typical scenarios you’d want this enabled. Disabling might be necessary
if there are no bonds between MM atoms (e.g. for a noble gas).

\sphinxcode{tinker\_angle\_energy (0 or 1)} \sphinxstylestrong{{[}optional, intermediate{]}} \textendash{} when
enabled (\sphinxcode{1}), the valence MM term due to angle bends is included in
the QM/MM energy expression. When omitted, defaults to \sphinxcode{0}. In typical
scenarios you’d want this enabled. Disabling might be necessary if there
are no angles between MM atoms (e.g. for a noble or diatomic gas).

\sphinxcode{tinker\_ureybrad\_energy (0 or 1)} \sphinxstylestrong{{[}optional, intermediate{]}} \textendash{} when
enabled (\sphinxcode{1}), the valence MM term due to Urey-Bradley interactions is
included in the QM/MM energy expression. When omitted, defaults to
\sphinxcode{0}. In typical scenarios you’d want this enabled. Disabling might be
necessary if there are no Urey-Bradley interactions between MM atoms.

\sphinxcode{tinker\_mm\_perm\_energy (0 or 1)} \sphinxstylestrong{{[}optional, intermediate{]}} \textendash{} when
enabled (\sphinxcode{1}), the electrostatic term due to permanent MM-MM
interactions is included in the QM/MM energy expression. When omitted,
defaults to \sphinxcode{0}. In typical scenarios you’d want this enabled.

\sphinxcode{tinker\_mm\_pol\_energy (0 or 1)} \sphinxstylestrong{{[}optional, intermediate{]}} \textendash{} when
enabled (\sphinxcode{1}), the electrostatic term due to MM-MM polarisation
interactions is included in the QM/MM energy expression. Even though
polarisation interactions are not additive, TINKER formally splits them
\sphinxstyleemphasis{a posteriori} into QM-MM polarisation and MM-MM polarisation, which add
up to total MM polarisation. When omitted, defaults to \sphinxcode{0}. In typical
scenarios you’d want this enabled.

\sphinxcode{tinker\_qm\_mm\_perm\_energy (0 or 1)} \sphinxstylestrong{{[}optional, intermediate{]}} \textendash{}
when enabled (\sphinxcode{1}), the electrostatic term due to interactions between
permanent MM multipoles and QM is included in the QM/MM energy
expression. When omitted, defaults to \sphinxcode{0}. In typical scenarios you’d
want this \sphinxstylestrong{disabled}, because TINKER’s idea of this interaction
suffers from charge-penetration error. This term would then be taken
into account on ONETEP’s side, via an \sphinxcode{energy\_from\_potential}
setting for permanent multipoles (cf. \sphinxcode{onetep\_perm\_mpoles}).

\sphinxcode{tinker\_qm\_mm\_pol\_energy (0 or 1)} \sphinxstylestrong{{[}optional, intermediate{]}} \textendash{} when
enabled (\sphinxcode{1}), the electrostatic term due to QM-MM polarisation
interactions is included in the QM/MM energy expression. Even though
polarisation interactions are not additive, TINKER formally splits them
\sphinxstyleemphasis{a posteriori} into QM-MM polarisation and MM-MM polarisation, which add
up to total MM polarisation. When omitted, defaults to \sphinxcode{0}. In typical
scenarios you’d want this \sphinxstylestrong{disabled}. This term would then be taken
into account on ONETEP’s side, via an \sphinxcode{energy\_from\_potential}
setting for induced dipoles (cf. \sphinxcode{onetep\_induced\_dipoles}). The two
expressions should yield the same result, provided \sphinxcode{qmstar} is used
for \sphinxcode{onetep\_induced\_dipoles}. Having ONETEP calculate this term
permits checking the two results (TINKER’s and ONETEP’s) for
consistency.

\sphinxcode{tinker\_mm\_vdw\_energy (0 or 1)} \sphinxstylestrong{{[}optional, intermediate{]}} \textendash{} when
enabled (\sphinxcode{1}), the van der Waals term due to MM-MM non-bonded
interactions is included in the QM/MM energy expression. When omitted,
defaults to \sphinxcode{0}. In typical scenarios you’d want this enabled.

\sphinxcode{tinker\_mm\_vdw\_energy (0 or 1 or 2 or 3)} \sphinxstylestrong{{[}mandatory,
intermediate{]}} \textendash{} controls if and how the van der Waals term due to
QM-MM non-bonded interactions is included in the QM/MM energy
expression. The following values are possible:
\begin{itemize}
\item {} 
0 \textendash{} omit QM-MM vdW interactions entirely.

\item {} 
1 \textendash{} include QM-MM vdW interactions, both the repulsive and dispersive
term, via classical Halgren potential. Recommended for TINKTEP1
model.

\item {} 
2 \textendash{} include QM-MM vdW interactions, but only the dispersive term, via
classical Halgren potential. Recommended for TINKTEP2 model, where
repulsive QM-MM vdW interactions would be handled via a repulsive MM
potential.

\item {} 
3 \textendash{} include QM-MM vdW interactions, but only the repulsive term, via
classical Halgren potential. Only included for completeness.

\end{itemize}


\subsubsection{QM/MM set-up: details of the interface}
\label{\detokenize{tinktep:qm-mm-set-up-details-of-the-interface}}
The following directives control how the QM/MM interface behaves.

\sphinxcode{qm\_mm\_polscal (real)} \sphinxstylestrong{{[}optional, intermediate{]}} \textendash{} controls scaling
of QM/MM polarisation interactions (introduced in TINKTEP2). Defaults to
no scaling if omitted. The apparent polarisability of QM sites is scaled
(multiplied) by the value of this parameter, thereby increasing damping
if it is greater than 1.0, and attenuating damping (increasing the
strength of polarisation interactions) if it is between 0.0 and 1.0.
Recommended value: 6.0 for TINKTEP2, omit for TINKTEP1.

\sphinxcode{renumber\_offset (integer)} \sphinxstylestrong{{[}mandatory, intermediate{]}} \textendash{} specifies
the value by which atom types for QM atoms are offset from their
original force field counterparts. This is used to avoid clashes between
“fake” QM types presented to TINKER and original atom types. Use a
large, three-digit value, like 500, unless you have good reason for
doing otherwise.

\sphinxcode{coord\_xlat (x) (y) (z)} \sphinxstylestrong{{[}optional, intermediate{]}} \textendash{} specifies the
vector (in bohr) by which all QM atoms are translated in the \sphinxcode{.dat}
file. All arguments are real numbers and are mandatory. Values will be
interpreted as bohr, do not specify any units. This directive becomes
useful when the contents of the \sphinxstyleemphasis{qm.xyz} file are positioned unsuitably
for ONETEP in OBC mode, e.g. leading to NGWFs not fitting in the
simulation cell. In general, TINKER always works with original
(untranslated) coordinates, and ONETEP always sees coordinates
translated by this vector. All \sphinxcode{.xyz} files work with the original
coordinates, the \sphinxcode{.dat} file works with the translated coordinates. If
omitted, this value will be determined automatically: a bounding box
will be calculated for the QM subsystem, and the translation vector will
be such that the centre of the bounding box will coincide with the
centre of the simulation cell. This is handy, but can lead to eggbox
errors when comparing energies between different molecules (as they
might be translated differently). It is advised to set this translation
vector manually, and identically for all molecules whose energies will
be compared.


\subsubsection{QM/MM set-up: expert options}
\label{\detokenize{tinktep:qm-mm-set-up-expert-options}}
\sphinxcode{classical\_atoms (no args)} \sphinxstylestrong{{[}optional, expert{]}} \textendash{} when present,
TINKTEP will add a \sphinxcode{\%block classical\_info} containing the species and
positions of MM atoms inferred from the \sphinxcode{.xyz} and \sphinxcode{.tag} files,
suitably translated, to the \sphinxcode{.dat} file. Charges for the classical
atoms will be extracted from specially crafted comments in the
\sphinxcode{.dat.template} file. This is useful when generating reference
classical embedding (“sparkles”) calculations. You should normally omit
this directive. The format for specifying charges of classical atoms is
as follows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
!\PYGZdl{} classical\PYGZus{}species\PYGZus{}charge H 0.417
!\PYGZdl{} classical\PYGZus{}species\PYGZus{}charge O \PYGZhy{}0.834
\end{sphinxVerbatim}

These lines are formally comments and will be ignored by ONETEP, but
\sphinxcode{qm\_xyz\_to\_dat} will know how to interpret them.

\sphinxcode{mm\_fixed\_charge (no args)} \sphinxstylestrong{{[}optional, expert{]}} \textendash{} when present,
instructs TINKTEP that the MM force field is not polarisable. Leave this
directive out by default. Non-polarisable force-fields need a few
particular tweaks (TINKER’s \sphinxcode{multipole} keyword is replaced by
\sphinxcode{charge} in the \sphinxcode{qm\_mm.key} file, the \sphinxcode{polarizable} keyword needs
to be omitted from same, \sphinxcode{pol\_emb\_fixed\_charge T} will be
automatically added to the \sphinxcode{.dat} file to instruct ONETEP not to look
for \sphinxcode{\%block thole\_polarisabilities} in the \sphinxcode{.dat} file, and
TINKER’s output will be parsed differently). These tweaks are
activated by this directive.

\sphinxcode{pure\_mm (no args)} \sphinxstylestrong{{[}optional, expert{]}} \textendash{} when present, instructs
TINKTEP that the calculation is a purely MM calculation, and ONETEP does
not need to be invoked.

\sphinxcode{pure\_qm (no args)} \sphinxstylestrong{{[}optional, expert{]}} \textendash{} when present, instructs
TINKTEP that the calculation is a purely QM calculation: TINKTEP does
not need to be invoked, and \sphinxcode{pol\_emb\_pot\_filename T} must \sphinxstylestrong{not} be
added to the \sphinxcode{.dat} file so that ONETEP runs without polarisable
embedding. This is necessary due to a bug in TINKER, which causes it to
hang if all atoms are inactive.

\sphinxcode{qm\_mm\_thole\_a (real)} \sphinxstylestrong{{[}optional, expert{]}} \textendash{} when present, the
specified value overrides the value of Thole’s \(a\) parameter read
from the \sphinxcode{.prm} file. This value will be used \sphinxstyleemphasis{only} for QM/MM
interactions, as TINKER will use the force-field value for MM/MM
interactions.

\sphinxcode{qm\_dummy\_atoms (no args)} \sphinxstylestrong{{[}optional, expert{]}} \textendash{} experimental
functionality for adding dummy DMA sites on MM atoms, do not use.


\subsubsection{Command-line options to the tinktep script}
\label{\detokenize{tinktep:command-line-options-to-the-tinktep-script}}
\sphinxcode{tinktep} is normally run without arguments. The following
command-line options are supported:

\sphinxcode{-1} \textendash{} Only the first two stages described in Section {[}running{]} are
performed, then TINKTEP exits. In essence, all input files are parsed
and intermediate inputs are prepared, but neither ONETEP nor TINKER are
actually run.

\sphinxcode{-2} \textendash{} All stages described in Section {[}running{]}, \sphinxstyleemphasis{except} the first
two, are performed. In essence, the calculation is run, assuming all
intermediate inputs have been prepared in advance. Splitting the two
parts of the calculation (preparation and actual execution) enables
manual or scripted tweaking of intermediate inputs by the user.

\sphinxcode{\textendash{}dry-run} \textendash{} equivalent to \sphinxcode{-1}, only deprecated.


\subsection{ONETEP keywords pertaining to polarisable embedding}
\label{\detokenize{tinktep:onetep-keywords-pertaining-to-polarisable-embedding}}
A number of ONETEP keywords can be used to control the polarisable
embedding functionality, which underlies QM/MM calculations.


\subsubsection{Keywords mandatory for polarisable embedding}
\label{\detokenize{tinktep:keywords-mandatory-for-polarisable-embedding}}
\sphinxcode{pol\_emb\_pot\_filename (string)} \textendash{} specifies the name of the file used
for exchanging information between ONETEP and TINKTEP. This file will be
read by ONETEP and constructed by TINKTEP at every energy evaluation.
This keyword is also used to turn on polarisable embedding (when it is
present), and to turn it off (when it is absent). Default: absent.

\sphinxcode{pol\_emb\_dma\_max\_l (integer)} \textendash{} specifies the maximum angular momentum
in the SW basis used in polarisable-embedding-DMA. In most scenarios
this will be equal to \(l_{\textrm{max}}\) that you specified in the
SWRI block. Read the description of \(l_{\textrm{max}}\) in the DMA
documentation to understand the meaning of this parameter. You can use a
lower value than the one specified in the SWRI block if you want to use
only a subset of the SW basis set (e.g. for benchmarking). This keyword
does not affect properties-DMA (for which \sphinxcode{dma\_max\_l} should be used).
This directly affects the quality of the QM\(^*\) representation \textendash{}
specifying 0 leads to a charge-only representation, specifying 1 leads
to a charge-and-dipole representation, specifying 2 leads to a
charge-dipole-and-quadrupole representation.


\subsubsection{Common optional keywords}
\label{\detokenize{tinktep:common-optional-keywords}}
\sphinxcode{pol\_emb\_polscal (real)} \textendash{} specifies the scaling factor applied to QM
polarisabilities (cf. \sphinxcode{qm\_mm\_polscal} \sphinxcode{tinktep.config} directive).
This keyword will be added automatically by TINKTEP, do not add it on
your own. Default: 1.0.

\sphinxcode{pol\_emb\_repulsive\_mm\_pot\_cutoff (physical)} \textendash{} specifies the cutoff
(in length units) for the MM repulsive potential (cf. \sphinxcode{rep} token in
\sphinxcode{tinktep.config} directives \sphinxcode{onetep\_perm\_mpoles} and
\sphinxcode{onetep\_induced\_dipoles}). The value of the MM repulsive potential
from an MM site will be assumed to be zero beyond this cutoff. This is
used to minimise computational effort. The default is 10.0 bohr.

\sphinxcode{pol\_emb\_mpole\_exclusion\_radius (physical)} \textendash{} specifies the distance
(in length units) around any multipole below which its Coulombic
potential is masked or smeared (cf. \sphinxcode{potential\_coulombic\_masked} and
\sphinxcode{potential\_coulombic\_smeared} arguments to \sphinxcode{tinktep.config}
directives \sphinxcode{onetep\_perm\_mpoles} and \sphinxcode{onetep\_induced\_dipoles}. This
has no effect on Thole-damped multipole sets. The default is 0.25 bohr.

\sphinxcode{pol\_emb\_fixed\_charge (logical)} \textendash{} if \sphinxcode{T}, the MM force field will
be assumed to be non-polarisable. If \sphinxcode{F} (which is the default), the
MM force field will be assumed to be polarisable. When the force field
is polarisable and the QM\(^*\) representation is used
(\sphinxcode{pol\_emb\_qmstar T}), \sphinxcode{\%block thole\_polarisabilities} becomes
mandatory. This keyword will be added automatically by TINKTEP, do not
add it on your own.

\sphinxcode{pol\_emb\_qmstar (logical)} \textendash{} if \sphinxcode{T}, the QM\(^*\)
representation will be employed for some or all QM-MM interactions. This
is automatically set to \sphinxcode{T} once polarisable embedding is activated.
Only use \sphinxcode{F} in the rare scenario, where the QM\(^*\)
representation will not be necessary (e.g. for non-polarisable force
fields) and you want to elide \sphinxcode{\%block thole\_polarisabilities}.


\subsubsection{Uncommon and expert optional keywords}
\label{\detokenize{tinktep:uncommon-and-expert-optional-keywords}}
\sphinxcode{pol\_emb\_thole\_a (real)} \textendash{} can be used to override the value of
Thole’s \(a\) parameter read from the \sphinxcode{.prm} file. This value will
be used \sphinxstyleemphasis{only} for QM/MM interactions, as TINKER will use the
force-field value for MM/MM interactions. This keyword will be added
automatically by TINKTEP if \sphinxcode{qm\_mm\_thole\_a} is specified in
\sphinxcode{tinktep.config}, do not add it on your own. Default: 0.39.

\sphinxcode{pol\_emb\_smearing\_a (physical)} \textendash{} can be used to control the
aggresiveness of Coulombic smearing (cf. \sphinxcode{potential\_coulombic\_smeared}
argument to \sphinxcode{tinktep.config} directives \sphinxcode{onetep\_perm\_mpoles} and
\sphinxcode{onetep\_induced\_dipoles}. This has no effect on Thole-damped multipole
sets. The default is 0.2 bohr.

\sphinxcode{pol\_emb\_pairwise\_polarisability (physical)} \textendash{} see discussion of
\sphinxcode{potential\_coulombic\_smeared} argument to \sphinxcode{tinktep.config}
directives \sphinxcode{onetep\_perm\_mpoles} and \sphinxcode{onetep\_induced\_dipoles}.
Default: 1.92618 bohr (yields the average AMOEBA09 polarisability). You
should not have to use this keyword.

\sphinxcode{pol\_emb\_repulsive\_mm\_pot\_write (logical)} \textendash{} if set to \sphinxcode{T}, the
repulsive MM potential will be written to a \sphinxcode{.cube}/\sphinxcode{.dx}/\sphinxcode{.grd}
file at every energy evaluation. Used for debugging purposes. Default:
\sphinxcode{F}.

\sphinxcode{pol\_emb\_dbl\_grid (logical)} \textendash{} if set to \sphinxcode{T} the polarisable
embedding contribution to the NGWF gradient will be computed on the
double grid. By default it is computed on the coarse grid, like in HFx.
Technically, to prevent aliasing, the double grid version should be
used, but it is unbearably inefficient and has not been optimised much,
as I plan this to remain an experimental facility at most. To ensure
consistency, \sphinxcode{pol\_emb\_dbl\_grid T} should only be used together with
\sphinxcode{swx\_dbl\_grid T}, which ensures NGWF-SWOP overlaps are calculated on
the double grid too. This functionality has not been thoroughly tested.
I strongly recommend leaving this at default (\sphinxcode{F}).

\sphinxcode{pol\_emb\_perm\_scaling (real)} \textendash{} all QM permanent multipoles will be
scaled by this factor (default: 1.0, so no scaling). This can be used to
test the effects of overpolarising/underpolarising QM/MM interactions.


\subsubsection{Experimental vacuum-DMA functionality}
\label{\detokenize{tinktep:experimental-vacuum-dma-functionality}}
This is an experimental, unpublished and hardly-tested functionality
that allows having two different QM\(^*\) descriptions \textendash{} one for
the vacuum density (i.e. in the absence of polarisable embedding), and
one for the difference between the density with embedding present and
without it (“polarisation density”). In principle this permits expanding
the vacuum state density e.g. up to quadrupoles, and the difference
e.g. only in dipoles, to mimic AMOEBA (by excluding “polarisable
quadrupoles” and “fluctuating charges” in QM). Preliminary tests (2017)
showed that this hardly matters, but it might be worth studying in more
detail.

\sphinxcode{pol\_emb\_vacuum\_qmstar (logical)} \textendash{} when set to \sphinxcode{T}, it enables the
vacuum-DMA functionality. Default: \sphinxcode{F}, unless (all three
simultaneously) \sphinxcode{pol\_emb\_write\_vacuum\_restart F},
\sphinxcode{pol\_emb\_vacuum\_dma\_max\_l} is present and \sphinxcode{pol\_emb\_qmstar T}.

\sphinxcode{pol\_emb\_dma\_min\_l (integer)} \textendash{} specifies the minimum angular momentum
in the SW basis used in polarisable-embedding-DMA \sphinxstyleemphasis{for the polarisation
density}. In most scenarios this will be equal to 0. This keyword does
not affect properties-DMA (for which the corresponding value is always
0). This directly affects the quality of the QM\(^*\)
representation \sphinxstyleemphasis{for the polarisation density}. Setting
\sphinxcode{pol\_emb\_dma\_min\_l 1} and \sphinxcode{pol\_emb\_dma\_max\_l 1} in particular will
cause the polarisation density to be expanded only in terms of dipoles.
Default: 0.

\sphinxcode{pol\_emb\_vacuum\_dma\_min\_l (integer)} \textendash{} specifies the minimum angular
momentum in the SW basis used in polarisable-embedding-DMA \sphinxstyleemphasis{for the
in-vacuum density}. In most scenarios this will be equal to 0. This
keyword does not affect properties-DMA (for which the corresponding
value is always 0). This directly affects the quality of the
QM\(^*\) representation \sphinxstyleemphasis{for the in-vacuum density}. Default: 0.

\sphinxcode{pol\_emb\_vacuum\_dma\_max\_l (integer)} \textendash{} specifies the maximum angular
momentum in the SW basis used in polarisable-embedding-DMA \sphinxstyleemphasis{for the
in-vacuum density}. In most scenarios this will be equal to 1 (up to
dipoles) or 2 (up to quadrupoles). This keyword does not affect
properties-DMA (for which \sphinxcode{dma\_max\_l} should be used). This directly
affects the quality of the QM\(^*\) representation \sphinxstyleemphasis{for the
in-vacuum density}. Default: -1 (indicating “unset”).

\sphinxcode{pol\_emb\_write\_vacuum\_restart (logical)} \textendash{} if set to \sphinxcode{T}, restart
files (\sphinxcode{.pol\_emb\_vac\_tightbox\_ngwfs} and \sphinxcode{.pol\_emb\_kdenskern}) will
be written every time the NGWF gradient is calculated. These restart
files can be later used in the polarisation calculation. Default: \sphinxcode{F}


\subsubsection{Block keywords used in polarisable embedding}
\label{\detokenize{tinktep:block-keywords-used-in-polarisable-embedding}}
The following blocks are used to control polarisable embedding in
ONETEP:
\begin{itemize}
\item {} 
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{thole\PYGZus{}polarisabilities}
\PYG{o}{\PYGZlt{}}\PYG{n}{QMatom1}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{polarisability1}\PYG{o}{\PYGZgt{}}
\PYG{o}{\PYGZlt{}}\PYG{n}{QMatom2}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{polarisability2}\PYG{o}{\PYGZgt{}}
\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}        \PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\PYG{o}{\PYGZlt{}}\PYG{n}{QMatom}\PYG{o}{\PYGZlt{}}\PYG{n}{n}\PYG{o}{\PYGZgt{}\PYGZgt{}} \PYG{o}{\PYGZlt{}}\PYG{n}{polarisability}\PYG{o}{\PYGZlt{}}\PYG{n}{n}\PYG{o}{\PYGZgt{}\PYGZgt{}}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{thole\PYGZus{}polarisabilities}
\end{sphinxVerbatim}

This block specifies Thole polarisabilities for all QM atoms, in
units of bohr\(^3\). Normally (i.e. if
\sphinxcode{qm\_thole\_polarisability} is specified in \sphinxcode{tinktep.config}), this
block will be automatically added by TINKTEP, which infers the QM
polarisabilities from the \sphinxcode{.prm} and \sphinxcode{.tag} files. If you prefer
to specify polarisabilities manually, add this block and omit
\sphinxcode{qm\_thole\_polarisability} from \sphinxcode{tinktep.config}. For example for
water TINKTEP would generate:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}block thole\PYGZus{}polarisabilities
O 5.648355971436 ! Water O
H 3.347173908999 ! Water H
H 3.347173908999 ! Water H
\PYGZpc{}endblock thole\PYGZus{}polarisabilities
\end{sphinxVerbatim}

\item {} 
\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}block mm\PYGZus{}rep\PYGZus{}params
\PYGZlt{}MMspecies1\PYGZgt{} \PYGZlt{}A!1\PYGZgt{} \PYGZlt{}zeta1\PYGZgt{}
\PYGZlt{}MMspecies2\PYGZgt{} \PYGZlt{}A!2\PYGZgt{} \PYGZlt{}zeta2\PYGZgt{}
...        ...
\PYGZlt{}MMspecies\PYGZlt{}n\PYGZgt{}\PYGZgt{} \PYGZlt{}A!\PYGZlt{}n\PYGZgt{}\PYGZgt{} \PYGZlt{}zeta\PYGZlt{}n\PYGZgt{}\PYGZgt{}
\PYGZpc{}endblock mm\PYGZus{}rep\PYGZus{}params
\end{sphinxVerbatim}

This block specifies the MM repulsive potential parameters for all MM
species in the system. The parameter \(A\) is the magnitude (in
hartree), the parameter zeta=\(\zeta\) is the inverse-width (in
bohr\(^{-1}\)). For example for water, parameterised as in
Ref. {[}Dziedzic2018{]}:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{mm\PYGZus{}rep\PYGZus{}params}
\PYG{n}{H}   \PYG{l+m+mi}{35} \PYG{l+m+mf}{2.400}
\PYG{n}{O}  \PYG{l+m+mi}{550} \PYG{l+m+mf}{1.580}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{mm\PYGZus{}rep\PYGZus{}params}
\end{sphinxVerbatim}

\end{itemize}


\subsection{Questions?}
\label{\detokenize{tinktep:questions}}
Questions should be directed to Jacek Dziedzic,
\sphinxcode{J.Dziedzic{[}-at-{]}soton.ac.uk.}

{[}Stone1998{]} A.J. Stone, GDMA: distributed multipoles from Gaussian98 wavefunctions (technical report), University of Cambridge (1998).

{[}Stone2005{]} A.J. Stone, Journal of Chemical Theory and Computation \sphinxstylestrong{6} 1128-1132 (2005).

{[}Dziedzic2016{]} J. Dziedzic, Y. Mao, Y. Shao, J. Ponder, T. Head-Gordon, M. Head-Gordon and C.-K. Skylaris, J. Chem. Phys. \sphinxstylestrong{145} 12 124106 (2016).

{[}Dziedzic2018{]} J. Dziedzic, T. Head-Gordon, M. Head-Gordon and C.-K. Skylaris, (in preparation) (2018).

{[}Vitale2015{]} V. Vitale, J. Dziedzic, S.M.-M. Dubois, H. Fangohr and C.-K. Skylaris, Journal of Chemical Theory and Computation \sphinxstylestrong{11} 7 3321-3332 (2015).


\chapter{Properties}
\label{\detokenize{index_properties:properties}}\label{\detokenize{index_properties::doc}}

\section{Energy Decomposition Analysis (EDA)}
\label{\detokenize{EDA::doc}}\label{\detokenize{EDA:energy-decomposition-analysis-eda}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Max Phipps, University of Southampton

\item[{Date}] \leavevmode
July 2016

\end{description}\end{quote}


\subsection{Introduction}
\label{\detokenize{EDA:introduction}}
Energy decomposition analysis (EDA) decomposes the interaction energy
(\(\Delta E\)) of an arbitrary number of non-bonded fragments into
its chemical components {[}Phipps2015{]}. In the case of
the ONETEP EDA {[}Phipps2016{]}, based on the
ALMO {[}Kaliullin2007{]} and LMO {[}Su2009{]} EDA
approaches, these components are combined into a frozen density
component (\(\Delta E_\mathrm{FRZ}\)) term, polarisation
(\(\Delta E_\mathrm{POL}\)), and charge transfer
(\(\Delta E_\mathrm{CT}\)) (as per the original ALMO EDA), as,
\begin{equation*}
\begin{split}\begin{aligned}
 \Delta E =& \Delta E_\mathrm{FRZ} + \Delta E_\mathrm{POL} + \Delta E_\mathrm{CT} \quad .\end{aligned}\end{split}
\end{equation*}
The frozen density component, representing the interaction of the frozen
densities of the fragments and subsequent antisymmetrization, is further
decomposed into its electrostatics (\(\Delta E_\mathrm{ES}\)),
exchange (\(\Delta E_\mathrm{EX}\)), correlation
(\(\Delta E_\mathrm{CORR}\)), and Pauli repulsion
(\(\Delta E_\mathrm{REP}\)) terms as,
\begin{equation*}
\begin{split}\begin{aligned}
 \Delta E_\mathrm{FRZ} =& \Delta E_\mathrm{ES} + \Delta E_\mathrm{EX} + \Delta E_\mathrm{CORR} + \Delta E_\mathrm{REP} \quad .\end{aligned}\end{split}
\end{equation*}
In the ONETEP implementation, the correlation term is further
partitioned into its frozen (\(\Delta E_\mathrm{FRZ-CORR}\)) and
Pauli repulsion (\(\Delta E_\mathrm{REP-CORR}\)) terms as,
\begin{equation*}
\begin{split}\begin{aligned}
 \Delta E_\mathrm{CORR} = \Delta E_\mathrm{FRZ-CORR} + \Delta E_\mathrm{REP-CORR}
\quad .\end{aligned}\end{split}
\end{equation*}
These terms may be recombined to obtain the full correlation energy
term.

The total interaction energy is expressed in its decomposed form as,
\begin{equation*}
\begin{split}\begin{aligned}
 \Delta E =& \Delta E_\mathrm{ES} + \Delta E_\mathrm{EX} + \Delta E_\mathrm{CORR} \nonumber \\
       &+ \Delta E_\mathrm{REP} + \Delta E_\mathrm{POL} + \Delta E_\mathrm{CT} \quad .\end{aligned}\end{split}
\end{equation*}

\subsection{Performing EDA calculations in ONETEP}
\label{\detokenize{EDA:performing-eda-calculations-in-onetep}}
There are two approaches to performing energy decomposition analysis
(EDA) calculations in ONETEP:
\begin{enumerate}
\item {} 
All-In-One (1S) This approach involves creating a single input file
with all the necessary information to complete an EDA calculation
(\sphinxcode{TASK EDA}).
\begin{itemize}
\item {} 
Designed for smaller systems.

\end{itemize}

\item {} 
Three-Stage Fragment-to-Supermolecule (3S) This approach involves
three stages. Firstly NGWF tightboxes and density kernels for the
fragments are optimised and written to disk. Next the fragment states
are superposed to the supermolecule to prepare the supermolecule data
(\sphinxcode{TASK EDA\_PREP}). Finally the EDA calculation is ran using this
supermolecule-prepared data (\sphinxcode{TASK EDA}).
\begin{itemize}
\item {} 
Designed for larger protein-ligand type EDA calculations.

\end{itemize}

\end{enumerate}

Both approaches are equivalent and produce identical results. The choice
of whether to use the 1S or 3S approach is usually determined by system
size and parallelisation requirements (please see
section {[}sect:ParallelisationReq{]}). Further details of calculations
using these two approaches and a list of the EDA-specific keywords and
descriptions are provided below:


\subsubsection{All-in-One}
\label{\detokenize{EDA:all-in-one}}
The all-in-one (1S) approach is the default EDA calculation
configuration, and is ran by simply setting the \sphinxcode{TASK} keyword to
\sphinxcode{EDA}. In addition to the standard input keywords and blocks, the
\sphinxcode{EDA\_IATM} block is necessary to perform ONETEP EDA calculations. This
block defines the fragment atoms (referenced to the atom definitions in
\sphinxcode{POSITIONS\_ABS}), and the fragment charges. Atoms of the supermolecule
are arranged in the \sphinxcode{POSITIONS\_ABS} block by concatenation of the
fragment atoms, using their nuclear coordinates found in the
supermolecule. For example, if a supermolecule system comprising the
fragments \(H_2O\) (atoms 1 to 3), \(OH^-\) (atoms 4 to 5), and
\(Na^+\) (atom 6) is defined in the \sphinxcode{POSITIONS\_ABS} block,

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{POSITIONS\PYGZus{}ABS}
  \PYG{n}{O}      \PYG{l+m+mf}{17.16973430}    \PYG{l+m+mf}{19.79077059}    \PYG{l+m+mf}{17.26422010}
  \PYG{n}{H}      \PYG{l+m+mf}{16.00000000}    \PYG{l+m+mf}{19.22196603}    \PYG{l+m+mf}{16.00000000}
  \PYG{n}{H}      \PYG{l+m+mf}{18.57568311}    \PYG{l+m+mf}{18.64371289}    \PYG{l+m+mf}{17.26799954}
  \PYG{n}{O}      \PYG{l+m+mf}{21.16270452}    \PYG{l+m+mf}{17.46075058}    \PYG{l+m+mf}{18.04467287}
  \PYG{n}{H}      \PYG{l+m+mf}{22.06598884}    \PYG{l+m+mf}{16.00000000}    \PYG{l+m+mf}{17.45886087}
  \PYG{n}{Na}     \PYG{l+m+mf}{20.73940810}    \PYG{l+m+mf}{20.59012052}    \PYG{l+m+mf}{20.33500884}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{POSITIONS\PYGZus{}ABS}
\end{sphinxVerbatim}

then the fragment data necessary for the EDA calculation is input as,

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZpc{}block EDA\PYGZus{}IATM
  !N\PYGZus{}at  Charge
   3     +0
   2     \PYGZhy{}1
   1     +1
\PYGZpc{}endblock EDA\PYGZus{}IATM
\end{sphinxVerbatim}


\subsubsection{Three-Stage}
\label{\detokenize{EDA:three-stage}}
The 3S EDA has been developed to work easily with EDA directory
structures, with fragment calculations being performed in separate
folders. These data directories are specified in the input file using
the \sphinxcode{EDA\_FRAG} and \sphinxcode{EDA\_SUPER} blocks as will be discussed below. In
our EDA calculation example of a supermolecule comprising three
fragments provided below, the following directory structure is used:
\begin{equation*}
\begin{split}\begin{aligned}
    &\left.
    \begin{array}{ll}
      \mathrm{./STAGE1/FRAG01/} \\
      \mathrm{./STAGE1/FRAG02/} \\
      \mathrm{./STAGE1/FRAG03/}
    \end{array}
    \right\} \mathrm{Fragment\ calculations} \nonumber \\
    &\left. \mathrm{./STAGE2} \right\} \mathrm{Supermolecule\ preparation\ calculation} \nonumber \\
    &\left. \mathrm{./STAGE3} \right\} \mathrm{Supermolecule\ EDA\ calculation} \nonumber\end{aligned}\end{split}
\end{equation*}
It is noted that the user is not limited to three fragments , and that
the folder names given above are for example purposes only and any
folder and input file names may be used.

In all three stages, it is necessary to ensure that the system
parameters are kept at constant values. For example, it is unwise to
modify the NGWF radii or box sizes between the calculation stages. It is
also important to ensure atomic orderings in the input file are
consistent, \sphinxstyleemphasis{i.e.} that the orderings of atoms within each of the
fragments do not change between the different calculation stages.


\paragraph{Stage 1}
\label{\detokenize{EDA:stage-1}}
The first stage simply involves the user writing converged fragment data
to disk. For each fragment comprising the supermolecule, a separate
input file is constructed with the following parameters set:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{write\PYGZus{}denskern} \PYG{n}{T}
\PYG{n}{write\PYGZus{}tightbox\PYGZus{}ngwfs} \PYG{n}{T}
\PYG{n}{TASK} \PYG{n}{SINGLEPOINT}
\end{sphinxVerbatim}

Running these calculations will result in fragment ‘.dkn’ and
‘.tightbox\_ngwfs’ files being written to disk. In our example, the
three fragment calculation are ran in the directories
\sphinxcode{STAGE1/FRAG01/}, \sphinxcode{STAGE1/FRAG02/}, and \sphinxcode{STAGE1/FRAG03/} using the
input filenames ‘frag01.dat’, ‘frag02.dat’, and ‘frag03.dat’ for the
respective fragments 1, 2, and 3.


\paragraph{Stage 2}
\label{\detokenize{EDA:stage-2}}
The input file for the second stage is prepared by including the
parameters \sphinxcode{EDA\_READ\_FRAGS T} and \sphinxcode{TASK EDA\_PREP}. Running ONETEP
with this input file will result in the converged fragment data being
loaded in and combined to produce the supermolecule complex data
(‘.eda’, ‘.dkn’ and ‘.tightbox\_ngwfs’ files) necessary for stage three.
These fragment files’ names are set via the \sphinxcode{EDA\_FRAG} block, e.g. for
a three fragment system:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{EDA\PYGZus{}FRAG}
  \PYG{n}{frag1prefix}
  \PYG{n}{frag2prefix}
  \PYG{n}{frag3prefix}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{EDA\PYGZus{}FRAG}
\end{sphinxVerbatim}

where \sphinxcode{frag1prefix}, \sphinxcode{frag2prefix} and \sphinxcode{frag3prefix} are the
filename prefixes that will result in loading of the ‘.dkn’ and
‘.tightbox\_ngwfs’ files for the three fragments that were converged in
stage one. In our example, we assume the second stage calculation is
performed in the directory \sphinxcode{STAGE2/} with the input filename
‘stage2.dat’. In this case the block would appear in the input file as,

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{EDA\PYGZus{}FRAG}
  \PYG{o}{.}\PYG{o}{.}\PYG{o}{/}\PYG{n}{STAGE1}\PYG{o}{/}\PYG{n}{FRAG01}\PYG{o}{/}\PYG{n}{frag01}
  \PYG{o}{.}\PYG{o}{.}\PYG{o}{/}\PYG{n}{STAGE1}\PYG{o}{/}\PYG{n}{FRAG02}\PYG{o}{/}\PYG{n}{frag02}
  \PYG{o}{.}\PYG{o}{.}\PYG{o}{/}\PYG{n}{STAGE1}\PYG{o}{/}\PYG{n}{FRAG03}\PYG{o}{/}\PYG{n}{frag03}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{EDA\PYGZus{}FRAG}
\end{sphinxVerbatim}


\paragraph{Stage 3}
\label{\detokenize{EDA:stage-3}}
The third stage is performed by including the parameters
\sphinxcode{EDA\_READ\_SUPER T} and \sphinxcode{TASK EDA} in the input file. As described
earlier for the 1S approach, it is necessary for the user to define the
fragment atoms and charges using the \sphinxcode{EDA\_IATM} block. On running
ONETEP with this input file, the ‘.dkn’, ‘.tightbox\_ngwfs’ and ‘.eda’
files for the supermolecule prepared from stage two will be loaded.
These files’ names are set via the \sphinxcode{EDA\_SUPER} block, e.g.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{EDA\PYGZus{}SUPER}
  \PYG{n}{supermoleculeprefix}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{EDA\PYGZus{}SUPER}
\end{sphinxVerbatim}

where \sphinxcode{supermoleculeprefix} is the filename prefix that will result in
loading of the ‘supermoleculeprefix.dkn’,
‘supermoleculeprefix.tightbox\_ngwfs’, and ‘supermoleculeprefix.eda’
files. In our example, where the third stage calculation is performed in
the directory \sphinxcode{STAGE3/} with the input filename ‘stage3.dat’, the
block would appear as,

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{EDA\PYGZus{}SUPER}
  \PYG{o}{.}\PYG{o}{.}\PYG{o}{/}\PYG{n}{STAGE2}\PYG{o}{/}\PYG{n}{stage2}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{EDA\PYGZus{}SUPER}
\end{sphinxVerbatim}


\subsection{Continuation}
\label{\detokenize{EDA:continuation}}
Continuation of supermolecule-stage EDA calculations (stage three of the
3S EDA) is controlled using the \sphinxcode{EDA\_CONTINUATION} keyword.
Continuation files are written to disk within the current working
directory when the value of the \sphinxcode{EDA\_WRITE} logical keyword is set to
true, and continuation files are read by setting the
\sphinxcode{EDA\_CONTINUATION} logical keyword to true.

It is recommended that the storage of continuation data should be kept
separate to the \sphinxcode{TASK EDA\_PREP} task calculation data of stage two.
This is achieved by performing the stage three calculation in a separate
directory to the stage two calculation. This is because the EDA data
produced from the \sphinxcode{TASK EDA\_PREP} calculation produces a reference to
the frozen state which the NGWFs and density kernel will be reset to in
a large proportion of EDA calculation cases.


\subsection{EDA schematic}
\label{\detokenize{EDA:eda-schematic}}
An example EDA calculation and directory structure is provided in \sphinxcode{exampleEDA}.


\subsection{Additional functionality}
\label{\detokenize{EDA:additional-functionality}}\label{\detokenize{EDA:exampleeda}}
Further details of the EDA functionalities is given below:


\subsubsection{Fragment-wise polarisations}
\label{\detokenize{EDA:fragment-wise-polarisations}}
\begin{DUlineblock}{0em}
\item[] \sphinxstyleemphasis{Please note that the following functionality is developmental and is
subject to change.}
\item[] It is possible to obtain polarisation energies for each of the
fragments by ‘freezing’ the electronic density during the SCF-MI
optimisation. The number of additional polarisation calculations
required to perform this is equal to the number of fragments in the
system. This functionality is activated using the
\sphinxcode{EDA\_FRAG\_ISOL\_POL} logical keyword. Also computed is a ‘higher
order’ polarisation contribution that quantifies the difference
between the individual fragment polarisation total and the full
polarisation energy, i.e.
\end{DUlineblock}
\begin{quote}
\begin{equation*}
\begin{split}\begin{aligned}
 \Delta E_\textrm{POL,HO} = \sum_{A\in \textrm{X}}^{N_\textrm{frag}} \Delta E_\textrm{POL(\textit{A})} - \Delta E_\textrm{POL}\end{aligned}\end{split}
\end{equation*}\end{quote}

\begin{DUlineblock}{0em}
\item[] where \(\Delta E_\textrm{POL,HO}\) is the higher order
polarisation contribution, \(N_\textrm{frag}\) is the number of
fragments, \(\Delta E_\textrm{POL(\textit{A})}\) is the
polarisation energy for fragment \(A\) that constitutes the
supermolecule \(\textrm{X}\), and \(\Delta E_\textrm{POL}\) is
the polarisation energy on polarising all fragments simultaneously.
\end{DUlineblock}


\subsubsection{Fragment pair-wise delocalisations}
\label{\detokenize{EDA:fragment-pair-wise-delocalisations}}
\begin{DUlineblock}{0em}
\item[] \sphinxstyleemphasis{Please note that the following functionality is developmental and is
subject to change.}
\item[] This functionality is activated using the \sphinxcode{EDA\_FRAG\_ISOL\_CT} logical
keyword.
\end{DUlineblock}

It is possible to calculate fragment pair delocalisation energies by
combining fragments within the SCF-MI optimisation. For example, if we
consider a system of interacting \((H_2O)_3\), the delocalisation
between any two water molecules is calculated by subtracting the SCF-MI
energy of a combined \((H_2O)_2\) ‘fragment’ interacting with
\(H_2O\) from the SCF-MI energy of the system with the
\((H_2O)_2\) ‘fragment’ partitioned into its two \(H_2O\)
constitutents.


\subsubsection{Density visualisation}
\label{\detokenize{EDA:density-visualisation}}
Obtaining electron density (ED) files for visualisation of the EDA
frozen, polarisation and fully electronically relaxed states can be done
using the \sphinxcode{WRITE\_DENSITY\_PLOT} logical keyword. The output densities
are identified by the ‘\_ed\_’ filename string.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstylethead{\sphinxstyletheadfamily 
Filename String
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Summary
\unskip}\relax \\
\hline
\sphinxstyleemphasis{xxx}\_eda\_frzidem\_ed\_density.cube
&
The ED of the frozen state.
\\
\hline
\sphinxstyleemphasis{xxx}\_eda\_pol\_\sphinxstyleemphasis{iii}\_ed\_density.cube
&
The ED of fragment \sphinxstyleemphasis{iii} electronically polarised in the field of all other fragments.
\\
\hline
\sphinxstyleemphasis{xxx}\_eda\_pol\_ed\_density.cube
&
The ED of the fully electronically polarised state.
\\
\hline
\sphinxstyleemphasis{xxx}\_eda\_relaxed\_ed\_density.cube
&
The ED of the fully electronically relaxed state.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Table: The EDA electron density (ED) filename extension descriptions
(filename root is denoted by \sphinxstyleemphasis{xxx}).

Visualisation of the density changes during the EDA polarisation and
charge transfer processes via electron density difference (EDD)
calculations are obtained using the \sphinxcode{EDA\_DELTADENS} logical keyword.
The output densities are identified by the ‘\_edd\_’ filename string.


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstylethead{\sphinxstyletheadfamily 
Filename String
\unskip}\relax &\sphinxstylethead{\sphinxstyletheadfamily 
Summary
\unskip}\relax \\
\hline
\sphinxstyleemphasis{xxx}\_pol\_\sphinxstyleemphasis{iii}\_edd\_density.cube
&
The electronic polarisation EDD of fragment \sphinxstyleemphasis{iii} in the field of all other fragments.
\\
\hline
\sphinxstyleemphasis{xxx}\_eda\_pol\_higher\_order\_edd\_density.cube
&
The higher order electronic polarisation EDD (of the individual fragment-polarised states to the fully polarised state).
\\
\hline
\sphinxstyleemphasis{xxx}\_eda\_pol\_edd\_density.cube
&
The fully electronically polarised EDD state.
\\
\hline
\sphinxstyleemphasis{xxx}\_eda\_ct\_edd\_density.cube
&
The charge transfer EDD.
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

Table: The EDA electron density difference filename extension
descriptions (filename root is denoted by \sphinxstyleemphasis{xxx}).

Both ED and EDD functionalities are compatible with fragment-specific
(see previous section) EDA calculations.
Note: electron density differences are currently not computable when the
\sphinxcode{EDA\_CONTINUATION} keyword is set to true. In this case, the edd\_cube
utility may be used along with the ED cube files produced using the
\sphinxcode{WRITE\_DENSITY\_PLOT} logical keyword to calculate EDD files
independently of ONETEP (see ‘Additional utilities’ section).


\subsection{Parallelisation}
\label{\detokenize{EDA:parallelisation}}

\subsubsection{Parallelisation requirements}
\label{\detokenize{EDA:parallelisation-requirements}}
The 1S calculation has a parallelisation strategy with restricted
maximum possible number of MPI processes, \({N_\mathrm{proc,max}}\),
\begin{equation*}
\begin{split}\begin{aligned}
  {N_\mathrm{proc,max}}= \mathrm{min}\left[ {N_\mathrm{at}(\mathrm{A})}, {N_\mathrm{at}(\mathrm{B})} \right]\end{aligned}\end{split}
\end{equation*}
where \(A\) and \(B\) are fragments comprising a supermolecule
\(AB\). For example in the case of a water dimer
\({N_\mathrm{proc,max}}= 3\).

The 3S EDA allows the user to take full advantage of the parallelisation
strategy during the supermolecule stage three, i.e.
\begin{equation*}
\begin{split}\begin{aligned}
 {N_\mathrm{proc,max}}= \mathrm{min}\left[ {N_\mathrm{at}(\mathrm{A})}, {N_\mathrm{at}(\mathrm{B})} \right] &|_{{\mathrm{S}}=1,2} \\
 {N_\mathrm{proc,max}}= {N_\mathrm{at}(\mathrm{AB})} &|_{{\mathrm{S}}=3}\end{aligned}\end{split}
\end{equation*}
where \({\mathrm{S}}\) is the stage number. For example in the case
of a water dimer \({N_\mathrm{proc,max}}= 6\) during the
supermolecule stage three (\({\mathrm{S}}\)=3).


\subsubsection{ScaLAPACK}
\label{\detokenize{EDA:scalapack}}
The current EDA implementation requires explicit calculation and
manipulation of the fragment MO eigenvectors. The ONETEP EDA
implementation is compatible with the LAPACK {[}Anderson1999{]}
and ScaLAPACK {[}Blackford1997{]} packages, and has been
interfaced to the DSYGVX and PDSYGVX eigensolvers. Compilation with the
ScaLAPACK solver is enabled at compilation time using the -DSCALAPACK
flag. Use of this package provides significant speed-ups by parallelised
computation of the eigenvectors required.

The threshold tolerance to which the eigenvectors are orthogonalised is
specified by the \sphinxcode{eigensolver\_abstol} keyword. It has been observed
that the eigensolver may require tighter than the default thresholds.
This parameter can be modified in the input, e.g.
\sphinxcode{eigensolver\_abstol = 1.0E-12}.


\subsection{Additional utilities}
\label{\detokenize{EDA:additional-utilities}}\begin{description}
\item[{utils/edd\_cube.F90}] \leavevmode
This utility calculates the electron density difference between two
‘.cube’ volumetric data files Usage: ./edd\_cube cubein1 cubein2
cubeout, where \sphinxstyleemphasis{n}(cubeout) = \sphinxstyleemphasis{n}(cubein1) - \sphinxstyleemphasis{n}(cubein2)

\end{description}

{[}Phipps2015{]} Maximillian J. S. Phipps, Thomas Fox, Christofer S. Tautermann, and Chris-Kriton Skylaris. Energy decomposition analysis approaches and their evaluation on prototypical protein-drug interaction patterns. \sphinxstyleemphasis{Chem. Soc. Rev.}, 44:3177\textendash{}3211, 2015.

{[}Phipps2016{]} Maximillian J. S. Phipps, Thomas Fox, Christofer S. Tautermann, and Chris-Kriton Skylaris. Energy decomposition analysis based on absolutely localised molecular orbitals for large-scale density functional theory calculations in drug design. \sphinxstyleemphasis{(Submitted)}, 2016.

{[}Khaliullin2007{]} R. Z. Khaliullin, E. A. Cobar, R. C. Lochan, A. T. Bell, and M. Head-Gordon. \sphinxstyleemphasis{J. Phys. Chem. A}, 111:8753\textendash{}8765, 2007.

{[}Su2009{]} Peifeng Su and Hui Li. Energy decomposition analysis of covalent bonds and intermolecular interactions. \sphinxstyleemphasis{J. Chem. Phys.}, 131(1):014102, 2009.

{[}Anderson1999{]} E. Anderson, Z. Bai, C. Bischof, S. Blackford, J. Demmel, J. Dongarra, J. Du Croz, A. Greenbaum, S. Hammarling, A. McKenney, and D. Sorensen. \sphinxstyleemphasis{LAPACK Users’ Guide}. Society for Industrial and Applied Mathematics, Philadelphia, PA, third edition, 1999.

{[}Blackford1997{]} L. S. Blackford, J. Choi, A. Cleary, E. D’Azevedo, J. Demmel, I. Dhillon, J. Dongarra, S. Hammarling, G. Henry, A. Petitet, K. Stanley, D. Walker, and R. C. Whaley. \sphinxstyleemphasis{ScaLAPACK Users’ Guide}. Society for Industrial and Applied Mathematics, Philadelphia, PA, 1997.


\section{Electron Localisation Descriptors}
\label{\detokenize{eld:electron-localisation-descriptors}}\label{\detokenize{eld::doc}}\begin{quote}\begin{description}
\item[{Author}] \leavevmode
Rebecca J. Clements, University of Southampton

\item[{Author}] \leavevmode
James C. Womack, University of Southampton

\item[{Author}] \leavevmode
Chris-Kriton Skylaris, University of Southampton

\item[{Date}] \leavevmode
July 2019

\end{description}\end{quote}

ONETEP now has the electron localisation descriptors:
\begin{itemize}
\item {} 
Electron Localisation Function (ELF) {[}Becke1990{]}

\item {} 
Localised Orbital Locator (LOL) {[}Becke2000{]}

\end{itemize}

These descriptors provide a visualisation tool for indicating the
location of electron pairs, including bonding and lone pairs, and
distinguishing between \(\sigma\) and \(\pi\) bonds. It is a
dimensionless quantity in the range of \(0\) and \(1\). The
plots can be output in \(.cube\) or \(.dx\) format for
visualisation as isosurfaces or volume slices.

The ELF was first introduced by Edgecombe and Becke in 1990 for
Hartree-Fock Theory, and later updated for Density Functional Theory by
Savin \sphinxstyleemphasis{et al.}.
{[}Becke1990{]}, {[}Becke2000{]}, {[}Savin1992{]} It is based
on the Hartree Fock probability of finding two particles of the same
spin \(\sigma\) at two different positions of a multielectron
system. From this, Edgecombe and Becke obtained the conditional
probability of an electron existing in the proximity of a reference
electron, which relates to electron localisation. The smaller the
probability, the increased likelihood that the reference electron is
localised, provided both the electrons are of the same spin. This
probability vanishes to zero when the two electrons have the same
position, in agreement with the Pauli principle.

This probability is not upper-bounded and so for more convenient
graphical interpretation, it is inverted. Localisation is represented at
unity. Details are below.

The LOL is similar to the ELF, but with a simpler representation, and produces cleaner plots in some cases. {[}Schmider2004{]}

The ELF provides quantum Valence Shell Electron Pair Repulsion (VSEPR)
representation of coordination compounds, and the identification of
covalent bonding across crystalline solids and surfaces. This provides a
useful tool for the main applications of ONETEP; biomolecular
simulations, catalysis, and the design of nanostructured materials.


\subsection{Electron Localisation Function}
\label{\detokenize{eld:electron-localisation-function}}
The starting point to the ELF formula is the exact kinetic energy
density for spin \(\sigma\),

\phantomsection\label{\detokenize{eld:equation-kedensity}}\begin{equation}\label{equation:eld:kedensity}
\begin{split}\tau_{\sigma}^{exact}(\textbf{r}) = \sum_{\alpha} \tau(\textbf{r};\alpha),\end{split}
\end{equation}
where
\(\tau(\textbf{r};\alpha)=(\nabla \psi_{\alpha}(\textbf{r})) \cdot \bigg( \nabla \sum_{\beta}K^{\alpha\beta}\psi_{\beta}(\textbf{r}) \bigg)\)

defined in ONETEP {[}Womack2016{]} in terms of NGWFs
where \(\beta\) are all which overlap with \(\psi_{\alpha}\).
Note that the standard \(\frac{1}{2}\) coefficient in ONETEP is
omitted for the purposes of the ELF, to follow the definition by Becke.
The term \(\tau_{\sigma}^{exact}\) is extended into a formula to
describe electron localisation, a \sphinxstyleemphasis{non-negative} probability density.
This will be called the Pauli kinetic energy, \(D_{\sigma}\). For
the individual spin, the Pauli kinetic energy takes the form:
\begin{equation*}
\begin{split}D_{\sigma} = \tau_{\sigma}^{exact} - \frac{1}{4} \frac{\left( \nabla n_{\sigma} \right) ^{2}} {n_{\sigma}}.\end{split}
\end{equation*}
where \(n_{\sigma}(\textbf{r})\) is the charge density for each
spin \(\sigma\), and \(\nabla n_{\sigma}(\textbf{r})\) is its
gradient. \(D_{\sigma}\) is compared with the uniform electron gas
as a reference, by taking the ratio:
\begin{equation*}
\begin{split}\chi_{\sigma} = \frac {D_{\sigma}} {D_{\sigma}^{0}}.\end{split}
\end{equation*}
where
\begin{equation*}
\begin{split}D_{\sigma}^{0} = \frac{3}{5} \left( 6\pi^{2} \right) ^{\frac{2}{3}} n_{\sigma}^{\frac{5}{3}}.\end{split}
\end{equation*}
The charge density is the local value of
\(n_{\sigma} \left( \textbf{r} \right)\) here and the coefficient is
the Fermi constant.

Hence, the measure of electron localisation has now become
dimensionless. \(\chi_{\sigma}\) is then reformulated to avoid the
open bounds of the above formula, limiting the ELF to a more desirable
finite range of values of \(0\) to \(1\) for visual
representation:
\begin{equation*}
\begin{split}ELF = \frac{1}{1+\chi_{\sigma}^{2}}\end{split}
\end{equation*}

\subsection{Localised Orbital Locator}
\label{\detokenize{eld:localised-orbital-locator}}
The LOL is similar to the ELF. Again, the starting point is the exact
kinetic energy for spin \(\sigma\), as in Equation \eqref{equation:eld:kedensity},
with the \(\frac{1}{2}\) coefficient omitted.

The uniform electron gas reference, \(D_{\sigma}^{0}\), is used
again here, also known as the local spin density approximation (LSDA):
\begin{equation*}
\begin{split}\tau_{\sigma}^{LSDA} = \frac{3}{5} \left( 6\pi^{2} \right) ^{\frac{2}{3}} n_{\sigma}^{\frac{5}{3}}.\end{split}
\end{equation*}
The ratio follows a similar structure to the ELF, except for it is
inverted, which again, makes the quantity dimensionless:
\begin{equation*}
\begin{split}t_{\sigma} = \frac {\tau_{\sigma}^{LSDA}} {\tau_{\sigma}^{exact}}.\end{split}
\end{equation*}
The quantity is reformulated to change the infinite range into a
\(0\) to \(1\) range like before:
\begin{equation*}
\begin{split}v_{\sigma} = \frac{t_{\sigma}} {1 + t_{\sigma}}\end{split}
\end{equation*}

\subsection{How to use}
\label{\detokenize{eld:how-to-use}}

\subsubsection{Keywords}
\label{\detokenize{eld:keywords}}
The keywords related to the implementation of the electron localisation
descriptors are as follows:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Keyword}\PYG{p}{:}                \PYG{n}{Options} \PYG{p}{(}\PYG{n}{default}\PYG{p}{)}\PYG{p}{:}
\PYG{n}{eld\PYGZus{}calculate}           \PYG{n}{T}\PYG{o}{/}\PYG{n}{F} \PYG{p}{(}\PYG{n}{F}\PYG{p}{)}
\PYG{n}{eld\PYGZus{}function}            \PYG{n}{ELF}\PYG{o}{/}\PYG{n}{LOL} \PYG{p}{(}\PYG{n}{ELF}\PYG{p}{)}
\PYG{n}{ke\PYGZus{}density\PYGZus{}calculate}    \PYG{n}{T}\PYG{o}{/}\PYG{n}{F} \PYG{p}{(}\PYG{n}{F}\PYG{p}{)}
\PYG{n}{do\PYGZus{}properties}           \PYG{n}{T}\PYG{o}{/}\PYG{n}{F} \PYG{p}{(}\PYG{n}{F}\PYG{p}{)}
\PYG{n}{cube\PYGZus{}format}             \PYG{n}{T}\PYG{o}{/}\PYG{n}{F} \PYG{p}{(}\PYG{n}{T}\PYG{p}{)}
\PYG{n}{dx\PYGZus{}format}               \PYG{n}{T}\PYG{o}{/}\PYG{n}{F} \PYG{p}{(}\PYG{n}{F}\PYG{p}{)}
\end{sphinxVerbatim}
\begin{itemize}
\item {} 
Setting \(eld\_calculate\) to true turns on the calculation. The
calculation will not proceed if this keyword is missing or if it set
to false.

\item {} 
The keyword \(eld\_function\) determines which of the ELF or LOL
ONETEP is to calculate, by specifying either string. The default here
is the ELF, provided the keyword \(eld\_calculate\) has been
specified.

\item {} 
As part of this implementation, the kinetic energy density can now
also be output, using the logical keyword
\(ke\_density\_calculate\). This does not automatically output
with \(eld\_calculate\).

\item {} 
Electron localisation descriptors and kinetic energy density are
available in the formats of \(.cube\) or \(.dx\) files.

\item {} 
For spin polarised systems, there will be an ELF output for each spin
individually, showing the electron localisation for one of the spins.

\end{itemize}

In order to use any of the above keywords, ONETEP’s properties
calculation must be enabled, using \(do\_properties\) or setting the
task to \(properties\), if reading in density results of an energy
minimisation calculation. To produce the density plot during the
original energy calculation, the input should include:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{task}                \PYG{n}{singlepoint}
\PYG{n}{write\PYGZus{}density\PYGZus{}plot}  \PYG{n}{T}
\end{sphinxVerbatim}


\subsubsection{Example input file}
\label{\detokenize{eld:example-input-file}}
Below is an example input for using the ELF, for the water molecule:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{task}            \PYG{n}{singlepoint}
\PYG{n}{cutoff\PYGZus{}energy}   \PYG{l+m+mf}{900.0} \PYG{n}{eV}
\PYG{n}{maxit\PYGZus{}ngwf\PYGZus{}cg}   \PYG{l+m+mi}{100}
\PYG{n}{output\PYGZus{}detail}   \PYG{n}{verbose}
\PYG{n}{do\PYGZus{}properties}   \PYG{n}{T}
\PYG{n}{cube\PYGZus{}format}     \PYG{n}{T}
\PYG{n}{dx\PYGZus{}format}       \PYG{n}{F}
\PYG{n}{grd\PYGZus{}format}      \PYG{n}{F}
\PYG{n}{eld\PYGZus{}calculate}   \PYG{n}{T}
\PYG{n}{eld\PYGZus{}function}    \PYG{n}{ELF}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{lattice\PYGZus{}cart}
\PYG{l+m+mf}{40.000000000000}    \PYG{l+m+mf}{0.000000000000}    \PYG{l+m+mf}{0.000000000000}
 \PYG{l+m+mf}{0.000000000000}   \PYG{l+m+mf}{40.000000000000}    \PYG{l+m+mf}{0.000000000000}
 \PYG{l+m+mf}{0.000000000000}    \PYG{l+m+mf}{0.000000000000}   \PYG{l+m+mf}{40.000000000000}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{lattice\PYGZus{}cart}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{positions\PYGZus{}abs}
\PYG{n}{O} \PYG{l+m+mf}{20.000000000}  \PYG{l+m+mf}{20.000000000}  \PYG{l+m+mf}{20.000000000}
\PYG{n}{H} \PYG{l+m+mf}{18.565580829}  \PYG{l+m+mf}{18.889354011}  \PYG{l+m+mf}{20.000000000}
\PYG{n}{H} \PYG{l+m+mf}{21.434419171}  \PYG{l+m+mf}{18.889354011}  \PYG{l+m+mf}{20.000000000}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{positions\PYGZus{}abs}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species}
\PYG{n}{O} \PYG{n}{O} \PYG{l+m+mi}{8} \PYG{l+m+mi}{4} \PYG{l+m+mf}{8.0}
\PYG{n}{H} \PYG{n}{H} \PYG{l+m+mi}{1} \PYG{l+m+mi}{1} \PYG{l+m+mf}{8.0}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species}

\PYG{o}{\PYGZpc{}}\PYG{n}{block} \PYG{n}{species\PYGZus{}pot}
\PYG{n}{O} \PYG{o}{\PYGZlt{}}\PYG{n}{path} \PYG{n}{to} \PYG{n}{oxygen}\PYG{o}{.}\PYG{n}{recpot}\PYG{o}{\PYGZgt{}}
\PYG{n}{H} \PYG{o}{\PYGZlt{}}\PYG{n}{path} \PYG{n}{to} \PYG{n}{hydrogen}\PYG{o}{.}\PYG{n}{recpot}\PYG{o}{\PYGZgt{}}
\PYG{o}{\PYGZpc{}}\PYG{n}{endblock} \PYG{n}{species\PYGZus{}pot}
\end{sphinxVerbatim}

{[}Becke1990{]} A. D. Becke and K. E. Edgecombe. A simple measure of electron localization in atomic and molecular systems. \sphinxstyleemphasis{J. Chem. Phys.}, 92(9):5397-5403, 1990.

{[}Becke2000{]} A. D. Becke and H. L. Schmider. Chemical content of the kinetic energy density. \sphinxstyleemphasis{Journal of Molecular Structure (Theochem)}, 527:51\textendash{}61, 2000.

{[}Savin1992{]} A. Savin, O. Jepsen, J. Flad, O. K. Andersen, H. Preuss, and H. G. von Schnering. Electron localization in solid-state structures of the elements: the diamond structure. \sphinxstyleemphasis{Angewandte Chemie International Edition in English}, 31(2):187\textendash{}188, 1992.

{[}Schmider2000{]} H. Schmider and A. Becke. Chemical content of the kinetic energy density. \sphinxstyleemphasis{Journal of Molecular Structure (Theochem)}, 527(1):51 \textendash{} 61, 2000.

{[}Womack2016{]} J. C. Womack, N. Mardirossian, M. Head-Gordon, and C.-K. Skylaris. Self-consistent implementation of meta-gga functionals for the ONETEP linear-scaling electronic structure package. \sphinxstyleemphasis{The Journal of Chemical Physics}, 145(20):204114, 2016.


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}



\renewcommand{\indexname}{Index}
\printindex
\end{document}